12/10/2017 02:14:11 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:11 [INFO] configuration: selected_context_id  :   0
12/10/2017 02:14:11 [INFO] configuration: selected_feature_set_id  :   1
12/10/2017 02:14:11 [INFO] configuration: similarity_feature  :   True
12/10/2017 02:14:11 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:11 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:11 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:11 [INFO] configuration: timemark  :   20171210-021411
12/10/2017 02:14:11 [INFO] configuration: context_set  :   next
12/10/2017 02:14:11 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:11 [INFO] configuration: utterance_range  :   ['current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:11 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:11 [INFO] configuration: feature_set  :   1-basic
12/10/2017 02:14:11 [INFO] configuration: feature_set_number  :   ['1', '2', '3']
12/10/2017 02:14:11 [INFO] configuration: experiment_name  :   20171210-021411.context=next.feature=1-basic.similarity=true
12/10/2017 02:14:11 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021411.context=next.feature=1-basic.similarity=true
12/10/2017 02:14:11 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021411.context=next.feature=1-basic.similarity=true/output.log
12/10/2017 02:14:11 [INFO] configuration: valid_type  :   {'C', 'A', 'R', 'F'}
12/10/2017 02:14:11 [INFO] configuration: data_name  :   
12/10/2017 02:14:11 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:11 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:11 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:11 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:11 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:11 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:11 [INFO] configuration: #division  :   5
12/10/2017 02:14:11 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:11 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:11 [INFO] configuration: action_words  :   {'any', 'phone', 'delete', 'snooze', 'item', 'address', 'items', 'delet', 'share', 'reminds', 'cast', 'discard', 'light', 'video', 'south', 'weather', 'reminders', 'temperatur', 'findcar', 'remove', 'stop', 'watch', 'area', 'part', 'findcare', 'north', 'music', 'moderate', 'help', 'volume', 'els', 'centr', 'song', 'post', 'expensive', 'shuffle', 'turn', 'tell', 'moder', 'telephone', 'number', 'price', 'volum', 'list', 'food', 'snooz', 'play', 'expens', 'time', 'skip', 'add', 'timer', 'next', 'temperature', 'shuffl', 'alarm', 'room', 'else', 'clear', 'show', 'member', 'reminder', 'matter', 'remind', 'cheap', 'remov', 'start', 'ani', 'centre', 'telephon'}
12/10/2017 02:14:11 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:11 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:11 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:11 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:11 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:11 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:11 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:11 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:11 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:11 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:11 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:11 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:11 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:11 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:11 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:11 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:11 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:11 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:11 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 3, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:11 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:14 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:14 [INFO] task_runner: context=next, feature=1-basic
12/10/2017 02:14:14 [INFO] task_runner: retained feature numbers=[2.1, 3, 2.2, 1, 2.3.1]
12/10/2017 02:14:14 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:14 [INFO] task_runner: #(feature)=61
12/10/2017 02:14:14 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:14 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:14 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:15 [INFO] exp_shallowmodel: train time: 0.725s
12/10/2017 02:14:15 [INFO] exp_shallowmodel: test time:  0.022s
12/10/2017 02:14:15 [INFO] exp_shallowmodel: accuracy:   0.786
12/10/2017 02:14:15 [INFO] exp_shallowmodel: f1_score:   0.565
12/10/2017 02:14:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.70      0.86      0.77       164
          F       0.86      0.91      0.88       268
          R       0.74      0.50      0.60       125

avg / total       0.77      0.79      0.77       571

12/10/2017 02:14:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:15 [INFO] exp_shallowmodel: 
[[  0   5   9   0]
 [  0 141  11  12]
 [  0  13 245  10]
 [  0  41  21  63]]
12/10/2017 02:14:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:14:15 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:15 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:16 [INFO] exp_shallowmodel: train time: 1.288s
12/10/2017 02:14:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:16 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:14:16 [INFO] exp_shallowmodel: f1_score:   0.544
12/10/2017 02:14:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.67      0.84      0.74       164
          F       0.84      0.90      0.87       268
          R       0.72      0.46      0.56       125

avg / total       0.74      0.76      0.74       571

12/10/2017 02:14:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:16 [INFO] exp_shallowmodel: 
[[  0   3  11   0]
 [  0 137  10  17]
 [  0  22 240   6]
 [  0  42  25  58]]
12/10/2017 02:14:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:14:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:16 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:18 [INFO] exp_shallowmodel: train time: 1.965s
12/10/2017 02:14:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:18 [INFO] exp_shallowmodel: accuracy:   0.774
12/10/2017 02:14:18 [INFO] exp_shallowmodel: f1_score:   0.554
12/10/2017 02:14:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.80      0.72       164
          F       0.88      0.92      0.90       268
          R       0.72      0.51      0.60       125

avg / total       0.76      0.77      0.76       571

12/10/2017 02:14:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:18 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 132  11  21]
 [  0  19 246   3]
 [  0  49  12  64]]
12/10/2017 02:14:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:14:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:18 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:19 [INFO] exp_shallowmodel: train time: 1.175s
12/10/2017 02:14:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:19 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 02:14:19 [INFO] exp_shallowmodel: f1_score:   0.560
12/10/2017 02:14:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.65      0.79      0.72       164
          F       0.82      0.88      0.85       268
          R       0.68      0.46      0.55       125

avg / total       0.75      0.74      0.73       571

12/10/2017 02:14:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:19 [INFO] exp_shallowmodel: 
[[  1   2  10   1]
 [  0 130  20  14]
 [  0  21 235  12]
 [  0  46  22  57]]
12/10/2017 02:14:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:14:19 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:19 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:20 [INFO] exp_shallowmodel: train time: 1.118s
12/10/2017 02:14:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:20 [INFO] exp_shallowmodel: accuracy:   0.744
12/10/2017 02:14:20 [INFO] exp_shallowmodel: f1_score:   0.531
12/10/2017 02:14:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.79      0.71       164
          F       0.84      0.88      0.86       268
          R       0.66      0.47      0.55       125

avg / total       0.72      0.74      0.73       571

12/10/2017 02:14:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:20 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 129  16  19]
 [  0  21 237  10]
 [  0  46  20  59]]
12/10/2017 02:14:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:14:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:20 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:22 [INFO] exp_shallowmodel: train time: 1.274s
12/10/2017 02:14:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:22 [INFO] exp_shallowmodel: accuracy:   0.786
12/10/2017 02:14:22 [INFO] exp_shallowmodel: f1_score:   0.598
12/10/2017 02:14:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.66      0.81      0.73       164
          F       0.87      0.93      0.90       268
          R       0.80      0.52      0.63       125

avg / total       0.80      0.79      0.77       571

12/10/2017 02:14:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:22 [INFO] exp_shallowmodel: 
[[  1   5   7   1]
 [  0 133  17  14]
 [  0  17 250   1]
 [  0  46  14  65]]
12/10/2017 02:14:22 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:14:22 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:22 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:23 [INFO] exp_shallowmodel: train time: 1.204s
12/10/2017 02:14:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:23 [INFO] exp_shallowmodel: accuracy:   0.781
12/10/2017 02:14:23 [INFO] exp_shallowmodel: f1_score:   0.558
12/10/2017 02:14:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.70      0.85      0.77       164
          F       0.86      0.92      0.89       268
          R       0.72      0.49      0.58       125

avg / total       0.76      0.78      0.76       571

12/10/2017 02:14:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:23 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 139  10  15]
 [  0  14 246   8]
 [  0  44  20  61]]
12/10/2017 02:14:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:14:23 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:23 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:24 [INFO] exp_shallowmodel: train time: 1.366s
12/10/2017 02:14:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:24 [INFO] exp_shallowmodel: accuracy:   0.748
12/10/2017 02:14:24 [INFO] exp_shallowmodel: f1_score:   0.531
12/10/2017 02:14:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.79      0.72       164
          F       0.84      0.90      0.87       268
          R       0.65      0.46      0.54       125

avg / total       0.73      0.75      0.73       571

12/10/2017 02:14:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:24 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 129  15  20]
 [  0  18 240  10]
 [  0  47  20  58]]
12/10/2017 02:14:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:14:24 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:24 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:25 [INFO] exp_shallowmodel: train time: 1.067s
12/10/2017 02:14:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:25 [INFO] exp_shallowmodel: accuracy:   0.746
12/10/2017 02:14:25 [INFO] exp_shallowmodel: f1_score:   0.524
12/10/2017 02:14:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.79      0.71       164
          F       0.83      0.91      0.87       268
          R       0.68      0.42      0.51       125

avg / total       0.72      0.75      0.73       571

12/10/2017 02:14:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:25 [INFO] exp_shallowmodel: 
[[  0   1  13   0]
 [  0 129  16  19]
 [  0  17 245   6]
 [  0  52  21  52]]
12/10/2017 02:14:25 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:14:25 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:14:25 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:28 [INFO] exp_shallowmodel: train time: 2.386s
12/10/2017 02:14:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:28 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:14:28 [INFO] exp_shallowmodel: f1_score:   0.493
12/10/2017 02:14:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.59      0.79      0.67       169
          F       0.84      0.89      0.87       271
          R       0.59      0.34      0.43       130

avg / total       0.69      0.71      0.69       586

12/10/2017 02:14:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:28 [INFO] exp_shallowmodel: 
[[  0   4  12   0]
 [  0 133  14  22]
 [  0  22 241   8]
 [  0  67  19  44]]
12/10/2017 02:14:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:14:28 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:28 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:29 [INFO] exp_shallowmodel: train time: 1.049s
12/10/2017 02:14:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:29 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:14:29 [INFO] exp_shallowmodel: f1_score:   0.566
12/10/2017 02:14:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.65      0.79      0.71       164
          F       0.83      0.90      0.87       268
          R       0.70      0.46      0.55       125

avg / total       0.76      0.75      0.74       571

12/10/2017 02:14:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:29 [INFO] exp_shallowmodel: 
[[  1   2  11   0]
 [  0 129  18  17]
 [  0  18 242   8]
 [  0  48  20  57]]
12/10/2017 02:14:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:14:29 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:29 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:30 [INFO] exp_shallowmodel: train time: 1.058s
12/10/2017 02:14:30 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:30 [INFO] exp_shallowmodel: accuracy:   0.760
12/10/2017 02:14:30 [INFO] exp_shallowmodel: f1_score:   0.539
12/10/2017 02:14:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.81      0.72       164
          F       0.84      0.91      0.88       268
          R       0.76      0.45      0.56       125

avg / total       0.75      0.76      0.74       571

12/10/2017 02:14:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:30 [INFO] exp_shallowmodel: 
[[  0   4  10   0]
 [  0 133  17  14]
 [  0  19 245   4]
 [  0  51  18  56]]
12/10/2017 02:14:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:14:30 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:30 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:31 [INFO] exp_shallowmodel: train time: 1.202s
12/10/2017 02:14:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:31 [INFO] exp_shallowmodel: accuracy:   0.746
12/10/2017 02:14:31 [INFO] exp_shallowmodel: f1_score:   0.533
12/10/2017 02:14:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.74      0.70       164
          F       0.84      0.90      0.87       268
          R       0.64      0.50      0.57       125

avg / total       0.72      0.75      0.73       571

12/10/2017 02:14:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:31 [INFO] exp_shallowmodel: 
[[  0   5   8   1]
 [  0 122  16  26]
 [  0  19 241   8]
 [  0  39  23  63]]
12/10/2017 02:14:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:14:31 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:31 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:32 [INFO] exp_shallowmodel: train time: 1.029s
12/10/2017 02:14:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:32 [INFO] exp_shallowmodel: accuracy:   0.760
12/10/2017 02:14:32 [INFO] exp_shallowmodel: f1_score:   0.537
12/10/2017 02:14:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.80      0.72       164
          F       0.87      0.92      0.89       268
          R       0.67      0.45      0.54       125

avg / total       0.74      0.76      0.74       571

12/10/2017 02:14:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:32 [INFO] exp_shallowmodel: 
[[  0   4   9   1]
 [  0 132  12  20]
 [  0  15 246   7]
 [  0  53  16  56]]
12/10/2017 02:14:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:14:32 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:32 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:33 [INFO] exp_shallowmodel: train time: 1.188s
12/10/2017 02:14:33 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:33 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:14:33 [INFO] exp_shallowmodel: f1_score:   0.541
12/10/2017 02:14:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.78      0.70       164
          F       0.85      0.88      0.86       268
          R       0.71      0.52      0.60       125

avg / total       0.74      0.75      0.74       571

12/10/2017 02:14:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:33 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 128  17  19]
 [  0  25 236   7]
 [  0  45  15  65]]
12/10/2017 02:14:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:14:33 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:33 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:34 [INFO] exp_shallowmodel: train time: 1.060s
12/10/2017 02:14:34 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:34 [INFO] exp_shallowmodel: accuracy:   0.767
12/10/2017 02:14:34 [INFO] exp_shallowmodel: f1_score:   0.547
12/10/2017 02:14:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.82      0.73       164
          F       0.86      0.91      0.89       268
          R       0.71      0.48      0.57       125

avg / total       0.75      0.77      0.75       571

12/10/2017 02:14:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:34 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 134  16  14]
 [  0  16 244   8]
 [  0  51  14  60]]
12/10/2017 02:14:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:14:34 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:34 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:35 [INFO] exp_shallowmodel: train time: 1.141s
12/10/2017 02:14:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:35 [INFO] exp_shallowmodel: accuracy:   0.758
12/10/2017 02:14:35 [INFO] exp_shallowmodel: f1_score:   0.565
12/10/2017 02:14:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.64      0.83      0.73       164
          F       0.86      0.91      0.88       268
          R       0.70      0.41      0.52       125

avg / total       0.76      0.76      0.74       571

12/10/2017 02:14:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:35 [INFO] exp_shallowmodel: 
[[  1   4   9   0]
 [  0 136   8  20]
 [  0  21 245   2]
 [  0  50  24  51]]
12/10/2017 02:14:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:14:35 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:35 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:37 [INFO] exp_shallowmodel: train time: 1.444s
12/10/2017 02:14:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:37 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:14:37 [INFO] exp_shallowmodel: f1_score:   0.534
12/10/2017 02:14:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.83      0.74       164
          F       0.84      0.88      0.86       268
          R       0.67      0.45      0.54       125

avg / total       0.73      0.75      0.73       571

12/10/2017 02:14:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:37 [INFO] exp_shallowmodel: 
[[  0   4  10   0]
 [  0 136   9  19]
 [  0  23 237   8]
 [  0  43  26  56]]
12/10/2017 02:14:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 02:14:37 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:37 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:38 [INFO] exp_shallowmodel: train time: 1.009s
12/10/2017 02:14:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:38 [INFO] exp_shallowmodel: accuracy:   0.746
12/10/2017 02:14:38 [INFO] exp_shallowmodel: f1_score:   0.525
12/10/2017 02:14:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.77      0.70       164
          F       0.84      0.91      0.88       268
          R       0.66      0.43      0.52       125

avg / total       0.72      0.75      0.73       571

12/10/2017 02:14:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:38 [INFO] exp_shallowmodel: 
[[  0   1  13   0]
 [  0 127  15  22]
 [  0  17 245   6]
 [  0  54  17  54]]
12/10/2017 02:14:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 02:14:38 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:14:38 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:39 [INFO] exp_shallowmodel: train time: 1.050s
12/10/2017 02:14:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:39 [INFO] exp_shallowmodel: accuracy:   0.768
12/10/2017 02:14:39 [INFO] exp_shallowmodel: f1_score:   0.551
12/10/2017 02:14:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.69      0.89      0.78       169
          F       0.85      0.88      0.87       271
          R       0.71      0.47      0.56       130

avg / total       0.75      0.77      0.75       586

12/10/2017 02:14:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:39 [INFO] exp_shallowmodel: 
[[  0   2  13   1]
 [  0 150   8  11]
 [  1  18 239  13]
 [  0  48  21  61]]
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 02:14:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:39 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:40 [INFO] exp_shallowmodel: train time: 1.071s
12/10/2017 02:14:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:40 [INFO] exp_shallowmodel: accuracy:   0.744
12/10/2017 02:14:40 [INFO] exp_shallowmodel: f1_score:   0.527
12/10/2017 02:14:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.80      0.71       164
          F       0.85      0.89      0.87       268
          R       0.64      0.45      0.53       125

avg / total       0.72      0.74      0.73       571

12/10/2017 02:14:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:40 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 131  14  19]
 [  0  19 238  11]
 [  0  51  18  56]]
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 02:14:40 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:40 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:42 [INFO] exp_shallowmodel: train time: 1.517s
12/10/2017 02:14:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:42 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:14:42 [INFO] exp_shallowmodel: f1_score:   0.533
12/10/2017 02:14:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.81      0.71       164
          F       0.87      0.90      0.88       268
          R       0.68      0.45      0.54       125

avg / total       0.74      0.75      0.74       571

12/10/2017 02:14:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:42 [INFO] exp_shallowmodel: 
[[  0   3  11   0]
 [  0 133  15  16]
 [  0  17 241  10]
 [  0  58  11  56]]
12/10/2017 02:14:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 02:14:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:42 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:43 [INFO] exp_shallowmodel: train time: 1.144s
12/10/2017 02:14:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:43 [INFO] exp_shallowmodel: accuracy:   0.765
12/10/2017 02:14:43 [INFO] exp_shallowmodel: f1_score:   0.541
12/10/2017 02:14:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.67      0.81      0.73       164
          F       0.85      0.93      0.89       268
          R       0.71      0.44      0.54       125

avg / total       0.75      0.77      0.75       571

12/10/2017 02:14:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:43 [INFO] exp_shallowmodel: 
[[  0   1  12   1]
 [  0 133  14  17]
 [  1  14 249   4]
 [  0  52  18  55]]
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 02:14:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:43 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:44 [INFO] exp_shallowmodel: train time: 1.369s
12/10/2017 02:14:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:44 [INFO] exp_shallowmodel: accuracy:   0.746
12/10/2017 02:14:44 [INFO] exp_shallowmodel: f1_score:   0.526
12/10/2017 02:14:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.84      0.73       164
          F       0.86      0.88      0.87       268
          R       0.63      0.42      0.50       125

avg / total       0.73      0.75      0.73       571

12/10/2017 02:14:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:44 [INFO] exp_shallowmodel: 
[[  0   2  12   0]
 [  0 138   6  20]
 [  0  22 236  10]
 [  0  51  22  52]]
12/10/2017 02:14:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 02:14:44 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:44 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:46 [INFO] exp_shallowmodel: train time: 1.347s
12/10/2017 02:14:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:46 [INFO] exp_shallowmodel: accuracy:   0.734
12/10/2017 02:14:46 [INFO] exp_shallowmodel: f1_score:   0.548
12/10/2017 02:14:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.63      0.78      0.70       164
          F       0.84      0.89      0.87       268
          R       0.62      0.42      0.50       125

avg / total       0.74      0.73      0.72       571

12/10/2017 02:14:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:46 [INFO] exp_shallowmodel: 
[[  1   5   5   3]
 [  0 128  13  23]
 [  0  24 238   6]
 [  0  47  26  52]]
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 02:14:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:46 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:47 [INFO] exp_shallowmodel: train time: 1.416s
12/10/2017 02:14:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:47 [INFO] exp_shallowmodel: accuracy:   0.804
12/10/2017 02:14:47 [INFO] exp_shallowmodel: f1_score:   0.620
12/10/2017 02:14:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.71      0.85      0.77       164
          F       0.87      0.91      0.89       268
          R       0.81      0.59      0.69       125

avg / total       0.81      0.80      0.79       571

12/10/2017 02:14:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:47 [INFO] exp_shallowmodel: 
[[  1   5   7   1]
 [  0 139  14  11]
 [  0  18 245   5]
 [  0  34  17  74]]
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 02:14:47 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:47 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:48 [INFO] exp_shallowmodel: train time: 1.278s
12/10/2017 02:14:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:48 [INFO] exp_shallowmodel: accuracy:   0.760
12/10/2017 02:14:48 [INFO] exp_shallowmodel: f1_score:   0.540
12/10/2017 02:14:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.80      0.72       164
          F       0.84      0.91      0.88       268
          R       0.72      0.46      0.56       125

avg / total       0.74      0.76      0.74       571

12/10/2017 02:14:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:48 [INFO] exp_shallowmodel: 
[[  0   3  11   0]
 [  0 131  17  16]
 [  0  16 245   7]
 [  0  48  19  58]]
12/10/2017 02:14:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 02:14:48 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:48 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:49 [INFO] exp_shallowmodel: train time: 0.949s
12/10/2017 02:14:49 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:49 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:14:49 [INFO] exp_shallowmodel: f1_score:   0.536
12/10/2017 02:14:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.79      0.71       164
          F       0.85      0.90      0.87       268
          R       0.66      0.48      0.56       125

avg / total       0.73      0.75      0.74       571

12/10/2017 02:14:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:49 [INFO] exp_shallowmodel: 
[[  0   2  12   0]
 [  0 129  11  24]
 [  0  20 241   7]
 [  0  46  19  60]]
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 02:14:49 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:49 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:50 [INFO] exp_shallowmodel: train time: 0.988s
12/10/2017 02:14:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:50 [INFO] exp_shallowmodel: accuracy:   0.771
12/10/2017 02:14:50 [INFO] exp_shallowmodel: f1_score:   0.550
12/10/2017 02:14:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.68      0.82      0.74       164
          F       0.85      0.92      0.88       268
          R       0.72      0.48      0.58       125

avg / total       0.75      0.77      0.75       571

12/10/2017 02:14:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:50 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 134  17  13]
 [  1  12 246   9]
 [  0  49  16  60]]
12/10/2017 02:14:50 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 02:14:50 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:14:50 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:51 [INFO] exp_shallowmodel: train time: 0.929s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 02:14:51 [INFO] exp_shallowmodel: f1_score:   0.528
12/10/2017 02:14:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.65      0.78      0.71       169
          F       0.82      0.90      0.86       271
          R       0.68      0.46      0.55       130

avg / total       0.72      0.74      0.72       586

12/10/2017 02:14:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:51 [INFO] exp_shallowmodel: 
[[  0   4  12   0]
 [  0 131  17  21]
 [  0  21 243   7]
 [  0  46  24  60]]
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:52 [INFO] exp_shallowmodel: train time: 1.153s
12/10/2017 02:14:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:52 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:14:52 [INFO] exp_shallowmodel: f1_score:   0.566
12/10/2017 02:14:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.64      0.82      0.72       164
          F       0.86      0.88      0.87       268
          R       0.66      0.46      0.54       125

avg / total       0.76      0.75      0.74       571

12/10/2017 02:14:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:52 [INFO] exp_shallowmodel: 
[[  1   1   8   4]
 [  0 134  12  18]
 [  0  23 237   8]
 [  0  51  17  57]]
12/10/2017 02:14:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 02:14:52 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:52 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:54 [INFO] exp_shallowmodel: train time: 1.407s
12/10/2017 02:14:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:54 [INFO] exp_shallowmodel: accuracy:   0.758
12/10/2017 02:14:54 [INFO] exp_shallowmodel: f1_score:   0.542
12/10/2017 02:14:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.80      0.73       164
          F       0.85      0.90      0.87       268
          R       0.70      0.48      0.57       125

avg / total       0.74      0.76      0.74       571

12/10/2017 02:14:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:54 [INFO] exp_shallowmodel: 
[[  0   0  13   1]
 [  0 132  14  18]
 [  0  20 241   7]
 [  1  47  17  60]]
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 02:14:54 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:54 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:55 [INFO] exp_shallowmodel: train time: 1.377s
12/10/2017 02:14:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:55 [INFO] exp_shallowmodel: accuracy:   0.748
12/10/2017 02:14:55 [INFO] exp_shallowmodel: f1_score:   0.532
12/10/2017 02:14:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.68      0.80      0.74       164
          F       0.83      0.88      0.86       268
          R       0.62      0.46      0.53       125

avg / total       0.72      0.75      0.73       571

12/10/2017 02:14:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:55 [INFO] exp_shallowmodel: 
[[  0   4  10   0]
 [  0 132  10  22]
 [  0  18 237  13]
 [  0  40  27  58]]
12/10/2017 02:14:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 02:14:55 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:55 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:56 [INFO] exp_shallowmodel: train time: 1.097s
12/10/2017 02:14:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:56 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:14:56 [INFO] exp_shallowmodel: f1_score:   0.527
12/10/2017 02:14:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.80      0.70       164
          F       0.86      0.93      0.89       268
          R       0.70      0.40      0.51       125

avg / total       0.74      0.75      0.73       571

12/10/2017 02:14:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:56 [INFO] exp_shallowmodel: 
[[  0   7   7   0]
 [  0 132  15  17]
 [  0  15 249   4]
 [  0  57  18  50]]
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 02:14:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:56 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:58 [INFO] exp_shallowmodel: train time: 1.486s
12/10/2017 02:14:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:58 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:14:58 [INFO] exp_shallowmodel: f1_score:   0.530
12/10/2017 02:14:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.67      0.79      0.72       164
          F       0.84      0.91      0.88       268
          R       0.63      0.44      0.52       125

avg / total       0.73      0.75      0.73       571

12/10/2017 02:14:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:58 [INFO] exp_shallowmodel: 
[[  0   1  12   1]
 [  0 129  15  20]
 [  0  12 245  11]
 [  0  51  19  55]]
12/10/2017 02:14:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 02:14:58 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:58 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:59 [INFO] exp_shallowmodel: train time: 1.015s
12/10/2017 02:14:59 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:59 [INFO] exp_shallowmodel: accuracy:   0.778
12/10/2017 02:14:59 [INFO] exp_shallowmodel: f1_score:   0.558
12/10/2017 02:14:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.67      0.83      0.74       164
          F       0.87      0.91      0.89       268
          R       0.73      0.51      0.60       125

avg / total       0.76      0.78      0.76       571

12/10/2017 02:14:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:59 [INFO] exp_shallowmodel: 
[[  0   5   8   1]
 [  0 136  14  14]
 [  0  15 244   9]
 [  0  46  15  64]]
12/10/2017 02:14:59 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 02:14:59 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:59 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:14:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:00 [INFO] exp_shallowmodel: train time: 0.946s
12/10/2017 02:15:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:00 [INFO] exp_shallowmodel: accuracy:   0.774
12/10/2017 02:15:00 [INFO] exp_shallowmodel: f1_score:   0.560
12/10/2017 02:15:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.86      0.75       164
          F       0.85      0.89      0.87       268
          R       0.82      0.50      0.62       125

avg / total       0.77      0.77      0.76       571

12/10/2017 02:15:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:00 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 141  15   8]
 [  0  26 238   4]
 [  0  45  17  63]]
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 02:15:00 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:00 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:01 [INFO] exp_shallowmodel: train time: 1.242s
12/10/2017 02:15:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:01 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:15:01 [INFO] exp_shallowmodel: f1_score:   0.538
12/10/2017 02:15:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.84      0.74       164
          F       0.86      0.91      0.88       268
          R       0.69      0.42      0.52       125

avg / total       0.74      0.76      0.74       571

12/10/2017 02:15:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:01 [INFO] exp_shallowmodel: 
[[  0   0  13   1]
 [  0 138  10  16]
 [  0  16 245   7]
 [  0  54  18  53]]
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 02:15:01 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:01 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:02 [INFO] exp_shallowmodel: train time: 1.318s
12/10/2017 02:15:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:02 [INFO] exp_shallowmodel: accuracy:   0.744
12/10/2017 02:15:02 [INFO] exp_shallowmodel: f1_score:   0.522
12/10/2017 02:15:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.79      0.71       164
          F       0.84      0.91      0.88       268
          R       0.62      0.42      0.50       125

avg / total       0.72      0.74      0.73       571

12/10/2017 02:15:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:02 [INFO] exp_shallowmodel: 
[[  0   3  11   0]
 [  0 129  10  25]
 [  1  16 244   7]
 [  0  49  24  52]]
12/10/2017 02:15:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 02:15:02 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:15:02 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:03 [INFO] exp_shallowmodel: train time: 1.189s
12/10/2017 02:15:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:03 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:15:03 [INFO] exp_shallowmodel: f1_score:   0.541
12/10/2017 02:15:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.65      0.78      0.71       169
          F       0.84      0.89      0.86       271
          R       0.70      0.51      0.59       130

avg / total       0.73      0.75      0.74       586

12/10/2017 02:15:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:03 [INFO] exp_shallowmodel: 
[[  0   4  12   0]
 [  0 132  18  19]
 [  0  20 242   9]
 [  0  47  17  66]]
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 02:15:03 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:03 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:05 [INFO] exp_shallowmodel: train time: 1.403s
12/10/2017 02:15:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:05 [INFO] exp_shallowmodel: accuracy:   0.734
12/10/2017 02:15:05 [INFO] exp_shallowmodel: f1_score:   0.517
12/10/2017 02:15:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.79      0.71       164
          F       0.82      0.89      0.85       268
          R       0.64      0.42      0.50       125

avg / total       0.71      0.73      0.71       571

12/10/2017 02:15:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:05 [INFO] exp_shallowmodel: 
[[  0   5   7   2]
 [  0 129  15  20]
 [  0  23 238   7]
 [  0  44  29  52]]
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 02:15:05 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:05 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:06 [INFO] exp_shallowmodel: train time: 1.165s
12/10/2017 02:15:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:06 [INFO] exp_shallowmodel: accuracy:   0.760
12/10/2017 02:15:06 [INFO] exp_shallowmodel: f1_score:   0.539
12/10/2017 02:15:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.82      0.72       164
          F       0.88      0.90      0.89       268
          R       0.67      0.46      0.54       125

avg / total       0.74      0.76      0.74       571

12/10/2017 02:15:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:06 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  0 135  10  19]
 [  1  19 242   6]
 [  0  52  16  57]]
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 02:15:06 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:06 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:07 [INFO] exp_shallowmodel: train time: 1.250s
12/10/2017 02:15:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:07 [INFO] exp_shallowmodel: accuracy:   0.732
12/10/2017 02:15:07 [INFO] exp_shallowmodel: f1_score:   0.517
12/10/2017 02:15:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.78      0.69       164
          F       0.86      0.88      0.87       268
          R       0.60      0.44      0.51       125

avg / total       0.72      0.73      0.72       571

12/10/2017 02:15:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:07 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 128  11  25]
 [  1  22 235  10]
 [  0  54  16  55]]
12/10/2017 02:15:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 02:15:07 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:07 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:09 [INFO] exp_shallowmodel: train time: 1.315s
12/10/2017 02:15:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:09 [INFO] exp_shallowmodel: accuracy:   0.774
12/10/2017 02:15:09 [INFO] exp_shallowmodel: f1_score:   0.590
12/10/2017 02:15:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.66      0.81      0.73       164
          F       0.86      0.91      0.88       268
          R       0.76      0.52      0.62       125

avg / total       0.78      0.77      0.76       571

12/10/2017 02:15:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:09 [INFO] exp_shallowmodel: 
[[  1   3  10   0]
 [  0 133  14  17]
 [  0  21 243   4]
 [  0  45  15  65]]
12/10/2017 02:15:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 02:15:09 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:09 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:10 [INFO] exp_shallowmodel: train time: 0.895s
12/10/2017 02:15:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:10 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:15:10 [INFO] exp_shallowmodel: f1_score:   0.536
12/10/2017 02:15:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.67      0.78      0.72       164
          F       0.85      0.94      0.89       268
          R       0.65      0.45      0.53       125

avg / total       0.74      0.76      0.74       571

12/10/2017 02:15:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:10 [INFO] exp_shallowmodel: 
[[  0   4   9   1]
 [  0 128  14  22]
 [  0  10 251   7]
 [  0  49  20  56]]
12/10/2017 02:15:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 02:15:10 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:10 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:11 [INFO] exp_shallowmodel: train time: 1.043s
12/10/2017 02:15:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:11 [INFO] exp_shallowmodel: accuracy:   0.760
12/10/2017 02:15:11 [INFO] exp_shallowmodel: f1_score:   0.540
12/10/2017 02:15:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.82      0.73       164
          F       0.84      0.91      0.87       268
          R       0.74      0.45      0.56       125

avg / total       0.74      0.76      0.74       571

12/10/2017 02:15:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:11 [INFO] exp_shallowmodel: 
[[  0   3  11   0]
 [  0 135  16  13]
 [  0  18 243   7]
 [  0  48  21  56]]
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 02:15:11 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:11 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:12 [INFO] exp_shallowmodel: train time: 1.201s
12/10/2017 02:15:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:12 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:15:12 [INFO] exp_shallowmodel: f1_score:   0.537
12/10/2017 02:15:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.79      0.72       164
          F       0.83      0.90      0.86       268
          R       0.72      0.46      0.57       125

avg / total       0.74      0.75      0.74       571

12/10/2017 02:15:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:12 [INFO] exp_shallowmodel: 
[[  0   0  14   0]
 [  0 130  18  16]
 [  0  20 242   6]
 [  0  49  18  58]]
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 02:15:12 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:12 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:13 [INFO] exp_shallowmodel: train time: 1.097s
12/10/2017 02:15:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:13 [INFO] exp_shallowmodel: accuracy:   0.778
12/10/2017 02:15:13 [INFO] exp_shallowmodel: f1_score:   0.551
12/10/2017 02:15:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.84      0.74       164
          F       0.87      0.93      0.90       268
          R       0.76      0.46      0.57       125

avg / total       0.76      0.78      0.76       571

12/10/2017 02:15:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:13 [INFO] exp_shallowmodel: 
[[  0   5   9   0]
 [  0 137  14  13]
 [  0  13 250   5]
 [  0  53  15  57]]
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 02:15:13 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:13 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:14 [INFO] exp_shallowmodel: train time: 1.142s
12/10/2017 02:15:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:14 [INFO] exp_shallowmodel: accuracy:   0.760
12/10/2017 02:15:14 [INFO] exp_shallowmodel: f1_score:   0.547
12/10/2017 02:15:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.67      0.82      0.74       164
          F       0.83      0.88      0.86       268
          R       0.72      0.50      0.59       125

avg / total       0.74      0.76      0.74       571

12/10/2017 02:15:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:14 [INFO] exp_shallowmodel: 
[[  0   1  13   0]
 [  0 135  12  17]
 [  0  24 237   7]
 [  0  41  22  62]]
12/10/2017 02:15:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 02:15:14 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:15:14 [INFO] exp_shallowmodel: #(feature) = 61
12/10/2017 02:15:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:16 [INFO] exp_shallowmodel: train time: 1.418s
12/10/2017 02:15:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:16 [INFO] exp_shallowmodel: accuracy:   0.754
12/10/2017 02:15:16 [INFO] exp_shallowmodel: f1_score:   0.539
12/10/2017 02:15:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.67      0.82      0.74       169
          F       0.84      0.90      0.87       271
          R       0.68      0.46      0.55       130

avg / total       0.73      0.75      0.74       586

12/10/2017 02:15:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:16 [INFO] exp_shallowmodel: 
[[  0   4  12   0]
 [  0 139  12  18]
 [  0  18 243  10]
 [  0  47  23  60]]
12/10/2017 02:15:19 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:15:19 [INFO] task_runner: context=next, feature=1-basic
12/10/2017 02:15:19 [INFO] task_runner: retained feature numbers=[2.1, 3, 2.2, 1, 2.3.1]
12/10/2017 02:15:19 [INFO] task_runner: #(data)=5934
12/10/2017 02:15:19 [INFO] task_runner: #(feature)=57
12/10/2017 02:15:19 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 02:15:19 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:19 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:20 [INFO] exp_shallowmodel: train time: 1.103s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: accuracy:   0.704
12/10/2017 02:15:20 [INFO] exp_shallowmodel: f1_score:   0.507
12/10/2017 02:15:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.63      0.80      0.70       169
          F       0.78      0.86      0.82       281
          R       0.59      0.31      0.41       122

avg / total       0.71      0.70      0.68       592

12/10/2017 02:15:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:20 [INFO] exp_shallowmodel: 
[[  1   1  17   1]
 [  0 136  21  12]
 [  0  26 242  13]
 [  0  54  30  38]]
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:21 [INFO] exp_shallowmodel: train time: 1.035s
12/10/2017 02:15:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:21 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 02:15:21 [INFO] exp_shallowmodel: f1_score:   0.529
12/10/2017 02:15:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.10      0.17        20
          C       0.63      0.79      0.70       169
          F       0.81      0.88      0.84       281
          R       0.55      0.32      0.40       122

avg / total       0.70      0.71      0.69       592

12/10/2017 02:15:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:21 [INFO] exp_shallowmodel: 
[[  2   4  13   1]
 [  0 133  19  17]
 [  1  19 247  14]
 [  0  56  27  39]]
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 02:15:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:21 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:22 [INFO] exp_shallowmodel: train time: 1.052s
12/10/2017 02:15:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:22 [INFO] exp_shallowmodel: accuracy:   0.721
12/10/2017 02:15:22 [INFO] exp_shallowmodel: f1_score:   0.512
12/10/2017 02:15:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.66      0.78      0.72       169
          F       0.77      0.88      0.82       281
          R       0.69      0.41      0.52       122

avg / total       0.70      0.72      0.70       592

12/10/2017 02:15:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:22 [INFO] exp_shallowmodel: 
[[  0   1  17   2]
 [  1 131  28   9]
 [  1  23 246  11]
 [  0  42  30  50]]
12/10/2017 02:15:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 02:15:22 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:22 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:23 [INFO] exp_shallowmodel: train time: 0.854s
12/10/2017 02:15:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:23 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:15:23 [INFO] exp_shallowmodel: f1_score:   0.527
12/10/2017 02:15:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.65      0.82      0.72       169
          F       0.78      0.85      0.81       281
          R       0.67      0.38      0.48       122

avg / total       0.71      0.72      0.69       592

12/10/2017 02:15:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:23 [INFO] exp_shallowmodel: 
[[  1   3  16   0]
 [  0 138  18  13]
 [  1  31 239  10]
 [  0  41  35  46]]
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 02:15:23 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:23 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:24 [INFO] exp_shallowmodel: train time: 1.008s
12/10/2017 02:15:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:24 [INFO] exp_shallowmodel: accuracy:   0.689
12/10/2017 02:15:24 [INFO] exp_shallowmodel: f1_score:   0.468
12/10/2017 02:15:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.58      0.79      0.67       169
          F       0.77      0.86      0.81       281
          R       0.64      0.28      0.39       122

avg / total       0.67      0.69      0.66       592

12/10/2017 02:15:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:24 [INFO] exp_shallowmodel: 
[[  0   1  19   0]
 [  0 133  25  11]
 [  0  32 241   8]
 [  0  62  26  34]]
12/10/2017 02:15:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 02:15:24 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:24 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:25 [INFO] exp_shallowmodel: train time: 0.791s
12/10/2017 02:15:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:25 [INFO] exp_shallowmodel: accuracy:   0.708
12/10/2017 02:15:25 [INFO] exp_shallowmodel: f1_score:   0.509
12/10/2017 02:15:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.64      0.81      0.71       169
          F       0.79      0.86      0.83       281
          R       0.56      0.32      0.41       122

avg / total       0.69      0.71      0.68       592

12/10/2017 02:15:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:25 [INFO] exp_shallowmodel: 
[[  1   3  15   1]
 [  0 137  15  17]
 [  1  25 242  13]
 [  0  50  33  39]]
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 02:15:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:25 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:26 [INFO] exp_shallowmodel: train time: 1.048s
12/10/2017 02:15:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:26 [INFO] exp_shallowmodel: accuracy:   0.694
12/10/2017 02:15:26 [INFO] exp_shallowmodel: f1_score:   0.495
12/10/2017 02:15:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.60      0.77      0.68       169
          F       0.79      0.87      0.83       281
          R       0.55      0.30      0.38       122

avg / total       0.69      0.69      0.67       592

12/10/2017 02:15:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:26 [INFO] exp_shallowmodel: 
[[  1   4  11   4]
 [  0 130  26  13]
 [  0  24 244  13]
 [  0  58  28  36]]
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 02:15:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:26 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:27 [INFO] exp_shallowmodel: train time: 1.104s
12/10/2017 02:15:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:27 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 02:15:27 [INFO] exp_shallowmodel: f1_score:   0.474
12/10/2017 02:15:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.60      0.75      0.66       169
          F       0.79      0.84      0.81       281
          R       0.52      0.35      0.42       122

avg / total       0.65      0.68      0.66       592

12/10/2017 02:15:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:27 [INFO] exp_shallowmodel: 
[[  0   1  15   4]
 [  0 126  22  21]
 [  0  32 235  14]
 [  0  52  27  43]]
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 02:15:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:27 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:28 [INFO] exp_shallowmodel: train time: 1.142s
12/10/2017 02:15:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:28 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 02:15:28 [INFO] exp_shallowmodel: f1_score:   0.515
12/10/2017 02:15:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.15      0.25        20
          C       0.58      0.72      0.64       169
          F       0.77      0.86      0.82       281
          R       0.51      0.27      0.35       122

avg / total       0.66      0.68      0.65       592

12/10/2017 02:15:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:28 [INFO] exp_shallowmodel: 
[[  3   0  14   3]
 [  0 121  32  16]
 [  1  24 243  13]
 [  0  63  26  33]]
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 02:15:28 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:15:28 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:30 [INFO] exp_shallowmodel: train time: 1.135s
12/10/2017 02:15:30 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:30 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 02:15:30 [INFO] exp_shallowmodel: f1_score:   0.508
12/10/2017 02:15:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.07        28
          C       0.61      0.76      0.68       172
          F       0.76      0.85      0.80       283
          R       0.64      0.39      0.48       123

avg / total       0.70      0.69      0.67       606

12/10/2017 02:15:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:30 [INFO] exp_shallowmodel: 
[[  1   4  21   2]
 [  0 131  29  12]
 [  0  30 240  13]
 [  0  50  25  48]]
12/10/2017 02:15:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 02:15:30 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:30 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:31 [INFO] exp_shallowmodel: train time: 1.122s
12/10/2017 02:15:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:31 [INFO] exp_shallowmodel: accuracy:   0.718
12/10/2017 02:15:31 [INFO] exp_shallowmodel: f1_score:   0.499
12/10/2017 02:15:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.62      0.82      0.71       169
          F       0.81      0.87      0.84       281
          R       0.63      0.35      0.45       122

avg / total       0.69      0.72      0.69       592

12/10/2017 02:15:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:31 [INFO] exp_shallowmodel: 
[[  0   2  17   1]
 [  0 138  21  10]
 [  0  23 244  14]
 [  0  59  20  43]]
12/10/2017 02:15:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 02:15:31 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:31 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:32 [INFO] exp_shallowmodel: train time: 1.251s
12/10/2017 02:15:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:32 [INFO] exp_shallowmodel: accuracy:   0.677
12/10/2017 02:15:32 [INFO] exp_shallowmodel: f1_score:   0.459
12/10/2017 02:15:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.59      0.80      0.68       169
          F       0.78      0.83      0.80       281
          R       0.51      0.27      0.35       122

avg / total       0.64      0.68      0.65       592

12/10/2017 02:15:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:32 [INFO] exp_shallowmodel: 
[[  0   2  15   3]
 [  0 135  19  15]
 [  0  34 233  14]
 [  0  57  32  33]]
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 02:15:32 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:32 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:33 [INFO] exp_shallowmodel: train time: 1.143s
12/10/2017 02:15:33 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:33 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 02:15:33 [INFO] exp_shallowmodel: f1_score:   0.512
12/10/2017 02:15:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.60      0.73      0.66       169
          F       0.77      0.86      0.82       281
          R       0.55      0.30      0.39       122

avg / total       0.68      0.69      0.66       592

12/10/2017 02:15:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:33 [INFO] exp_shallowmodel: 
[[  2   1  16   1]
 [  0 124  27  18]
 [  0  27 243  11]
 [  0  56  29  37]]
12/10/2017 02:15:33 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 02:15:33 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:33 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:34 [INFO] exp_shallowmodel: train time: 1.126s
12/10/2017 02:15:34 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:34 [INFO] exp_shallowmodel: accuracy:   0.718
12/10/2017 02:15:34 [INFO] exp_shallowmodel: f1_score:   0.559
12/10/2017 02:15:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.15      0.26        20
          C       0.64      0.82      0.72       169
          F       0.79      0.87      0.83       281
          R       0.62      0.33      0.43       122

avg / total       0.72      0.72      0.69       592

12/10/2017 02:15:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:34 [INFO] exp_shallowmodel: 
[[  3   1  15   1]
 [  0 138  21  10]
 [  0  24 244  13]
 [  0  53  29  40]]
12/10/2017 02:15:34 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 02:15:34 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:34 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:35 [INFO] exp_shallowmodel: train time: 0.935s
12/10/2017 02:15:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:35 [INFO] exp_shallowmodel: accuracy:   0.720
12/10/2017 02:15:35 [INFO] exp_shallowmodel: f1_score:   0.520
12/10/2017 02:15:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.64      0.78      0.71       169
          F       0.80      0.89      0.84       281
          R       0.59      0.34      0.44       122

avg / total       0.72      0.72      0.69       592

12/10/2017 02:15:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:35 [INFO] exp_shallowmodel: 
[[  1   0  16   3]
 [  0 132  24  13]
 [  0  17 251  13]
 [  0  56  24  42]]
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 02:15:35 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:35 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:36 [INFO] exp_shallowmodel: train time: 1.030s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: accuracy:   0.681
12/10/2017 02:15:36 [INFO] exp_shallowmodel: f1_score:   0.483
12/10/2017 02:15:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.61      0.74      0.67       169
          F       0.77      0.86      0.82       281
          R       0.48      0.28      0.35       122

avg / total       0.67      0.68      0.65       592

12/10/2017 02:15:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:36 [INFO] exp_shallowmodel: 
[[  1   2  14   3]
 [  0 125  24  20]
 [  0  24 243  14]
 [  0  55  33  34]]
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:37 [INFO] exp_shallowmodel: train time: 1.196s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:15:37 [INFO] exp_shallowmodel: f1_score:   0.531
12/10/2017 02:15:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.60      0.73      0.66       169
          F       0.77      0.85      0.81       281
          R       0.61      0.38      0.47       122

avg / total       0.70      0.70      0.68       592

12/10/2017 02:15:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:37 [INFO] exp_shallowmodel: 
[[  2   1  17   0]
 [  0 124  28  17]
 [  0  29 240  12]
 [  0  51  25  46]]
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:39 [INFO] exp_shallowmodel: train time: 1.231s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:39 [INFO] exp_shallowmodel: f1_score:   0.499
12/10/2017 02:15:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.63      0.81      0.71       169
          F       0.78      0.86      0.82       281
          R       0.67      0.36      0.47       122

avg / total       0.69      0.71      0.69       592

12/10/2017 02:15:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:39 [INFO] exp_shallowmodel: 
[[  0   1  15   4]
 [  0 137  21  11]
 [  1  32 241   7]
 [  0  47  31  44]]
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:40 [INFO] exp_shallowmodel: train time: 0.944s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:15:40 [INFO] exp_shallowmodel: f1_score:   0.512
12/10/2017 02:15:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.64      0.79      0.71       169
          F       0.75      0.84      0.79       281
          R       0.66      0.34      0.45       122

avg / total       0.71      0.70      0.67       592

12/10/2017 02:15:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:40 [INFO] exp_shallowmodel: 
[[  1   5  12   2]
 [  0 134  26   9]
 [  0  33 237  11]
 [  0  38  42  42]]
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:40 [INFO] exp_shallowmodel: train time: 0.707s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 02:15:40 [INFO] exp_shallowmodel: f1_score:   0.494
12/10/2017 02:15:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.61      0.77      0.68       172
          F       0.78      0.87      0.82       283
          R       0.64      0.37      0.47       123

avg / total       0.67      0.70      0.67       606

12/10/2017 02:15:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:40 [INFO] exp_shallowmodel: 
[[  0   6  21   1]
 [  0 132  26  14]
 [  0  25 247  11]
 [  0  53  24  46]]
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:41 [INFO] exp_shallowmodel: train time: 0.752s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:15:41 [INFO] exp_shallowmodel: f1_score:   0.552
12/10/2017 02:15:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.64      0.82      0.72       169
          F       0.80      0.88      0.84       281
          R       0.66      0.36      0.47       122

avg / total       0.73      0.73      0.71       592

12/10/2017 02:15:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:41 [INFO] exp_shallowmodel: 
[[  2   1  15   2]
 [  0 138  20  11]
 [  0  23 248  10]
 [  0  52  26  44]]
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:42 [INFO] exp_shallowmodel: train time: 0.857s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: accuracy:   0.691
12/10/2017 02:15:42 [INFO] exp_shallowmodel: f1_score:   0.479
12/10/2017 02:15:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.59      0.73      0.65       169
          F       0.79      0.86      0.82       281
          R       0.57      0.35      0.44       122

avg / total       0.66      0.69      0.67       592

12/10/2017 02:15:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:42 [INFO] exp_shallowmodel: 
[[  0   3  16   1]
 [  0 124  27  18]
 [  1  25 242  13]
 [  0  58  21  43]]
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:43 [INFO] exp_shallowmodel: train time: 1.059s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:15:43 [INFO] exp_shallowmodel: f1_score:   0.508
12/10/2017 02:15:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.64      0.78      0.70       169
          F       0.76      0.84      0.80       281
          R       0.57      0.35      0.44       122

avg / total       0.70      0.70      0.67       592

12/10/2017 02:15:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:43 [INFO] exp_shallowmodel: 
[[  1   1  16   2]
 [  0 131  26  12]
 [  0  26 237  18]
 [  0  47  32  43]]
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:44 [INFO] exp_shallowmodel: train time: 1.061s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: accuracy:   0.708
12/10/2017 02:15:44 [INFO] exp_shallowmodel: f1_score:   0.511
12/10/2017 02:15:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.61      0.81      0.70       169
          F       0.80      0.86      0.83       281
          R       0.62      0.33      0.43       122

avg / total       0.70      0.71      0.68       592

12/10/2017 02:15:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:44 [INFO] exp_shallowmodel: 
[[  1   2  15   2]
 [  0 137  21  11]
 [  1  27 241  12]
 [  0  58  24  40]]
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:45 [INFO] exp_shallowmodel: train time: 0.960s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:15:45 [INFO] exp_shallowmodel: f1_score:   0.519
12/10/2017 02:15:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.10      0.17        20
          C       0.61      0.76      0.68       169
          F       0.78      0.86      0.82       281
          R       0.58      0.31      0.41       122

avg / total       0.69      0.70      0.67       592

12/10/2017 02:15:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:45 [INFO] exp_shallowmodel: 
[[  2   4  12   2]
 [  1 129  25  14]
 [  0  27 243  11]
 [  0  52  32  38]]
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:47 [INFO] exp_shallowmodel: train time: 1.629s
12/10/2017 02:15:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:47 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 02:15:47 [INFO] exp_shallowmodel: f1_score:   0.481
12/10/2017 02:15:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.61      0.77      0.68       169
          F       0.79      0.88      0.83       281
          R       0.58      0.32      0.41       122

avg / total       0.67      0.70      0.67       592

12/10/2017 02:15:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:47 [INFO] exp_shallowmodel: 
[[  0   2  16   2]
 [  0 130  24  15]
 [  0  24 246  11]
 [  0  58  25  39]]
12/10/2017 02:15:47 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 02:15:47 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:47 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:48 [INFO] exp_shallowmodel: train time: 1.151s
12/10/2017 02:15:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:48 [INFO] exp_shallowmodel: accuracy:   0.698
12/10/2017 02:15:48 [INFO] exp_shallowmodel: f1_score:   0.500
12/10/2017 02:15:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.65      0.81      0.72       169
          F       0.77      0.85      0.81       281
          R       0.52      0.30      0.38       122

avg / total       0.69      0.70      0.67       592

12/10/2017 02:15:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:48 [INFO] exp_shallowmodel: 
[[  1   2  14   3]
 [  0 137  16  16]
 [  0  28 239  14]
 [  0  43  43  36]]
12/10/2017 02:15:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 02:15:48 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:48 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:49 [INFO] exp_shallowmodel: train time: 1.369s
12/10/2017 02:15:49 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:49 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 02:15:49 [INFO] exp_shallowmodel: f1_score:   0.500
12/10/2017 02:15:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.63      0.80      0.70       169
          F       0.79      0.86      0.83       281
          R       0.64      0.37      0.47       122

avg / total       0.69      0.71      0.69       592

12/10/2017 02:15:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:49 [INFO] exp_shallowmodel: 
[[  0   1  16   3]
 [  0 135  20  14]
 [  0  30 243   8]
 [  0  49  28  45]]
12/10/2017 02:15:49 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 02:15:49 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:49 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:50 [INFO] exp_shallowmodel: train time: 1.163s
12/10/2017 02:15:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:50 [INFO] exp_shallowmodel: accuracy:   0.720
12/10/2017 02:15:50 [INFO] exp_shallowmodel: f1_score:   0.527
12/10/2017 02:15:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.61      0.80      0.69       169
          F       0.83      0.86      0.85       281
          R       0.64      0.39      0.48       122

avg / total       0.71      0.72      0.70       592

12/10/2017 02:15:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:50 [INFO] exp_shallowmodel: 
[[  1   2  15   2]
 [  0 135  19  15]
 [  1  28 243   9]
 [  0  58  17  47]]
12/10/2017 02:15:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 02:15:50 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:15:50 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:52 [INFO] exp_shallowmodel: train time: 1.132s
12/10/2017 02:15:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:52 [INFO] exp_shallowmodel: accuracy:   0.658
12/10/2017 02:15:52 [INFO] exp_shallowmodel: f1_score:   0.474
12/10/2017 02:15:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.07        28
          C       0.60      0.72      0.65       172
          F       0.72      0.83      0.77       283
          R       0.56      0.32      0.40       123

avg / total       0.64      0.66      0.63       606

12/10/2017 02:15:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:52 [INFO] exp_shallowmodel: 
[[  1   5  21   1]
 [  0 124  33  15]
 [  1  32 235  15]
 [  0  47  37  39]]
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 02:15:52 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:52 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:53 [INFO] exp_shallowmodel: train time: 1.218s
12/10/2017 02:15:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:53 [INFO] exp_shallowmodel: accuracy:   0.725
12/10/2017 02:15:53 [INFO] exp_shallowmodel: f1_score:   0.520
12/10/2017 02:15:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.66      0.85      0.74       169
          F       0.80      0.88      0.84       281
          R       0.58      0.31      0.41       122

avg / total       0.72      0.72      0.70       592

12/10/2017 02:15:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:53 [INFO] exp_shallowmodel: 
[[  1   3  15   1]
 [  0 144  18   7]
 [  0  16 246  19]
 [  0  55  29  38]]
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 02:15:53 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:53 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:54 [INFO] exp_shallowmodel: train time: 0.988s
12/10/2017 02:15:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:54 [INFO] exp_shallowmodel: accuracy:   0.703
12/10/2017 02:15:54 [INFO] exp_shallowmodel: f1_score:   0.501
12/10/2017 02:15:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.63      0.82      0.71       169
          F       0.79      0.86      0.82       281
          R       0.53      0.29      0.37       122

avg / total       0.70      0.70      0.67       592

12/10/2017 02:15:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:54 [INFO] exp_shallowmodel: 
[[  1   0  16   3]
 [  0 138  19  12]
 [  0  23 242  16]
 [  0  57  30  35]]
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 02:15:54 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:54 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:55 [INFO] exp_shallowmodel: train time: 0.943s
12/10/2017 02:15:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:55 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 02:15:55 [INFO] exp_shallowmodel: f1_score:   0.496
12/10/2017 02:15:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.62      0.78      0.69       169
          F       0.79      0.88      0.83       281
          R       0.66      0.36      0.47       122

avg / total       0.69      0.71      0.69       592

12/10/2017 02:15:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:55 [INFO] exp_shallowmodel: 
[[  0   2  16   2]
 [  0 131  26  12]
 [  0  26 246   9]
 [  1  53  24  44]]
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 02:15:55 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:55 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:56 [INFO] exp_shallowmodel: train time: 1.302s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 02:15:56 [INFO] exp_shallowmodel: f1_score:   0.519
12/10/2017 02:15:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.63      0.77      0.70       169
          F       0.80      0.87      0.83       281
          R       0.58      0.38      0.46       122

avg / total       0.70      0.71      0.69       592

12/10/2017 02:15:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:56 [INFO] exp_shallowmodel: 
[[  1   1  17   1]
 [  1 130  19  19]
 [  0  24 244  13]
 [  0  50  26  46]]
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:57 [INFO] exp_shallowmodel: train time: 0.910s
12/10/2017 02:15:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:57 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 02:15:57 [INFO] exp_shallowmodel: f1_score:   0.484
12/10/2017 02:15:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.59      0.80      0.68       169
          F       0.78      0.83      0.80       281
          R       0.52      0.27      0.36       122

avg / total       0.68      0.68      0.65       592

12/10/2017 02:15:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:57 [INFO] exp_shallowmodel: 
[[  1   2  13   4]
 [  0 136  23  10]
 [  0  33 232  16]
 [  0  58  31  33]]
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 02:15:57 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:57 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:58 [INFO] exp_shallowmodel: train time: 0.988s
12/10/2017 02:15:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:58 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:15:58 [INFO] exp_shallowmodel: f1_score:   0.506
12/10/2017 02:15:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.61      0.76      0.68       169
          F       0.77      0.87      0.82       281
          R       0.62      0.34      0.44       122

avg / total       0.69      0.70      0.67       592

12/10/2017 02:15:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:58 [INFO] exp_shallowmodel: 
[[  1   3  15   1]
 [  0 128  27  14]
 [  1  26 244  10]
 [  0  52  29  41]]
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 02:15:58 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:58 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:59 [INFO] exp_shallowmodel: train time: 1.038s
12/10/2017 02:15:59 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:59 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 02:15:59 [INFO] exp_shallowmodel: f1_score:   0.470
12/10/2017 02:15:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.59      0.75      0.66       169
          F       0.79      0.88      0.83       281
          R       0.55      0.30      0.39       122

avg / total       0.66      0.69      0.66       592

12/10/2017 02:15:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:59 [INFO] exp_shallowmodel: 
[[  0   4  13   3]
 [  0 127  25  17]
 [  1  24 247   9]
 [  0  59  27  36]]
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 02:15:59 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:59 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:00 [INFO] exp_shallowmodel: train time: 0.822s
12/10/2017 02:16:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:00 [INFO] exp_shallowmodel: accuracy:   0.681
12/10/2017 02:16:00 [INFO] exp_shallowmodel: f1_score:   0.520
12/10/2017 02:16:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.59      0.75      0.66       169
          F       0.77      0.82      0.79       281
          R       0.58      0.36      0.44       122

avg / total       0.69      0.68      0.66       592

12/10/2017 02:16:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:00 [INFO] exp_shallowmodel: 
[[  2   2  14   2]
 [  0 126  26  17]
 [  0  37 231  13]
 [  0  48  30  44]]
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 02:16:00 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:00 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:01 [INFO] exp_shallowmodel: train time: 0.884s
12/10/2017 02:16:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:01 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 02:16:01 [INFO] exp_shallowmodel: f1_score:   0.531
12/10/2017 02:16:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.63      0.75      0.68       169
          F       0.77      0.86      0.82       281
          R       0.59      0.35      0.44       122

avg / total       0.70      0.70      0.68       592

12/10/2017 02:16:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:01 [INFO] exp_shallowmodel: 
[[  2   2  15   1]
 [  0 127  23  19]
 [  0  28 243  10]
 [  0  46  33  43]]
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 02:16:01 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:16:01 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:02 [INFO] exp_shallowmodel: train time: 1.012s
12/10/2017 02:16:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:02 [INFO] exp_shallowmodel: accuracy:   0.695
12/10/2017 02:16:02 [INFO] exp_shallowmodel: f1_score:   0.488
12/10/2017 02:16:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.61      0.77      0.68       172
          F       0.77      0.86      0.81       283
          R       0.62      0.37      0.46       123

avg / total       0.66      0.69      0.67       606

12/10/2017 02:16:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:02 [INFO] exp_shallowmodel: 
[[  0   6  21   1]
 [  0 132  28  12]
 [  0  24 244  15]
 [  0  54  24  45]]
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 02:16:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:02 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:03 [INFO] exp_shallowmodel: train time: 1.038s
12/10/2017 02:16:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:03 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 02:16:03 [INFO] exp_shallowmodel: f1_score:   0.486
12/10/2017 02:16:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.62      0.83      0.71       169
          F       0.81      0.88      0.84       281
          R       0.57      0.30      0.39       122

avg / total       0.68      0.71      0.68       592

12/10/2017 02:16:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:03 [INFO] exp_shallowmodel: 
[[  0   5  13   2]
 [  0 141  20   8]
 [  0  18 246  17]
 [  0  62  24  36]]
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 02:16:03 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:03 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:04 [INFO] exp_shallowmodel: train time: 1.260s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:16:04 [INFO] exp_shallowmodel: f1_score:   0.531
12/10/2017 02:16:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.60      0.79      0.69       169
          F       0.78      0.83      0.80       281
          R       0.62      0.36      0.46       122

avg / total       0.70      0.70      0.68       592

12/10/2017 02:16:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:04 [INFO] exp_shallowmodel: 
[[  2   1  16   1]
 [  0 134  23  12]
 [  0  35 232  14]
 [  0  52  26  44]]
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:05 [INFO] exp_shallowmodel: train time: 1.127s
12/10/2017 02:16:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:05 [INFO] exp_shallowmodel: accuracy:   0.723
12/10/2017 02:16:05 [INFO] exp_shallowmodel: f1_score:   0.500
12/10/2017 02:16:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.64      0.82      0.72       169
          F       0.81      0.88      0.84       281
          R       0.60      0.34      0.44       122

avg / total       0.69      0.72      0.70       592

12/10/2017 02:16:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:05 [INFO] exp_shallowmodel: 
[[  0   1  17   2]
 [  0 138  17  14]
 [  0  21 248  12]
 [  0  55  25  42]]
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 02:16:05 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:05 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:06 [INFO] exp_shallowmodel: train time: 0.828s
12/10/2017 02:16:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:06 [INFO] exp_shallowmodel: accuracy:   0.725
12/10/2017 02:16:06 [INFO] exp_shallowmodel: f1_score:   0.526
12/10/2017 02:16:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.68      0.82      0.74       169
          F       0.79      0.88      0.83       281
          R       0.59      0.35      0.44       122

avg / total       0.71      0.72      0.70       592

12/10/2017 02:16:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:06 [INFO] exp_shallowmodel: 
[[  1   0  18   1]
 [  1 139  16  13]
 [  0  19 246  16]
 [  0  47  32  43]]
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 02:16:06 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:06 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:07 [INFO] exp_shallowmodel: train time: 0.943s
12/10/2017 02:16:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:07 [INFO] exp_shallowmodel: accuracy:   0.684
12/10/2017 02:16:07 [INFO] exp_shallowmodel: f1_score:   0.493
12/10/2017 02:16:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.60      0.73      0.66       169
          F       0.76      0.86      0.81       281
          R       0.57      0.32      0.41       122

avg / total       0.68      0.68      0.66       592

12/10/2017 02:16:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:07 [INFO] exp_shallowmodel: 
[[  1   2  15   2]
 [  0 124  28  17]
 [  0  30 241  10]
 [  0  51  32  39]]
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 02:16:07 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:07 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:08 [INFO] exp_shallowmodel: train time: 1.104s
12/10/2017 02:16:08 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:08 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:08 [INFO] exp_shallowmodel: f1_score:   0.496
12/10/2017 02:16:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.62      0.76      0.69       169
          F       0.79      0.90      0.84       281
          R       0.66      0.35      0.46       122

avg / total       0.69      0.72      0.69       592

12/10/2017 02:16:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:08 [INFO] exp_shallowmodel: 
[[  0   2  17   1]
 [  0 129  23  17]
 [  0  25 252   4]
 [  0  51  28  43]]
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 02:16:08 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:08 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:09 [INFO] exp_shallowmodel: train time: 1.107s
12/10/2017 02:16:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:09 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 02:16:09 [INFO] exp_shallowmodel: f1_score:   0.513
12/10/2017 02:16:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.61      0.78      0.68       169
          F       0.78      0.88      0.83       281
          R       0.68      0.34      0.45       122

avg / total       0.70      0.71      0.68       592

12/10/2017 02:16:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:09 [INFO] exp_shallowmodel: 
[[  1   1  16   2]
 [  0 131  26  12]
 [  1  28 247   5]
 [  0  54  27  41]]
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 02:16:09 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:09 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:10 [INFO] exp_shallowmodel: train time: 0.889s
12/10/2017 02:16:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:10 [INFO] exp_shallowmodel: accuracy:   0.698
12/10/2017 02:16:10 [INFO] exp_shallowmodel: f1_score:   0.559
12/10/2017 02:16:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.20      0.33        20
          C       0.63      0.82      0.71       169
          F       0.77      0.84      0.80       281
          R       0.58      0.30      0.39       122

avg / total       0.70      0.70      0.67       592

12/10/2017 02:16:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:10 [INFO] exp_shallowmodel: 
[[  4   2  13   1]
 [  0 138  20  11]
 [  0  32 235  14]
 [  0  47  39  36]]
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 02:16:10 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:10 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:11 [INFO] exp_shallowmodel: train time: 0.911s
12/10/2017 02:16:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:11 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 02:16:11 [INFO] exp_shallowmodel: f1_score:   0.480
12/10/2017 02:16:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.57      0.74      0.64       169
          F       0.76      0.81      0.78       281
          R       0.66      0.39      0.49       122

avg / total       0.66      0.68      0.66       592

12/10/2017 02:16:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:11 [INFO] exp_shallowmodel: 
[[  0   3  16   1]
 [  0 125  35   9]
 [  0  39 227  15]
 [  0  52  22  48]]
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 02:16:11 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:16:11 [INFO] exp_shallowmodel: #(feature) = 57
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:12 [INFO] exp_shallowmodel: train time: 0.953s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: accuracy:   0.695
12/10/2017 02:16:12 [INFO] exp_shallowmodel: f1_score:   0.494
12/10/2017 02:16:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.07        28
          C       0.63      0.77      0.69       172
          F       0.77      0.88      0.83       283
          R       0.53      0.31      0.39       123

avg / total       0.69      0.69      0.66       606

12/10/2017 02:16:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:12 [INFO] exp_shallowmodel: 
[[  1   5  17   5]
 [  0 132  22  18]
 [  0  22 250  11]
 [  0  51  34  38]]
12/10/2017 02:16:17 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:16:17 [INFO] task_runner: context=next, feature=1-basic
12/10/2017 02:16:17 [INFO] task_runner: retained feature numbers=[2.1, 3, 2.2, 1, 2.3.1]
12/10/2017 02:16:17 [INFO] task_runner: #(data)=3530
12/10/2017 02:16:17 [INFO] task_runner: #(feature)=63
12/10/2017 02:16:17 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:16:17 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 02:16:17 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:17 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:18 [INFO] exp_shallowmodel: train time: 0.835s
12/10/2017 02:16:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:18 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:16:18 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 02:16:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.62      0.19      0.29        27
          F       0.73      0.98      0.84       250
          R       0.57      0.08      0.14        52

avg / total       0.65      0.72      0.64       352

12/10/2017 02:16:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:18 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   5  21   1]
 [  2   0 246   2]
 [  0   3  45   4]]
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 02:16:18 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:18 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:19 [INFO] exp_shallowmodel: train time: 0.561s
12/10/2017 02:16:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:19 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:16:19 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 02:16:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.57      0.15      0.24        27
          F       0.73      0.98      0.84       250
          R       0.50      0.10      0.16        52

avg / total       0.70      0.72      0.64       352

12/10/2017 02:16:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:19 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   4  23   0]
 [  0   3 245   2]
 [  0   0  47   5]]
12/10/2017 02:16:19 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 02:16:19 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:19 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:19 [INFO] exp_shallowmodel: train time: 0.534s
12/10/2017 02:16:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:19 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:16:19 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 02:16:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.30      0.11      0.16        27
          F       0.74      0.97      0.84       250
          R       0.45      0.10      0.16        52

avg / total       0.61      0.71      0.63       352

12/10/2017 02:16:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:19 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   3  22   2]
 [  1   3 243   3]
 [  0   4  43   5]]
12/10/2017 02:16:19 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 02:16:19 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:19 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:20 [INFO] exp_shallowmodel: train time: 0.684s
12/10/2017 02:16:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:20 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 02:16:20 [INFO] exp_shallowmodel: f1_score:   0.284
12/10/2017 02:16:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.60      0.11      0.19        27
          F       0.72      0.96      0.83       250
          R       0.29      0.08      0.12        52

avg / total       0.60      0.70      0.62       352

12/10/2017 02:16:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:20 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   3  23   1]
 [  0   2 241   7]
 [  0   0  48   4]]
12/10/2017 02:16:20 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 02:16:20 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:20 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:20 [INFO] exp_shallowmodel: train time: 0.571s
12/10/2017 02:16:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:20 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:20 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 02:16:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.09      0.15        23
          C       0.60      0.11      0.19        27
          F       0.72      0.98      0.83       250
          R       0.43      0.06      0.10        52

avg / total       0.67      0.72      0.63       352

12/10/2017 02:16:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:20 [INFO] exp_shallowmodel: 
[[  2   1  20   0]
 [  0   3  24   0]
 [  1   1 244   4]
 [  0   0  49   3]]
12/10/2017 02:16:20 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 02:16:20 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:20 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:21 [INFO] exp_shallowmodel: train time: 0.745s
12/10/2017 02:16:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:21 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:21 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 02:16:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.43      0.11      0.18        27
          F       0.74      0.97      0.84       250
          R       0.40      0.12      0.18        52

avg / total       0.61      0.72      0.64       352

12/10/2017 02:16:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:21 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  0   3  23   1]
 [  0   2 243   5]
 [  0   1  45   6]]
12/10/2017 02:16:21 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 02:16:21 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:21 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:22 [INFO] exp_shallowmodel: train time: 0.576s
12/10/2017 02:16:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:22 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:16:22 [INFO] exp_shallowmodel: f1_score:   0.321
12/10/2017 02:16:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.67      0.22      0.33        27
          F       0.75      0.99      0.85       250
          R       0.38      0.06      0.10        52

avg / total       0.64      0.73      0.65       352

12/10/2017 02:16:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:22 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   6  18   3]
 [  0   1 248   1]
 [  3   2  44   3]]
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 02:16:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:22 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:22 [INFO] exp_shallowmodel: train time: 0.533s
12/10/2017 02:16:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:22 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:16:22 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 02:16:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.43      0.11      0.18        27
          F       0.74      0.98      0.84       250
          R       0.50      0.10      0.16        52

avg / total       0.65      0.72      0.64       352

12/10/2017 02:16:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:22 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  0   3  23   1]
 [  0   2 245   3]
 [  3   1  43   5]]
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 02:16:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:22 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:23 [INFO] exp_shallowmodel: train time: 0.490s
12/10/2017 02:16:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:23 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:23 [INFO] exp_shallowmodel: f1_score:   0.303
12/10/2017 02:16:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.80      0.15      0.25        27
          F       0.73      0.98      0.84       250
          R       0.31      0.08      0.12        52

avg / total       0.63      0.72      0.63       352

12/10/2017 02:16:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:23 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  1   4  20   2]
 [  0   0 244   6]
 [  0   1  47   4]]
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 02:16:23 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:16:23 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:23 [INFO] exp_shallowmodel: train time: 0.625s
12/10/2017 02:16:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:23 [INFO] exp_shallowmodel: accuracy:   0.704
12/10/2017 02:16:23 [INFO] exp_shallowmodel: f1_score:   0.285
12/10/2017 02:16:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        25
          C       0.14      0.04      0.06        27
          F       0.72      0.98      0.83       251
          R       0.55      0.10      0.17        59

avg / total       0.67      0.70      0.61       362

12/10/2017 02:16:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:23 [INFO] exp_shallowmodel: 
[[  1   1  20   3]
 [  0   1  26   0]
 [  0   2 247   2]
 [  0   3  50   6]]
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 02:16:23 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:23 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:24 [INFO] exp_shallowmodel: train time: 0.541s
12/10/2017 02:16:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:24 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:24 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 02:16:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.40      0.15      0.22        27
          F       0.73      0.98      0.84       250
          R       0.38      0.06      0.10        52

avg / total       0.61      0.72      0.63       352

12/10/2017 02:16:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:24 [INFO] exp_shallowmodel: 
[[  0   1  22   0]
 [  0   4  22   1]
 [  0   1 245   4]
 [  0   4  45   3]]
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 02:16:24 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:24 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:24 [INFO] exp_shallowmodel: train time: 0.481s
12/10/2017 02:16:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:24 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:16:24 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 02:16:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.75      0.22      0.34        27
          F       0.73      0.98      0.84       250
          R       0.22      0.04      0.07        52

avg / total       0.61      0.72      0.63       352

12/10/2017 02:16:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:24 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  1   6  18   2]
 [  0   1 245   4]
 [  0   0  50   2]]
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 02:16:24 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:24 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:25 [INFO] exp_shallowmodel: train time: 0.510s
12/10/2017 02:16:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:25 [INFO] exp_shallowmodel: accuracy:   0.733
12/10/2017 02:16:25 [INFO] exp_shallowmodel: f1_score:   0.355
12/10/2017 02:16:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.13      0.23        23
          C       0.50      0.11      0.18        27
          F       0.75      0.99      0.85       250
          R       0.42      0.10      0.16        52

avg / total       0.70      0.73      0.66       352

12/10/2017 02:16:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:25 [INFO] exp_shallowmodel: 
[[  3   0  18   2]
 [  0   3  21   3]
 [  0   1 247   2]
 [  0   2  45   5]]
12/10/2017 02:16:25 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 02:16:25 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:25 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:25 [INFO] exp_shallowmodel: train time: 0.506s
12/10/2017 02:16:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:25 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:16:25 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 02:16:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.38      0.11      0.17        27
          F       0.73      0.97      0.83       250
          R       0.55      0.12      0.19        52

avg / total       0.63      0.71      0.63       352

12/10/2017 02:16:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:25 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  0   3  24   0]
 [  1   3 242   4]
 [  1   1  44   6]]
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 02:16:26 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:26 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:26 [INFO] exp_shallowmodel: train time: 0.538s
12/10/2017 02:16:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:26 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:16:26 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 02:16:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.62      0.19      0.29        27
          F       0.74      0.98      0.85       250
          R       0.50      0.13      0.21        52

avg / total       0.65      0.73      0.65       352

12/10/2017 02:16:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:26 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   5  19   3]
 [  1   2 245   2]
 [  0   1  44   7]]
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 02:16:26 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:26 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:27 [INFO] exp_shallowmodel: train time: 0.498s
12/10/2017 02:16:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:27 [INFO] exp_shallowmodel: accuracy:   0.739
12/10/2017 02:16:27 [INFO] exp_shallowmodel: f1_score:   0.356
12/10/2017 02:16:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.80      0.15      0.25        27
          F       0.75      0.99      0.85       250
          R       0.57      0.15      0.24        52

avg / total       0.71      0.74      0.66       352

12/10/2017 02:16:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:27 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   4  23   0]
 [  0   0 247   3]
 [  1   0  43   8]]
12/10/2017 02:16:27 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 02:16:27 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:27 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:27 [INFO] exp_shallowmodel: train time: 0.725s
12/10/2017 02:16:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:27 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:16:27 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 02:16:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.29      0.07      0.12        27
          F       0.73      0.97      0.83       250
          R       0.36      0.08      0.13        52

avg / total       0.63      0.71      0.62       352

12/10/2017 02:16:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:27 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   2  24   1]
 [  0   3 242   5]
 [  1   2  45   4]]
12/10/2017 02:16:27 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 02:16:27 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:27 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:28 [INFO] exp_shallowmodel: train time: 0.755s
12/10/2017 02:16:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:28 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:28 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 02:16:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.75      0.11      0.19        27
          F       0.73      0.98      0.84       250
          R       0.30      0.06      0.10        52

avg / total       0.65      0.72      0.63       352

12/10/2017 02:16:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:28 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   3  22   2]
 [  1   0 245   4]
 [  0   1  48   3]]
12/10/2017 02:16:28 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 02:16:28 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:28 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:29 [INFO] exp_shallowmodel: train time: 0.512s
12/10/2017 02:16:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:29 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:16:29 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 02:16:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.50      0.15      0.23        27
          F       0.74      0.98      0.85       250
          R       0.50      0.08      0.13        52

avg / total       0.65      0.72      0.64       352

12/10/2017 02:16:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:29 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   4  23   0]
 [  0   3 246   1]
 [  3   0  45   4]]
12/10/2017 02:16:29 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 02:16:29 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:16:29 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:29 [INFO] exp_shallowmodel: train time: 0.538s
12/10/2017 02:16:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:29 [INFO] exp_shallowmodel: accuracy:   0.704
12/10/2017 02:16:29 [INFO] exp_shallowmodel: f1_score:   0.323
12/10/2017 02:16:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.07        25
          C       0.44      0.15      0.22        27
          F       0.72      0.97      0.83       251
          R       0.50      0.10      0.17        59

avg / total       0.64      0.70      0.62       362

12/10/2017 02:16:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:29 [INFO] exp_shallowmodel: 
[[  1   0  23   1]
 [  0   4  21   2]
 [  1   3 244   3]
 [  1   2  50   6]]
12/10/2017 02:16:29 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 02:16:29 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:29 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:30 [INFO] exp_shallowmodel: train time: 0.502s
12/10/2017 02:16:30 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:30 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:16:30 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 02:16:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.60      0.22      0.32        27
          F       0.75      0.98      0.85       250
          R       0.43      0.12      0.18        52

avg / total       0.64      0.73      0.65       352

12/10/2017 02:16:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:30 [INFO] exp_shallowmodel: 
[[  0   1  18   4]
 [  0   6  21   0]
 [  0   2 244   4]
 [  1   1  44   6]]
12/10/2017 02:16:30 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 02:16:30 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:30 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:31 [INFO] exp_shallowmodel: train time: 0.955s
12/10/2017 02:16:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:31 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:16:31 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 02:16:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.50      0.22      0.31        27
          F       0.75      0.97      0.84       250
          R       0.45      0.10      0.16        52

avg / total       0.66      0.72      0.65       352

12/10/2017 02:16:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:31 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   6  19   2]
 [  1   3 243   3]
 [  1   3  43   5]]
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 02:16:31 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:31 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:31 [INFO] exp_shallowmodel: train time: 0.843s
12/10/2017 02:16:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:31 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:16:31 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 02:16:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.09      0.15        23
          C       0.33      0.11      0.17        27
          F       0.74      0.98      0.84       250
          R       0.56      0.10      0.16        52

avg / total       0.67      0.72      0.64       352

12/10/2017 02:16:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:31 [INFO] exp_shallowmodel: 
[[  2   1  19   1]
 [  0   3  22   2]
 [  0   5 244   1]
 [  1   0  46   5]]
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 02:16:31 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:31 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:32 [INFO] exp_shallowmodel: train time: 0.448s
12/10/2017 02:16:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:32 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:16:32 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 02:16:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.75      0.22      0.34        27
          F       0.74      0.99      0.85       250
          R       0.40      0.08      0.13        52

avg / total       0.64      0.73      0.65       352

12/10/2017 02:16:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:32 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   6  19   2]
 [  0   0 247   3]
 [  0   2  46   4]]
12/10/2017 02:16:32 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 02:16:32 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:32 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:32 [INFO] exp_shallowmodel: train time: 0.516s
12/10/2017 02:16:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:32 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:16:32 [INFO] exp_shallowmodel: f1_score:   0.256
12/10/2017 02:16:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.04      0.07        27
          F       0.73      0.98      0.84       250
          R       0.25      0.08      0.12        52

avg / total       0.59      0.71      0.62       352

12/10/2017 02:16:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:32 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   1  23   3]
 [  0   0 244   6]
 [  0   1  47   4]]
12/10/2017 02:16:32 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 02:16:32 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:32 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:33 [INFO] exp_shallowmodel: train time: 0.794s
12/10/2017 02:16:33 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:33 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:16:33 [INFO] exp_shallowmodel: f1_score:   0.296
12/10/2017 02:16:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.43      0.11      0.18        27
          F       0.74      0.99      0.84       250
          R       0.50      0.10      0.16        52

avg / total       0.63      0.72      0.64       352

12/10/2017 02:16:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:33 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   3  23   1]
 [  0   1 247   2]
 [  0   3  44   5]]
12/10/2017 02:16:33 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 02:16:33 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:33 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:34 [INFO] exp_shallowmodel: train time: 0.548s
12/10/2017 02:16:34 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:34 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:16:34 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 02:16:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.07      0.12        27
          F       0.74      0.97      0.84       250
          R       0.41      0.13      0.20        52

avg / total       0.61      0.71      0.63       352

12/10/2017 02:16:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:34 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   2  22   3]
 [  0   2 242   6]
 [  0   2  43   7]]
12/10/2017 02:16:34 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 02:16:34 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:34 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:34 [INFO] exp_shallowmodel: train time: 0.512s
12/10/2017 02:16:34 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:34 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:16:34 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 02:16:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.09      0.16        23
          C       1.00      0.11      0.20        27
          F       0.73      0.98      0.84       250
          R       0.31      0.08      0.12        52

avg / total       0.71      0.72      0.64       352

12/10/2017 02:16:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:34 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   3  21   3]
 [  0   0 245   5]
 [  0   0  48   4]]
12/10/2017 02:16:34 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 02:16:34 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:34 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:35 [INFO] exp_shallowmodel: train time: 0.522s
12/10/2017 02:16:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:35 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:16:35 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 02:16:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.43      0.11      0.18        27
          F       0.73      0.99      0.84       250
          R       0.80      0.08      0.14        52

avg / total       0.67      0.72      0.63       352

12/10/2017 02:16:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:35 [INFO] exp_shallowmodel: 
[[  0   2  21   0]
 [  0   3  24   0]
 [  1   1 247   1]
 [  1   1  46   4]]
12/10/2017 02:16:35 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 02:16:35 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:16:35 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:35 [INFO] exp_shallowmodel: train time: 0.499s
12/10/2017 02:16:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:35 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:16:35 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:16:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.08      0.14        25
          C       0.33      0.07      0.12        27
          F       0.71      0.98      0.82       251
          R       0.43      0.05      0.09        59

avg / total       0.62      0.70      0.60       362

12/10/2017 02:16:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:35 [INFO] exp_shallowmodel: 
[[  2   1  21   1]
 [  0   2  25   0]
 [  2   1 245   3]
 [  0   2  54   3]]
12/10/2017 02:16:35 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 02:16:35 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:35 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:36 [INFO] exp_shallowmodel: train time: 0.551s
12/10/2017 02:16:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:36 [INFO] exp_shallowmodel: accuracy:   0.750
12/10/2017 02:16:36 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 02:16:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.50      0.22      0.31        27
          F       0.76      0.99      0.86       250
          R       0.82      0.17      0.29        52

avg / total       0.76      0.75      0.68       352

12/10/2017 02:16:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:36 [INFO] exp_shallowmodel: 
[[  1   2  19   1]
 [  0   6  21   0]
 [  0   1 248   1]
 [  0   3  40   9]]
12/10/2017 02:16:36 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 02:16:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:36 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:36 [INFO] exp_shallowmodel: train time: 0.533s
12/10/2017 02:16:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:36 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:36 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 02:16:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.50      0.11      0.18        27
          F       0.73      0.96      0.83       250
          R       0.58      0.13      0.22        52

avg / total       0.67      0.72      0.64       352

12/10/2017 02:16:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:36 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   3  24   0]
 [  1   3 241   5]
 [  0   0  45   7]]
12/10/2017 02:16:36 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 02:16:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:36 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:37 [INFO] exp_shallowmodel: train time: 0.508s
12/10/2017 02:16:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:37 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:16:37 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 02:16:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.09      0.16        23
          C       0.43      0.11      0.18        27
          F       0.74      0.99      0.84       250
          R       0.25      0.04      0.07        52

avg / total       0.66      0.72      0.63       352

12/10/2017 02:16:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:37 [INFO] exp_shallowmodel: 
[[  2   1  19   1]
 [  0   3  21   3]
 [  0   1 247   2]
 [  0   2  48   2]]
12/10/2017 02:16:37 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 02:16:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:37 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:38 [INFO] exp_shallowmodel: train time: 0.718s
12/10/2017 02:16:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:38 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:16:38 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 02:16:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.50      0.11      0.18        27
          F       0.73      0.98      0.84       250
          R       0.54      0.13      0.22        52

avg / total       0.71      0.72      0.65       352

12/10/2017 02:16:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:38 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   3  24   0]
 [  0   2 244   4]
 [  0   0  45   7]]
12/10/2017 02:16:38 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 02:16:38 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:38 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:38 [INFO] exp_shallowmodel: train time: 0.611s
12/10/2017 02:16:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:38 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:16:38 [INFO] exp_shallowmodel: f1_score:   0.303
12/10/2017 02:16:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.19      0.27        27
          F       0.74      0.98      0.84       250
          R       0.33      0.06      0.10        52

avg / total       0.61      0.72      0.63       352

12/10/2017 02:16:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:38 [INFO] exp_shallowmodel: 
[[  0   1  20   2]
 [  0   5  20   2]
 [  1   2 245   2]
 [  1   2  46   3]]
12/10/2017 02:16:38 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 02:16:38 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:38 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:39 [INFO] exp_shallowmodel: train time: 0.584s
12/10/2017 02:16:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:39 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:16:39 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 02:16:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.09      0.15        23
          C       0.44      0.15      0.22        27
          F       0.73      0.96      0.83       250
          R       0.33      0.08      0.12        52

avg / total       0.64      0.71      0.63       352

12/10/2017 02:16:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:39 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   4  23   0]
 [  1   3 239   7]
 [  0   2  46   4]]
12/10/2017 02:16:39 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 02:16:39 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:39 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:40 [INFO] exp_shallowmodel: train time: 0.798s
12/10/2017 02:16:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:40 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 02:16:40 [INFO] exp_shallowmodel: f1_score:   0.224
12/10/2017 02:16:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.04      0.07        27
          F       0.73      0.97      0.83       250
          R       0.00      0.00      0.00        52

avg / total       0.54      0.69      0.60       352

12/10/2017 02:16:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:40 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   1  23   3]
 [  2   1 243   4]
 [  2   1  49   0]]
12/10/2017 02:16:40 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 02:16:40 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:40 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:40 [INFO] exp_shallowmodel: train time: 0.568s
12/10/2017 02:16:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:40 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:16:40 [INFO] exp_shallowmodel: f1_score:   0.301
12/10/2017 02:16:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.57      0.15      0.24        27
          F       0.72      0.98      0.83       250
          R       0.57      0.08      0.14        52

avg / total       0.64      0.72      0.63       352

12/10/2017 02:16:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:40 [INFO] exp_shallowmodel: 
[[  0   1  22   0]
 [  0   4  23   0]
 [  0   2 245   3]
 [  0   0  48   4]]
12/10/2017 02:16:40 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 02:16:40 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:40 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:41 [INFO] exp_shallowmodel: train time: 0.533s
12/10/2017 02:16:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:41 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:16:41 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 02:16:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.20      0.04      0.06        27
          F       0.73      0.97      0.83       250
          R       0.40      0.08      0.13        52

avg / total       0.61      0.71      0.62       352

12/10/2017 02:16:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:41 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  1   1  23   2]
 [  1   3 243   3]
 [  0   1  47   4]]
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 02:16:41 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:16:41 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:41 [INFO] exp_shallowmodel: train time: 0.465s
12/10/2017 02:16:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:41 [INFO] exp_shallowmodel: accuracy:   0.721
12/10/2017 02:16:41 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 02:16:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        25
          C       0.70      0.26      0.38        27
          F       0.73      0.99      0.84       251
          R       0.50      0.08      0.14        59

avg / total       0.71      0.72      0.64       362

12/10/2017 02:16:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:41 [INFO] exp_shallowmodel: 
[[  1   0  24   0]
 [  0   7  17   3]
 [  0   1 248   2]
 [  0   2  52   5]]
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 02:16:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:41 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:42 [INFO] exp_shallowmodel: train time: 0.518s
12/10/2017 02:16:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:42 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:16:42 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 02:16:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.42      0.19      0.26        27
          F       0.74      0.98      0.84       250
          R       0.50      0.06      0.10        52

avg / total       0.66      0.72      0.64       352

12/10/2017 02:16:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:42 [INFO] exp_shallowmodel: 
[[  1   1  21   0]
 [  0   5  22   0]
 [  0   2 245   3]
 [  1   4  44   3]]
12/10/2017 02:16:42 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 02:16:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:42 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:42 [INFO] exp_shallowmodel: train time: 0.625s
12/10/2017 02:16:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:42 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:16:42 [INFO] exp_shallowmodel: f1_score:   0.295
12/10/2017 02:16:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.40      0.15      0.22        27
          F       0.74      0.97      0.84       250
          R       0.36      0.08      0.13        52

avg / total       0.61      0.71      0.63       352

12/10/2017 02:16:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:42 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  0   4  22   1]
 [  1   2 242   5]
 [  1   3  44   4]]
12/10/2017 02:16:42 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 02:16:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:42 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:43 [INFO] exp_shallowmodel: train time: 0.884s
12/10/2017 02:16:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:43 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:16:43 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:16:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.80      0.15      0.25        27
          F       0.73      0.97      0.83       250
          R       0.23      0.06      0.09        52

avg / total       0.61      0.71      0.62       352

12/10/2017 02:16:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:43 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  1   4  21   1]
 [  0   1 242   7]
 [  0   0  49   3]]
12/10/2017 02:16:43 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 02:16:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:43 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:44 [INFO] exp_shallowmodel: train time: 0.453s
12/10/2017 02:16:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:44 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:16:44 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 02:16:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.33      0.04      0.07        27
          F       0.73      0.99      0.84       250
          R       0.50      0.10      0.16        52

avg / total       0.69      0.72      0.63       352

12/10/2017 02:16:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:44 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   1  23   3]
 [  0   1 248   1]
 [  0   1  46   5]]
12/10/2017 02:16:44 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 02:16:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:44 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:44 [INFO] exp_shallowmodel: train time: 0.535s
12/10/2017 02:16:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:44 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:16:44 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 02:16:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.44      0.15      0.22        27
          F       0.74      0.97      0.84       250
          R       0.54      0.13      0.22        52

avg / total       0.66      0.72      0.65       352

12/10/2017 02:16:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:44 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   4  23   0]
 [  1   3 242   4]
 [  1   2  42   7]]
12/10/2017 02:16:44 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 02:16:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:44 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:45 [INFO] exp_shallowmodel: train time: 0.720s
12/10/2017 02:16:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:45 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:16:45 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 02:16:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.67      0.15      0.24        27
          F       0.74      0.99      0.85       250
          R       0.56      0.10      0.16        52

avg / total       0.68      0.73      0.65       352

12/10/2017 02:16:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:45 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  1   4  20   2]
 [  1   1 247   1]
 [  1   0  46   5]]
12/10/2017 02:16:45 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 02:16:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:45 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:46 [INFO] exp_shallowmodel: train time: 0.795s
12/10/2017 02:16:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:46 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:16:46 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 02:16:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.60      0.22      0.32        27
          F       0.75      0.98      0.85       250
          R       0.38      0.10      0.15        52

avg / total       0.64      0.73      0.65       352

12/10/2017 02:16:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:46 [INFO] exp_shallowmodel: 
[[  0   2  17   4]
 [  0   6  20   1]
 [  1   0 246   3]
 [  0   2  45   5]]
12/10/2017 02:16:46 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 02:16:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:46 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:47 [INFO] exp_shallowmodel: train time: 0.696s
12/10/2017 02:16:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:47 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:16:47 [INFO] exp_shallowmodel: f1_score:   0.308
12/10/2017 02:16:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.44      0.15      0.22        27
          F       0.73      0.97      0.83       250
          R       0.38      0.06      0.10        52

avg / total       0.63      0.71      0.63       352

12/10/2017 02:16:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:47 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   4  23   0]
 [  1   2 242   5]
 [  1   3  45   3]]
12/10/2017 02:16:47 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 02:16:47 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:47 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:47 [INFO] exp_shallowmodel: train time: 0.503s
12/10/2017 02:16:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:47 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:47 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 02:16:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.60      0.11      0.19        27
          F       0.74      0.98      0.84       250
          R       0.33      0.08      0.12        52

avg / total       0.64      0.72      0.63       352

12/10/2017 02:16:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:47 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   3  22   2]
 [  0   2 244   4]
 [  3   0  45   4]]
12/10/2017 02:16:47 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 02:16:47 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:16:47 [INFO] exp_shallowmodel: #(feature) = 63
12/10/2017 02:16:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:48 [INFO] exp_shallowmodel: train time: 0.516s
12/10/2017 02:16:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:48 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:16:48 [INFO] exp_shallowmodel: f1_score:   0.272
12/10/2017 02:16:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.07        25
          C       0.50      0.07      0.13        27
          F       0.71      0.98      0.82       251
          R       0.25      0.03      0.06        59

avg / total       0.60      0.70      0.60       362

12/10/2017 02:16:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:48 [INFO] exp_shallowmodel: 
[[  1   0  23   1]
 [  0   2  22   3]
 [  0   2 247   2]
 [  1   0  56   2]]
12/10/2017 02:16:53 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:16:53 [INFO] task_runner: context=next, feature=1-basic
12/10/2017 02:16:53 [INFO] task_runner: retained feature numbers=[2.1, 3, 2.2, 1, 2.3.1]
12/10/2017 02:16:53 [INFO] task_runner: #(data)=5241
12/10/2017 02:16:53 [INFO] task_runner: #(feature)=93
12/10/2017 02:16:53 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:16:53 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 02:16:53 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:53 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:16:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:55 [INFO] exp_shallowmodel: train time: 1.313s
12/10/2017 02:16:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:55 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:16:55 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 02:16:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.46      0.11      0.18        55

avg / total       0.68      0.76      0.69       522

12/10/2017 02:16:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:55 [INFO] exp_shallowmodel: 
[[  4   0  54   1]
 [  1   0  10   1]
 [  3   0 388   5]
 [  2   1  46   6]]
12/10/2017 02:16:55 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 02:16:55 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:55 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:16:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:56 [INFO] exp_shallowmodel: train time: 1.795s
12/10/2017 02:16:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:56 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:16:56 [INFO] exp_shallowmodel: f1_score:   0.261
12/10/2017 02:16:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.25      0.05      0.09        55

avg / total       0.66      0.75      0.67       522

12/10/2017 02:16:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:56 [INFO] exp_shallowmodel: 
[[  3   0  54   2]
 [  1   0   9   2]
 [  3   1 387   5]
 [  0   1  51   3]]
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 02:16:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:56 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:58 [INFO] exp_shallowmodel: train time: 1.397s
12/10/2017 02:16:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:58 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:16:58 [INFO] exp_shallowmodel: f1_score:   0.278
12/10/2017 02:16:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.86       396
          R       0.44      0.15      0.22        55

avg / total       0.65      0.76      0.68       522

12/10/2017 02:16:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:58 [INFO] exp_shallowmodel: 
[[  1   0  54   4]
 [  1   0  11   0]
 [  4   0 386   6]
 [  0   0  47   8]]
12/10/2017 02:16:58 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 02:16:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:58 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:16:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:59 [INFO] exp_shallowmodel: train time: 1.172s
12/10/2017 02:16:59 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:59 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:16:59 [INFO] exp_shallowmodel: f1_score:   0.265
12/10/2017 02:16:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.07      0.11        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.30      0.05      0.09        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:16:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:59 [INFO] exp_shallowmodel: 
[[  4   0  55   0]
 [  0   0  10   2]
 [  7   0 384   5]
 [  5   0  47   3]]
12/10/2017 02:16:59 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 02:16:59 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:59 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:16:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:00 [INFO] exp_shallowmodel: train time: 1.307s
12/10/2017 02:17:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:00 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:17:00 [INFO] exp_shallowmodel: f1_score:   0.282
12/10/2017 02:17:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.36      0.09      0.14        55

avg / total       0.68      0.76      0.69       522

12/10/2017 02:17:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:00 [INFO] exp_shallowmodel: 
[[  4   1  52   2]
 [  0   0  10   2]
 [  3   0 388   5]
 [  3   0  47   5]]
12/10/2017 02:17:00 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 02:17:00 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:00 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:02 [INFO] exp_shallowmodel: train time: 1.122s
12/10/2017 02:17:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:02 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:17:02 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 02:17:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.05      0.09        59
          C       0.50      0.08      0.14        12
          F       0.78      0.98      0.87       396
          R       0.32      0.11      0.16        55

avg / total       0.71      0.76      0.69       522

12/10/2017 02:17:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:02 [INFO] exp_shallowmodel: 
[[  3   0  51   5]
 [  0   1   9   2]
 [  1   1 388   6]
 [  1   0  48   6]]
12/10/2017 02:17:02 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 02:17:02 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:02 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:03 [INFO] exp_shallowmodel: train time: 1.242s
12/10/2017 02:17:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:03 [INFO] exp_shallowmodel: accuracy:   0.778
12/10/2017 02:17:03 [INFO] exp_shallowmodel: f1_score:   0.352
12/10/2017 02:17:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.08      0.14        59
          C       0.50      0.08      0.14        12
          F       0.79      0.99      0.88       396
          R       0.80      0.15      0.25        55

avg / total       0.74      0.78      0.71       522

12/10/2017 02:17:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:03 [INFO] exp_shallowmodel: 
[[  5   1  52   1]
 [  1   1  10   0]
 [  3   0 392   1]
 [  2   0  45   8]]
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 02:17:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:03 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:04 [INFO] exp_shallowmodel: train time: 1.345s
12/10/2017 02:17:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:04 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:17:04 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 02:17:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.55      0.11      0.18        55

avg / total       0.70      0.76      0.69       522

12/10/2017 02:17:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:04 [INFO] exp_shallowmodel: 
[[  5   0  53   1]
 [  0   0  12   0]
 [  3   1 388   4]
 [  2   1  46   6]]
12/10/2017 02:17:04 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 02:17:04 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:04 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:05 [INFO] exp_shallowmodel: train time: 1.247s
12/10/2017 02:17:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:05 [INFO] exp_shallowmodel: accuracy:   0.774
12/10/2017 02:17:05 [INFO] exp_shallowmodel: f1_score:   0.333
12/10/2017 02:17:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.05      0.09        59
          C       1.00      0.08      0.15        12
          F       0.78      0.99      0.87       396
          R       0.70      0.13      0.22        55

avg / total       0.73      0.77      0.70       522

12/10/2017 02:17:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:05 [INFO] exp_shallowmodel: 
[[  3   0  54   2]
 [  0   1  10   1]
 [  3   0 393   0]
 [  2   0  46   7]]
12/10/2017 02:17:05 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 02:17:05 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:17:05 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:07 [INFO] exp_shallowmodel: train time: 1.285s
12/10/2017 02:17:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:07 [INFO] exp_shallowmodel: accuracy:   0.744
12/10/2017 02:17:07 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 02:17:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.08      0.14        64
          C       0.00      0.00      0.00        14
          F       0.76      0.98      0.85       402
          R       0.40      0.06      0.11        63

avg / total       0.67      0.74      0.66       543

12/10/2017 02:17:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:07 [INFO] exp_shallowmodel: 
[[  5   0  58   1]
 [  1   0  13   0]
 [  1   1 395   5]
 [  3   0  56   4]]
12/10/2017 02:17:07 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 02:17:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:07 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:08 [INFO] exp_shallowmodel: train time: 1.409s
12/10/2017 02:17:08 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:08 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:17:08 [INFO] exp_shallowmodel: f1_score:   0.287
12/10/2017 02:17:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.86       396
          R       0.38      0.09      0.15        55

avg / total       0.67      0.76      0.69       522

12/10/2017 02:17:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:08 [INFO] exp_shallowmodel: 
[[  5   0  53   1]
 [  0   0  11   1]
 [  5   0 385   6]
 [  4   0  46   5]]
12/10/2017 02:17:08 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 02:17:08 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:08 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:10 [INFO] exp_shallowmodel: train time: 1.624s
12/10/2017 02:17:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:10 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:17:10 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 02:17:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.38      0.09      0.15        55

avg / total       0.67      0.76      0.69       522

12/10/2017 02:17:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:10 [INFO] exp_shallowmodel: 
[[  3   0  53   3]
 [  0   0   9   3]
 [  4   0 390   2]
 [  3   0  47   5]]
12/10/2017 02:17:10 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 02:17:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:10 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:11 [INFO] exp_shallowmodel: train time: 1.394s
12/10/2017 02:17:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:11 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:17:11 [INFO] exp_shallowmodel: f1_score:   0.274
12/10/2017 02:17:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.86       396
          R       0.33      0.09      0.14        55

avg / total       0.66      0.75      0.68       522

12/10/2017 02:17:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:11 [INFO] exp_shallowmodel: 
[[  3   0  53   3]
 [  2   0  10   0]
 [  3   0 386   7]
 [  1   0  49   5]]
12/10/2017 02:17:11 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 02:17:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:11 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:13 [INFO] exp_shallowmodel: train time: 1.722s
12/10/2017 02:17:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:13 [INFO] exp_shallowmodel: accuracy:   0.768
12/10/2017 02:17:13 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 02:17:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.08      0.15        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.57      0.15      0.23        55

avg / total       0.72      0.77      0.70       522

12/10/2017 02:17:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:13 [INFO] exp_shallowmodel: 
[[  5   0  54   0]
 [  0   0  11   1]
 [  3   0 388   5]
 [  0   0  47   8]]
12/10/2017 02:17:13 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 02:17:13 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:13 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:15 [INFO] exp_shallowmodel: train time: 2.368s
12/10/2017 02:17:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:15 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 02:17:15 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 02:17:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.71      0.09      0.16        55

avg / total       0.72      0.77      0.69       522

12/10/2017 02:17:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:15 [INFO] exp_shallowmodel: 
[[  4   0  54   1]
 [  1   0  11   0]
 [  1   1 393   1]
 [  3   0  47   5]]
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 02:17:15 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:15 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:17 [INFO] exp_shallowmodel: train time: 1.844s
12/10/2017 02:17:17 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:17 [INFO] exp_shallowmodel: accuracy:   0.772
12/10/2017 02:17:17 [INFO] exp_shallowmodel: f1_score:   0.294
12/10/2017 02:17:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.80      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.50      0.11      0.18        55

avg / total       0.73      0.77      0.70       522

12/10/2017 02:17:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:17 [INFO] exp_shallowmodel: 
[[  4   0  53   2]
 [  0   0  11   1]
 [  0   0 393   3]
 [  1   1  47   6]]
12/10/2017 02:17:17 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 02:17:17 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:17 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:19 [INFO] exp_shallowmodel: train time: 1.745s
12/10/2017 02:17:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:19 [INFO] exp_shallowmodel: accuracy:   0.772
12/10/2017 02:17:19 [INFO] exp_shallowmodel: f1_score:   0.300
12/10/2017 02:17:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.79      0.99      0.88       396
          R       0.47      0.13      0.20        55

avg / total       0.72      0.77      0.70       522

12/10/2017 02:17:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:19 [INFO] exp_shallowmodel: 
[[  4   1  51   3]
 [  0   0  10   2]
 [  0   1 392   3]
 [  2   0  46   7]]
12/10/2017 02:17:19 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 02:17:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:19 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:20 [INFO] exp_shallowmodel: train time: 1.493s
12/10/2017 02:17:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:20 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:17:20 [INFO] exp_shallowmodel: f1_score:   0.270
12/10/2017 02:17:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.87       396
          R       0.38      0.05      0.10        55

avg / total       0.68      0.76      0.68       522

12/10/2017 02:17:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:20 [INFO] exp_shallowmodel: 
[[  4   0  53   2]
 [  1   0  10   1]
 [  3   1 390   2]
 [  1   0  51   3]]
12/10/2017 02:17:20 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 02:17:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:20 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:22 [INFO] exp_shallowmodel: train time: 1.501s
12/10/2017 02:17:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:22 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:17:22 [INFO] exp_shallowmodel: f1_score:   0.267
12/10/2017 02:17:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.86       396
          R       0.42      0.09      0.15        55

avg / total       0.65      0.75      0.68       522

12/10/2017 02:17:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:22 [INFO] exp_shallowmodel: 
[[  2   1  53   3]
 [  1   0  11   0]
 [  6   0 386   4]
 [  2   0  48   5]]
12/10/2017 02:17:22 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 02:17:22 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:17:22 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:23 [INFO] exp_shallowmodel: train time: 1.339s
12/10/2017 02:17:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:23 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:17:23 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 02:17:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.03      0.06        64
          C       1.00      0.07      0.13        14
          F       0.76      0.99      0.86       402
          R       0.54      0.11      0.18        63

avg / total       0.69      0.75      0.67       543

12/10/2017 02:17:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:23 [INFO] exp_shallowmodel: 
[[  2   0  57   5]
 [  0   1  13   0]
 [  3   0 398   1]
 [  2   0  54   7]]
12/10/2017 02:17:23 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 02:17:23 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:23 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:25 [INFO] exp_shallowmodel: train time: 1.365s
12/10/2017 02:17:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:25 [INFO] exp_shallowmodel: accuracy:   0.768
12/10/2017 02:17:25 [INFO] exp_shallowmodel: f1_score:   0.305
12/10/2017 02:17:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.64      0.12      0.20        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.42      0.09      0.15        55

avg / total       0.71      0.77      0.70       522

12/10/2017 02:17:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:25 [INFO] exp_shallowmodel: 
[[  7   0  51   1]
 [  0   0  11   1]
 [  2   0 389   5]
 [  2   1  47   5]]
12/10/2017 02:17:25 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 02:17:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:25 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:26 [INFO] exp_shallowmodel: train time: 1.426s
12/10/2017 02:17:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:26 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:17:26 [INFO] exp_shallowmodel: f1_score:   0.269
12/10/2017 02:17:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.23      0.05      0.09        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:17:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:26 [INFO] exp_shallowmodel: 
[[  4   1  54   0]
 [  0   0   7   5]
 [  2   1 388   5]
 [  2   0  50   3]]
12/10/2017 02:17:26 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 02:17:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:26 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:28 [INFO] exp_shallowmodel: train time: 1.446s
12/10/2017 02:17:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:28 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 02:17:28 [INFO] exp_shallowmodel: f1_score:   0.282
12/10/2017 02:17:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.86      0.11      0.19        55

avg / total       0.73      0.77      0.69       522

12/10/2017 02:17:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:28 [INFO] exp_shallowmodel: 
[[  2   1  56   0]
 [  1   0  11   0]
 [  1   0 394   1]
 [  0   1  48   6]]
12/10/2017 02:17:28 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 02:17:28 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:28 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:29 [INFO] exp_shallowmodel: train time: 1.256s
12/10/2017 02:17:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:29 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:17:29 [INFO] exp_shallowmodel: f1_score:   0.286
12/10/2017 02:17:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.86       396
          R       0.36      0.09      0.14        55

avg / total       0.67      0.75      0.69       522

12/10/2017 02:17:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:29 [INFO] exp_shallowmodel: 
[[  5   0  52   2]
 [  0   0  11   1]
 [  5   2 383   6]
 [  5   0  45   5]]
12/10/2017 02:17:29 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 02:17:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:29 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:30 [INFO] exp_shallowmodel: train time: 1.223s
12/10/2017 02:17:30 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:30 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:17:30 [INFO] exp_shallowmodel: f1_score:   0.230
12/10/2017 02:17:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.00      0.00      0.00        55

avg / total       0.61      0.75      0.66       522

12/10/2017 02:17:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:30 [INFO] exp_shallowmodel: 
[[  2   0  54   3]
 [  1   0  10   1]
 [  5   0 388   3]
 [  1   0  54   0]]
12/10/2017 02:17:30 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 02:17:30 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:30 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:32 [INFO] exp_shallowmodel: train time: 1.672s
12/10/2017 02:17:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:32 [INFO] exp_shallowmodel: accuracy:   0.772
12/10/2017 02:17:32 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 02:17:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.60      0.16      0.26        55

avg / total       0.73      0.77      0.70       522

12/10/2017 02:17:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:32 [INFO] exp_shallowmodel: 
[[  2   1  54   2]
 [  0   0  11   1]
 [  0   1 392   3]
 [  1   0  45   9]]
12/10/2017 02:17:32 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 02:17:32 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:32 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:33 [INFO] exp_shallowmodel: train time: 1.488s
12/10/2017 02:17:33 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:33 [INFO] exp_shallowmodel: accuracy:   0.772
12/10/2017 02:17:33 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 02:17:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.10      0.17        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.55      0.11      0.18        55

avg / total       0.72      0.77      0.70       522

12/10/2017 02:17:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:33 [INFO] exp_shallowmodel: 
[[  6   0  50   3]
 [  0   0  12   0]
 [  3   0 391   2]
 [  1   0  48   6]]
12/10/2017 02:17:33 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 02:17:33 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:33 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:35 [INFO] exp_shallowmodel: train time: 1.416s
12/10/2017 02:17:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:35 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:17:35 [INFO] exp_shallowmodel: f1_score:   0.279
12/10/2017 02:17:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.56      0.09      0.16        55

avg / total       0.71      0.77      0.68       522

12/10/2017 02:17:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:35 [INFO] exp_shallowmodel: 
[[  3   0  56   0]
 [  0   0  10   2]
 [  2   0 392   2]
 [  0   0  50   5]]
12/10/2017 02:17:35 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 02:17:35 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:35 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:36 [INFO] exp_shallowmodel: train time: 1.135s
12/10/2017 02:17:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:36 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:17:36 [INFO] exp_shallowmodel: f1_score:   0.304
12/10/2017 02:17:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.10      0.17        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.50      0.11      0.18        55

avg / total       0.70      0.77      0.70       522

12/10/2017 02:17:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:36 [INFO] exp_shallowmodel: 
[[  6   0  52   1]
 [  1   0  10   1]
 [  4   0 388   4]
 [  1   0  48   6]]
12/10/2017 02:17:36 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 02:17:36 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:17:36 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:38 [INFO] exp_shallowmodel: train time: 1.689s
12/10/2017 02:17:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:38 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:17:38 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 02:17:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.08      0.13        64
          C       0.00      0.00      0.00        14
          F       0.77      0.98      0.86       402
          R       0.60      0.19      0.29        63

avg / total       0.68      0.75      0.69       543

12/10/2017 02:17:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:38 [INFO] exp_shallowmodel: 
[[  5   0  55   4]
 [  2   0  12   0]
 [  6   0 392   4]
 [  0   0  51  12]]
12/10/2017 02:17:38 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 02:17:38 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:38 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:39 [INFO] exp_shallowmodel: train time: 1.313s
12/10/2017 02:17:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:39 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:17:39 [INFO] exp_shallowmodel: f1_score:   0.292
12/10/2017 02:17:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.56      0.09      0.16        55

avg / total       0.70      0.77      0.69       522

12/10/2017 02:17:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:39 [INFO] exp_shallowmodel: 
[[  5   1  52   1]
 [  2   0  10   0]
 [  3   0 390   3]
 [  1   1  48   5]]
12/10/2017 02:17:39 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 02:17:39 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:39 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:41 [INFO] exp_shallowmodel: train time: 1.693s
12/10/2017 02:17:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:41 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:17:41 [INFO] exp_shallowmodel: f1_score:   0.263
12/10/2017 02:17:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.71      0.09      0.16        55

avg / total       0.67      0.76      0.67       522

12/10/2017 02:17:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:41 [INFO] exp_shallowmodel: 
[[  1   0  56   2]
 [  0   0  12   0]
 [  7   0 389   0]
 [  1   0  49   5]]
12/10/2017 02:17:41 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 02:17:41 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:41 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:42 [INFO] exp_shallowmodel: train time: 1.280s
12/10/2017 02:17:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:42 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:17:42 [INFO] exp_shallowmodel: f1_score:   0.296
12/10/2017 02:17:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.46      0.11      0.18        55

avg / total       0.69      0.76      0.69       522

12/10/2017 02:17:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:42 [INFO] exp_shallowmodel: 
[[  5   0  53   1]
 [  1   0  10   1]
 [  4   0 387   5]
 [  1   0  48   6]]
12/10/2017 02:17:42 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 02:17:42 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:42 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:43 [INFO] exp_shallowmodel: train time: 1.509s
12/10/2017 02:17:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:43 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:17:43 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 02:17:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.10      0.17        59
          C       0.00      0.00      0.00        12
          F       0.79      0.99      0.87       396
          R       0.17      0.04      0.06        55

avg / total       0.67      0.76      0.69       522

12/10/2017 02:17:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:43 [INFO] exp_shallowmodel: 
[[  6   0  48   5]
 [  0   0  10   2]
 [  1   1 391   3]
 [  4   0  49   2]]
12/10/2017 02:17:43 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 02:17:43 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:43 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:45 [INFO] exp_shallowmodel: train time: 1.277s
12/10/2017 02:17:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:45 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:17:45 [INFO] exp_shallowmodel: f1_score:   0.266
12/10/2017 02:17:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.46      0.11      0.18        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:17:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:45 [INFO] exp_shallowmodel: 
[[  1   0  57   1]
 [  0   0  11   1]
 [  6   1 384   5]
 [  1   0  48   6]]
12/10/2017 02:17:45 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 02:17:45 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:45 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:46 [INFO] exp_shallowmodel: train time: 1.226s
12/10/2017 02:17:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:46 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:17:46 [INFO] exp_shallowmodel: f1_score:   0.264
12/10/2017 02:17:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.50      0.09      0.15        55

avg / total       0.66      0.76      0.68       522

12/10/2017 02:17:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:46 [INFO] exp_shallowmodel: 
[[  1   0  56   2]
 [  2   0   9   1]
 [  1   1 392   2]
 [  3   0  47   5]]
12/10/2017 02:17:46 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 02:17:46 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:46 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:48 [INFO] exp_shallowmodel: train time: 2.042s
12/10/2017 02:17:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:48 [INFO] exp_shallowmodel: accuracy:   0.789
12/10/2017 02:17:48 [INFO] exp_shallowmodel: f1_score:   0.362
12/10/2017 02:17:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.15      0.25        59
          C       0.00      0.00      0.00        12
          F       0.80      0.99      0.88       396
          R       0.69      0.20      0.31        55

avg / total       0.76      0.79      0.73       522

12/10/2017 02:17:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:48 [INFO] exp_shallowmodel: 
[[  9   0  48   2]
 [  0   0  11   1]
 [  2   0 392   2]
 [  1   2  41  11]]
12/10/2017 02:17:48 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 02:17:48 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:48 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:50 [INFO] exp_shallowmodel: train time: 2.177s
12/10/2017 02:17:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:50 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:17:50 [INFO] exp_shallowmodel: f1_score:   0.271
12/10/2017 02:17:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.56      0.09      0.16        55

avg / total       0.68      0.76      0.68       522

12/10/2017 02:17:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:50 [INFO] exp_shallowmodel: 
[[  2   1  56   0]
 [  0   0  11   1]
 [  3   0 390   3]
 [  1   0  49   5]]
12/10/2017 02:17:50 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 02:17:50 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:50 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:51 [INFO] exp_shallowmodel: train time: 1.184s
12/10/2017 02:17:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:51 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 02:17:51 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 02:17:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.50      0.13      0.20        55

avg / total       0.70      0.77      0.70       522

12/10/2017 02:17:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:51 [INFO] exp_shallowmodel: 
[[  4   0  53   2]
 [  1   0  10   1]
 [  1   0 391   4]
 [  2   0  46   7]]
12/10/2017 02:17:51 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 02:17:51 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:17:51 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:53 [INFO] exp_shallowmodel: train time: 1.352s
12/10/2017 02:17:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:53 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 02:17:53 [INFO] exp_shallowmodel: f1_score:   0.297
12/10/2017 02:17:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.03      0.06        64
          C       1.00      0.07      0.13        14
          F       0.76      0.98      0.85       402
          R       0.27      0.10      0.14        63

avg / total       0.67      0.74      0.66       543

12/10/2017 02:17:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:53 [INFO] exp_shallowmodel: 
[[  2   0  55   7]
 [  0   1  12   1]
 [  2   0 392   8]
 [  1   0  56   6]]
12/10/2017 02:17:53 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 02:17:53 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:53 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:54 [INFO] exp_shallowmodel: train time: 0.987s
12/10/2017 02:17:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:54 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:17:54 [INFO] exp_shallowmodel: f1_score:   0.308
12/10/2017 02:17:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        59
          C       0.50      0.08      0.14        12
          F       0.78      0.97      0.86       396
          R       0.21      0.07      0.11        55

avg / total       0.68      0.75      0.68       522

12/10/2017 02:17:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:54 [INFO] exp_shallowmodel: 
[[  4   1  50   4]
 [  1   1  10   0]
 [  2   0 383  11]
 [  1   0  50   4]]
12/10/2017 02:17:54 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 02:17:54 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:54 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:55 [INFO] exp_shallowmodel: train time: 1.099s
12/10/2017 02:17:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:55 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:17:55 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 02:17:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.05      0.10        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.44      0.13      0.20        55

avg / total       0.72      0.77      0.69       522

12/10/2017 02:17:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:55 [INFO] exp_shallowmodel: 
[[  3   0  53   3]
 [  0   0  11   1]
 [  1   0 390   5]
 [  0   1  47   7]]
12/10/2017 02:17:55 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 02:17:55 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:55 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:56 [INFO] exp_shallowmodel: train time: 1.319s
12/10/2017 02:17:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:56 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:17:56 [INFO] exp_shallowmodel: f1_score:   0.272
12/10/2017 02:17:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.56      0.09      0.16        55

avg / total       0.67      0.77      0.69       522

12/10/2017 02:17:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:56 [INFO] exp_shallowmodel: 
[[  2   0  54   3]
 [  2   0  10   0]
 [  2   0 393   1]
 [  4   0  46   5]]
12/10/2017 02:17:56 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 02:17:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:56 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:58 [INFO] exp_shallowmodel: train time: 1.431s
12/10/2017 02:17:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:58 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:17:58 [INFO] exp_shallowmodel: f1_score:   0.285
12/10/2017 02:17:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.55      0.11      0.18        55

avg / total       0.68      0.77      0.69       522

12/10/2017 02:17:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:58 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  2   0   8   2]
 [  3   0 391   2]
 [  2   0  47   6]]
12/10/2017 02:17:58 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 02:17:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:58 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:59 [INFO] exp_shallowmodel: train time: 1.161s
12/10/2017 02:17:59 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:59 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:17:59 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 02:17:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.12      0.19        59
          C       1.00      0.08      0.15        12
          F       0.77      0.97      0.86       396
          R       0.22      0.04      0.06        55

avg / total       0.68      0.75      0.68       522

12/10/2017 02:17:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:59 [INFO] exp_shallowmodel: 
[[  7   0  50   2]
 [  0   1  11   0]
 [  7   0 384   5]
 [  2   0  51   2]]
12/10/2017 02:17:59 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 02:17:59 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:59 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:17:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:00 [INFO] exp_shallowmodel: train time: 1.183s
12/10/2017 02:18:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:00 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:18:00 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 02:18:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.50      0.09      0.15        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:18:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:00 [INFO] exp_shallowmodel: 
[[  3   0  54   2]
 [  0   0  12   0]
 [  5   1 387   3]
 [  2   0  48   5]]
12/10/2017 02:18:00 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 02:18:00 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:00 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:18:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:01 [INFO] exp_shallowmodel: train time: 1.390s
12/10/2017 02:18:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:01 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 02:18:01 [INFO] exp_shallowmodel: f1_score:   0.300
12/10/2017 02:18:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.10      0.17        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.56      0.09      0.16        55

avg / total       0.72      0.77      0.70       522

12/10/2017 02:18:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:01 [INFO] exp_shallowmodel: 
[[  6   0  51   2]
 [  0   0  12   0]
 [  3   0 391   2]
 [  1   2  47   5]]
12/10/2017 02:18:01 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 02:18:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:01 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:18:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:03 [INFO] exp_shallowmodel: train time: 1.320s
12/10/2017 02:18:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:03 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:18:03 [INFO] exp_shallowmodel: f1_score:   0.278
12/10/2017 02:18:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.56      0.09      0.16        55

avg / total       0.68      0.76      0.68       522

12/10/2017 02:18:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:03 [INFO] exp_shallowmodel: 
[[  3   0  56   0]
 [  0   0  11   1]
 [  3   0 390   3]
 [  3   1  46   5]]
12/10/2017 02:18:03 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 02:18:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:03 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:18:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:04 [INFO] exp_shallowmodel: train time: 1.437s
12/10/2017 02:18:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:04 [INFO] exp_shallowmodel: accuracy:   0.785
12/10/2017 02:18:04 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:18:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.10      0.18        59
          C       1.00      0.08      0.15        12
          F       0.79      0.99      0.88       396
          R       0.75      0.22      0.34        55

avg / total       0.78      0.79      0.72       522

12/10/2017 02:18:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:04 [INFO] exp_shallowmodel: 
[[  6   0  53   0]
 [  0   1  10   1]
 [  2   0 391   3]
 [  1   0  42  12]]
12/10/2017 02:18:04 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 02:18:04 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:18:04 [INFO] exp_shallowmodel: #(feature) = 93
12/10/2017 02:18:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:05 [INFO] exp_shallowmodel: train time: 1.242s
12/10/2017 02:18:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:05 [INFO] exp_shallowmodel: accuracy:   0.748
12/10/2017 02:18:05 [INFO] exp_shallowmodel: f1_score:   0.268
12/10/2017 02:18:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.03      0.06        64
          C       0.00      0.00      0.00        14
          F       0.76      0.99      0.86       402
          R       0.38      0.10      0.15        63

avg / total       0.67      0.75      0.66       543

12/10/2017 02:18:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:05 [INFO] exp_shallowmodel: 
[[  2   0  58   4]
 [  1   0  10   3]
 [  0   1 398   3]
 [  1   0  56   6]]
