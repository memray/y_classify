12/10/2017 02:14:33 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:33 [INFO] configuration: selected_context_id  :   0
12/10/2017 02:14:33 [INFO] configuration: selected_feature_set_id  :   1
12/10/2017 02:14:33 [INFO] configuration: similarity_feature  :   False
12/10/2017 02:14:33 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:33 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:33 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:33 [INFO] configuration: timemark  :   20171210-021433
12/10/2017 02:14:33 [INFO] configuration: context_set  :   next
12/10/2017 02:14:33 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:33 [INFO] configuration: utterance_range  :   ['current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:33 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:33 [INFO] configuration: feature_set  :   1-basic
12/10/2017 02:14:33 [INFO] configuration: feature_set_number  :   ['1', '2', '3']
12/10/2017 02:14:33 [INFO] configuration: experiment_name  :   20171210-021433.context=next.feature=1-basic.similarity=false
12/10/2017 02:14:33 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021433.context=next.feature=1-basic.similarity=false
12/10/2017 02:14:33 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021433.context=next.feature=1-basic.similarity=false/output.log
12/10/2017 02:14:33 [INFO] configuration: valid_type  :   {'C', 'A', 'R', 'F'}
12/10/2017 02:14:33 [INFO] configuration: data_name  :   
12/10/2017 02:14:33 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:33 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:33 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:33 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:33 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:33 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:33 [INFO] configuration: #division  :   5
12/10/2017 02:14:33 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:33 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:33 [INFO] configuration: action_words  :   {'start', 'else', 'moder', 'skip', 'discard', 'temperatur', 'volum', 'els', 'centre', 'shuffle', 'centr', 'moderate', 'telephone', 'member', 'expensive', 'items', 'temperature', 'price', 'snooze', 'remind', 'turn', 'time', 'findcare', 'food', 'weather', 'next', 'any', 'number', 'show', 'play', 'cheap', 'area', 'share', 'song', 'shuffl', 'add', 'reminds', 'video', 'telephon', 'delete', 'address', 'watch', 'volume', 'timer', 'list', 'south', 'north', 'stop', 'music', 'part', 'phone', 'ani', 'expens', 'light', 'clear', 'cast', 'matter', 'reminder', 'reminders', 'remove', 'delet', 'alarm', 'tell', 'post', 'help', 'remov', 'findcar', 'item', 'snooz', 'room'}
12/10/2017 02:14:33 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:33 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:33 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:33 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:33 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:33 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:33 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:33 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:33 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:33 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:33 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:33 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:33 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:33 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:33 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:33 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:33 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:33 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:33 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 3, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:33 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:35 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:35 [INFO] task_runner: context=next, feature=1-basic
12/10/2017 02:14:35 [INFO] task_runner: retained feature numbers=[1, 3, 2.1, 2.2]
12/10/2017 02:14:35 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:35 [INFO] task_runner: #(feature)=60
12/10/2017 02:14:35 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:35 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:35 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:37 [INFO] exp_shallowmodel: train time: 1.263s
12/10/2017 02:14:37 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:14:37 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:14:37 [INFO] exp_shallowmodel: f1_score:   0.491
12/10/2017 02:14:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.68      0.85      0.76       164
          F       0.80      0.90      0.84       268
          R       0.55      0.27      0.36       125

avg / total       0.69      0.73      0.69       571

12/10/2017 02:14:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:37 [INFO] exp_shallowmodel: 
[[  0   1  10   3]
 [  0 140  12  12]
 [  0  14 241  13]
 [  0  51  40  34]]
12/10/2017 02:14:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:14:37 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:37 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:39 [INFO] exp_shallowmodel: train time: 2.480s
12/10/2017 02:14:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:39 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 02:14:39 [INFO] exp_shallowmodel: f1_score:   0.475
12/10/2017 02:14:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.79      0.71       164
          F       0.78      0.88      0.82       268
          R       0.51      0.28      0.36       125

avg / total       0.66      0.70      0.67       571

12/10/2017 02:14:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:39 [INFO] exp_shallowmodel: 
[[  0   3  11   0]
 [  0 130  12  22]
 [  0  22 235  11]
 [  0  45  45  35]]
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:14:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:39 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:42 [INFO] exp_shallowmodel: train time: 2.459s
12/10/2017 02:14:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:42 [INFO] exp_shallowmodel: accuracy:   0.706
12/10/2017 02:14:42 [INFO] exp_shallowmodel: f1_score:   0.478
12/10/2017 02:14:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.77      0.68       164
          F       0.82      0.90      0.86       268
          R       0.51      0.30      0.37       125

avg / total       0.67      0.71      0.68       571

12/10/2017 02:14:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:42 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 126  12  26]
 [  0  21 240   7]
 [  0  57  31  37]]
12/10/2017 02:14:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:14:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:42 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:43 [INFO] exp_shallowmodel: train time: 1.153s
12/10/2017 02:14:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:43 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:14:43 [INFO] exp_shallowmodel: f1_score:   0.467
12/10/2017 02:14:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.76      0.68       164
          F       0.78      0.87      0.82       268
          R       0.51      0.29      0.37       125

avg / total       0.65      0.69      0.66       571

12/10/2017 02:14:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:43 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 124  19  21]
 [  0  23 233  12]
 [  0  54  35  36]]
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:14:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:43 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:44 [INFO] exp_shallowmodel: train time: 1.254s
12/10/2017 02:14:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:44 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:14:44 [INFO] exp_shallowmodel: f1_score:   0.489
12/10/2017 02:14:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.75      0.69       164
          F       0.80      0.86      0.83       268
          R       0.53      0.38      0.44       125

avg / total       0.67      0.70      0.68       571

12/10/2017 02:14:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:44 [INFO] exp_shallowmodel: 
[[  0   3   9   2]
 [  0 123  16  25]
 [  0  22 231  15]
 [  0  47  31  47]]
12/10/2017 02:14:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:14:44 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:44 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:45 [INFO] exp_shallowmodel: train time: 1.303s
12/10/2017 02:14:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:45 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 02:14:45 [INFO] exp_shallowmodel: f1_score:   0.469
12/10/2017 02:14:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.76      0.68       164
          F       0.80      0.90      0.85       268
          R       0.48      0.26      0.34       125

avg / total       0.66      0.70      0.67       571

12/10/2017 02:14:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:45 [INFO] exp_shallowmodel: 
[[  0   5   8   1]
 [  0 125  15  24]
 [  0  15 242  11]
 [  0  56  36  33]]
12/10/2017 02:14:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:14:45 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:45 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:47 [INFO] exp_shallowmodel: train time: 1.306s
12/10/2017 02:14:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:47 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:14:47 [INFO] exp_shallowmodel: f1_score:   0.476
12/10/2017 02:14:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.83      0.73       164
          F       0.80      0.90      0.85       268
          R       0.50      0.25      0.33       125

avg / total       0.67      0.71      0.68       571

12/10/2017 02:14:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:47 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 136  10  18]
 [  0  16 240  12]
 [  0  55  39  31]]
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:14:47 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:47 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:48 [INFO] exp_shallowmodel: train time: 1.074s
12/10/2017 02:14:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:48 [INFO] exp_shallowmodel: accuracy:   0.695
12/10/2017 02:14:48 [INFO] exp_shallowmodel: f1_score:   0.464
12/10/2017 02:14:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.78      0.69       164
          F       0.80      0.89      0.84       268
          R       0.47      0.25      0.32       125

avg / total       0.66      0.70      0.66       571

12/10/2017 02:14:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:48 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 128  14  22]
 [  0  18 238  12]
 [  0  59  35  31]]
12/10/2017 02:14:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:14:48 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:48 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:49 [INFO] exp_shallowmodel: train time: 1.329s
12/10/2017 02:14:49 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:49 [INFO] exp_shallowmodel: accuracy:   0.692
12/10/2017 02:14:49 [INFO] exp_shallowmodel: f1_score:   0.465
12/10/2017 02:14:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.76      0.69       164
          F       0.77      0.89      0.82       268
          R       0.49      0.26      0.34       125

avg / total       0.65      0.69      0.66       571

12/10/2017 02:14:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:49 [INFO] exp_shallowmodel: 
[[  0   0  13   1]
 [  0 124  20  20]
 [  0  16 238  14]
 [  0  54  38  33]]
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:14:49 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:14:49 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:51 [INFO] exp_shallowmodel: train time: 1.412s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 02:14:51 [INFO] exp_shallowmodel: f1_score:   0.446
12/10/2017 02:14:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.57      0.76      0.65       169
          F       0.79      0.89      0.84       271
          R       0.47      0.22      0.29       130

avg / total       0.64      0.68      0.64       586

12/10/2017 02:14:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:51 [INFO] exp_shallowmodel: 
[[  0   3  10   3]
 [  0 128  19  22]
 [  0  24 240   7]
 [  0  68  34  28]]
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:52 [INFO] exp_shallowmodel: train time: 1.586s
12/10/2017 02:14:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:52 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 02:14:52 [INFO] exp_shallowmodel: f1_score:   0.445
12/10/2017 02:14:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.76      0.69       164
          F       0.77      0.88      0.82       268
          R       0.39      0.21      0.27       125

avg / total       0.63      0.68      0.64       571

12/10/2017 02:14:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:52 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 125  17  22]
 [  0  15 235  18]
 [  0  57  42  26]]
12/10/2017 02:14:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:14:52 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:52 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:54 [INFO] exp_shallowmodel: train time: 1.664s
12/10/2017 02:14:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:54 [INFO] exp_shallowmodel: accuracy:   0.720
12/10/2017 02:14:54 [INFO] exp_shallowmodel: f1_score:   0.495
12/10/2017 02:14:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.79      0.70       164
          F       0.81      0.90      0.85       268
          R       0.58      0.34      0.43       125

avg / total       0.69      0.72      0.69       571

12/10/2017 02:14:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:54 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 129  18  17]
 [  0  16 240  12]
 [  0  54  29  42]]
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:14:54 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:54 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:56 [INFO] exp_shallowmodel: train time: 1.853s
12/10/2017 02:14:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:56 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:14:56 [INFO] exp_shallowmodel: f1_score:   0.466
12/10/2017 02:14:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.73      0.68       164
          F       0.78      0.88      0.83       268
          R       0.44      0.29      0.35       125

avg / total       0.65      0.69      0.66       571

12/10/2017 02:14:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:56 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  0 120  14  30]
 [  0  20 237  11]
 [  0  46  43  36]]
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:14:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:56 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:57 [INFO] exp_shallowmodel: train time: 1.157s
12/10/2017 02:14:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:57 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 02:14:57 [INFO] exp_shallowmodel: f1_score:   0.480
12/10/2017 02:14:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.79      0.71       164
          F       0.81      0.90      0.85       268
          R       0.51      0.28      0.36       125

avg / total       0.67      0.71      0.68       571

12/10/2017 02:14:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:57 [INFO] exp_shallowmodel: 
[[  0   4   8   2]
 [  0 130  14  20]
 [  0  15 241  12]
 [  0  55  35  35]]
12/10/2017 02:14:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:14:57 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:57 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:59 [INFO] exp_shallowmodel: train time: 1.806s
12/10/2017 02:14:59 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:59 [INFO] exp_shallowmodel: accuracy:   0.706
12/10/2017 02:14:59 [INFO] exp_shallowmodel: f1_score:   0.489
12/10/2017 02:14:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.76      0.68       164
          F       0.80      0.87      0.83       268
          R       0.59      0.35      0.44       125

avg / total       0.68      0.71      0.68       571

12/10/2017 02:14:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:59 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 125  20  19]
 [  0  23 234  11]
 [  0  52  29  44]]
12/10/2017 02:14:59 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:14:59 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:59 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:14:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:00 [INFO] exp_shallowmodel: train time: 1.670s
12/10/2017 02:15:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:00 [INFO] exp_shallowmodel: accuracy:   0.706
12/10/2017 02:15:00 [INFO] exp_shallowmodel: f1_score:   0.474
12/10/2017 02:15:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.79      0.70       164
          F       0.79      0.90      0.84       268
          R       0.56      0.26      0.36       125

avg / total       0.67      0.71      0.67       571

12/10/2017 02:15:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:00 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 130  19  15]
 [  0  20 240   8]
 [  0  57  35  33]]
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:15:00 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:00 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:02 [INFO] exp_shallowmodel: train time: 1.183s
12/10/2017 02:15:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:02 [INFO] exp_shallowmodel: accuracy:   0.706
12/10/2017 02:15:02 [INFO] exp_shallowmodel: f1_score:   0.504
12/10/2017 02:15:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        14
          C       0.62      0.79      0.69       164
          F       0.82      0.90      0.86       268
          R       0.49      0.26      0.34       125

avg / total       0.68      0.71      0.68       571

12/10/2017 02:15:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:02 [INFO] exp_shallowmodel: 
[[  1   4   7   2]
 [  0 129  10  25]
 [  0  20 240   8]
 [  1  56  35  33]]
12/10/2017 02:15:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:15:02 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:02 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:03 [INFO] exp_shallowmodel: train time: 1.432s
12/10/2017 02:15:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:03 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 02:15:03 [INFO] exp_shallowmodel: f1_score:   0.474
12/10/2017 02:15:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.82      0.73       164
          F       0.79      0.86      0.83       268
          R       0.48      0.27      0.35       125

avg / total       0.66      0.70      0.67       571

12/10/2017 02:15:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:03 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 135  10  19]
 [  0  20 231  17]
 [  0  50  41  34]]
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 02:15:03 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:03 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:04 [INFO] exp_shallowmodel: train time: 1.083s
12/10/2017 02:15:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:04 [INFO] exp_shallowmodel: accuracy:   0.694
12/10/2017 02:15:04 [INFO] exp_shallowmodel: f1_score:   0.460
12/10/2017 02:15:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.77      0.69       164
          F       0.78      0.90      0.83       268
          R       0.49      0.23      0.32       125

avg / total       0.65      0.69      0.66       571

12/10/2017 02:15:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:04 [INFO] exp_shallowmodel: 
[[  0   1  13   0]
 [  0 127  18  19]
 [  0  17 240  11]
 [  0  60  36  29]]
12/10/2017 02:15:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 02:15:04 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:15:04 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:05 [INFO] exp_shallowmodel: train time: 1.317s
12/10/2017 02:15:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:05 [INFO] exp_shallowmodel: accuracy:   0.708
12/10/2017 02:15:05 [INFO] exp_shallowmodel: f1_score:   0.481
12/10/2017 02:15:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.63      0.82      0.71       169
          F       0.80      0.89      0.84       271
          R       0.58      0.28      0.38       130

avg / total       0.68      0.71      0.68       586

12/10/2017 02:15:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:05 [INFO] exp_shallowmodel: 
[[  0   2  13   1]
 [  0 138  12  19]
 [  1  23 241   6]
 [  0  57  37  36]]
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 02:15:05 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:05 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:07 [INFO] exp_shallowmodel: train time: 1.265s
12/10/2017 02:15:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:07 [INFO] exp_shallowmodel: accuracy:   0.697
12/10/2017 02:15:07 [INFO] exp_shallowmodel: f1_score:   0.472
12/10/2017 02:15:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.79      0.70       164
          F       0.80      0.87      0.84       268
          R       0.48      0.28      0.35       125

avg / total       0.66      0.70      0.67       571

12/10/2017 02:15:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:07 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 130  12  22]
 [  0  20 233  15]
 [  0  55  35  35]]
12/10/2017 02:15:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 02:15:07 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:07 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:09 [INFO] exp_shallowmodel: train time: 1.963s
12/10/2017 02:15:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:09 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:15:09 [INFO] exp_shallowmodel: f1_score:   0.519
12/10/2017 02:15:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.63      0.77      0.69       164
          F       0.81      0.91      0.86       268
          R       0.55      0.30      0.39       125

avg / total       0.71      0.72      0.69       571

12/10/2017 02:15:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:09 [INFO] exp_shallowmodel: 
[[  1   1  10   2]
 [  0 126  17  21]
 [  0  16 244   8]
 [  0  58  29  38]]
12/10/2017 02:15:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 02:15:09 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:09 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:10 [INFO] exp_shallowmodel: train time: 1.423s
12/10/2017 02:15:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:10 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:10 [INFO] exp_shallowmodel: f1_score:   0.476
12/10/2017 02:15:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.80      0.72       164
          F       0.80      0.91      0.85       268
          R       0.51      0.25      0.33       125

avg / total       0.67      0.71      0.68       571

12/10/2017 02:15:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:10 [INFO] exp_shallowmodel: 
[[  0   0  10   4]
 [  0 132  14  18]
 [  1  15 244   8]
 [  0  56  38  31]]
12/10/2017 02:15:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 02:15:10 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:10 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:12 [INFO] exp_shallowmodel: train time: 1.456s
12/10/2017 02:15:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:12 [INFO] exp_shallowmodel: accuracy:   0.695
12/10/2017 02:15:12 [INFO] exp_shallowmodel: f1_score:   0.468
12/10/2017 02:15:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.79      0.70       164
          F       0.80      0.88      0.84       268
          R       0.44      0.26      0.33       125

avg / total       0.66      0.70      0.67       571

12/10/2017 02:15:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:12 [INFO] exp_shallowmodel: 
[[  0   1  12   1]
 [  0 129   8  27]
 [  0  19 235  14]
 [  0  54  38  33]]
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 02:15:12 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:12 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:13 [INFO] exp_shallowmodel: train time: 1.816s
12/10/2017 02:15:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:13 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:15:13 [INFO] exp_shallowmodel: f1_score:   0.487
12/10/2017 02:15:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.60      0.80      0.69       164
          F       0.81      0.87      0.84       268
          R       0.44      0.22      0.29       125

avg / total       0.67      0.69      0.66       571

12/10/2017 02:15:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:13 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  0 132  12  20]
 [  0  25 233  10]
 [  0  60  38  27]]
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 02:15:13 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:13 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:15 [INFO] exp_shallowmodel: train time: 1.690s
12/10/2017 02:15:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:15 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:15:15 [INFO] exp_shallowmodel: f1_score:   0.536
12/10/2017 02:15:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.65      0.81      0.72       164
          F       0.81      0.90      0.85       268
          R       0.63      0.34      0.44       125

avg / total       0.73      0.73      0.71       571

12/10/2017 02:15:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:15 [INFO] exp_shallowmodel: 
[[  1   5   7   1]
 [  0 133  15  16]
 [  0  19 241   8]
 [  0  49  34  42]]
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 02:15:15 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:15 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:16 [INFO] exp_shallowmodel: train time: 1.146s
12/10/2017 02:15:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:16 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 02:15:16 [INFO] exp_shallowmodel: f1_score:   0.480
12/10/2017 02:15:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.77      0.71       164
          F       0.79      0.90      0.84       268
          R       0.53      0.29      0.37       125

avg / total       0.67      0.71      0.68       571

12/10/2017 02:15:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:16 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 127  17  20]
 [  0  15 242  11]
 [  0  50  39  36]]
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 02:15:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:16 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:18 [INFO] exp_shallowmodel: train time: 1.490s
12/10/2017 02:15:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:18 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 02:15:18 [INFO] exp_shallowmodel: f1_score:   0.488
12/10/2017 02:15:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.77      0.70       164
          F       0.81      0.89      0.85       268
          R       0.52      0.33      0.40       125

avg / total       0.68      0.71      0.69       571

12/10/2017 02:15:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:18 [INFO] exp_shallowmodel: 
[[  0   1  10   3]
 [  0 127  11  26]
 [  0  21 238   9]
 [  0  48  36  41]]
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 02:15:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:18 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:19 [INFO] exp_shallowmodel: train time: 1.244s
12/10/2017 02:15:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:19 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 02:15:19 [INFO] exp_shallowmodel: f1_score:   0.473
12/10/2017 02:15:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.78      0.70       164
          F       0.79      0.89      0.84       268
          R       0.51      0.27      0.35       125

avg / total       0.66      0.70      0.67       571

12/10/2017 02:15:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:19 [INFO] exp_shallowmodel: 
[[  0   1  11   2]
 [  0 128  21  15]
 [  1  13 238  16]
 [  0  59  32  34]]
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 02:15:19 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:15:19 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:20 [INFO] exp_shallowmodel: train time: 0.981s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: accuracy:   0.684
12/10/2017 02:15:20 [INFO] exp_shallowmodel: f1_score:   0.458
12/10/2017 02:15:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.62      0.77      0.69       169
          F       0.75      0.89      0.81       271
          R       0.53      0.24      0.33       130

avg / total       0.64      0.68      0.65       586

12/10/2017 02:15:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:20 [INFO] exp_shallowmodel: 
[[  0   3  11   2]
 [  0 130  19  20]
 [  0  25 240   6]
 [  0  51  48  31]]
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:21 [INFO] exp_shallowmodel: train time: 1.138s
12/10/2017 02:15:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:21 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:15:21 [INFO] exp_shallowmodel: f1_score:   0.496
12/10/2017 02:15:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.62      0.74      0.68       164
          F       0.80      0.88      0.84       268
          R       0.44      0.27      0.33       125

avg / total       0.67      0.69      0.66       571

12/10/2017 02:15:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:21 [INFO] exp_shallowmodel: 
[[  1   0   8   5]
 [  0 122  14  28]
 [  0  21 236  11]
 [  0  54  37  34]]
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 02:15:21 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:21 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:23 [INFO] exp_shallowmodel: train time: 1.675s
12/10/2017 02:15:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:23 [INFO] exp_shallowmodel: accuracy:   0.687
12/10/2017 02:15:23 [INFO] exp_shallowmodel: f1_score:   0.460
12/10/2017 02:15:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.76      0.68       164
          F       0.78      0.88      0.82       268
          R       0.51      0.26      0.34       125

avg / total       0.65      0.69      0.66       571

12/10/2017 02:15:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:23 [INFO] exp_shallowmodel: 
[[  0   1  11   2]
 [  0 125  19  20]
 [  0  24 235   9]
 [  0  55  38  32]]
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 02:15:23 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:23 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:24 [INFO] exp_shallowmodel: train time: 1.526s
12/10/2017 02:15:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:24 [INFO] exp_shallowmodel: accuracy:   0.706
12/10/2017 02:15:24 [INFO] exp_shallowmodel: f1_score:   0.517
12/10/2017 02:15:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.66      0.76      0.71       164
          F       0.79      0.88      0.84       268
          R       0.49      0.33      0.39       125

avg / total       0.69      0.71      0.68       571

12/10/2017 02:15:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:24 [INFO] exp_shallowmodel: 
[[  1   3   9   1]
 [  0 124  11  29]
 [  0  18 237  13]
 [  0  42  42  41]]
12/10/2017 02:15:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 02:15:24 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:24 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:26 [INFO] exp_shallowmodel: train time: 1.428s
12/10/2017 02:15:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:26 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 02:15:26 [INFO] exp_shallowmodel: f1_score:   0.467
12/10/2017 02:15:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.79      0.70       164
          F       0.80      0.90      0.84       268
          R       0.48      0.25      0.33       125

avg / total       0.66      0.70      0.67       571

12/10/2017 02:15:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:26 [INFO] exp_shallowmodel: 
[[  0   5   7   2]
 [  0 129  17  18]
 [  0  15 240  13]
 [  0  57  37  31]]
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 02:15:26 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:26 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:27 [INFO] exp_shallowmodel: train time: 1.396s
12/10/2017 02:15:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:27 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:15:27 [INFO] exp_shallowmodel: f1_score:   0.479
12/10/2017 02:15:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.82      0.71       164
          F       0.81      0.91      0.85       268
          R       0.55      0.26      0.35       125

avg / total       0.68      0.72      0.68       571

12/10/2017 02:15:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:27 [INFO] exp_shallowmodel: 
[[  0   1  12   1]
 [  0 134  16  14]
 [  0  14 243  11]
 [  0  63  30  32]]
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 02:15:27 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:27 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:28 [INFO] exp_shallowmodel: train time: 1.093s
12/10/2017 02:15:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:28 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:15:28 [INFO] exp_shallowmodel: f1_score:   0.488
12/10/2017 02:15:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.82      0.70       164
          F       0.84      0.90      0.87       268
          R       0.58      0.29      0.39       125

avg / total       0.70      0.72      0.69       571

12/10/2017 02:15:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:28 [INFO] exp_shallowmodel: 
[[  0   5   8   1]
 [  0 135  11  18]
 [  0  20 241   7]
 [  0  61  28  36]]
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 02:15:28 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:28 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:30 [INFO] exp_shallowmodel: train time: 1.836s
12/10/2017 02:15:30 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:30 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:30 [INFO] exp_shallowmodel: f1_score:   0.481
12/10/2017 02:15:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.85      0.73       164
          F       0.77      0.88      0.82       268
          R       0.71      0.26      0.38       125

avg / total       0.70      0.71      0.68       571

12/10/2017 02:15:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:30 [INFO] exp_shallowmodel: 
[[  0   4  10   0]
 [  0 140  17   7]
 [  0  27 235   6]
 [  0  49  44  32]]
12/10/2017 02:15:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 02:15:30 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:30 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:32 [INFO] exp_shallowmodel: train time: 1.551s
12/10/2017 02:15:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:32 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:15:32 [INFO] exp_shallowmodel: f1_score:   0.466
12/10/2017 02:15:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.79      0.70       164
          F       0.81      0.89      0.85       268
          R       0.44      0.25      0.32       125

avg / total       0.66      0.70      0.67       571

12/10/2017 02:15:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:32 [INFO] exp_shallowmodel: 
[[  0   0  11   3]
 [  0 130  12  22]
 [  0  16 238  14]
 [  0  62  32  31]]
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 02:15:32 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:32 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:33 [INFO] exp_shallowmodel: train time: 1.286s
12/10/2017 02:15:33 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:33 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:15:33 [INFO] exp_shallowmodel: f1_score:   0.468
12/10/2017 02:15:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.77      0.70       164
          F       0.80      0.90      0.84       268
          R       0.46      0.26      0.33       125

avg / total       0.66      0.70      0.67       571

12/10/2017 02:15:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:33 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 127  12  25]
 [  1  16 240  11]
 [  0  54  39  32]]
12/10/2017 02:15:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 02:15:33 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:15:33 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:34 [INFO] exp_shallowmodel: train time: 1.394s
12/10/2017 02:15:34 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:34 [INFO] exp_shallowmodel: accuracy:   0.677
12/10/2017 02:15:34 [INFO] exp_shallowmodel: f1_score:   0.461
12/10/2017 02:15:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.61      0.73      0.67       169
          F       0.76      0.87      0.81       271
          R       0.49      0.28      0.36       130

avg / total       0.64      0.68      0.65       586

12/10/2017 02:15:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:34 [INFO] exp_shallowmodel: 
[[  0   3  11   2]
 [  0 123  24  22]
 [  0  20 237  14]
 [  0  54  39  37]]
12/10/2017 02:15:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 02:15:34 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:34 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:36 [INFO] exp_shallowmodel: train time: 1.060s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 02:15:36 [INFO] exp_shallowmodel: f1_score:   0.467
12/10/2017 02:15:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.77      0.69       164
          F       0.78      0.87      0.82       268
          R       0.51      0.28      0.36       125

avg / total       0.65      0.69      0.66       571

12/10/2017 02:15:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:36 [INFO] exp_shallowmodel: 
[[  0   4   9   1]
 [  0 126  15  23]
 [  0  25 233  10]
 [  0  47  43  35]]
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:37 [INFO] exp_shallowmodel: train time: 1.916s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:37 [INFO] exp_shallowmodel: f1_score:   0.482
12/10/2017 02:15:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.81      0.71       164
          F       0.82      0.89      0.85       268
          R       0.54      0.28      0.37       125

avg / total       0.68      0.71      0.68       571

12/10/2017 02:15:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:37 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 133  12  19]
 [  1  20 239   8]
 [  0  56  34  35]]
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:39 [INFO] exp_shallowmodel: train time: 1.864s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:15:39 [INFO] exp_shallowmodel: f1_score:   0.465
12/10/2017 02:15:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.83      0.70       164
          F       0.82      0.87      0.84       268
          R       0.52      0.23      0.32       125

avg / total       0.67      0.70      0.67       571

12/10/2017 02:15:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:39 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 136  11  17]
 [  1  24 234   9]
 [  0  64  32  29]]
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:41 [INFO] exp_shallowmodel: train time: 1.258s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:41 [INFO] exp_shallowmodel: f1_score:   0.518
12/10/2017 02:15:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.63      0.79      0.70       164
          F       0.81      0.89      0.85       268
          R       0.54      0.30      0.39       125

avg / total       0.70      0.71      0.69       571

12/10/2017 02:15:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:41 [INFO] exp_shallowmodel: 
[[  1   2  10   1]
 [  0 129  13  22]
 [  0  20 239   9]
 [  0  55  32  38]]
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:42 [INFO] exp_shallowmodel: train time: 1.231s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: accuracy:   0.729
12/10/2017 02:15:42 [INFO] exp_shallowmodel: f1_score:   0.495
12/10/2017 02:15:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.67      0.79      0.73       164
          F       0.79      0.93      0.86       268
          R       0.58      0.30      0.40       125

avg / total       0.69      0.73      0.70       571

12/10/2017 02:15:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:42 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 130  17  17]
 [  0  12 248   8]
 [  0  49  38  38]]
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:43 [INFO] exp_shallowmodel: train time: 1.448s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 02:15:43 [INFO] exp_shallowmodel: f1_score:   0.486
12/10/2017 02:15:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.78      0.71       164
          F       0.79      0.88      0.83       268
          R       0.53      0.32      0.40       125

avg / total       0.68      0.71      0.68       571

12/10/2017 02:15:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:43 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 128  17  19]
 [  0  17 237  14]
 [  0  49  36  40]]
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:45 [INFO] exp_shallowmodel: train time: 1.744s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: accuracy:   0.674
12/10/2017 02:15:45 [INFO] exp_shallowmodel: f1_score:   0.444
12/10/2017 02:15:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.72      0.65       164
          F       0.76      0.89      0.82       268
          R       0.47      0.22      0.30       125

avg / total       0.63      0.67      0.64       571

12/10/2017 02:15:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:45 [INFO] exp_shallowmodel: 
[[  0   0  13   1]
 [  0 118  23  23]
 [  0  21 239   8]
 [  0  58  39  28]]
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:46 [INFO] exp_shallowmodel: train time: 1.132s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:15:46 [INFO] exp_shallowmodel: f1_score:   0.486
12/10/2017 02:15:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.81      0.71       164
          F       0.84      0.91      0.87       268
          R       0.52      0.28      0.36       125

avg / total       0.69      0.72      0.69       571

12/10/2017 02:15:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:46 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  0 133  13  18]
 [  0  14 244  10]
 [  0  61  29  35]]
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 02:15:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:46 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:47 [INFO] exp_shallowmodel: train time: 1.185s
12/10/2017 02:15:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:47 [INFO] exp_shallowmodel: accuracy:   0.708
12/10/2017 02:15:47 [INFO] exp_shallowmodel: f1_score:   0.487
12/10/2017 02:15:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.79      0.71       164
          F       0.80      0.87      0.83       268
          R       0.55      0.33      0.41       125

avg / total       0.68      0.71      0.68       571

12/10/2017 02:15:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:47 [INFO] exp_shallowmodel: 
[[  0   0  13   1]
 [  0 130  11  23]
 [  0  26 233   9]
 [  0  48  36  41]]
12/10/2017 02:15:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 02:15:47 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:15:47 [INFO] exp_shallowmodel: #(feature) = 60
12/10/2017 02:15:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:49 [INFO] exp_shallowmodel: train time: 1.271s
12/10/2017 02:15:49 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:49 [INFO] exp_shallowmodel: accuracy:   0.677
12/10/2017 02:15:49 [INFO] exp_shallowmodel: f1_score:   0.452
12/10/2017 02:15:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.62      0.78      0.69       169
          F       0.78      0.87      0.82       271
          R       0.42      0.23      0.30       130

avg / total       0.63      0.68      0.64       586

12/10/2017 02:15:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:49 [INFO] exp_shallowmodel: 
[[  0   4  12   0]
 [  0 132  14  23]
 [  0  18 235  18]
 [  0  59  41  30]]
12/10/2017 02:15:52 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:15:52 [INFO] task_runner: context=next, feature=1-basic
12/10/2017 02:15:52 [INFO] task_runner: retained feature numbers=[1, 3, 2.1, 2.2]
12/10/2017 02:15:52 [INFO] task_runner: #(data)=5934
12/10/2017 02:15:52 [INFO] task_runner: #(feature)=56
12/10/2017 02:15:52 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 02:15:52 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:52 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:53 [INFO] exp_shallowmodel: train time: 0.912s
12/10/2017 02:15:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:53 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 02:15:53 [INFO] exp_shallowmodel: f1_score:   0.474
12/10/2017 02:15:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.60      0.77      0.67       169
          F       0.77      0.89      0.82       281
          R       0.53      0.21      0.30       122

avg / total       0.68      0.69      0.65       592

12/10/2017 02:15:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:53 [INFO] exp_shallowmodel: 
[[  1   0  16   3]
 [  0 130  21  18]
 [  0  30 249   2]
 [  0  57  39  26]]
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 02:15:53 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:53 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:54 [INFO] exp_shallowmodel: train time: 1.038s
12/10/2017 02:15:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:54 [INFO] exp_shallowmodel: accuracy:   0.684
12/10/2017 02:15:54 [INFO] exp_shallowmodel: f1_score:   0.489
12/10/2017 02:15:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.10      0.17        20
          C       0.60      0.76      0.67       169
          F       0.79      0.89      0.84       281
          R       0.42      0.20      0.27       122

avg / total       0.66      0.68      0.65       592

12/10/2017 02:15:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:54 [INFO] exp_shallowmodel: 
[[  2   4  12   2]
 [  0 129  18  22]
 [  1  20 249  11]
 [  0  62  35  25]]
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 02:15:54 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:54 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:55 [INFO] exp_shallowmodel: train time: 0.906s
12/10/2017 02:15:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:55 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 02:15:55 [INFO] exp_shallowmodel: f1_score:   0.448
12/10/2017 02:15:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.62      0.77      0.69       169
          F       0.74      0.88      0.80       281
          R       0.53      0.21      0.30       122

avg / total       0.64      0.68      0.64       592

12/10/2017 02:15:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:55 [INFO] exp_shallowmodel: 
[[  0   1  17   2]
 [  1 130  26  12]
 [  0  26 246   9]
 [  0  51  45  26]]
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 02:15:55 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:55 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:56 [INFO] exp_shallowmodel: train time: 0.970s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:15:56 [INFO] exp_shallowmodel: f1_score:   0.496
12/10/2017 02:15:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.64      0.79      0.70       169
          F       0.77      0.86      0.81       281
          R       0.54      0.29      0.37       122

avg / total       0.69      0.70      0.67       592

12/10/2017 02:15:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:56 [INFO] exp_shallowmodel: 
[[  1   2  16   1]
 [  0 133  15  21]
 [  0  30 243   8]
 [  0  44  43  35]]
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:57 [INFO] exp_shallowmodel: train time: 0.922s
12/10/2017 02:15:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:57 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 02:15:57 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 02:15:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.56      0.76      0.65       169
          F       0.78      0.87      0.82       281
          R       0.45      0.18      0.26       122

avg / total       0.62      0.67      0.63       592

12/10/2017 02:15:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:57 [INFO] exp_shallowmodel: 
[[  0   1  18   1]
 [  0 129  20  20]
 [  0  30 245   6]
 [  0  69  31  22]]
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 02:15:57 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:57 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:58 [INFO] exp_shallowmodel: train time: 0.751s
12/10/2017 02:15:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:58 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 02:15:58 [INFO] exp_shallowmodel: f1_score:   0.486
12/10/2017 02:15:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.61      0.78      0.68       169
          F       0.79      0.88      0.83       281
          R       0.51      0.25      0.34       122

avg / total       0.67      0.69      0.66       592

12/10/2017 02:15:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:58 [INFO] exp_shallowmodel: 
[[  1   3  15   1]
 [  0 132  17  20]
 [  1  25 246   9]
 [  0  58  33  31]]
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 02:15:58 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:58 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:59 [INFO] exp_shallowmodel: train time: 0.797s
12/10/2017 02:15:59 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:59 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 02:15:59 [INFO] exp_shallowmodel: f1_score:   0.463
12/10/2017 02:15:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.58      0.72      0.64       169
          F       0.78      0.88      0.82       281
          R       0.42      0.22      0.29       122

avg / total       0.65      0.67      0.64       592

12/10/2017 02:15:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:59 [INFO] exp_shallowmodel: 
[[  1   4  11   4]
 [  0 122  26  21]
 [  0  22 246  13]
 [  0  62  33  27]]
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 02:15:59 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:59 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:00 [INFO] exp_shallowmodel: train time: 1.040s
12/10/2017 02:16:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:00 [INFO] exp_shallowmodel: accuracy:   0.659
12/10/2017 02:16:00 [INFO] exp_shallowmodel: f1_score:   0.447
12/10/2017 02:16:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.58      0.72      0.64       169
          F       0.77      0.83      0.80       281
          R       0.44      0.29      0.35       122

avg / total       0.62      0.66      0.63       592

12/10/2017 02:16:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:00 [INFO] exp_shallowmodel: 
[[  0   0  15   5]
 [  0 121  24  24]
 [  0  31 234  16]
 [  0  57  30  35]]
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 02:16:00 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:00 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:01 [INFO] exp_shallowmodel: train time: 1.190s
12/10/2017 02:16:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:01 [INFO] exp_shallowmodel: accuracy:   0.649
12/10/2017 02:16:01 [INFO] exp_shallowmodel: f1_score:   0.482
12/10/2017 02:16:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.15      0.25        20
          C       0.56      0.67      0.61       169
          F       0.76      0.86      0.81       281
          R       0.36      0.20      0.26       122

avg / total       0.62      0.65      0.62       592

12/10/2017 02:16:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:01 [INFO] exp_shallowmodel: 
[[  3   0  13   4]
 [  0 114  30  25]
 [  1  24 243  13]
 [  0  65  33  24]]
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 02:16:01 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:16:01 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:02 [INFO] exp_shallowmodel: train time: 0.852s
12/10/2017 02:16:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:02 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 02:16:02 [INFO] exp_shallowmodel: f1_score:   0.487
12/10/2017 02:16:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.07        28
          C       0.61      0.76      0.68       172
          F       0.75      0.86      0.80       283
          R       0.57      0.31      0.40       123

avg / total       0.69      0.68      0.65       606

12/10/2017 02:16:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:02 [INFO] exp_shallowmodel: 
[[  1   4  21   2]
 [  0 131  26  15]
 [  0  28 243  12]
 [  0  52  33  38]]
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 02:16:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:02 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:03 [INFO] exp_shallowmodel: train time: 1.035s
12/10/2017 02:16:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:03 [INFO] exp_shallowmodel: accuracy:   0.691
12/10/2017 02:16:03 [INFO] exp_shallowmodel: f1_score:   0.457
12/10/2017 02:16:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.60      0.79      0.68       169
          F       0.78      0.88      0.83       281
          R       0.50      0.23      0.31       122

avg / total       0.65      0.69      0.65       592

12/10/2017 02:16:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:03 [INFO] exp_shallowmodel: 
[[  0   2  15   3]
 [  0 133  19  17]
 [  0  25 248   8]
 [  0  60  34  28]]
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 02:16:03 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:03 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:04 [INFO] exp_shallowmodel: train time: 1.048s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: accuracy:   0.664
12/10/2017 02:16:04 [INFO] exp_shallowmodel: f1_score:   0.436
12/10/2017 02:16:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.57      0.76      0.65       169
          F       0.78      0.85      0.81       281
          R       0.43      0.20      0.28       122

avg / total       0.62      0.66      0.63       592

12/10/2017 02:16:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:04 [INFO] exp_shallowmodel: 
[[  0   2  15   3]
 [  0 129  19  21]
 [  0  33 239   9]
 [  0  63  34  25]]
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:05 [INFO] exp_shallowmodel: train time: 1.089s
12/10/2017 02:16:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:05 [INFO] exp_shallowmodel: accuracy:   0.677
12/10/2017 02:16:05 [INFO] exp_shallowmodel: f1_score:   0.495
12/10/2017 02:16:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.58      0.74      0.65       169
          F       0.78      0.87      0.82       281
          R       0.50      0.25      0.33       122

avg / total       0.67      0.68      0.65       592

12/10/2017 02:16:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:05 [INFO] exp_shallowmodel: 
[[  2   1  16   1]
 [  0 125  23  21]
 [  0  29 244   8]
 [  0  61  31  30]]
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 02:16:05 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:05 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:06 [INFO] exp_shallowmodel: train time: 0.961s
12/10/2017 02:16:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:06 [INFO] exp_shallowmodel: accuracy:   0.708
12/10/2017 02:16:06 [INFO] exp_shallowmodel: f1_score:   0.535
12/10/2017 02:16:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.15      0.26        20
          C       0.62      0.80      0.70       169
          F       0.79      0.89      0.84       281
          R       0.53      0.25      0.34       122

avg / total       0.70      0.71      0.68       592

12/10/2017 02:16:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:06 [INFO] exp_shallowmodel: 
[[  3   2  15   0]
 [  0 135  16  18]
 [  0  21 251   9]
 [  0  58  34  30]]
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 02:16:06 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:06 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:07 [INFO] exp_shallowmodel: train time: 0.835s
12/10/2017 02:16:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:07 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 02:16:07 [INFO] exp_shallowmodel: f1_score:   0.473
12/10/2017 02:16:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.60      0.75      0.66       169
          F       0.79      0.90      0.84       281
          R       0.44      0.22      0.29       122

avg / total       0.67      0.69      0.65       592

12/10/2017 02:16:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:07 [INFO] exp_shallowmodel: 
[[  1   0  14   5]
 [  0 126  23  20]
 [  0  19 252  10]
 [  0  65  30  27]]
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 02:16:07 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:07 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:08 [INFO] exp_shallowmodel: train time: 1.077s
12/10/2017 02:16:08 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:08 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 02:16:08 [INFO] exp_shallowmodel: f1_score:   0.477
12/10/2017 02:16:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.60      0.75      0.66       169
          F       0.77      0.88      0.82       281
          R       0.48      0.25      0.33       122

avg / total       0.67      0.68      0.65       592

12/10/2017 02:16:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:08 [INFO] exp_shallowmodel: 
[[  1   2  14   3]
 [  0 126  22  21]
 [  0  26 247   8]
 [  0  56  36  30]]
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 02:16:08 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:08 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:09 [INFO] exp_shallowmodel: train time: 1.142s
12/10/2017 02:16:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:09 [INFO] exp_shallowmodel: accuracy:   0.654
12/10/2017 02:16:09 [INFO] exp_shallowmodel: f1_score:   0.476
12/10/2017 02:16:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.57      0.72      0.64       169
          F       0.75      0.84      0.80       281
          R       0.42      0.22      0.29       122

avg / total       0.64      0.65      0.63       592

12/10/2017 02:16:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:09 [INFO] exp_shallowmodel: 
[[  2   1  17   0]
 [  0 121  26  22]
 [  0  28 237  16]
 [  0  61  34  27]]
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 02:16:09 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:09 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:10 [INFO] exp_shallowmodel: train time: 1.077s
12/10/2017 02:16:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:10 [INFO] exp_shallowmodel: accuracy:   0.660
12/10/2017 02:16:10 [INFO] exp_shallowmodel: f1_score:   0.438
12/10/2017 02:16:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.60      0.76      0.67       169
          F       0.76      0.84      0.80       281
          R       0.41      0.22      0.29       122

avg / total       0.62      0.66      0.63       592

12/10/2017 02:16:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:10 [INFO] exp_shallowmodel: 
[[  0   1  15   4]
 [  0 128  20  21]
 [  1  30 236  14]
 [  0  55  40  27]]
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 02:16:10 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:10 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:11 [INFO] exp_shallowmodel: train time: 0.853s
12/10/2017 02:16:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:11 [INFO] exp_shallowmodel: accuracy:   0.671
12/10/2017 02:16:11 [INFO] exp_shallowmodel: f1_score:   0.476
12/10/2017 02:16:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.63      0.78      0.70       169
          F       0.73      0.83      0.78       281
          R       0.48      0.25      0.33       122

avg / total       0.66      0.67      0.64       592

12/10/2017 02:16:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:11 [INFO] exp_shallowmodel: 
[[  1   5  12   2]
 [  0 132  23  14]
 [  0  31 233  17]
 [  0  41  50  31]]
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 02:16:11 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:16:11 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:12 [INFO] exp_shallowmodel: train time: 0.665s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: accuracy:   0.683
12/10/2017 02:16:12 [INFO] exp_shallowmodel: f1_score:   0.467
12/10/2017 02:16:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.60      0.75      0.66       172
          F       0.77      0.88      0.82       283
          R       0.55      0.29      0.38       123

avg / total       0.64      0.68      0.65       606

12/10/2017 02:16:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:12 [INFO] exp_shallowmodel: 
[[  0   5  19   4]
 [  0 129  26  17]
 [  0  25 249   9]
 [  0  57  30  36]]
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 02:16:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:12 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:13 [INFO] exp_shallowmodel: train time: 0.922s
12/10/2017 02:16:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:13 [INFO] exp_shallowmodel: accuracy:   0.708
12/10/2017 02:16:13 [INFO] exp_shallowmodel: f1_score:   0.520
12/10/2017 02:16:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.61      0.76      0.68       169
          F       0.80      0.91      0.85       281
          R       0.55      0.28      0.37       122

avg / total       0.70      0.71      0.68       592

12/10/2017 02:16:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:13 [INFO] exp_shallowmodel: 
[[  2   1  16   1]
 [  0 128  18  23]
 [  0  22 255   4]
 [  0  59  29  34]]
12/10/2017 02:16:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 02:16:13 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:13 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:14 [INFO] exp_shallowmodel: train time: 1.487s
12/10/2017 02:16:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:14 [INFO] exp_shallowmodel: accuracy:   0.672
12/10/2017 02:16:14 [INFO] exp_shallowmodel: f1_score:   0.448
12/10/2017 02:16:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.57      0.72      0.64       169
          F       0.78      0.87      0.82       281
          R       0.48      0.25      0.33       122

avg / total       0.63      0.67      0.64       592

12/10/2017 02:16:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:14 [INFO] exp_shallowmodel: 
[[  0   2  16   2]
 [  0 122  22  25]
 [  0  29 245   7]
 [  0  60  31  31]]
12/10/2017 02:16:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 02:16:14 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:14 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:15 [INFO] exp_shallowmodel: train time: 0.814s
12/10/2017 02:16:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:15 [INFO] exp_shallowmodel: accuracy:   0.677
12/10/2017 02:16:15 [INFO] exp_shallowmodel: f1_score:   0.481
12/10/2017 02:16:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.62      0.75      0.68       169
          F       0.75      0.85      0.80       281
          R       0.50      0.27      0.35       122

avg / total       0.67      0.68      0.65       592

12/10/2017 02:16:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:15 [INFO] exp_shallowmodel: 
[[  1   1  15   3]
 [  0 127  26  16]
 [  0  27 240  14]
 [  0  50  39  33]]
12/10/2017 02:16:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 02:16:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:15 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:16 [INFO] exp_shallowmodel: train time: 1.179s
12/10/2017 02:16:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:16 [INFO] exp_shallowmodel: accuracy:   0.703
12/10/2017 02:16:16 [INFO] exp_shallowmodel: f1_score:   0.496
12/10/2017 02:16:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.60      0.82      0.69       169
          F       0.80      0.87      0.83       281
          R       0.58      0.26      0.36       122

avg / total       0.70      0.70      0.67       592

12/10/2017 02:16:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:16 [INFO] exp_shallowmodel: 
[[  1   2  14   3]
 [  0 138  19  12]
 [  0  28 245   8]
 [  0  61  29  32]]
12/10/2017 02:16:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 02:16:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:16 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:17 [INFO] exp_shallowmodel: train time: 1.187s
12/10/2017 02:16:17 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:17 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 02:16:17 [INFO] exp_shallowmodel: f1_score:   0.480
12/10/2017 02:16:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.10      0.17        20
          C       0.58      0.73      0.65       169
          F       0.76      0.87      0.81       281
          R       0.46      0.20      0.28       122

avg / total       0.64      0.67      0.64       592

12/10/2017 02:16:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:17 [INFO] exp_shallowmodel: 
[[  2   3  12   3]
 [  1 124  27  17]
 [  0  27 245   9]
 [  0  58  39  25]]
12/10/2017 02:16:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 02:16:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:17 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:18 [INFO] exp_shallowmodel: train time: 0.916s
12/10/2017 02:16:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:18 [INFO] exp_shallowmodel: accuracy:   0.667
12/10/2017 02:16:18 [INFO] exp_shallowmodel: f1_score:   0.438
12/10/2017 02:16:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.58      0.74      0.65       169
          F       0.78      0.87      0.82       281
          R       0.42      0.21      0.28       122

avg / total       0.62      0.67      0.63       592

12/10/2017 02:16:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:18 [INFO] exp_shallowmodel: 
[[  0   2  15   3]
 [  0 125  24  20]
 [  0  24 244  13]
 [  0  65  31  26]]
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 02:16:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:18 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:19 [INFO] exp_shallowmodel: train time: 0.829s
12/10/2017 02:16:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:19 [INFO] exp_shallowmodel: accuracy:   0.681
12/10/2017 02:16:19 [INFO] exp_shallowmodel: f1_score:   0.477
12/10/2017 02:16:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.63      0.78      0.70       169
          F       0.77      0.86      0.81       281
          R       0.41      0.24      0.30       122

avg / total       0.67      0.68      0.65       592

12/10/2017 02:16:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:19 [INFO] exp_shallowmodel: 
[[  1   2  14   3]
 [  0 132  14  23]
 [  0  25 241  15]
 [  0  49  44  29]]
12/10/2017 02:16:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 02:16:19 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:19 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:20 [INFO] exp_shallowmodel: train time: 0.997s
12/10/2017 02:16:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:20 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 02:16:20 [INFO] exp_shallowmodel: f1_score:   0.461
12/10/2017 02:16:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.58      0.78      0.67       169
          F       0.79      0.86      0.83       281
          R       0.52      0.26      0.35       122

avg / total       0.65      0.69      0.65       592

12/10/2017 02:16:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:20 [INFO] exp_shallowmodel: 
[[  0   1  15   4]
 [  0 131  17  21]
 [  0  33 243   5]
 [  0  59  31  32]]
12/10/2017 02:16:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 02:16:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:20 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:21 [INFO] exp_shallowmodel: train time: 0.909s
12/10/2017 02:16:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:21 [INFO] exp_shallowmodel: accuracy:   0.666
12/10/2017 02:16:21 [INFO] exp_shallowmodel: f1_score:   0.455
12/10/2017 02:16:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.58      0.75      0.65       169
          F       0.78      0.86      0.82       281
          R       0.40      0.19      0.26       122

avg / total       0.63      0.67      0.63       592

12/10/2017 02:16:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:21 [INFO] exp_shallowmodel: 
[[  1   2  15   2]
 [  0 127  19  23]
 [  1  27 243  10]
 [  0  64  35  23]]
12/10/2017 02:16:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 02:16:21 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:16:21 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:22 [INFO] exp_shallowmodel: train time: 1.079s
12/10/2017 02:16:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:22 [INFO] exp_shallowmodel: accuracy:   0.637
12/10/2017 02:16:22 [INFO] exp_shallowmodel: f1_score:   0.440
12/10/2017 02:16:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.07        28
          C       0.59      0.72      0.65       172
          F       0.72      0.83      0.77       283
          R       0.38      0.21      0.27       123

avg / total       0.63      0.64      0.60       606

12/10/2017 02:16:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:22 [INFO] exp_shallowmodel: 
[[  1   4  21   2]
 [  0 123  28  21]
 [  0  28 236  19]
 [  0  54  43  26]]
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 02:16:22 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:22 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:23 [INFO] exp_shallowmodel: train time: 1.015s
12/10/2017 02:16:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:23 [INFO] exp_shallowmodel: accuracy:   0.704
12/10/2017 02:16:23 [INFO] exp_shallowmodel: f1_score:   0.478
12/10/2017 02:16:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.62      0.82      0.71       169
          F       0.79      0.91      0.85       281
          R       0.48      0.18      0.26       122

avg / total       0.69      0.70      0.66       592

12/10/2017 02:16:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:23 [INFO] exp_shallowmodel: 
[[  1   3  14   2]
 [  0 138  17  14]
 [  0  17 256   8]
 [  0  63  37  22]]
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 02:16:23 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:23 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:24 [INFO] exp_shallowmodel: train time: 0.824s
12/10/2017 02:16:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:24 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:16:24 [INFO] exp_shallowmodel: f1_score:   0.476
12/10/2017 02:16:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.61      0.77      0.68       169
          F       0.78      0.89      0.83       281
          R       0.44      0.22      0.30       122

avg / total       0.67      0.69      0.65       592

12/10/2017 02:16:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:24 [INFO] exp_shallowmodel: 
[[  1   0  15   4]
 [  0 130  18  21]
 [  0  23 249   9]
 [  0  59  36  27]]
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 02:16:24 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:24 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:25 [INFO] exp_shallowmodel: train time: 0.938s
12/10/2017 02:16:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:25 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:16:25 [INFO] exp_shallowmodel: f1_score:   0.463
12/10/2017 02:16:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.59      0.76      0.66       169
          F       0.78      0.88      0.82       281
          R       0.57      0.27      0.37       122

avg / total       0.66      0.69      0.66       592

12/10/2017 02:16:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:25 [INFO] exp_shallowmodel: 
[[  0   2  14   4]
 [  0 128  25  16]
 [  0  30 246   5]
 [  1  57  31  33]]
12/10/2017 02:16:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 02:16:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:25 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:26 [INFO] exp_shallowmodel: train time: 1.048s
12/10/2017 02:16:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:26 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 02:16:26 [INFO] exp_shallowmodel: f1_score:   0.458
12/10/2017 02:16:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.61      0.75      0.67       169
          F       0.78      0.88      0.82       281
          R       0.46      0.26      0.33       122

avg / total       0.64      0.68      0.65       592

12/10/2017 02:16:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:26 [INFO] exp_shallowmodel: 
[[  0   1  17   2]
 [  1 126  17  25]
 [  0  24 246  11]
 [  0  54  36  32]]
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 02:16:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:26 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:27 [INFO] exp_shallowmodel: train time: 0.990s
12/10/2017 02:16:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:27 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 02:16:27 [INFO] exp_shallowmodel: f1_score:   0.471
12/10/2017 02:16:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.60      0.80      0.69       169
          F       0.76      0.84      0.80       281
          R       0.48      0.22      0.30       122

avg / total       0.67      0.68      0.64       592

12/10/2017 02:16:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:27 [INFO] exp_shallowmodel: 
[[  1   2  13   4]
 [  0 135  22  12]
 [  0  31 237  13]
 [  0  57  38  27]]
12/10/2017 02:16:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 02:16:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:27 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:28 [INFO] exp_shallowmodel: train time: 1.011s
12/10/2017 02:16:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:28 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 02:16:28 [INFO] exp_shallowmodel: f1_score:   0.481
12/10/2017 02:16:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.59      0.73      0.65       169
          F       0.78      0.89      0.83       281
          R       0.54      0.26      0.35       122

avg / total       0.67      0.69      0.66       592

12/10/2017 02:16:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:28 [INFO] exp_shallowmodel: 
[[  1   2  16   1]
 [  0 123  27  19]
 [  1  23 250   7]
 [  0  61  29  32]]
12/10/2017 02:16:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 02:16:28 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:28 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:29 [INFO] exp_shallowmodel: train time: 0.887s
12/10/2017 02:16:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:29 [INFO] exp_shallowmodel: accuracy:   0.684
12/10/2017 02:16:29 [INFO] exp_shallowmodel: f1_score:   0.453
12/10/2017 02:16:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.59      0.75      0.66       169
          F       0.78      0.89      0.83       281
          R       0.50      0.24      0.32       122

avg / total       0.64      0.68      0.65       592

12/10/2017 02:16:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:29 [INFO] exp_shallowmodel: 
[[  0   4  13   3]
 [  0 126  24  19]
 [  0  24 250   7]
 [  0  59  34  29]]
12/10/2017 02:16:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 02:16:29 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:29 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:30 [INFO] exp_shallowmodel: train time: 0.952s
12/10/2017 02:16:30 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:30 [INFO] exp_shallowmodel: accuracy:   0.647
12/10/2017 02:16:30 [INFO] exp_shallowmodel: f1_score:   0.471
12/10/2017 02:16:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.56      0.73      0.63       169
          F       0.75      0.83      0.79       281
          R       0.41      0.21      0.28       122

avg / total       0.64      0.65      0.62       592

12/10/2017 02:16:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:30 [INFO] exp_shallowmodel: 
[[  2   2  14   2]
 [  0 123  25  21]
 [  0  35 232  14]
 [  0  59  37  26]]
12/10/2017 02:16:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 02:16:30 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:30 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:31 [INFO] exp_shallowmodel: train time: 0.881s
12/10/2017 02:16:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:31 [INFO] exp_shallowmodel: accuracy:   0.662
12/10/2017 02:16:31 [INFO] exp_shallowmodel: f1_score:   0.488
12/10/2017 02:16:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.59      0.70      0.64       169
          F       0.76      0.85      0.80       281
          R       0.43      0.26      0.33       122

avg / total       0.65      0.66      0.64       592

12/10/2017 02:16:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:31 [INFO] exp_shallowmodel: 
[[  2   1  15   2]
 [  0 119  23  27]
 [  0  29 239  13]
 [  0  54  36  32]]
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 02:16:31 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:16:31 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:31 [INFO] exp_shallowmodel: train time: 0.786s
12/10/2017 02:16:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:31 [INFO] exp_shallowmodel: accuracy:   0.667
12/10/2017 02:16:31 [INFO] exp_shallowmodel: f1_score:   0.443
12/10/2017 02:16:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.59      0.77      0.67       172
          F       0.76      0.87      0.81       283
          R       0.44      0.22      0.29       123

avg / total       0.61      0.67      0.63       606

12/10/2017 02:16:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:31 [INFO] exp_shallowmodel: 
[[  0   6  20   2]
 [  0 132  23  17]
 [  0  23 245  15]
 [  0  63  33  27]]
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 02:16:31 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:31 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:33 [INFO] exp_shallowmodel: train time: 1.352s
12/10/2017 02:16:33 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:33 [INFO] exp_shallowmodel: accuracy:   0.694
12/10/2017 02:16:33 [INFO] exp_shallowmodel: f1_score:   0.456
12/10/2017 02:16:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.59      0.78      0.68       169
          F       0.81      0.90      0.85       281
          R       0.46      0.22      0.30       122

avg / total       0.65      0.69      0.66       592

12/10/2017 02:16:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:33 [INFO] exp_shallowmodel: 
[[  0   4  13   3]
 [  0 132  18  19]
 [  0  19 252  10]
 [  0  67  28  27]]
12/10/2017 02:16:33 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 02:16:33 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:33 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:34 [INFO] exp_shallowmodel: train time: 1.210s
12/10/2017 02:16:34 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:34 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 02:16:34 [INFO] exp_shallowmodel: f1_score:   0.493
12/10/2017 02:16:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.59      0.78      0.67       169
          F       0.76      0.85      0.80       281
          R       0.51      0.23      0.32       122

avg / total       0.67      0.68      0.64       592

12/10/2017 02:16:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:34 [INFO] exp_shallowmodel: 
[[  2   1  15   2]
 [  0 131  23  15]
 [  0  32 239  10]
 [  0  58  36  28]]
12/10/2017 02:16:34 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 02:16:34 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:34 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:35 [INFO] exp_shallowmodel: train time: 1.159s
12/10/2017 02:16:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:35 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 02:16:35 [INFO] exp_shallowmodel: f1_score:   0.443
12/10/2017 02:16:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.60      0.78      0.68       169
          F       0.79      0.88      0.83       281
          R       0.40      0.20      0.26       122

avg / total       0.63      0.68      0.64       592

12/10/2017 02:16:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:35 [INFO] exp_shallowmodel: 
[[  0   1  17   2]
 [  0 132  15  22]
 [  0  23 246  12]
 [  0  63  35  24]]
12/10/2017 02:16:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 02:16:35 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:35 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:36 [INFO] exp_shallowmodel: train time: 0.892s
12/10/2017 02:16:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:36 [INFO] exp_shallowmodel: accuracy:   0.704
12/10/2017 02:16:36 [INFO] exp_shallowmodel: f1_score:   0.499
12/10/2017 02:16:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.65      0.80      0.72       169
          F       0.78      0.88      0.83       281
          R       0.52      0.28      0.36       122

avg / total       0.68      0.70      0.67       592

12/10/2017 02:16:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:36 [INFO] exp_shallowmodel: 
[[  1   0  17   2]
 [  1 135  17  16]
 [  0  20 247  14]
 [  0  52  36  34]]
12/10/2017 02:16:36 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 02:16:36 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:36 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:37 [INFO] exp_shallowmodel: train time: 0.987s
12/10/2017 02:16:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:37 [INFO] exp_shallowmodel: accuracy:   0.654
12/10/2017 02:16:37 [INFO] exp_shallowmodel: f1_score:   0.456
12/10/2017 02:16:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.59      0.70      0.64       169
          F       0.74      0.85      0.79       281
          R       0.43      0.23      0.30       122

avg / total       0.64      0.65      0.62       592

12/10/2017 02:16:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:37 [INFO] exp_shallowmodel: 
[[  1   2  15   2]
 [  0 119  29  21]
 [  0  28 239  14]
 [  0  54  40  28]]
12/10/2017 02:16:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 02:16:37 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:37 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:38 [INFO] exp_shallowmodel: train time: 0.919s
12/10/2017 02:16:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:38 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 02:16:38 [INFO] exp_shallowmodel: f1_score:   0.450
12/10/2017 02:16:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.59      0.73      0.65       169
          F       0.78      0.89      0.83       281
          R       0.49      0.24      0.32       122

avg / total       0.64      0.68      0.65       592

12/10/2017 02:16:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:38 [INFO] exp_shallowmodel: 
[[  0   2  16   2]
 [  0 124  23  22]
 [  0  26 249   6]
 [  1  59  33  29]]
12/10/2017 02:16:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 02:16:38 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:38 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:39 [INFO] exp_shallowmodel: train time: 0.873s
12/10/2017 02:16:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:39 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 02:16:39 [INFO] exp_shallowmodel: f1_score:   0.468
12/10/2017 02:16:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.58      0.74      0.65       169
          F       0.76      0.88      0.81       281
          R       0.54      0.22      0.31       122

avg / total       0.65      0.68      0.64       592

12/10/2017 02:16:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:39 [INFO] exp_shallowmodel: 
[[  1   1  16   2]
 [  0 125  28  16]
 [  1  28 247   5]
 [  0  60  35  27]]
12/10/2017 02:16:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 02:16:39 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:39 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:40 [INFO] exp_shallowmodel: train time: 0.827s
12/10/2017 02:16:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:40 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 02:16:40 [INFO] exp_shallowmodel: f1_score:   0.538
12/10/2017 02:16:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.20      0.33        20
          C       0.62      0.78      0.69       169
          F       0.76      0.85      0.80       281
          R       0.48      0.25      0.33       122

avg / total       0.67      0.68      0.66       592

12/10/2017 02:16:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:40 [INFO] exp_shallowmodel: 
[[  4   2  12   2]
 [  0 131  21  17]
 [  0  29 239  13]
 [  0  50  42  30]]
12/10/2017 02:16:40 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 02:16:40 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:16:40 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:41 [INFO] exp_shallowmodel: train time: 0.776s
12/10/2017 02:16:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:41 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 02:16:41 [INFO] exp_shallowmodel: f1_score:   0.464
12/10/2017 02:16:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.56      0.74      0.64       169
          F       0.77      0.82      0.79       281
          R       0.58      0.34      0.42       122

avg / total       0.64      0.67      0.65       592

12/10/2017 02:16:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:41 [INFO] exp_shallowmodel: 
[[  0   3  15   2]
 [  0 125  27  17]
 [  0  40 230  11]
 [  0  54  27  41]]
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 02:16:41 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:16:41 [INFO] exp_shallowmodel: #(feature) = 56
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:42 [INFO] exp_shallowmodel: train time: 0.997s
12/10/2017 02:16:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:42 [INFO] exp_shallowmodel: accuracy:   0.680
12/10/2017 02:16:42 [INFO] exp_shallowmodel: f1_score:   0.465
12/10/2017 02:16:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.07        28
          C       0.60      0.76      0.67       172
          F       0.77      0.90      0.83       283
          R       0.45      0.21      0.29       123

avg / total       0.67      0.68      0.64       606

12/10/2017 02:16:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:42 [INFO] exp_shallowmodel: 
[[  1   5  16   6]
 [  0 131  21  20]
 [  0  23 254   6]
 [  0  58  39  26]]
12/10/2017 02:16:46 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:16:46 [INFO] task_runner: context=next, feature=1-basic
12/10/2017 02:16:46 [INFO] task_runner: retained feature numbers=[1, 3, 2.1, 2.2]
12/10/2017 02:16:46 [INFO] task_runner: #(data)=3530
12/10/2017 02:16:46 [INFO] task_runner: #(feature)=62
12/10/2017 02:16:46 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:16:46 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 02:16:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:46 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:47 [INFO] exp_shallowmodel: train time: 0.818s
12/10/2017 02:16:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:47 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:16:47 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 02:16:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.62      0.19      0.29        27
          F       0.73      0.98      0.84       250
          R       0.57      0.08      0.14        52

avg / total       0.65      0.72      0.64       352

12/10/2017 02:16:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:47 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   5  21   1]
 [  2   0 246   2]
 [  0   3  45   4]]
12/10/2017 02:16:47 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 02:16:47 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:47 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:48 [INFO] exp_shallowmodel: train time: 0.543s
12/10/2017 02:16:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:48 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:16:48 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 02:16:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.50      0.15      0.23        27
          F       0.73      0.98      0.84       250
          R       0.56      0.10      0.16        52

avg / total       0.71      0.72      0.64       352

12/10/2017 02:16:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:48 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   4  23   0]
 [  0   4 245   1]
 [  0   0  47   5]]
12/10/2017 02:16:48 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 02:16:48 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:48 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:48 [INFO] exp_shallowmodel: train time: 0.581s
12/10/2017 02:16:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:48 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:16:48 [INFO] exp_shallowmodel: f1_score:   0.296
12/10/2017 02:16:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.30      0.11      0.16        27
          F       0.74      0.97      0.84       250
          R       0.46      0.12      0.18        52

avg / total       0.62      0.71      0.63       352

12/10/2017 02:16:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:48 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   3  22   2]
 [  1   3 242   4]
 [  0   4  42   6]]
12/10/2017 02:16:48 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 02:16:48 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:48 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:49 [INFO] exp_shallowmodel: train time: 0.827s
12/10/2017 02:16:49 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:49 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 02:16:49 [INFO] exp_shallowmodel: f1_score:   0.284
12/10/2017 02:16:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.60      0.11      0.19        27
          F       0.72      0.96      0.83       250
          R       0.29      0.08      0.12        52

avg / total       0.60      0.70      0.62       352

12/10/2017 02:16:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:49 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   3  23   1]
 [  0   2 241   7]
 [  0   0  48   4]]
12/10/2017 02:16:49 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 02:16:49 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:49 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:50 [INFO] exp_shallowmodel: train time: 0.570s
12/10/2017 02:16:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:50 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:50 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 02:16:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.09      0.15        23
          C       0.60      0.11      0.19        27
          F       0.72      0.98      0.83       250
          R       0.43      0.06      0.10        52

avg / total       0.67      0.72      0.63       352

12/10/2017 02:16:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:50 [INFO] exp_shallowmodel: 
[[  2   1  20   0]
 [  0   3  24   0]
 [  1   1 244   4]
 [  0   0  49   3]]
12/10/2017 02:16:50 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 02:16:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:50 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:51 [INFO] exp_shallowmodel: train time: 0.836s
12/10/2017 02:16:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:51 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:16:51 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:16:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.43      0.11      0.18        27
          F       0.74      0.98      0.84       250
          R       0.42      0.10      0.16        52

avg / total       0.62      0.72      0.63       352

12/10/2017 02:16:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:51 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  0   3  23   1]
 [  0   2 245   3]
 [  0   1  46   5]]
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 02:16:51 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:51 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:51 [INFO] exp_shallowmodel: train time: 0.647s
12/10/2017 02:16:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:51 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:16:51 [INFO] exp_shallowmodel: f1_score:   0.313
12/10/2017 02:16:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.67      0.22      0.33        27
          F       0.75      0.99      0.85       250
          R       0.29      0.04      0.07        52

avg / total       0.62      0.73      0.64       352

12/10/2017 02:16:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:51 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   6  18   3]
 [  0   1 248   1]
 [  4   2  44   2]]
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 02:16:51 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:51 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:52 [INFO] exp_shallowmodel: train time: 0.472s
12/10/2017 02:16:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:52 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:16:52 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 02:16:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.43      0.11      0.18        27
          F       0.74      0.98      0.84       250
          R       0.50      0.10      0.16        52

avg / total       0.65      0.72      0.64       352

12/10/2017 02:16:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:52 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  0   3  23   1]
 [  0   2 245   3]
 [  3   1  43   5]]
12/10/2017 02:16:52 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 02:16:52 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:52 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:52 [INFO] exp_shallowmodel: train time: 0.471s
12/10/2017 02:16:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:52 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:16:52 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 02:16:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.83      0.19      0.30        27
          F       0.73      0.98      0.84       250
          R       0.33      0.08      0.12        52

avg / total       0.63      0.72      0.64       352

12/10/2017 02:16:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:52 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  1   5  20   1]
 [  0   0 244   6]
 [  0   1  47   4]]
12/10/2017 02:16:52 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 02:16:52 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:16:52 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:53 [INFO] exp_shallowmodel: train time: 0.676s
12/10/2017 02:16:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:53 [INFO] exp_shallowmodel: accuracy:   0.704
12/10/2017 02:16:53 [INFO] exp_shallowmodel: f1_score:   0.285
12/10/2017 02:16:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        25
          C       0.14      0.04      0.06        27
          F       0.72      0.98      0.83       251
          R       0.55      0.10      0.17        59

avg / total       0.67      0.70      0.61       362

12/10/2017 02:16:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:53 [INFO] exp_shallowmodel: 
[[  1   1  20   3]
 [  0   1  26   0]
 [  0   2 247   2]
 [  0   3  50   6]]
12/10/2017 02:16:53 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 02:16:53 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:53 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:53 [INFO] exp_shallowmodel: train time: 0.494s
12/10/2017 02:16:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:53 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:53 [INFO] exp_shallowmodel: f1_score:   0.281
12/10/2017 02:16:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.40      0.15      0.22        27
          F       0.73      0.98      0.84       250
          R       0.33      0.04      0.07        52

avg / total       0.60      0.72      0.62       352

12/10/2017 02:16:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:53 [INFO] exp_shallowmodel: 
[[  0   1  22   0]
 [  0   4  22   1]
 [  0   1 246   3]
 [  0   4  46   2]]
12/10/2017 02:16:54 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 02:16:54 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:54 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:54 [INFO] exp_shallowmodel: train time: 0.497s
12/10/2017 02:16:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:54 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:16:54 [INFO] exp_shallowmodel: f1_score:   0.313
12/10/2017 02:16:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.75      0.22      0.34        27
          F       0.73      0.98      0.84       250
          R       0.29      0.04      0.07        52

avg / total       0.62      0.72      0.63       352

12/10/2017 02:16:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:54 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  1   6  19   1]
 [  0   1 246   3]
 [  0   0  50   2]]
12/10/2017 02:16:54 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 02:16:54 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:54 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:54 [INFO] exp_shallowmodel: train time: 0.428s
12/10/2017 02:16:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:54 [INFO] exp_shallowmodel: accuracy:   0.733
12/10/2017 02:16:54 [INFO] exp_shallowmodel: f1_score:   0.355
12/10/2017 02:16:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.13      0.23        23
          C       0.50      0.11      0.18        27
          F       0.75      0.99      0.85       250
          R       0.42      0.10      0.16        52

avg / total       0.70      0.73      0.66       352

12/10/2017 02:16:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:54 [INFO] exp_shallowmodel: 
[[  3   0  18   2]
 [  0   3  21   3]
 [  0   1 247   2]
 [  0   2  45   5]]
12/10/2017 02:16:54 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 02:16:54 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:54 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:55 [INFO] exp_shallowmodel: train time: 0.499s
12/10/2017 02:16:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:55 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:16:55 [INFO] exp_shallowmodel: f1_score:   0.313
12/10/2017 02:16:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.44      0.15      0.22        27
          F       0.73      0.97      0.84       250
          R       0.60      0.12      0.19        52

avg / total       0.64      0.72      0.64       352

12/10/2017 02:16:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:55 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  0   4  23   0]
 [  1   3 243   3]
 [  1   1  44   6]]
12/10/2017 02:16:55 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 02:16:55 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:55 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:55 [INFO] exp_shallowmodel: train time: 0.456s
12/10/2017 02:16:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:55 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:16:55 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 02:16:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.62      0.19      0.29        27
          F       0.74      0.98      0.84       250
          R       0.46      0.12      0.18        52

avg / total       0.64      0.73      0.65       352

12/10/2017 02:16:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:55 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   5  19   3]
 [  1   2 245   2]
 [  0   1  45   6]]
12/10/2017 02:16:55 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 02:16:55 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:55 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:56 [INFO] exp_shallowmodel: train time: 0.425s
12/10/2017 02:16:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:56 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 02:16:56 [INFO] exp_shallowmodel: f1_score:   0.357
12/10/2017 02:16:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.80      0.15      0.25        27
          F       0.75      0.99      0.85       250
          R       0.62      0.15      0.25        52

avg / total       0.72      0.74      0.67       352

12/10/2017 02:16:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:56 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   4  23   0]
 [  0   0 248   2]
 [  1   0  43   8]]
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 02:16:56 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:56 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:57 [INFO] exp_shallowmodel: train time: 0.700s
12/10/2017 02:16:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:57 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:16:57 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 02:16:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.29      0.07      0.12        27
          F       0.73      0.97      0.83       250
          R       0.40      0.08      0.13        52

avg / total       0.63      0.71      0.63       352

12/10/2017 02:16:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:57 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   2  24   1]
 [  0   3 243   4]
 [  1   2  45   4]]
12/10/2017 02:16:57 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 02:16:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:57 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:57 [INFO] exp_shallowmodel: train time: 0.709s
12/10/2017 02:16:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:57 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:16:57 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 02:16:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.75      0.11      0.19        27
          F       0.73      0.98      0.84       250
          R       0.30      0.06      0.10        52

avg / total       0.65      0.72      0.63       352

12/10/2017 02:16:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:57 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   3  22   2]
 [  1   0 245   4]
 [  0   1  48   3]]
12/10/2017 02:16:57 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 02:16:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:57 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:58 [INFO] exp_shallowmodel: train time: 0.537s
12/10/2017 02:16:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:58 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:16:58 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 02:16:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.50      0.15      0.23        27
          F       0.74      0.98      0.85       250
          R       0.50      0.08      0.13        52

avg / total       0.65      0.72      0.64       352

12/10/2017 02:16:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:58 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   4  23   0]
 [  0   3 246   1]
 [  3   0  45   4]]
12/10/2017 02:16:58 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 02:16:58 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:16:58 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:58 [INFO] exp_shallowmodel: train time: 0.478s
12/10/2017 02:16:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:58 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:16:58 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 02:16:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.07        25
          C       0.50      0.15      0.23        27
          F       0.72      0.97      0.83       251
          R       0.54      0.12      0.19        59

avg / total       0.65      0.71      0.63       362

12/10/2017 02:16:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:58 [INFO] exp_shallowmodel: 
[[  1   0  23   1]
 [  0   4  21   2]
 [  1   3 244   3]
 [  1   1  50   7]]
12/10/2017 02:16:58 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 02:16:58 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:58 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:59 [INFO] exp_shallowmodel: train time: 0.494s
12/10/2017 02:16:59 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:59 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:16:59 [INFO] exp_shallowmodel: f1_score:   0.339
12/10/2017 02:16:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.60      0.22      0.32        27
          F       0.75      0.98      0.85       250
          R       0.46      0.12      0.18        52

avg / total       0.64      0.73      0.65       352

12/10/2017 02:16:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:59 [INFO] exp_shallowmodel: 
[[  0   1  18   4]
 [  0   6  21   0]
 [  0   2 245   3]
 [  1   1  44   6]]
12/10/2017 02:16:59 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 02:16:59 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:16:59 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:16:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:00 [INFO] exp_shallowmodel: train time: 0.789s
12/10/2017 02:17:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:00 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:17:00 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 02:17:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.50      0.22      0.31        27
          F       0.75      0.97      0.84       250
          R       0.45      0.10      0.16        52

avg / total       0.66      0.72      0.65       352

12/10/2017 02:17:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:00 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   6  19   2]
 [  1   3 243   3]
 [  1   3  43   5]]
12/10/2017 02:17:00 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 02:17:00 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:00 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:00 [INFO] exp_shallowmodel: train time: 0.803s
12/10/2017 02:17:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:00 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:17:00 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 02:17:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.09      0.15        23
          C       0.33      0.11      0.17        27
          F       0.74      0.98      0.84       250
          R       0.56      0.10      0.16        52

avg / total       0.67      0.72      0.64       352

12/10/2017 02:17:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:00 [INFO] exp_shallowmodel: 
[[  2   1  19   1]
 [  0   3  22   2]
 [  0   5 244   1]
 [  1   0  46   5]]
12/10/2017 02:17:00 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 02:17:00 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:00 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:01 [INFO] exp_shallowmodel: train time: 0.452s
12/10/2017 02:17:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:01 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:17:01 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 02:17:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.75      0.22      0.34        27
          F       0.74      0.98      0.84       250
          R       0.33      0.08      0.12        52

avg / total       0.63      0.72      0.64       352

12/10/2017 02:17:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:01 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   6  19   2]
 [  0   0 245   5]
 [  0   2  46   4]]
12/10/2017 02:17:01 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 02:17:01 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:01 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:01 [INFO] exp_shallowmodel: train time: 0.596s
12/10/2017 02:17:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:01 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:17:01 [INFO] exp_shallowmodel: f1_score:   0.256
12/10/2017 02:17:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.04      0.07        27
          F       0.73      0.98      0.84       250
          R       0.27      0.08      0.12        52

avg / total       0.60      0.71      0.62       352

12/10/2017 02:17:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:01 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   1  23   3]
 [  0   0 245   5]
 [  0   1  47   4]]
12/10/2017 02:17:01 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 02:17:01 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:01 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:02 [INFO] exp_shallowmodel: train time: 0.823s
12/10/2017 02:17:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:02 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:17:02 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 02:17:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.15      0.23        27
          F       0.74      0.99      0.84       250
          R       0.56      0.10      0.16        52

avg / total       0.64      0.73      0.64       352

12/10/2017 02:17:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:02 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   4  23   0]
 [  0   1 247   2]
 [  0   3  44   5]]
12/10/2017 02:17:02 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 02:17:02 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:02 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:03 [INFO] exp_shallowmodel: train time: 0.457s
12/10/2017 02:17:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:03 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:17:03 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 02:17:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.29      0.07      0.12        27
          F       0.74      0.97      0.84       250
          R       0.41      0.13      0.20        52

avg / total       0.61      0.71      0.63       352

12/10/2017 02:17:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:03 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  0   2  22   3]
 [  0   2 242   6]
 [  0   2  43   7]]
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 02:17:03 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:03 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:03 [INFO] exp_shallowmodel: train time: 0.636s
12/10/2017 02:17:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:03 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:17:03 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 02:17:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.09      0.16        23
          C       1.00      0.11      0.20        27
          F       0.73      0.98      0.84       250
          R       0.33      0.08      0.12        52

avg / total       0.71      0.72      0.64       352

12/10/2017 02:17:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:03 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   3  21   3]
 [  0   0 246   4]
 [  0   0  48   4]]
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 02:17:03 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:03 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:04 [INFO] exp_shallowmodel: train time: 0.483s
12/10/2017 02:17:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:04 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:17:04 [INFO] exp_shallowmodel: f1_score:   0.280
12/10/2017 02:17:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.38      0.11      0.17        27
          F       0.73      0.99      0.84       250
          R       0.75      0.06      0.11        52

avg / total       0.66      0.72      0.63       352

12/10/2017 02:17:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:04 [INFO] exp_shallowmodel: 
[[  0   2  21   0]
 [  0   3  24   0]
 [  1   1 247   1]
 [  1   2  46   3]]
12/10/2017 02:17:04 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 02:17:04 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:17:04 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:04 [INFO] exp_shallowmodel: train time: 0.520s
12/10/2017 02:17:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:04 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:17:04 [INFO] exp_shallowmodel: f1_score:   0.294
12/10/2017 02:17:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.08      0.14        25
          C       0.33      0.07      0.12        27
          F       0.71      0.98      0.82       251
          R       0.50      0.05      0.09        59

avg / total       0.63      0.70      0.61       362

12/10/2017 02:17:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:04 [INFO] exp_shallowmodel: 
[[  2   1  21   1]
 [  0   2  25   0]
 [  2   1 246   2]
 [  0   2  54   3]]
12/10/2017 02:17:04 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 02:17:04 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:04 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:05 [INFO] exp_shallowmodel: train time: 0.529s
12/10/2017 02:17:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:05 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:17:05 [INFO] exp_shallowmodel: f1_score:   0.376
12/10/2017 02:17:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.50      0.22      0.31        27
          F       0.76      0.99      0.86       250
          R       0.80      0.15      0.26        52

avg / total       0.73      0.75      0.68       352

12/10/2017 02:17:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:05 [INFO] exp_shallowmodel: 
[[  1   2  19   1]
 [  0   6  21   0]
 [  0   1 248   1]
 [  1   3  40   8]]
12/10/2017 02:17:05 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 02:17:05 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:05 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:05 [INFO] exp_shallowmodel: train time: 0.521s
12/10/2017 02:17:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:05 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:17:05 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 02:17:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.50      0.11      0.18        27
          F       0.73      0.96      0.83       250
          R       0.58      0.13      0.22        52

avg / total       0.67      0.72      0.64       352

12/10/2017 02:17:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:05 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   3  24   0]
 [  1   3 241   5]
 [  0   0  45   7]]
12/10/2017 02:17:05 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 02:17:05 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:05 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:06 [INFO] exp_shallowmodel: train time: 0.477s
12/10/2017 02:17:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:06 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:17:06 [INFO] exp_shallowmodel: f1_score:   0.322
12/10/2017 02:17:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.09      0.16        23
          C       0.43      0.11      0.18        27
          F       0.74      1.00      0.85       250
          R       0.43      0.06      0.10        52

avg / total       0.69      0.73      0.64       352

12/10/2017 02:17:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:06 [INFO] exp_shallowmodel: 
[[  2   1  19   1]
 [  0   3  21   3]
 [  0   1 249   0]
 [  0   2  47   3]]
12/10/2017 02:17:06 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 02:17:06 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:06 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:07 [INFO] exp_shallowmodel: train time: 0.690s
12/10/2017 02:17:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:07 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:17:07 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 02:17:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.50      0.11      0.18        27
          F       0.73      0.98      0.84       250
          R       0.54      0.13      0.22        52

avg / total       0.71      0.72      0.65       352

12/10/2017 02:17:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:07 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   3  24   0]
 [  0   2 244   4]
 [  0   0  45   7]]
12/10/2017 02:17:07 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 02:17:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:07 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:07 [INFO] exp_shallowmodel: train time: 0.718s
12/10/2017 02:17:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:07 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:17:07 [INFO] exp_shallowmodel: f1_score:   0.303
12/10/2017 02:17:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.19      0.27        27
          F       0.74      0.98      0.84       250
          R       0.33      0.06      0.10        52

avg / total       0.61      0.72      0.63       352

12/10/2017 02:17:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:07 [INFO] exp_shallowmodel: 
[[  0   1  20   2]
 [  0   5  20   2]
 [  1   2 245   2]
 [  1   2  46   3]]
12/10/2017 02:17:07 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 02:17:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:07 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:08 [INFO] exp_shallowmodel: train time: 0.543s
12/10/2017 02:17:08 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:08 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:17:08 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 02:17:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.09      0.15        23
          C       0.44      0.15      0.22        27
          F       0.73      0.96      0.83       250
          R       0.36      0.08      0.13        52

avg / total       0.64      0.71      0.64       352

12/10/2017 02:17:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:08 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   4  23   0]
 [  1   3 240   6]
 [  1   2  45   4]]
12/10/2017 02:17:08 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 02:17:08 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:08 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:09 [INFO] exp_shallowmodel: train time: 0.723s
12/10/2017 02:17:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:09 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 02:17:09 [INFO] exp_shallowmodel: f1_score:   0.224
12/10/2017 02:17:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.04      0.07        27
          F       0.73      0.97      0.83       250
          R       0.00      0.00      0.00        52

avg / total       0.54      0.69      0.60       352

12/10/2017 02:17:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:09 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   1  23   3]
 [  2   1 243   4]
 [  2   1  49   0]]
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 02:17:09 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:09 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:09 [INFO] exp_shallowmodel: train time: 0.536s
12/10/2017 02:17:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:09 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:17:09 [INFO] exp_shallowmodel: f1_score:   0.301
12/10/2017 02:17:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.57      0.15      0.24        27
          F       0.72      0.98      0.83       250
          R       0.57      0.08      0.14        52

avg / total       0.64      0.72      0.63       352

12/10/2017 02:17:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:09 [INFO] exp_shallowmodel: 
[[  0   1  22   0]
 [  0   4  23   0]
 [  0   2 245   3]
 [  0   0  48   4]]
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 02:17:09 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:09 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:10 [INFO] exp_shallowmodel: train time: 0.506s
12/10/2017 02:17:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:10 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:17:10 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 02:17:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.20      0.04      0.06        27
          F       0.73      0.97      0.83       250
          R       0.40      0.08      0.13        52

avg / total       0.61      0.71      0.62       352

12/10/2017 02:17:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:10 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  1   1  23   2]
 [  1   3 243   3]
 [  0   1  47   4]]
12/10/2017 02:17:10 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 02:17:10 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:17:10 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:10 [INFO] exp_shallowmodel: train time: 0.468s
12/10/2017 02:17:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:10 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:17:10 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 02:17:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        25
          C       0.78      0.26      0.39        27
          F       0.73      0.99      0.84       251
          R       0.55      0.10      0.17        59

avg / total       0.72      0.72      0.64       362

12/10/2017 02:17:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:10 [INFO] exp_shallowmodel: 
[[  1   0  24   0]
 [  0   7  17   3]
 [  0   1 248   2]
 [  0   1  52   6]]
12/10/2017 02:17:10 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 02:17:10 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:10 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:11 [INFO] exp_shallowmodel: train time: 0.460s
12/10/2017 02:17:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:11 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:17:11 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 02:17:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.42      0.19      0.26        27
          F       0.74      0.98      0.84       250
          R       0.50      0.06      0.10        52

avg / total       0.66      0.72      0.64       352

12/10/2017 02:17:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:11 [INFO] exp_shallowmodel: 
[[  1   1  21   0]
 [  0   5  22   0]
 [  0   2 245   3]
 [  1   4  44   3]]
12/10/2017 02:17:11 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 02:17:11 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:11 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:11 [INFO] exp_shallowmodel: train time: 0.603s
12/10/2017 02:17:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:11 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:17:11 [INFO] exp_shallowmodel: f1_score:   0.295
12/10/2017 02:17:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.40      0.15      0.22        27
          F       0.74      0.97      0.84       250
          R       0.36      0.08      0.13        52

avg / total       0.61      0.71      0.63       352

12/10/2017 02:17:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:11 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  0   4  22   1]
 [  1   2 242   5]
 [  1   3  44   4]]
12/10/2017 02:17:11 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 02:17:11 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:11 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:12 [INFO] exp_shallowmodel: train time: 0.788s
12/10/2017 02:17:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:12 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:17:12 [INFO] exp_shallowmodel: f1_score:   0.308
12/10/2017 02:17:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.83      0.19      0.30        27
          F       0.73      0.97      0.83       250
          R       0.27      0.06      0.10        52

avg / total       0.62      0.71      0.63       352

12/10/2017 02:17:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:12 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  1   5  21   0]
 [  0   1 243   6]
 [  0   0  49   3]]
12/10/2017 02:17:12 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 02:17:12 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:12 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:13 [INFO] exp_shallowmodel: train time: 0.434s
12/10/2017 02:17:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:13 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:17:13 [INFO] exp_shallowmodel: f1_score:   0.296
12/10/2017 02:17:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.33      0.04      0.07        27
          F       0.74      0.99      0.84       250
          R       0.55      0.12      0.19        52

avg / total       0.69      0.73      0.64       352

12/10/2017 02:17:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:13 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   1  23   3]
 [  0   1 248   1]
 [  0   1  45   6]]
12/10/2017 02:17:13 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 02:17:13 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:13 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:13 [INFO] exp_shallowmodel: train time: 0.495s
12/10/2017 02:17:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:13 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:17:13 [INFO] exp_shallowmodel: f1_score:   0.346
12/10/2017 02:17:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.44      0.15      0.22        27
          F       0.74      0.97      0.84       250
          R       0.57      0.15      0.24        52

avg / total       0.68      0.72      0.65       352

12/10/2017 02:17:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:13 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   4  23   0]
 [  1   3 242   4]
 [  0   2  42   8]]
12/10/2017 02:17:13 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 02:17:13 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:13 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:14 [INFO] exp_shallowmodel: train time: 0.692s
12/10/2017 02:17:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:14 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:17:14 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 02:17:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.67      0.15      0.24        27
          F       0.74      0.99      0.85       250
          R       0.56      0.10      0.16        52

avg / total       0.67      0.73      0.65       352

12/10/2017 02:17:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:14 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  1   4  20   2]
 [  1   1 247   1]
 [  2   0  45   5]]
12/10/2017 02:17:14 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 02:17:14 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:14 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:15 [INFO] exp_shallowmodel: train time: 0.804s
12/10/2017 02:17:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:15 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:17:15 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 02:17:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.60      0.22      0.32        27
          F       0.75      0.98      0.85       250
          R       0.38      0.10      0.15        52

avg / total       0.64      0.73      0.65       352

12/10/2017 02:17:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:15 [INFO] exp_shallowmodel: 
[[  0   2  17   4]
 [  0   6  20   1]
 [  1   0 246   3]
 [  0   2  45   5]]
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 02:17:15 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:15 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:15 [INFO] exp_shallowmodel: train time: 0.647s
12/10/2017 02:17:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:15 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:17:15 [INFO] exp_shallowmodel: f1_score:   0.308
12/10/2017 02:17:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.44      0.15      0.22        27
          F       0.73      0.97      0.83       250
          R       0.38      0.06      0.10        52

avg / total       0.63      0.71      0.63       352

12/10/2017 02:17:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:15 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   4  23   0]
 [  1   2 242   5]
 [  1   3  45   3]]
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 02:17:15 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:17:15 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:16 [INFO] exp_shallowmodel: train time: 0.449s
12/10/2017 02:17:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:16 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:17:16 [INFO] exp_shallowmodel: f1_score:   0.321
12/10/2017 02:17:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.67      0.15      0.24        27
          F       0.74      0.98      0.84       250
          R       0.36      0.08      0.13        52

avg / total       0.64      0.72      0.64       352

12/10/2017 02:17:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:16 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   4  22   1]
 [  0   2 244   4]
 [  4   0  44   4]]
12/10/2017 02:17:16 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 02:17:16 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:17:16 [INFO] exp_shallowmodel: #(feature) = 62
12/10/2017 02:17:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:16 [INFO] exp_shallowmodel: train time: 0.492s
12/10/2017 02:17:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:16 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:17:16 [INFO] exp_shallowmodel: f1_score:   0.273
12/10/2017 02:17:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.07        25
          C       0.67      0.07      0.13        27
          F       0.71      0.99      0.83       251
          R       0.25      0.03      0.06        59

avg / total       0.62      0.70      0.60       362

12/10/2017 02:17:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:16 [INFO] exp_shallowmodel: 
[[  1   0  23   1]
 [  0   2  22   3]
 [  0   1 248   2]
 [  1   0  56   2]]
12/10/2017 02:17:22 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:17:22 [INFO] task_runner: context=next, feature=1-basic
12/10/2017 02:17:22 [INFO] task_runner: retained feature numbers=[1, 3, 2.1, 2.2]
12/10/2017 02:17:22 [INFO] task_runner: #(data)=5241
12/10/2017 02:17:22 [INFO] task_runner: #(feature)=92
12/10/2017 02:17:22 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:17:22 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 02:17:22 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:22 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:23 [INFO] exp_shallowmodel: train time: 1.234s
12/10/2017 02:17:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:23 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:17:23 [INFO] exp_shallowmodel: f1_score:   0.281
12/10/2017 02:17:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.87       396
          R       0.27      0.07      0.11        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:17:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:23 [INFO] exp_shallowmodel: 
[[  5   0  52   2]
 [  1   0  10   1]
 [  2   0 386   8]
 [  2   1  48   4]]
12/10/2017 02:17:23 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 02:17:23 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:23 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:25 [INFO] exp_shallowmodel: train time: 1.701s
12/10/2017 02:17:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:25 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:17:25 [INFO] exp_shallowmodel: f1_score:   0.253
12/10/2017 02:17:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.21      0.05      0.09        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:17:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:25 [INFO] exp_shallowmodel: 
[[  2   0  53   4]
 [  1   0  10   1]
 [  3   1 386   6]
 [  1   1  50   3]]
12/10/2017 02:17:25 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 02:17:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:25 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:26 [INFO] exp_shallowmodel: train time: 1.456s
12/10/2017 02:17:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:26 [INFO] exp_shallowmodel: accuracy:   0.745
12/10/2017 02:17:26 [INFO] exp_shallowmodel: f1_score:   0.250
12/10/2017 02:17:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.27      0.07      0.11        55

avg / total       0.63      0.75      0.67       522

12/10/2017 02:17:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:26 [INFO] exp_shallowmodel: 
[[  1   0  55   3]
 [  1   0  11   0]
 [  4   0 384   8]
 [  0   0  51   4]]
12/10/2017 02:17:26 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 02:17:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:26 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:27 [INFO] exp_shallowmodel: train time: 1.354s
12/10/2017 02:17:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:27 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:17:27 [INFO] exp_shallowmodel: f1_score:   0.272
12/10/2017 02:17:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.05      0.08        59
          C       0.00      0.00      0.00        12
          F       0.77      0.96      0.86       396
          R       0.38      0.09      0.15        55

avg / total       0.65      0.75      0.68       522

12/10/2017 02:17:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:27 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  0   0  10   2]
 [  9   0 382   5]
 [  4   0  46   5]]
12/10/2017 02:17:27 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 02:17:27 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:27 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:29 [INFO] exp_shallowmodel: train time: 1.256s
12/10/2017 02:17:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:29 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:17:29 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 02:17:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.07      0.11        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.36      0.07      0.12        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:17:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:29 [INFO] exp_shallowmodel: 
[[  4   1  52   2]
 [  0   0  12   0]
 [  3   0 388   5]
 [  4   0  47   4]]
12/10/2017 02:17:29 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 02:17:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:29 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:30 [INFO] exp_shallowmodel: train time: 1.183s
12/10/2017 02:17:30 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:30 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:17:30 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 02:17:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.05      0.09        59
          C       0.50      0.08      0.14        12
          F       0.78      0.98      0.87       396
          R       0.21      0.05      0.09        55

avg / total       0.69      0.76      0.68       522

12/10/2017 02:17:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:30 [INFO] exp_shallowmodel: 
[[  3   0  52   4]
 [  0   1  10   1]
 [  0   1 389   6]
 [  2   0  50   3]]
12/10/2017 02:17:30 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 02:17:30 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:30 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:32 [INFO] exp_shallowmodel: train time: 1.560s
12/10/2017 02:17:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:32 [INFO] exp_shallowmodel: accuracy:   0.776
12/10/2017 02:17:32 [INFO] exp_shallowmodel: f1_score:   0.344
12/10/2017 02:17:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.10      0.17        59
          C       0.50      0.08      0.14        12
          F       0.79      0.99      0.88       396
          R       0.75      0.11      0.19        55

avg / total       0.74      0.78      0.71       522

12/10/2017 02:17:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:32 [INFO] exp_shallowmodel: 
[[  6   1  51   1]
 [  1   1  10   0]
 [  3   0 392   1]
 [  3   0  46   6]]
12/10/2017 02:17:32 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 02:17:32 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:32 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:33 [INFO] exp_shallowmodel: train time: 1.501s
12/10/2017 02:17:33 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:33 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:17:33 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 02:17:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.67      0.11      0.19        55

avg / total       0.71      0.76      0.69       522

12/10/2017 02:17:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:33 [INFO] exp_shallowmodel: 
[[  5   0  53   1]
 [  0   0  12   0]
 [  5   1 388   2]
 [  2   1  46   6]]
12/10/2017 02:17:33 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 02:17:33 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:33 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:34 [INFO] exp_shallowmodel: train time: 0.970s
12/10/2017 02:17:34 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:34 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:17:34 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:17:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.05      0.09        59
          C       1.00      0.08      0.15        12
          F       0.77      0.98      0.86       396
          R       0.33      0.04      0.07        55

avg / total       0.68      0.76      0.68       522

12/10/2017 02:17:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:34 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  0   1  11   0]
 [  3   0 390   3]
 [  2   0  51   2]]
12/10/2017 02:17:34 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 02:17:34 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:17:34 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:35 [INFO] exp_shallowmodel: train time: 1.383s
12/10/2017 02:17:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:35 [INFO] exp_shallowmodel: accuracy:   0.746
12/10/2017 02:17:35 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 02:17:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.08      0.14        64
          C       0.00      0.00      0.00        14
          F       0.76      0.99      0.86       402
          R       0.44      0.06      0.11        63

avg / total       0.68      0.75      0.66       543

12/10/2017 02:17:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:35 [INFO] exp_shallowmodel: 
[[  5   0  58   1]
 [  1   0  13   0]
 [  1   1 396   4]
 [  2   0  57   4]]
12/10/2017 02:17:35 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 02:17:35 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:35 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:37 [INFO] exp_shallowmodel: train time: 1.556s
12/10/2017 02:17:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:37 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:17:37 [INFO] exp_shallowmodel: f1_score:   0.280
12/10/2017 02:17:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.86       396
          R       0.33      0.07      0.12        55

avg / total       0.66      0.75      0.68       522

12/10/2017 02:17:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:37 [INFO] exp_shallowmodel: 
[[  5   0  52   2]
 [  0   0  12   0]
 [  5   0 385   6]
 [  4   0  47   4]]
12/10/2017 02:17:37 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 02:17:37 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:37 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:39 [INFO] exp_shallowmodel: train time: 1.853s
12/10/2017 02:17:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:39 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:17:39 [INFO] exp_shallowmodel: f1_score:   0.284
12/10/2017 02:17:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.11        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.50      0.09      0.15        55

avg / total       0.68      0.76      0.69       522

12/10/2017 02:17:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:39 [INFO] exp_shallowmodel: 
[[  4   0  54   1]
 [  0   0  10   2]
 [  5   0 389   2]
 [  3   0  47   5]]
12/10/2017 02:17:39 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 02:17:39 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:39 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:40 [INFO] exp_shallowmodel: train time: 1.459s
12/10/2017 02:17:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:40 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:17:40 [INFO] exp_shallowmodel: f1_score:   0.274
12/10/2017 02:17:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.33      0.09      0.14        55

avg / total       0.67      0.75      0.68       522

12/10/2017 02:17:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:40 [INFO] exp_shallowmodel: 
[[  3   0  54   2]
 [  2   0  10   0]
 [  2   0 386   8]
 [  0   0  50   5]]
12/10/2017 02:17:40 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 02:17:40 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:40 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:42 [INFO] exp_shallowmodel: train time: 1.857s
12/10/2017 02:17:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:42 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 02:17:42 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 02:17:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.08      0.15        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.58      0.13      0.21        55

avg / total       0.71      0.77      0.70       522

12/10/2017 02:17:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:42 [INFO] exp_shallowmodel: 
[[  5   0  53   1]
 [  0   0  10   2]
 [  4   0 390   2]
 [  0   0  48   7]]
12/10/2017 02:17:42 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 02:17:42 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:42 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:44 [INFO] exp_shallowmodel: train time: 1.353s
12/10/2017 02:17:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:44 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:17:44 [INFO] exp_shallowmodel: f1_score:   0.277
12/10/2017 02:17:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.87       396
          R       0.36      0.07      0.12        55

avg / total       0.68      0.76      0.68       522

12/10/2017 02:17:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:44 [INFO] exp_shallowmodel: 
[[  4   0  54   1]
 [  1   0  11   0]
 [  0   1 389   6]
 [  3   0  48   4]]
12/10/2017 02:17:44 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 02:17:44 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:44 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:46 [INFO] exp_shallowmodel: train time: 2.110s
12/10/2017 02:17:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:46 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:17:46 [INFO] exp_shallowmodel: f1_score:   0.271
12/10/2017 02:17:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.05      0.10        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.36      0.07      0.12        55

avg / total       0.71      0.76      0.68       522

12/10/2017 02:17:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:46 [INFO] exp_shallowmodel: 
[[  3   0  54   2]
 [  0   0  11   1]
 [  0   0 392   4]
 [  1   1  49   4]]
12/10/2017 02:17:46 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 02:17:46 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:46 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:48 [INFO] exp_shallowmodel: train time: 1.847s
12/10/2017 02:17:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:48 [INFO] exp_shallowmodel: accuracy:   0.774
12/10/2017 02:17:48 [INFO] exp_shallowmodel: f1_score:   0.296
12/10/2017 02:17:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.71      0.08      0.15        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.88       396
          R       0.56      0.09      0.16        55

avg / total       0.73      0.77      0.70       522

12/10/2017 02:17:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:48 [INFO] exp_shallowmodel: 
[[  5   1  51   2]
 [  0   0  11   1]
 [  0   1 394   1]
 [  2   0  48   5]]
12/10/2017 02:17:48 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 02:17:48 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:48 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:49 [INFO] exp_shallowmodel: train time: 1.563s
12/10/2017 02:17:49 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:49 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:17:49 [INFO] exp_shallowmodel: f1_score:   0.263
12/10/2017 02:17:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.87       396
          R       0.43      0.05      0.10        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:17:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:49 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  1   0  10   1]
 [  3   1 390   2]
 [  2   0  50   3]]
12/10/2017 02:17:49 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 02:17:49 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:49 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:50 [INFO] exp_shallowmodel: train time: 1.268s
12/10/2017 02:17:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:50 [INFO] exp_shallowmodel: accuracy:   0.745
12/10/2017 02:17:50 [INFO] exp_shallowmodel: f1_score:   0.252
12/10/2017 02:17:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.27      0.05      0.09        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:17:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:50 [INFO] exp_shallowmodel: 
[[  2   2  53   2]
 [  1   0  11   0]
 [  6   0 384   6]
 [  1   0  51   3]]
12/10/2017 02:17:50 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 02:17:50 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:17:50 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:52 [INFO] exp_shallowmodel: train time: 1.282s
12/10/2017 02:17:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:52 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:17:52 [INFO] exp_shallowmodel: f1_score:   0.321
12/10/2017 02:17:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.06      0.11        64
          C       1.00      0.07      0.13        14
          F       0.76      0.99      0.86       402
          R       0.50      0.11      0.18        63

avg / total       0.70      0.75      0.67       543

12/10/2017 02:17:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:52 [INFO] exp_shallowmodel: 
[[  4   0  55   5]
 [  0   1  13   0]
 [  4   0 396   2]
 [  2   0  54   7]]
12/10/2017 02:17:52 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 02:17:52 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:52 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:53 [INFO] exp_shallowmodel: train time: 1.293s
12/10/2017 02:17:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:53 [INFO] exp_shallowmodel: accuracy:   0.768
12/10/2017 02:17:53 [INFO] exp_shallowmodel: f1_score:   0.305
12/10/2017 02:17:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.64      0.12      0.20        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.45      0.09      0.15        55

avg / total       0.71      0.77      0.70       522

12/10/2017 02:17:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:53 [INFO] exp_shallowmodel: 
[[  7   0  51   1]
 [  0   0  12   0]
 [  2   0 389   5]
 [  2   1  47   5]]
12/10/2017 02:17:53 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 02:17:53 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:53 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:55 [INFO] exp_shallowmodel: train time: 1.789s
12/10/2017 02:17:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:55 [INFO] exp_shallowmodel: accuracy:   0.739
12/10/2017 02:17:55 [INFO] exp_shallowmodel: f1_score:   0.243
12/10/2017 02:17:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.96      0.85       396
          R       0.07      0.02      0.03        55

avg / total       0.63      0.74      0.66       522

12/10/2017 02:17:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:55 [INFO] exp_shallowmodel: 
[[  3   1  55   0]
 [  0   0  10   2]
 [  2   1 382  11]
 [  3   0  51   1]]
12/10/2017 02:17:55 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 02:17:55 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:55 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:56 [INFO] exp_shallowmodel: train time: 1.241s
12/10/2017 02:17:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:56 [INFO] exp_shallowmodel: accuracy:   0.768
12/10/2017 02:17:56 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 02:17:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       1.00      0.09      0.17        55

avg / total       0.73      0.77      0.69       522

12/10/2017 02:17:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:56 [INFO] exp_shallowmodel: 
[[  2   1  56   0]
 [  1   0  11   0]
 [  2   0 394   0]
 [  1   1  48   5]]
12/10/2017 02:17:56 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 02:17:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:56 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:57 [INFO] exp_shallowmodel: train time: 1.055s
12/10/2017 02:17:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:57 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:17:57 [INFO] exp_shallowmodel: f1_score:   0.278
12/10/2017 02:17:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.86       396
          R       0.33      0.11      0.16        55

avg / total       0.66      0.75      0.68       522

12/10/2017 02:17:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:57 [INFO] exp_shallowmodel: 
[[  3   0  52   4]
 [  0   0  11   1]
 [  4   2 383   7]
 [  4   0  45   6]]
12/10/2017 02:17:57 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 02:17:57 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:57 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:58 [INFO] exp_shallowmodel: train time: 1.319s
12/10/2017 02:17:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:58 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:17:58 [INFO] exp_shallowmodel: f1_score:   0.238
12/10/2017 02:17:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.17      0.02      0.03        55

avg / total       0.62      0.75      0.66       522

12/10/2017 02:17:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:58 [INFO] exp_shallowmodel: 
[[  2   0  54   3]
 [  1   0  11   0]
 [  5   0 389   2]
 [  1   0  53   1]]
12/10/2017 02:17:58 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 02:17:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:17:58 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:17:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:00 [INFO] exp_shallowmodel: train time: 1.571s
12/10/2017 02:18:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:00 [INFO] exp_shallowmodel: accuracy:   0.772
12/10/2017 02:18:00 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:18:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.62      0.15      0.24        55

avg / total       0.71      0.77      0.70       522

12/10/2017 02:18:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:00 [INFO] exp_shallowmodel: 
[[  2   1  53   3]
 [  0   0  12   0]
 [  0   1 393   2]
 [  2   0  45   8]]
12/10/2017 02:18:00 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 02:18:00 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:00 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:02 [INFO] exp_shallowmodel: train time: 1.589s
12/10/2017 02:18:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:02 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:18:02 [INFO] exp_shallowmodel: f1_score:   0.283
12/10/2017 02:18:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.64      0.12      0.20        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.87       396
          R       0.29      0.04      0.06        55

avg / total       0.69      0.76      0.69       522

12/10/2017 02:18:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:02 [INFO] exp_shallowmodel: 
[[  7   0  50   2]
 [  0   0  12   0]
 [  3   0 390   3]
 [  1   0  52   2]]
12/10/2017 02:18:02 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 02:18:02 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:02 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:03 [INFO] exp_shallowmodel: train time: 1.339s
12/10/2017 02:18:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:03 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:18:03 [INFO] exp_shallowmodel: f1_score:   0.255
12/10/2017 02:18:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.38      0.05      0.10        55

avg / total       0.66      0.76      0.67       522

12/10/2017 02:18:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:03 [INFO] exp_shallowmodel: 
[[  2   0  55   2]
 [  0   0  11   1]
 [  4   0 390   2]
 [  0   0  52   3]]
12/10/2017 02:18:03 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 02:18:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:03 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:04 [INFO] exp_shallowmodel: train time: 1.199s
12/10/2017 02:18:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:04 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:18:04 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 02:18:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.36      0.09      0.14        55

avg / total       0.68      0.76      0.69       522

12/10/2017 02:18:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:04 [INFO] exp_shallowmodel: 
[[  5   0  52   2]
 [  1   0  10   1]
 [  3   0 387   6]
 [  1   0  49   5]]
12/10/2017 02:18:04 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 02:18:04 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:18:04 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:06 [INFO] exp_shallowmodel: train time: 1.493s
12/10/2017 02:18:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:06 [INFO] exp_shallowmodel: accuracy:   0.746
12/10/2017 02:18:06 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:18:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.09      0.15        64
          C       0.00      0.00      0.00        14
          F       0.76      0.98      0.86       402
          R       0.55      0.10      0.16        63

avg / total       0.68      0.75      0.67       543

12/10/2017 02:18:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:06 [INFO] exp_shallowmodel: 
[[  6   0  56   2]
 [  2   0  12   0]
 [  6   0 393   3]
 [  0   1  56   6]]
12/10/2017 02:18:06 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 02:18:06 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:06 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:07 [INFO] exp_shallowmodel: train time: 1.222s
12/10/2017 02:18:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:07 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:18:07 [INFO] exp_shallowmodel: f1_score:   0.283
12/10/2017 02:18:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.08      0.15        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.36      0.07      0.12        55

avg / total       0.69      0.76      0.68       522

12/10/2017 02:18:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:07 [INFO] exp_shallowmodel: 
[[  5   1  52   1]
 [  1   0  11   0]
 [  3   0 387   6]
 [  0   1  50   4]]
12/10/2017 02:18:07 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 02:18:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:07 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:09 [INFO] exp_shallowmodel: train time: 1.753s
12/10/2017 02:18:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:09 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:18:09 [INFO] exp_shallowmodel: f1_score:   0.261
12/10/2017 02:18:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.56      0.09      0.16        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:18:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:09 [INFO] exp_shallowmodel: 
[[  1   0  56   2]
 [  0   0  12   0]
 [  7   0 387   2]
 [  1   0  49   5]]
12/10/2017 02:18:09 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 02:18:09 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:09 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:10 [INFO] exp_shallowmodel: train time: 1.225s
12/10/2017 02:18:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:10 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:18:10 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 02:18:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.10      0.17        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.86       396
          R       0.36      0.07      0.12        55

avg / total       0.68      0.76      0.69       522

12/10/2017 02:18:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:10 [INFO] exp_shallowmodel: 
[[  6   0  53   0]
 [  1   0  10   1]
 [  3   0 387   6]
 [  2   0  49   4]]
12/10/2017 02:18:10 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 02:18:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:10 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:11 [INFO] exp_shallowmodel: train time: 1.292s
12/10/2017 02:18:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:11 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:18:11 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 02:18:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.10      0.17        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.18      0.04      0.06        55

avg / total       0.67      0.76      0.69       522

12/10/2017 02:18:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:11 [INFO] exp_shallowmodel: 
[[  6   0  49   4]
 [  0   0  11   1]
 [  1   2 389   4]
 [  4   0  49   2]]
12/10/2017 02:18:11 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 02:18:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:11 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:12 [INFO] exp_shallowmodel: train time: 1.067s
12/10/2017 02:18:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:12 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:18:12 [INFO] exp_shallowmodel: f1_score:   0.253
12/10/2017 02:18:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.76      0.97      0.86       396
          R       0.50      0.07      0.13        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:18:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:12 [INFO] exp_shallowmodel: 
[[  1   0  57   1]
 [  0   0  12   0]
 [  7   1 385   3]
 [  1   0  50   4]]
12/10/2017 02:18:12 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 02:18:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:12 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:14 [INFO] exp_shallowmodel: train time: 1.335s
12/10/2017 02:18:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:14 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:18:14 [INFO] exp_shallowmodel: f1_score:   0.283
12/10/2017 02:18:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.02      0.03        59
          C       0.50      0.08      0.14        12
          F       0.78      0.98      0.87       396
          R       0.25      0.05      0.09        55

avg / total       0.64      0.75      0.68       522

12/10/2017 02:18:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:14 [INFO] exp_shallowmodel: 
[[  1   0  55   3]
 [  2   1   8   1]
 [  1   1 389   5]
 [  5   0  47   3]]
12/10/2017 02:18:14 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 02:18:14 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:14 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:15 [INFO] exp_shallowmodel: train time: 1.250s
12/10/2017 02:18:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:15 [INFO] exp_shallowmodel: accuracy:   0.784
12/10/2017 02:18:15 [INFO] exp_shallowmodel: f1_score:   0.341
12/10/2017 02:18:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.14      0.22        59
          C       0.00      0.00      0.00        12
          F       0.79      0.99      0.88       396
          R       0.64      0.16      0.26        55

avg / total       0.74      0.78      0.72       522

12/10/2017 02:18:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:15 [INFO] exp_shallowmodel: 
[[  8   0  49   2]
 [  1   0  10   1]
 [  2   0 392   2]
 [  2   1  43   9]]
12/10/2017 02:18:15 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 02:18:15 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:15 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:17 [INFO] exp_shallowmodel: train time: 1.760s
12/10/2017 02:18:17 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:17 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:18:17 [INFO] exp_shallowmodel: f1_score:   0.272
12/10/2017 02:18:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.86       396
          R       0.71      0.09      0.16        55

avg / total       0.70      0.76      0.68       522

12/10/2017 02:18:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:17 [INFO] exp_shallowmodel: 
[[  2   1  56   0]
 [  0   0  12   0]
 [  3   0 391   2]
 [  0   0  50   5]]
12/10/2017 02:18:17 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 02:18:17 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:17 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:18 [INFO] exp_shallowmodel: train time: 1.330s
12/10/2017 02:18:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:18 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:18:18 [INFO] exp_shallowmodel: f1_score:   0.344
12/10/2017 02:18:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        59
          C       0.67      0.17      0.27        12
          F       0.78      0.98      0.87       396
          R       0.38      0.09      0.15        55

avg / total       0.70      0.77      0.69       522

12/10/2017 02:18:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:18 [INFO] exp_shallowmodel: 
[[  3   0  53   3]
 [  0   2   9   1]
 [  1   1 390   4]
 [  2   0  48   5]]
12/10/2017 02:18:18 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 02:18:18 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:18:18 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:19 [INFO] exp_shallowmodel: train time: 1.247s
12/10/2017 02:18:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:19 [INFO] exp_shallowmodel: accuracy:   0.742
12/10/2017 02:18:19 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 02:18:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.06      0.11        64
          C       1.00      0.07      0.13        14
          F       0.76      0.97      0.85       402
          R       0.30      0.11      0.16        63

avg / total       0.70      0.74      0.67       543

12/10/2017 02:18:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:19 [INFO] exp_shallowmodel: 
[[  4   0  54   6]
 [  0   1  12   1]
 [  2   0 391   9]
 [  0   0  56   7]]
12/10/2017 02:18:19 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 02:18:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:19 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:20 [INFO] exp_shallowmodel: train time: 0.950s
12/10/2017 02:18:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:20 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:18:20 [INFO] exp_shallowmodel: f1_score:   0.301
12/10/2017 02:18:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.07      0.12        59
          C       0.50      0.08      0.14        12
          F       0.77      0.96      0.86       396
          R       0.17      0.05      0.08        55

avg / total       0.67      0.75      0.68       522

12/10/2017 02:18:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:20 [INFO] exp_shallowmodel: 
[[  4   1  51   3]
 [  1   1  10   0]
 [  2   0 382  12]
 [  2   0  50   3]]
12/10/2017 02:18:20 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 02:18:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:20 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:21 [INFO] exp_shallowmodel: train time: 1.090s
12/10/2017 02:18:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:21 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:18:21 [INFO] exp_shallowmodel: f1_score:   0.283
12/10/2017 02:18:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.36      0.09      0.14        55

avg / total       0.70      0.76      0.68       522

12/10/2017 02:18:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:21 [INFO] exp_shallowmodel: 
[[  4   0  54   1]
 [  0   0  11   1]
 [  1   0 388   7]
 [  1   0  49   5]]
12/10/2017 02:18:21 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 02:18:21 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:21 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:23 [INFO] exp_shallowmodel: train time: 1.825s
12/10/2017 02:18:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:23 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:18:23 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 02:18:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.43      0.11      0.17        55

avg / total       0.66      0.76      0.69       522

12/10/2017 02:18:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:23 [INFO] exp_shallowmodel: 
[[  2   0  54   3]
 [  2   0  10   0]
 [  2   0 389   5]
 [  4   0  45   6]]
12/10/2017 02:18:23 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 02:18:23 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:23 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:24 [INFO] exp_shallowmodel: train time: 1.151s
12/10/2017 02:18:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:24 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:18:24 [INFO] exp_shallowmodel: f1_score:   0.277
12/10/2017 02:18:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.44      0.07      0.12        55

avg / total       0.68      0.76      0.68       522

12/10/2017 02:18:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:24 [INFO] exp_shallowmodel: 
[[  4   0  55   0]
 [  2   0   8   2]
 [  3   0 390   3]
 [  1   0  50   4]]
12/10/2017 02:18:24 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 02:18:24 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:24 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:25 [INFO] exp_shallowmodel: train time: 1.060s
12/10/2017 02:18:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:25 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:18:25 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 02:18:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.12      0.18        59
          C       1.00      0.08      0.15        12
          F       0.78      0.96      0.86       396
          R       0.17      0.04      0.06        55

avg / total       0.67      0.75      0.68       522

12/10/2017 02:18:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:25 [INFO] exp_shallowmodel: 
[[  7   0  48   4]
 [  0   1  11   0]
 [  9   0 381   6]
 [  2   0  51   2]]
12/10/2017 02:18:25 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 02:18:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:25 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:27 [INFO] exp_shallowmodel: train time: 1.119s
12/10/2017 02:18:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:27 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:18:27 [INFO] exp_shallowmodel: f1_score:   0.262
12/10/2017 02:18:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.27      0.05      0.09        55

avg / total       0.67      0.75      0.67       522

12/10/2017 02:18:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:27 [INFO] exp_shallowmodel: 
[[  3   0  54   2]
 [  0   0  12   0]
 [  1   1 388   6]
 [  2   1  49   3]]
12/10/2017 02:18:27 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 02:18:27 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:27 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:28 [INFO] exp_shallowmodel: train time: 1.251s
12/10/2017 02:18:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:28 [INFO] exp_shallowmodel: accuracy:   0.772
12/10/2017 02:18:28 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 02:18:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.14      0.23        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.62      0.09      0.16        55

avg / total       0.73      0.77      0.70       522

12/10/2017 02:18:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:28 [INFO] exp_shallowmodel: 
[[  8   0  50   1]
 [  0   0  12   0]
 [  3   1 390   2]
 [  1   2  47   5]]
12/10/2017 02:18:28 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 02:18:28 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:28 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:29 [INFO] exp_shallowmodel: train time: 1.313s
12/10/2017 02:18:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:29 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:18:29 [INFO] exp_shallowmodel: f1_score:   0.266
12/10/2017 02:18:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.33      0.09      0.14        55

avg / total       0.65      0.75      0.68       522

12/10/2017 02:18:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:29 [INFO] exp_shallowmodel: 
[[  2   0  54   3]
 [  0   0  11   1]
 [  4   0 386   6]
 [  2   0  48   5]]
12/10/2017 02:18:29 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 02:18:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:18:29 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:31 [INFO] exp_shallowmodel: train time: 1.387s
12/10/2017 02:18:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:31 [INFO] exp_shallowmodel: accuracy:   0.784
12/10/2017 02:18:31 [INFO] exp_shallowmodel: f1_score:   0.370
12/10/2017 02:18:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.10      0.18        59
          C       1.00      0.08      0.15        12
          F       0.78      0.99      0.88       396
          R       0.82      0.16      0.27        55

avg / total       0.78      0.78      0.72       522

12/10/2017 02:18:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:31 [INFO] exp_shallowmodel: 
[[  6   0  53   0]
 [  0   1  10   1]
 [  2   0 393   1]
 [  1   0  45   9]]
12/10/2017 02:18:31 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 02:18:31 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:18:31 [INFO] exp_shallowmodel: #(feature) = 92
12/10/2017 02:18:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:32 [INFO] exp_shallowmodel: train time: 1.258s
12/10/2017 02:18:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:32 [INFO] exp_shallowmodel: accuracy:   0.748
12/10/2017 02:18:32 [INFO] exp_shallowmodel: f1_score:   0.264
12/10/2017 02:18:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        64
          C       0.00      0.00      0.00        14
          F       0.76      0.99      0.86       402
          R       0.44      0.06      0.11        63

avg / total       0.67      0.75      0.66       543

12/10/2017 02:18:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:32 [INFO] exp_shallowmodel: 
[[  3   0  59   2]
 [  2   0  11   1]
 [  0   1 399   2]
 [  1   0  58   4]]
