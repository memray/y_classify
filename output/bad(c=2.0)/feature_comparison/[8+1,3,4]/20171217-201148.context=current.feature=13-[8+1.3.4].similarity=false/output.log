12/17/2017 20:11:48 [INFO] configuration: deep_model  :   False
12/17/2017 20:11:48 [INFO] configuration: selected_context_id  :   1
12/17/2017 20:11:48 [INFO] configuration: selected_feature_set_id  :   13
12/17/2017 20:11:48 [INFO] configuration: similarity_feature  :   False
12/17/2017 20:11:48 [INFO] configuration: seed  :   154316847
12/17/2017 20:11:48 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/17/2017 20:11:48 [INFO] configuration: task_name  :   utterance_type
12/17/2017 20:11:48 [INFO] configuration: timemark  :   20171217-201148
12/17/2017 20:11:48 [INFO] configuration: context_set  :   current
12/17/2017 20:11:48 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/17/2017 20:11:48 [INFO] configuration: utterance_range  :   ['current_user_utterance']
12/17/2017 20:11:48 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/17/2017 20:11:48 [INFO] configuration: feature_set  :   13-[8+1.3.4]
12/17/2017 20:11:48 [INFO] configuration: feature_set_number  :   ['1', '2', '3', '5', '6', '7', '11']
12/17/2017 20:11:48 [INFO] configuration: experiment_name  :   20171217-201148.context=current.feature=13-[8+1.3.4].similarity=false
12/17/2017 20:11:48 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171217-201148.context=current.feature=13-[8+1.3.4].similarity=false
12/17/2017 20:11:48 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171217-201148.context=current.feature=13-[8+1.3.4].similarity=false/output.log
12/17/2017 20:11:48 [INFO] configuration: valid_type  :   {'R', 'A', 'C', 'F'}
12/17/2017 20:11:48 [INFO] configuration: data_name  :   
12/17/2017 20:11:48 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/17/2017 20:11:48 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/17/2017 20:11:48 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/17/2017 20:11:48 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/17/2017 20:11:48 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/17/2017 20:11:48 [INFO] configuration: do_cross_validation  :   True
12/17/2017 20:11:48 [INFO] configuration: #division  :   5
12/17/2017 20:11:48 [INFO] configuration: #cross_validation  :   10
12/17/2017 20:11:48 [INFO] configuration: cv_index_cache_path  :   
12/17/2017 20:11:48 [INFO] configuration: action_words  :   {'moder', 'price', 'skip', 'north', 'temperature', 'weather', 'number', 'ani', 'room', 'cheap', 'reminders', 'remov', 'address', 'time', 'snooz', 'expensive', 'alarm', 'temperatur', 'start', 'video', 'volume', 'reminder', 'shuffle', 'tell', 'next', 'expens', 'watch', 'turn', 'moderate', 'matter', 'post', 'delete', 'song', 'findcar', 'area', 'els', 'items', 'timer', 'show', 'help', 'delet', 'reminds', 'shuffl', 'centre', 'part', 'item', 'play', 'list', 'findcare', 'add', 'centr', 'food', 'clear', 'volum', 'else', 'light', 'snooze', 'telephon', 'remove', 'phone', 'share', 'member', 'stop', 'any', 'discard', 'remind', 'cast', 'music', 'south', 'telephone'}
12/17/2017 20:11:48 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/17/2017 20:11:48 [INFO] configuration: lda_topic_number  :   50
12/17/2017 20:11:48 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/17/2017 20:11:48 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/17/2017 20:11:48 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/17/2017 20:11:48 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/17/2017 20:11:48 [INFO] configuration: w2v_vector_length  :   300
12/17/2017 20:11:48 [INFO] configuration: d2v_vector_length  :   300
12/17/2017 20:11:48 [INFO] configuration: d2v_window_size  :   5
12/17/2017 20:11:48 [INFO] configuration: d2v_min_count  :   2
12/17/2017 20:11:48 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/17/2017 20:11:48 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/17/2017 20:11:48 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/17/2017 20:11:48 [INFO] configuration: batch_size  :   128
12/17/2017 20:11:48 [INFO] configuration: max_epoch  :   50
12/17/2017 20:11:48 [INFO] configuration: early_stop_tolerance  :   2
12/17/2017 20:11:48 [INFO] configuration: concat_sents  :   True
12/17/2017 20:11:48 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/17/2017 20:11:48 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 1, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/17/2017 20:11:48 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/17/2017 20:11:54 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 20:11:54 [INFO] task_runner: context=current, feature=13-[8+1.3.4]
12/17/2017 20:11:54 [INFO] task_runner: retained feature numbers=[5, 7, 2.2, 3, 2.1, 1, 11.1, 6]
12/17/2017 20:11:54 [INFO] task_runner: #(data)=5725
12/17/2017 20:11:54 [INFO] task_runner: #(feature)=3440
12/17/2017 20:11:54 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 20:11:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/17/2017 20:11:55 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:11:55 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:11:55 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:11:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:11:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:11:55 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:11:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:15:16 [INFO] exp_shallowmodel: train time: 200.813s
12/17/2017 20:15:16 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:15:16 [INFO] exp_shallowmodel: accuracy:   0.630
12/17/2017 20:15:16 [INFO] exp_shallowmodel: f1_score:   0.472
12/17/2017 20:15:16 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:15:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        14
          C       0.60      0.67      0.63       164
          F       0.72      0.76      0.74       268
          R       0.44      0.35      0.39       125

avg / total       0.62      0.63      0.62       571

12/17/2017 20:15:16 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:15:16 [INFO] exp_shallowmodel: 
[[  1   2   8   3]
 [  0 110  28  26]
 [  0  35 205  28]
 [  1  36  44  44]]
12/17/2017 20:15:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/17/2017 20:15:17 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:15:17 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:15:17 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:15:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:15:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:15:17 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:15:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:18:39 [INFO] exp_shallowmodel: train time: 201.640s
12/17/2017 20:18:39 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:18:39 [INFO] exp_shallowmodel: accuracy:   0.646
12/17/2017 20:18:39 [INFO] exp_shallowmodel: f1_score:   0.527
12/17/2017 20:18:39 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:18:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.21      0.27        14
          C       0.59      0.57      0.58       164
          F       0.73      0.80      0.76       268
          R       0.53      0.46      0.49       125

avg / total       0.64      0.65      0.64       571

12/17/2017 20:18:39 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:18:39 [INFO] exp_shallowmodel: 
[[  3   2   7   2]
 [  1  94  40  29]
 [  1  32 215  20]
 [  3  32  33  57]]
12/17/2017 20:18:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/17/2017 20:18:40 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:18:40 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:18:40 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:18:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:18:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:18:40 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:18:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:22:00 [INFO] exp_shallowmodel: train time: 200.132s
12/17/2017 20:22:00 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:22:00 [INFO] exp_shallowmodel: accuracy:   0.650
12/17/2017 20:22:00 [INFO] exp_shallowmodel: f1_score:   0.483
12/17/2017 20:22:00 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:22:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.59      0.68      0.63       164
          F       0.76      0.78      0.77       268
          R       0.49      0.38      0.43       125

avg / total       0.64      0.65      0.64       571

12/17/2017 20:22:00 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:22:00 [INFO] exp_shallowmodel: 
[[  1   5   6   2]
 [  1 112  29  22]
 [  2  31 210  25]
 [  3  41  33  48]]
12/17/2017 20:22:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/17/2017 20:22:02 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:22:02 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:22:02 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:22:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:22:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:22:02 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:22:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:26:27 [INFO] exp_shallowmodel: train time: 265.246s
12/17/2017 20:26:27 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:26:27 [INFO] exp_shallowmodel: accuracy:   0.618
12/17/2017 20:26:27 [INFO] exp_shallowmodel: f1_score:   0.476
12/17/2017 20:26:27 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:26:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.14      0.17        14
          C       0.58      0.61      0.60       164
          F       0.73      0.77      0.75       268
          R       0.42      0.36      0.39       125

avg / total       0.61      0.62      0.61       571

12/17/2017 20:26:27 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:26:27 [INFO] exp_shallowmodel: 
[[  2   1   7   4]
 [  2 100  34  28]
 [  2  30 206  30]
 [  3  40  37  45]]
12/17/2017 20:26:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/17/2017 20:26:28 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:26:28 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:26:28 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:26:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:26:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:26:28 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:26:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:29:44 [INFO] exp_shallowmodel: train time: 196.345s
12/17/2017 20:29:44 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:29:44 [INFO] exp_shallowmodel: accuracy:   0.636
12/17/2017 20:29:44 [INFO] exp_shallowmodel: f1_score:   0.447
12/17/2017 20:29:44 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:29:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.66      0.62       164
          F       0.74      0.78      0.76       268
          R       0.45      0.37      0.40       125

avg / total       0.61      0.64      0.62       571

12/17/2017 20:29:44 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:29:44 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  1 108  29  26]
 [  1  31 209  27]
 [  1  41  37  46]]
12/17/2017 20:29:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/17/2017 20:29:46 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:29:46 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:29:46 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:29:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:29:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:29:46 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:29:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:33:01 [INFO] exp_shallowmodel: train time: 195.097s
12/17/2017 20:33:01 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:33:01 [INFO] exp_shallowmodel: accuracy:   0.604
12/17/2017 20:33:01 [INFO] exp_shallowmodel: f1_score:   0.428
12/17/2017 20:33:01 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:33:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.63      0.60       164
          F       0.68      0.73      0.71       268
          R       0.46      0.36      0.41       125

avg / total       0.59      0.60      0.59       571

12/17/2017 20:33:01 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:33:01 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  0 104  36  24]
 [  3  45 196  24]
 [  2  31  47  45]]
12/17/2017 20:33:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/17/2017 20:33:02 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:33:02 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:33:02 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:33:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:33:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:33:02 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:33:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:36:32 [INFO] exp_shallowmodel: train time: 209.714s
12/17/2017 20:36:32 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:36:32 [INFO] exp_shallowmodel: accuracy:   0.662
12/17/2017 20:36:32 [INFO] exp_shallowmodel: f1_score:   0.522
12/17/2017 20:36:32 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:36:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.14      0.20        14
          C       0.64      0.71      0.67       164
          F       0.76      0.77      0.77       268
          R       0.47      0.42      0.45       125

avg / total       0.65      0.66      0.66       571

12/17/2017 20:36:32 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:36:32 [INFO] exp_shallowmodel: 
[[  2   4   6   2]
 [  0 116  20  28]
 [  3  28 207  30]
 [  1  32  39  53]]
12/17/2017 20:36:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/17/2017 20:36:33 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:36:33 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:36:33 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:36:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:36:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:36:33 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:36:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:39:51 [INFO] exp_shallowmodel: train time: 198.421s
12/17/2017 20:39:51 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:39:51 [INFO] exp_shallowmodel: accuracy:   0.594
12/17/2017 20:39:51 [INFO] exp_shallowmodel: f1_score:   0.434
12/17/2017 20:39:51 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:39:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.07      0.11        14
          C       0.54      0.60      0.57       164
          F       0.73      0.76      0.74       268
          R       0.34      0.29      0.31       125

avg / total       0.58      0.59      0.58       571

12/17/2017 20:39:51 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:39:51 [INFO] exp_shallowmodel: 
[[  1   2   7   4]
 [  0  99  27  38]
 [  2  36 203  27]
 [  1  46  42  36]]
12/17/2017 20:39:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/17/2017 20:39:52 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:39:52 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:39:52 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:39:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:39:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:39:52 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:39:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:43:11 [INFO] exp_shallowmodel: train time: 198.429s
12/17/2017 20:43:11 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:43:11 [INFO] exp_shallowmodel: accuracy:   0.665
12/17/2017 20:43:11 [INFO] exp_shallowmodel: f1_score:   0.525
12/17/2017 20:43:11 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:43:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.14      0.24        14
          C       0.65      0.69      0.67       164
          F       0.71      0.82      0.76       268
          R       0.53      0.37      0.44       125

avg / total       0.65      0.67      0.65       571

12/17/2017 20:43:11 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:43:11 [INFO] exp_shallowmodel: 
[[  2   2   8   2]
 [  0 113  29  22]
 [  0  33 219  16]
 [  1  27  51  46]]
12/17/2017 20:43:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/17/2017 20:43:12 [INFO] exp_shallowmodel: #(data) = 4568
12/17/2017 20:43:12 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:43:12 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:43:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:43:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:43:12 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:43:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:46:44 [INFO] exp_shallowmodel: train time: 211.874s
12/17/2017 20:46:44 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 20:46:44 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 20:46:44 [INFO] exp_shallowmodel: f1_score:   0.440
12/17/2017 20:46:44 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:46:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.56      0.59      0.57       169
          F       0.69      0.80      0.74       271
          R       0.53      0.38      0.44       130

avg / total       0.60      0.62      0.61       586

12/17/2017 20:46:44 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:46:44 [INFO] exp_shallowmodel: 
[[  0   2   8   6]
 [  2 100  46  21]
 [  0  38 217  16]
 [  0  39  42  49]]
12/17/2017 20:46:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/17/2017 20:46:45 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:46:45 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:46:45 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:46:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:46:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:46:45 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:46:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:50:30 [INFO] exp_shallowmodel: train time: 224.497s
12/17/2017 20:50:30 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:50:30 [INFO] exp_shallowmodel: accuracy:   0.623
12/17/2017 20:50:30 [INFO] exp_shallowmodel: f1_score:   0.441
12/17/2017 20:50:30 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:50:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.65      0.62       164
          F       0.70      0.76      0.73       268
          R       0.49      0.36      0.41       125

avg / total       0.61      0.62      0.61       571

12/17/2017 20:50:30 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:50:30 [INFO] exp_shallowmodel: 
[[  0   1  11   2]
 [  3 106  34  21]
 [  4  35 205  24]
 [  1  37  42  45]]
12/17/2017 20:50:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/17/2017 20:50:31 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:50:31 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:50:31 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:50:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:50:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:50:31 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:50:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:53:40 [INFO] exp_shallowmodel: train time: 189.221s
12/17/2017 20:53:40 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:53:40 [INFO] exp_shallowmodel: accuracy:   0.639
12/17/2017 20:53:40 [INFO] exp_shallowmodel: f1_score:   0.479
12/17/2017 20:53:40 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:53:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.60      0.62      0.61       164
          F       0.74      0.78      0.76       268
          R       0.47      0.42      0.45       125

avg / total       0.63      0.64      0.63       571

12/17/2017 20:53:40 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:53:40 [INFO] exp_shallowmodel: 
[[  1   2   9   2]
 [  1 101  33  29]
 [  1  28 210  29]
 [  3  36  33  53]]
12/17/2017 20:53:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/17/2017 20:53:41 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:53:41 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:53:41 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:53:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:53:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:53:41 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:53:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:57:05 [INFO] exp_shallowmodel: train time: 203.842s
12/17/2017 20:57:05 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 20:57:05 [INFO] exp_shallowmodel: accuracy:   0.590
12/17/2017 20:57:05 [INFO] exp_shallowmodel: f1_score:   0.411
12/17/2017 20:57:05 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:57:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.53      0.54       164
          F       0.67      0.77      0.72       268
          R       0.42      0.35      0.38       125

avg / total       0.57      0.59      0.58       571

12/17/2017 20:57:05 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:57:05 [INFO] exp_shallowmodel: 
[[  0   0  10   4]
 [  1  87  45  31]
 [  1  35 206  26]
 [  1  34  46  44]]
12/17/2017 20:57:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/17/2017 20:57:06 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:57:06 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 20:57:06 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:57:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:57:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:57:06 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:57:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:00:37 [INFO] exp_shallowmodel: train time: 210.233s
12/17/2017 21:00:37 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:00:37 [INFO] exp_shallowmodel: accuracy:   0.646
12/17/2017 21:00:37 [INFO] exp_shallowmodel: f1_score:   0.489
12/17/2017 21:00:37 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:00:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.07      0.09        14
          C       0.62      0.61      0.61       164
          F       0.75      0.77      0.76       268
          R       0.50      0.50      0.50       125

avg / total       0.64      0.65      0.64       571

12/17/2017 21:00:37 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:00:37 [INFO] exp_shallowmodel: 
[[  1   4   5   4]
 [  1 100  33  30]
 [  3  31 206  28]
 [  4  27  32  62]]
12/17/2017 21:00:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/17/2017 21:00:38 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:00:38 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:00:38 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:00:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:00:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:00:38 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:00:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:04:04 [INFO] exp_shallowmodel: train time: 205.932s
12/17/2017 21:04:04 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:04:04 [INFO] exp_shallowmodel: accuracy:   0.648
12/17/2017 21:04:04 [INFO] exp_shallowmodel: f1_score:   0.512
12/17/2017 21:04:04 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:04:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.14      0.22        14
          C       0.60      0.59      0.59       164
          F       0.72      0.81      0.76       268
          R       0.51      0.43      0.47       125

avg / total       0.64      0.65      0.64       571

12/17/2017 21:04:04 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:04:04 [INFO] exp_shallowmodel: 
[[  2   3   7   2]
 [  0  96  36  32]
 [  0  32 218  18]
 [  2  28  41  54]]
12/17/2017 21:04:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/17/2017 21:04:05 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:04:05 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:04:05 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:04:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:04:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:04:05 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:04:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:07:19 [INFO] exp_shallowmodel: train time: 193.974s
12/17/2017 21:07:19 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:07:19 [INFO] exp_shallowmodel: accuracy:   0.620
12/17/2017 21:07:19 [INFO] exp_shallowmodel: f1_score:   0.467
12/17/2017 21:07:19 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:07:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.60      0.66      0.63       164
          F       0.71      0.73      0.72       268
          R       0.45      0.39      0.42       125

avg / total       0.61      0.62      0.61       571

12/17/2017 21:07:19 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:07:19 [INFO] exp_shallowmodel: 
[[  1   1   6   6]
 [  1 108  30  25]
 [  1  42 196  29]
 [  3  30  43  49]]
12/17/2017 21:07:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/17/2017 21:07:20 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:07:20 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:07:20 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:07:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:07:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:07:20 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:07:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:10:40 [INFO] exp_shallowmodel: train time: 200.189s
12/17/2017 21:10:40 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:10:40 [INFO] exp_shallowmodel: accuracy:   0.658
12/17/2017 21:10:40 [INFO] exp_shallowmodel: f1_score:   0.518
12/17/2017 21:10:40 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:10:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.14      0.20        14
          C       0.60      0.65      0.62       164
          F       0.77      0.79      0.78       268
          R       0.50      0.45      0.47       125

avg / total       0.65      0.66      0.65       571

12/17/2017 21:10:40 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:10:40 [INFO] exp_shallowmodel: 
[[  2   2   6   4]
 [  2 106  25  31]
 [  2  33 212  21]
 [  0  36  33  56]]
12/17/2017 21:10:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/17/2017 21:10:41 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:10:41 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:10:41 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:10:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:10:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:10:41 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:10:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:14:11 [INFO] exp_shallowmodel: train time: 209.683s
12/17/2017 21:14:11 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:14:11 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 21:14:11 [INFO] exp_shallowmodel: f1_score:   0.467
12/17/2017 21:14:11 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:14:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.07      0.09        14
          C       0.60      0.65      0.62       164
          F       0.71      0.75      0.73       268
          R       0.49      0.38      0.43       125

avg / total       0.61      0.63      0.62       571

12/17/2017 21:14:11 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:14:11 [INFO] exp_shallowmodel: 
[[  1   1  10   2]
 [  3 106  31  24]
 [  5  37 202  24]
 [  0  34  43  48]]
12/17/2017 21:14:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/17/2017 21:14:12 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:14:12 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:14:12 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:14:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:14:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:14:12 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:14:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:17:39 [INFO] exp_shallowmodel: train time: 206.583s
12/17/2017 21:17:39 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:17:39 [INFO] exp_shallowmodel: accuracy:   0.634
12/17/2017 21:17:39 [INFO] exp_shallowmodel: f1_score:   0.515
12/17/2017 21:17:39 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:17:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.21      0.32        14
          C       0.57      0.63      0.60       164
          F       0.72      0.80      0.76       268
          R       0.47      0.33      0.38       125

avg / total       0.62      0.63      0.62       571

12/17/2017 21:17:39 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:17:39 [INFO] exp_shallowmodel: 
[[  3   1   6   4]
 [  0 103  40  21]
 [  1  30 215  22]
 [  1  46  37  41]]
12/17/2017 21:17:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/17/2017 21:17:40 [INFO] exp_shallowmodel: #(data) = 4568
12/17/2017 21:17:40 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:17:40 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:17:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:17:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:17:40 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:17:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:20:58 [INFO] exp_shallowmodel: train time: 197.876s
12/17/2017 21:20:59 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:20:59 [INFO] exp_shallowmodel: accuracy:   0.631
12/17/2017 21:20:59 [INFO] exp_shallowmodel: f1_score:   0.451
12/17/2017 21:20:59 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:20:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.62      0.72      0.66       169
          F       0.71      0.74      0.72       271
          R       0.47      0.37      0.41       130

avg / total       0.61      0.63      0.62       586

12/17/2017 21:20:59 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:20:59 [INFO] exp_shallowmodel: 
[[  0   1  10   5]
 [  0 121  28  20]
 [  1  40 201  29]
 [  4  33  45  48]]
12/17/2017 21:21:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/17/2017 21:21:00 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:21:00 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:21:00 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:21:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:21:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:21:00 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:21:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:24:16 [INFO] exp_shallowmodel: train time: 196.084s
12/17/2017 21:24:16 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:24:16 [INFO] exp_shallowmodel: accuracy:   0.608
12/17/2017 21:24:16 [INFO] exp_shallowmodel: f1_score:   0.453
12/17/2017 21:24:16 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:24:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.56      0.61      0.58       164
          F       0.71      0.75      0.73       268
          R       0.44      0.37      0.40       125

avg / total       0.59      0.61      0.60       571

12/17/2017 21:24:16 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:24:16 [INFO] exp_shallowmodel: 
[[  1   2   7   4]
 [  1 100  32  31]
 [  2  42 200  24]
 [  2  35  42  46]]
12/17/2017 21:24:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/17/2017 21:24:17 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:24:17 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:24:17 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:24:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:24:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:24:17 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:24:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:27:35 [INFO] exp_shallowmodel: train time: 197.319s
12/17/2017 21:27:35 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:27:35 [INFO] exp_shallowmodel: accuracy:   0.636
12/17/2017 21:27:35 [INFO] exp_shallowmodel: f1_score:   0.475
12/17/2017 21:27:35 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:27:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.07      0.11        14
          C       0.59      0.63      0.61       164
          F       0.72      0.79      0.75       268
          R       0.49      0.38      0.43       125

avg / total       0.62      0.64      0.62       571

12/17/2017 21:27:35 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:27:35 [INFO] exp_shallowmodel: 
[[  1   4   8   1]
 [  0 103  40  21]
 [  1  28 211  28]
 [  2  40  35  48]]
12/17/2017 21:27:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/17/2017 21:27:36 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:27:36 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:27:36 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:27:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:27:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:27:36 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:27:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:30:33 [INFO] exp_shallowmodel: train time: 177.757s
12/17/2017 21:30:33 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:30:33 [INFO] exp_shallowmodel: accuracy:   0.618
12/17/2017 21:30:33 [INFO] exp_shallowmodel: f1_score:   0.475
12/17/2017 21:30:33 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:30:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.14      0.19        14
          C       0.60      0.65      0.63       164
          F       0.71      0.77      0.74       268
          R       0.40      0.30      0.34       125

avg / total       0.60      0.62      0.61       571

12/17/2017 21:30:33 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:30:33 [INFO] exp_shallowmodel: 
[[  2   0   6   6]
 [  3 107  30  24]
 [  1  33 206  28]
 [  1  37  49  38]]
12/17/2017 21:30:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/17/2017 21:30:34 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:30:34 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:30:34 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:30:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:30:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:30:34 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:30:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:33:10 [INFO] exp_shallowmodel: train time: 156.143s
12/17/2017 21:33:10 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:33:10 [INFO] exp_shallowmodel: accuracy:   0.673
12/17/2017 21:33:10 [INFO] exp_shallowmodel: f1_score:   0.538
12/17/2017 21:33:10 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:33:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.14      0.24        14
          C       0.61      0.69      0.65       164
          F       0.77      0.79      0.78       268
          R       0.53      0.46      0.49       125

avg / total       0.67      0.67      0.67       571

12/17/2017 21:33:10 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:33:10 [INFO] exp_shallowmodel: 
[[  2   2   5   5]
 [  0 113  28  23]
 [  0  34 212  22]
 [  1  36  31  57]]
12/17/2017 21:33:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/17/2017 21:33:11 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:33:11 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:33:11 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:33:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:33:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:33:11 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:33:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:36:27 [INFO] exp_shallowmodel: train time: 195.351s
12/17/2017 21:36:27 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:36:27 [INFO] exp_shallowmodel: accuracy:   0.636
12/17/2017 21:36:27 [INFO] exp_shallowmodel: f1_score:   0.474
12/17/2017 21:36:27 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:36:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.07      0.11        14
          C       0.59      0.60      0.59       164
          F       0.72      0.80      0.76       268
          R       0.48      0.39      0.43       125

avg / total       0.62      0.64      0.62       571

12/17/2017 21:36:27 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:36:27 [INFO] exp_shallowmodel: 
[[  1   3   7   3]
 [  1  98  39  26]
 [  0  29 215  24]
 [  2  36  38  49]]
12/17/2017 21:36:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/17/2017 21:36:28 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:36:28 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:36:28 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:36:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:36:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:36:28 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:36:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:40:54 [INFO] exp_shallowmodel: train time: 266.059s
12/17/2017 21:40:54 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:40:54 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 21:40:54 [INFO] exp_shallowmodel: f1_score:   0.446
12/17/2017 21:40:54 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:40:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.65      0.62       164
          F       0.73      0.75      0.74       268
          R       0.46      0.38      0.42       125

avg / total       0.61      0.63      0.62       571

12/17/2017 21:40:54 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:40:54 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 107  29  28]
 [  4  35 202  27]
 [  6  34  37  48]]
12/17/2017 21:40:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/17/2017 21:40:55 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:40:55 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:40:55 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:40:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:40:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:40:55 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:40:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:44:12 [INFO] exp_shallowmodel: train time: 196.251s
12/17/2017 21:44:12 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:44:12 [INFO] exp_shallowmodel: accuracy:   0.636
12/17/2017 21:44:12 [INFO] exp_shallowmodel: f1_score:   0.503
12/17/2017 21:44:12 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:44:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.14      0.24        14
          C       0.57      0.60      0.59       164
          F       0.72      0.80      0.76       268
          R       0.49      0.39      0.43       125

avg / total       0.63      0.64      0.62       571

12/17/2017 21:44:12 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:44:12 [INFO] exp_shallowmodel: 
[[  2   2   5   5]
 [  0  98  40  26]
 [  0  33 214  21]
 [  1  38  37  49]]
12/17/2017 21:44:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/17/2017 21:44:13 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:44:13 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:44:13 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:44:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:44:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:44:13 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:44:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:47:52 [INFO] exp_shallowmodel: train time: 219.206s
12/17/2017 21:47:52 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:47:52 [INFO] exp_shallowmodel: accuracy:   0.646
12/17/2017 21:47:52 [INFO] exp_shallowmodel: f1_score:   0.483
12/17/2017 21:47:52 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:47:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.60      0.63      0.61       164
          F       0.74      0.80      0.77       268
          R       0.50      0.41      0.45       125

avg / total       0.63      0.65      0.64       571

12/17/2017 21:47:52 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:47:52 [INFO] exp_shallowmodel: 
[[  1   1   8   4]
 [  1 103  30  30]
 [  1  36 214  17]
 [  2  33  39  51]]
12/17/2017 21:47:53 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/17/2017 21:47:53 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:47:53 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:47:53 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:47:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:47:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:47:53 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:47:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:51:03 [INFO] exp_shallowmodel: train time: 190.055s
12/17/2017 21:51:03 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:51:03 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 21:51:03 [INFO] exp_shallowmodel: f1_score:   0.441
12/17/2017 21:51:03 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:51:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.60      0.58       164
          F       0.73      0.78      0.76       268
          R       0.46      0.39      0.42       125

avg / total       0.61      0.63      0.62       571

12/17/2017 21:51:03 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:51:03 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  2  98  35  29]
 [  2  31 210  25]
 [  1  40  35  49]]
12/17/2017 21:51:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/17/2017 21:51:04 [INFO] exp_shallowmodel: #(data) = 4568
12/17/2017 21:51:04 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:51:04 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:51:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:51:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:51:04 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:51:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:54:18 [INFO] exp_shallowmodel: train time: 194.116s
12/17/2017 21:54:19 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:54:19 [INFO] exp_shallowmodel: accuracy:   0.619
12/17/2017 21:54:19 [INFO] exp_shallowmodel: f1_score:   0.476
12/17/2017 21:54:19 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:54:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.12      0.15        16
          C       0.58      0.67      0.62       169
          F       0.70      0.75      0.72       271
          R       0.51      0.34      0.41       130

avg / total       0.61      0.62      0.61       586

12/17/2017 21:54:19 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:54:19 [INFO] exp_shallowmodel: 
[[  2   4   8   2]
 [  3 114  32  20]
 [  2  45 203  21]
 [  3  34  49  44]]
12/17/2017 21:54:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/17/2017 21:54:20 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:54:20 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:54:20 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:54:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:54:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:54:20 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:54:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:57:39 [INFO] exp_shallowmodel: train time: 199.306s
12/17/2017 21:57:39 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:57:39 [INFO] exp_shallowmodel: accuracy:   0.608
12/17/2017 21:57:39 [INFO] exp_shallowmodel: f1_score:   0.425
12/17/2017 21:57:39 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:57:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.63      0.59       164
          F       0.72      0.75      0.73       268
          R       0.43      0.33      0.37       125

avg / total       0.59      0.61      0.60       571

12/17/2017 21:57:39 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:57:39 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  1 104  32  27]
 [  1  42 202  23]
 [  4  38  42  41]]
12/17/2017 21:57:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/17/2017 21:57:40 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:57:40 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:57:40 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:57:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:57:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:57:40 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:57:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:59:43 [INFO] exp_shallowmodel: train time: 122.919s
12/17/2017 21:59:43 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 21:59:43 [INFO] exp_shallowmodel: accuracy:   0.632
12/17/2017 21:59:43 [INFO] exp_shallowmodel: f1_score:   0.490
12/17/2017 21:59:43 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:59:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.14      0.19        14
          C       0.63      0.65      0.64       164
          F       0.70      0.78      0.74       268
          R       0.45      0.34      0.39       125

avg / total       0.61      0.63      0.62       571

12/17/2017 21:59:43 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:59:43 [INFO] exp_shallowmodel: 
[[  2   0   7   5]
 [  0 107  29  28]
 [  3  37 209  19]
 [  2  25  55  43]]
12/17/2017 21:59:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/17/2017 21:59:44 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:59:44 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 21:59:44 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:59:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:59:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:59:44 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:59:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:03:06 [INFO] exp_shallowmodel: train time: 201.990s
12/17/2017 22:03:06 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:03:06 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 22:03:06 [INFO] exp_shallowmodel: f1_score:   0.491
12/17/2017 22:03:06 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:03:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.14      0.21        14
          C       0.57      0.62      0.59       164
          F       0.73      0.77      0.75       268
          R       0.44      0.38      0.41       125

avg / total       0.62      0.63      0.62       571

12/17/2017 22:03:06 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:03:06 [INFO] exp_shallowmodel: 
[[  2   4   4   4]
 [  1 101  30  32]
 [  1  37 206  24]
 [  1  35  41  48]]
12/17/2017 22:03:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/17/2017 22:03:08 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:03:08 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:03:08 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:03:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:03:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:03:08 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:03:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:06:38 [INFO] exp_shallowmodel: train time: 210.873s
12/17/2017 22:06:38 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:06:38 [INFO] exp_shallowmodel: accuracy:   0.643
12/17/2017 22:06:38 [INFO] exp_shallowmodel: f1_score:   0.452
12/17/2017 22:06:38 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:06:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.60      0.61       164
          F       0.71      0.82      0.76       268
          R       0.51      0.39      0.44       125

avg / total       0.62      0.64      0.63       571

12/17/2017 22:06:38 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:06:38 [INFO] exp_shallowmodel: 
[[  0   3   9   2]
 [  2  99  40  23]
 [  0  26 219  23]
 [  2  35  39  49]]
12/17/2017 22:06:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/17/2017 22:06:40 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:06:40 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:06:40 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:06:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:06:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:06:40 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:06:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:10:26 [INFO] exp_shallowmodel: train time: 226.756s
12/17/2017 22:10:26 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:10:26 [INFO] exp_shallowmodel: accuracy:   0.658
12/17/2017 22:10:26 [INFO] exp_shallowmodel: f1_score:   0.518
12/17/2017 22:10:26 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:10:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.14      0.24        14
          C       0.57      0.64      0.61       164
          F       0.75      0.82      0.79       268
          R       0.53      0.38      0.44       125

avg / total       0.65      0.66      0.65       571

12/17/2017 22:10:26 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:10:26 [INFO] exp_shallowmodel: 
[[  2   2  10   0]
 [  0 105  37  22]
 [  0  26 221  21]
 [  1  50  26  48]]
12/17/2017 22:10:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/17/2017 22:10:28 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:10:28 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:10:28 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:10:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:10:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:10:28 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:10:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:13:58 [INFO] exp_shallowmodel: train time: 210.859s
12/17/2017 22:13:58 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:13:58 [INFO] exp_shallowmodel: accuracy:   0.618
12/17/2017 22:13:58 [INFO] exp_shallowmodel: f1_score:   0.434
12/17/2017 22:13:58 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:13:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.68      0.63       164
          F       0.73      0.75      0.74       268
          R       0.40      0.34      0.37       125

avg / total       0.60      0.62      0.61       571

12/17/2017 22:13:58 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:13:58 [INFO] exp_shallowmodel: 
[[  0   1  10   3]
 [  0 111  28  25]
 [  1  33 200  34]
 [  4  42  37  42]]
12/17/2017 22:14:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/17/2017 22:14:00 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:14:00 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:14:00 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:14:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:14:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:14:00 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:14:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:17:34 [INFO] exp_shallowmodel: train time: 213.993s
12/17/2017 22:17:34 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:17:34 [INFO] exp_shallowmodel: accuracy:   0.616
12/17/2017 22:17:34 [INFO] exp_shallowmodel: f1_score:   0.442
12/17/2017 22:17:34 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:17:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.65      0.61       164
          F       0.71      0.72      0.72       268
          R       0.47      0.42      0.45       125

avg / total       0.60      0.62      0.61       571

12/17/2017 22:17:34 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:17:34 [INFO] exp_shallowmodel: 
[[  0   1   7   6]
 [  0 106  35  23]
 [  1  44 193  30]
 [  1  35  36  53]]
12/17/2017 22:17:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/17/2017 22:17:35 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:17:35 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:17:35 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:17:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:17:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:17:35 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:17:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:20:53 [INFO] exp_shallowmodel: train time: 197.889s
12/17/2017 22:20:53 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:20:53 [INFO] exp_shallowmodel: accuracy:   0.601
12/17/2017 22:20:53 [INFO] exp_shallowmodel: f1_score:   0.462
12/17/2017 22:20:53 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:20:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.14      0.17        14
          C       0.54      0.53      0.54       164
          F       0.71      0.77      0.74       268
          R       0.44      0.38      0.41       125

avg / total       0.59      0.60      0.59       571

12/17/2017 22:20:53 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:20:53 [INFO] exp_shallowmodel: 
[[  2   1   9   2]
 [  3  87  36  38]
 [  1  40 206  21]
 [  4  32  41  48]]
12/17/2017 22:20:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/17/2017 22:20:54 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:20:54 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:20:54 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:20:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:20:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:20:54 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:20:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:23:24 [INFO] exp_shallowmodel: train time: 149.728s
12/17/2017 22:23:24 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:23:24 [INFO] exp_shallowmodel: accuracy:   0.613
12/17/2017 22:23:24 [INFO] exp_shallowmodel: f1_score:   0.476
12/17/2017 22:23:24 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:23:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.14      0.17        14
          C       0.58      0.60      0.59       164
          F       0.69      0.75      0.72       268
          R       0.47      0.38      0.42       125

avg / total       0.60      0.61      0.61       571

12/17/2017 22:23:24 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:23:24 [INFO] exp_shallowmodel: 
[[  2   1   8   3]
 [  1  98  39  26]
 [  4  37 202  25]
 [  3  32  42  48]]
12/17/2017 22:23:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/17/2017 22:23:24 [INFO] exp_shallowmodel: #(data) = 4568
12/17/2017 22:23:24 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:23:24 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:23:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:23:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:23:24 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:23:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:25:00 [INFO] exp_shallowmodel: train time: 96.048s
12/17/2017 22:25:00 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:25:00 [INFO] exp_shallowmodel: accuracy:   0.604
12/17/2017 22:25:00 [INFO] exp_shallowmodel: f1_score:   0.451
12/17/2017 22:25:00 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:25:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.06      0.09        16
          C       0.59      0.65      0.62       169
          F       0.69      0.72      0.71       271
          R       0.44      0.36      0.39       130

avg / total       0.59      0.60      0.59       586

12/17/2017 22:25:00 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:25:00 [INFO] exp_shallowmodel: 
[[  1   3   9   3]
 [  2 110  36  21]
 [  0  38 196  37]
 [  4  37  42  47]]
12/17/2017 22:25:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/17/2017 22:25:01 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:25:01 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:25:01 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:25:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:25:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:25:01 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:25:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:26:40 [INFO] exp_shallowmodel: train time: 98.675s
12/17/2017 22:26:40 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:26:40 [INFO] exp_shallowmodel: accuracy:   0.646
12/17/2017 22:26:40 [INFO] exp_shallowmodel: f1_score:   0.460
12/17/2017 22:26:40 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:26:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.68      0.63       164
          F       0.73      0.77      0.75       268
          R       0.53      0.41      0.46       125

avg / total       0.63      0.65      0.63       571

12/17/2017 22:26:40 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:26:40 [INFO] exp_shallowmodel: 
[[  0   4   8   2]
 [  0 111  32  21]
 [  1  37 207  23]
 [  1  35  38  51]]
12/17/2017 22:26:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/17/2017 22:26:40 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:26:40 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:26:40 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:26:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:26:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:26:40 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:26:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:28:16 [INFO] exp_shallowmodel: train time: 95.636s
12/17/2017 22:28:16 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:28:16 [INFO] exp_shallowmodel: accuracy:   0.622
12/17/2017 22:28:16 [INFO] exp_shallowmodel: f1_score:   0.468
12/17/2017 22:28:16 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:28:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        14
          C       0.57      0.71      0.63       164
          F       0.73      0.73      0.73       268
          R       0.45      0.34      0.39       125

avg / total       0.61      0.62      0.61       571

12/17/2017 22:28:16 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:28:16 [INFO] exp_shallowmodel: 
[[  1   2   9   2]
 [  0 116  27  21]
 [  1  42 195  30]
 [  0  45  37  43]]
12/17/2017 22:28:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/17/2017 22:28:17 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:28:17 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:28:17 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:28:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:28:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:28:17 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:28:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:31:34 [INFO] exp_shallowmodel: train time: 196.627s
12/17/2017 22:31:34 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:31:34 [INFO] exp_shallowmodel: accuracy:   0.620
12/17/2017 22:31:34 [INFO] exp_shallowmodel: f1_score:   0.441
12/17/2017 22:31:34 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:31:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.60      0.60       164
          F       0.70      0.76      0.73       268
          R       0.47      0.41      0.44       125

avg / total       0.60      0.62      0.61       571

12/17/2017 22:31:34 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:31:34 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  0  99  40  25]
 [  1  33 204  30]
 [  2  32  40  51]]
12/17/2017 22:31:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/17/2017 22:31:35 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:31:35 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:31:35 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:31:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:31:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:31:35 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:31:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:34:55 [INFO] exp_shallowmodel: train time: 200.120s
12/17/2017 22:34:55 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:34:55 [INFO] exp_shallowmodel: accuracy:   0.639
12/17/2017 22:34:55 [INFO] exp_shallowmodel: f1_score:   0.530
12/17/2017 22:34:55 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:34:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.21      0.30        14
          C       0.58      0.64      0.61       164
          F       0.73      0.76      0.74       268
          R       0.50      0.43      0.47       125

avg / total       0.63      0.64      0.63       571

12/17/2017 22:34:55 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:34:55 [INFO] exp_shallowmodel: 
[[  3   2   8   1]
 [  0 105  31  28]
 [  1  40 203  24]
 [  2  34  35  54]]
12/17/2017 22:34:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/17/2017 22:34:56 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:34:56 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:34:56 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:34:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:34:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:34:56 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:34:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:38:22 [INFO] exp_shallowmodel: train time: 205.897s
12/17/2017 22:38:22 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:38:22 [INFO] exp_shallowmodel: accuracy:   0.629
12/17/2017 22:38:22 [INFO] exp_shallowmodel: f1_score:   0.449
12/17/2017 22:38:22 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:38:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.67      0.63       164
          F       0.73      0.75      0.74       268
          R       0.49      0.38      0.43       125

avg / total       0.62      0.63      0.62       571

12/17/2017 22:38:22 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:38:22 [INFO] exp_shallowmodel: 
[[  0   5   6   3]
 [  1 110  33  20]
 [  4  36 201  27]
 [  4  37  36  48]]
12/17/2017 22:38:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/17/2017 22:38:23 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:38:23 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:38:23 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:38:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:38:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:38:23 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:38:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:41:51 [INFO] exp_shallowmodel: train time: 207.557s
12/17/2017 22:41:51 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:41:51 [INFO] exp_shallowmodel: accuracy:   0.646
12/17/2017 22:41:51 [INFO] exp_shallowmodel: f1_score:   0.475
12/17/2017 22:41:51 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:41:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.61      0.69      0.65       164
          F       0.72      0.81      0.76       268
          R       0.46      0.31      0.37       125

avg / total       0.62      0.65      0.63       571

12/17/2017 22:41:51 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:41:51 [INFO] exp_shallowmodel: 
[[  1   2   6   5]
 [  0 113  30  21]
 [  1  31 216  20]
 [  1  39  46  39]]
12/17/2017 22:41:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/17/2017 22:41:52 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:41:52 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:41:52 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:41:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:41:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:41:52 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:41:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:45:16 [INFO] exp_shallowmodel: train time: 203.520s
12/17/2017 22:45:16 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:45:16 [INFO] exp_shallowmodel: accuracy:   0.636
12/17/2017 22:45:16 [INFO] exp_shallowmodel: f1_score:   0.472
12/17/2017 22:45:16 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:45:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        14
          C       0.60      0.63      0.62       164
          F       0.72      0.80      0.76       268
          R       0.44      0.34      0.39       125

avg / total       0.62      0.64      0.62       571

12/17/2017 22:45:16 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:45:16 [INFO] exp_shallowmodel: 
[[  1   1   8   4]
 [  0 104  29  31]
 [  1  33 215  19]
 [  0  36  46  43]]
12/17/2017 22:45:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/17/2017 22:45:17 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:45:17 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:45:17 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:45:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:45:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:45:17 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:45:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:48:30 [INFO] exp_shallowmodel: train time: 193.173s
12/17/2017 22:48:30 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:48:30 [INFO] exp_shallowmodel: accuracy:   0.611
12/17/2017 22:48:30 [INFO] exp_shallowmodel: f1_score:   0.499
12/17/2017 22:48:30 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:48:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.21      0.29        14
          C       0.58      0.60      0.59       164
          F       0.71      0.75      0.73       268
          R       0.42      0.37      0.39       125

avg / total       0.60      0.61      0.60       571

12/17/2017 22:48:30 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:48:30 [INFO] exp_shallowmodel: 
[[  3   1   6   4]
 [  2  98  33  31]
 [  1  36 202  29]
 [  1  34  44  46]]
12/17/2017 22:48:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/17/2017 22:48:31 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 22:48:31 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:48:31 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:48:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:48:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:48:31 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:48:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:52:08 [INFO] exp_shallowmodel: train time: 216.630s
12/17/2017 22:52:08 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:52:08 [INFO] exp_shallowmodel: accuracy:   0.644
12/17/2017 22:52:08 [INFO] exp_shallowmodel: f1_score:   0.497
12/17/2017 22:52:08 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:52:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.14      0.18        14
          C       0.64      0.66      0.65       164
          F       0.73      0.79      0.76       268
          R       0.45      0.36      0.40       125

avg / total       0.63      0.64      0.63       571

12/17/2017 22:52:08 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:52:08 [INFO] exp_shallowmodel: 
[[  2   3   6   3]
 [  1 108  31  24]
 [  2  25 213  28]
 [  3  34  43  45]]
12/17/2017 22:52:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/17/2017 22:52:09 [INFO] exp_shallowmodel: #(data) = 4568
12/17/2017 22:52:09 [INFO] exp_shallowmodel: #(feature) = 3440
12/17/2017 22:52:09 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:52:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:52:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:52:09 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:52:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:55:40 [INFO] exp_shallowmodel: train time: 210.813s
12/17/2017 22:55:40 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:55:40 [INFO] exp_shallowmodel: accuracy:   0.638
12/17/2017 22:55:40 [INFO] exp_shallowmodel: f1_score:   0.487
12/17/2017 22:55:40 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:55:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.06      0.09        16
          C       0.60      0.60      0.60       169
          F       0.73      0.76      0.74       271
          R       0.52      0.52      0.52       130

avg / total       0.63      0.64      0.63       586

12/17/2017 22:55:40 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:55:40 [INFO] exp_shallowmodel: 
[[  1   3   8   4]
 [  3 101  38  27]
 [  1  33 205  32]
 [  1  31  31  67]]
12/17/2017 22:55:47 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 22:55:47 [INFO] task_runner: context=current, feature=13-[8+1.3.4]
12/17/2017 22:55:47 [INFO] task_runner: retained feature numbers=[5, 7, 2.2, 3, 2.1, 1, 11.1, 6]
12/17/2017 22:55:47 [INFO] task_runner: #(data)=5934
12/17/2017 22:55:47 [INFO] task_runner: #(feature)=3759
12/17/2017 22:55:47 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 22:55:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/17/2017 22:55:48 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:55:48 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 22:55:48 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:55:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:55:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:55:48 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:55:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:00:30 [INFO] exp_shallowmodel: train time: 281.666s
12/17/2017 23:00:30 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:00:30 [INFO] exp_shallowmodel: accuracy:   0.588
12/17/2017 23:00:30 [INFO] exp_shallowmodel: f1_score:   0.457
12/17/2017 23:00:30 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:00:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.15      0.21        20
          C       0.53      0.55      0.54       169
          F       0.70      0.75      0.72       281
          R       0.39      0.33      0.36       122

avg / total       0.57      0.59      0.58       592

12/17/2017 23:00:30 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:00:30 [INFO] exp_shallowmodel: 
[[  3   1   8   8]
 [  3  93  48  25]
 [  2  37 212  30]
 [  1  44  37  40]]
12/17/2017 23:00:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/17/2017 23:00:31 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:00:31 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:00:31 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:00:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:00:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:00:31 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:00:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:05:05 [INFO] exp_shallowmodel: train time: 273.280s
12/17/2017 23:05:05 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:05:05 [INFO] exp_shallowmodel: accuracy:   0.633
12/17/2017 23:05:05 [INFO] exp_shallowmodel: f1_score:   0.502
12/17/2017 23:05:05 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:05:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.20      0.23        20
          C       0.58      0.64      0.61       169
          F       0.75      0.77      0.76       281
          R       0.45      0.38      0.41       122

avg / total       0.62      0.63      0.63       592

12/17/2017 23:05:05 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:05:05 [INFO] exp_shallowmodel: 
[[  4   2  10   4]
 [  3 108  29  29]
 [  2  39 217  23]
 [  6  38  32  46]]
12/17/2017 23:05:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/17/2017 23:05:06 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:05:06 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:05:06 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:05:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:05:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:05:06 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:05:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:09:41 [INFO] exp_shallowmodel: train time: 275.168s
12/17/2017 23:09:41 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:09:41 [INFO] exp_shallowmodel: accuracy:   0.598
12/17/2017 23:09:41 [INFO] exp_shallowmodel: f1_score:   0.430
12/17/2017 23:09:41 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:09:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.54      0.50      0.52       169
          F       0.72      0.79      0.76       281
          R       0.39      0.37      0.38       122

avg / total       0.58      0.60      0.59       592

12/17/2017 23:09:41 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:09:41 [INFO] exp_shallowmodel: 
[[  1   4  11   4]
 [  1  85  45  38]
 [  4  26 223  28]
 [  6  41  30  45]]
12/17/2017 23:09:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/17/2017 23:09:43 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:09:43 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:09:43 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:09:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:09:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:09:43 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:09:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:14:48 [INFO] exp_shallowmodel: train time: 305.776s
12/17/2017 23:14:48 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:14:48 [INFO] exp_shallowmodel: accuracy:   0.595
12/17/2017 23:14:48 [INFO] exp_shallowmodel: f1_score:   0.444
12/17/2017 23:14:48 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:14:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.10      0.13        20
          C       0.58      0.61      0.59       169
          F       0.72      0.74      0.73       281
          R       0.34      0.31      0.33       122

avg / total       0.58      0.59      0.59       592

12/17/2017 23:14:48 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:14:48 [INFO] exp_shallowmodel: 
[[  2   4   9   5]
 [  0 103  29  37]
 [  5  36 209  31]
 [  4  36  44  38]]
12/17/2017 23:14:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/17/2017 23:14:50 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:14:50 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:14:50 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:14:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:14:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:14:50 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:14:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:17:57 [INFO] exp_shallowmodel: train time: 187.423s
12/17/2017 23:17:57 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:17:57 [INFO] exp_shallowmodel: accuracy:   0.586
12/17/2017 23:17:57 [INFO] exp_shallowmodel: f1_score:   0.434
12/17/2017 23:17:57 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:17:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.53      0.60      0.56       169
          F       0.73      0.70      0.72       281
          R       0.41      0.39      0.40       122

avg / total       0.58      0.59      0.58       592

12/17/2017 23:17:57 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:17:57 [INFO] exp_shallowmodel: 
[[  1   6   5   8]
 [  2 101  35  31]
 [  7  46 197  31]
 [  2  39  33  48]]
12/17/2017 23:17:58 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/17/2017 23:17:58 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:17:58 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:17:58 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:17:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:17:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:17:58 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:17:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:21:04 [INFO] exp_shallowmodel: train time: 185.979s
12/17/2017 23:21:04 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:21:04 [INFO] exp_shallowmodel: accuracy:   0.583
12/17/2017 23:21:04 [INFO] exp_shallowmodel: f1_score:   0.407
12/17/2017 23:21:04 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:21:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.57      0.55       169
          F       0.70      0.74      0.72       281
          R       0.41      0.32      0.36       122

avg / total       0.57      0.58      0.57       592

12/17/2017 23:21:04 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:21:04 [INFO] exp_shallowmodel: 
[[  0   5  11   4]
 [  2  97  41  29]
 [  3  45 209  24]
 [  7  38  38  39]]
12/17/2017 23:21:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/17/2017 23:21:05 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:21:05 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:21:05 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:21:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:21:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:21:05 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:21:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:25:42 [INFO] exp_shallowmodel: train time: 276.928s
12/17/2017 23:25:42 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:25:42 [INFO] exp_shallowmodel: accuracy:   0.608
12/17/2017 23:25:42 [INFO] exp_shallowmodel: f1_score:   0.448
12/17/2017 23:25:42 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:25:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.57      0.63      0.60       169
          F       0.73      0.74      0.73       281
          R       0.39      0.37      0.38       122

avg / total       0.60      0.61      0.60       592

12/17/2017 23:25:42 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:25:42 [INFO] exp_shallowmodel: 
[[  1   5   6   8]
 [  0 106  34  29]
 [  4  36 208  33]
 [  0  39  38  45]]
12/17/2017 23:25:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/17/2017 23:25:44 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:25:44 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:25:44 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:25:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:25:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:25:44 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:25:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:30:06 [INFO] exp_shallowmodel: train time: 262.602s
12/17/2017 23:30:06 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:30:06 [INFO] exp_shallowmodel: accuracy:   0.603
12/17/2017 23:30:06 [INFO] exp_shallowmodel: f1_score:   0.464
12/17/2017 23:30:06 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:30:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.15      0.19        20
          C       0.53      0.57      0.55       169
          F       0.71      0.77      0.74       281
          R       0.43      0.34      0.38       122

avg / total       0.59      0.60      0.59       592

12/17/2017 23:30:06 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:30:06 [INFO] exp_shallowmodel: 
[[  3   4   6   7]
 [  5  96  42  26]
 [  1  42 217  21]
 [  3  39  39  41]]
12/17/2017 23:30:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/17/2017 23:30:08 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:30:08 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:30:08 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:30:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:30:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:30:08 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:30:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:34:34 [INFO] exp_shallowmodel: train time: 266.331s
12/17/2017 23:34:34 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:34:34 [INFO] exp_shallowmodel: accuracy:   0.603
12/17/2017 23:34:34 [INFO] exp_shallowmodel: f1_score:   0.482
12/17/2017 23:34:34 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:34:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.20      0.26        20
          C       0.54      0.63      0.58       169
          F       0.72      0.74      0.73       281
          R       0.41      0.32      0.36       122

avg / total       0.59      0.60      0.59       592

12/17/2017 23:34:34 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:34:34 [INFO] exp_shallowmodel: 
[[  4   1  10   5]
 [  2 107  36  24]
 [  4  44 207  26]
 [  1  48  34  39]]
12/17/2017 23:34:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/17/2017 23:34:35 [INFO] exp_shallowmodel: #(data) = 4736
12/17/2017 23:34:35 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:34:35 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:34:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:34:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:34:35 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:34:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:38:13 [INFO] exp_shallowmodel: train time: 217.752s
12/17/2017 23:38:13 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:38:13 [INFO] exp_shallowmodel: accuracy:   0.616
12/17/2017 23:38:13 [INFO] exp_shallowmodel: f1_score:   0.437
12/17/2017 23:38:13 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:38:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.53      0.63      0.57       172
          F       0.75      0.77      0.76       283
          R       0.45      0.39      0.42       123

avg / total       0.59      0.62      0.60       606

12/17/2017 23:38:13 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:38:13 [INFO] exp_shallowmodel: 
[[  0   7  11  10]
 [  1 108  35  28]
 [  3  42 217  21]
 [  1  47  27  48]]
12/17/2017 23:38:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/17/2017 23:38:14 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:38:14 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:38:14 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:38:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:38:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:38:14 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:38:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:42:53 [INFO] exp_shallowmodel: train time: 278.480s
12/17/2017 23:42:53 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:42:53 [INFO] exp_shallowmodel: accuracy:   0.618
12/17/2017 23:42:53 [INFO] exp_shallowmodel: f1_score:   0.474
12/17/2017 23:42:53 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:42:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.56      0.63      0.59       169
          F       0.75      0.74      0.75       281
          R       0.42      0.40      0.41       122

avg / total       0.61      0.62      0.61       592

12/17/2017 23:42:53 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:42:53 [INFO] exp_shallowmodel: 
[[  2   2  11   5]
 [  3 106  33  27]
 [  1  34 209  37]
 [  1  47  25  49]]
12/17/2017 23:42:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/17/2017 23:42:54 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:42:54 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:42:54 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:42:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:42:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:42:54 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:42:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:47:38 [INFO] exp_shallowmodel: train time: 284.145s
12/17/2017 23:47:38 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:47:38 [INFO] exp_shallowmodel: accuracy:   0.579
12/17/2017 23:47:38 [INFO] exp_shallowmodel: f1_score:   0.432
12/17/2017 23:47:38 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:47:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.10      0.12        20
          C       0.53      0.54      0.54       169
          F       0.70      0.74      0.72       281
          R       0.37      0.33      0.35       122

avg / total       0.57      0.58      0.57       592

12/17/2017 23:47:38 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:47:38 [INFO] exp_shallowmodel: 
[[  2   5   7   6]
 [  0  92  48  29]
 [  6  33 209  33]
 [  5  42  35  40]]
12/17/2017 23:47:40 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/17/2017 23:47:40 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:47:40 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:47:40 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:47:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:47:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:47:40 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:47:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:52:09 [INFO] exp_shallowmodel: train time: 269.414s
12/17/2017 23:52:09 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:52:09 [INFO] exp_shallowmodel: accuracy:   0.598
12/17/2017 23:52:09 [INFO] exp_shallowmodel: f1_score:   0.434
12/17/2017 23:52:09 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:52:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.58      0.64      0.61       169
          F       0.73      0.73      0.73       281
          R       0.36      0.32      0.34       122

avg / total       0.59      0.60      0.59       592

12/17/2017 23:52:09 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:52:09 [INFO] exp_shallowmodel: 
[[  1   5   9   5]
 [  3 109  28  29]
 [  5  35 205  36]
 [  5  39  39  39]]
12/17/2017 23:52:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/17/2017 23:52:11 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:52:11 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:52:11 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:52:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:52:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:52:11 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:52:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:56:05 [INFO] exp_shallowmodel: train time: 234.818s
12/17/2017 23:56:05 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:56:05 [INFO] exp_shallowmodel: accuracy:   0.611
12/17/2017 23:56:05 [INFO] exp_shallowmodel: f1_score:   0.447
12/17/2017 23:56:05 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:56:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.05      0.08        20
          C       0.55      0.61      0.58       169
          F       0.74      0.76      0.75       281
          R       0.41      0.36      0.38       122

avg / total       0.60      0.61      0.60       592

12/17/2017 23:56:05 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:56:05 [INFO] exp_shallowmodel: 
[[  1   3  12   4]
 [  2 103  33  31]
 [  1  38 214  28]
 [  2  44  32  44]]
12/17/2017 23:56:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/17/2017 23:56:06 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:56:06 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:56:06 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:56:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:56:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:56:06 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:56:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:58:27 [INFO] exp_shallowmodel: train time: 140.890s
12/17/2017 23:58:27 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:58:27 [INFO] exp_shallowmodel: accuracy:   0.606
12/17/2017 23:58:27 [INFO] exp_shallowmodel: f1_score:   0.438
12/17/2017 23:58:27 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:58:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.05      0.07        20
          C       0.55      0.62      0.58       169
          F       0.73      0.76      0.75       281
          R       0.39      0.32      0.35       122

avg / total       0.59      0.61      0.60       592

12/17/2017 23:58:27 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:58:27 [INFO] exp_shallowmodel: 
[[  1   3  12   4]
 [  1 105  31  32]
 [  3  40 214  24]
 [  3  44  36  39]]
12/17/2017 23:58:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/17/2017 23:58:28 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 23:58:28 [INFO] exp_shallowmodel: #(feature) = 3759
12/17/2017 23:58:28 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:58:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:58:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:58:28 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:58:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:02:48 [INFO] exp_shallowmodel: train time: 259.478s
12/18/2017 00:02:48 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 00:02:48 [INFO] exp_shallowmodel: accuracy:   0.596
12/18/2017 00:02:48 [INFO] exp_shallowmodel: f1_score:   0.485
12/18/2017 00:02:48 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:02:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.20      0.27        20
          C       0.53      0.65      0.58       169
          F       0.71      0.70      0.71       281
          R       0.43      0.34      0.38       122

avg / total       0.59      0.60      0.59       592

12/18/2017 00:02:48 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:02:48 [INFO] exp_shallowmodel: 
[[  4   3   7   6]
 [  3 110  35  21]
 [  2  53 197  29]
 [  1  42  37  42]]
12/18/2017 00:02:49 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/18/2017 00:02:49 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:02:49 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:02:49 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:02:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:02:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:02:49 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:02:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:07:11 [INFO] exp_shallowmodel: train time: 261.895s
12/18/2017 00:07:11 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 00:07:11 [INFO] exp_shallowmodel: accuracy:   0.627
12/18/2017 00:07:11 [INFO] exp_shallowmodel: f1_score:   0.512
12/18/2017 00:07:11 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:07:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.25      0.32        20
          C       0.57      0.68      0.62       169
          F       0.74      0.76      0.75       281
          R       0.41      0.31      0.36       122

avg / total       0.61      0.63      0.62       592

12/18/2017 00:07:11 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:07:11 [INFO] exp_shallowmodel: 
[[  5   0  12   3]
 [  1 115  28  25]
 [  3  39 213  26]
 [  2  46  36  38]]
12/18/2017 00:07:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/18/2017 00:07:12 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:07:12 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:07:12 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:07:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:07:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:07:12 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:07:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:11:47 [INFO] exp_shallowmodel: train time: 274.473s
12/18/2017 00:11:47 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 00:11:47 [INFO] exp_shallowmodel: accuracy:   0.615
12/18/2017 00:11:47 [INFO] exp_shallowmodel: f1_score:   0.462
12/18/2017 00:11:47 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:11:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.10      0.13        20
          C       0.55      0.56      0.55       169
          F       0.74      0.79      0.76       281
          R       0.42      0.39      0.40       122

avg / total       0.60      0.61      0.61       592

12/18/2017 00:11:47 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:11:47 [INFO] exp_shallowmodel: 
[[  2   1   9   8]
 [  2  94  35  38]
 [  3  37 221  20]
 [  3  38  34  47]]
12/18/2017 00:11:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/18/2017 00:11:48 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:11:48 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:11:48 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:11:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:11:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:11:48 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:11:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:16:20 [INFO] exp_shallowmodel: train time: 271.957s
12/18/2017 00:16:20 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 00:16:20 [INFO] exp_shallowmodel: accuracy:   0.620
12/18/2017 00:16:20 [INFO] exp_shallowmodel: f1_score:   0.462
12/18/2017 00:16:20 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:16:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.10      0.12        20
          C       0.57      0.63      0.60       169
          F       0.74      0.78      0.76       281
          R       0.41      0.34      0.37       122

avg / total       0.60      0.62      0.61       592

12/18/2017 00:16:20 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:16:20 [INFO] exp_shallowmodel: 
[[  2   6   9   3]
 [  1 106  28  34]
 [  3  37 218  23]
 [  6  36  39  41]]
12/18/2017 00:16:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/18/2017 00:16:22 [INFO] exp_shallowmodel: #(data) = 4736
12/18/2017 00:16:22 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:16:22 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:16:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:16:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:16:22 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:16:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:21:04 [INFO] exp_shallowmodel: train time: 282.073s
12/18/2017 00:21:04 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 00:21:04 [INFO] exp_shallowmodel: accuracy:   0.609
12/18/2017 00:21:04 [INFO] exp_shallowmodel: f1_score:   0.469
12/18/2017 00:21:04 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:21:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.11      0.16        28
          C       0.55      0.63      0.59       172
          F       0.72      0.75      0.74       283
          R       0.43      0.36      0.39       123

avg / total       0.59      0.61      0.60       606

12/18/2017 00:21:04 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:21:04 [INFO] exp_shallowmodel: 
[[  3   8  10   7]
 [  0 109  40  23]
 [  3  38 213  29]
 [  3  44  32  44]]
12/18/2017 00:21:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/18/2017 00:21:05 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:21:05 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:21:05 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:21:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:21:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:21:05 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:21:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:25:42 [INFO] exp_shallowmodel: train time: 277.290s
12/18/2017 00:25:42 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 00:25:42 [INFO] exp_shallowmodel: accuracy:   0.574
12/18/2017 00:25:42 [INFO] exp_shallowmodel: f1_score:   0.455
12/18/2017 00:25:42 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:25:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.20      0.25        20
          C       0.48      0.53      0.50       169
          F       0.72      0.74      0.73       281
          R       0.36      0.31      0.33       122

avg / total       0.57      0.57      0.57       592

12/18/2017 00:25:42 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:25:42 [INFO] exp_shallowmodel: 
[[  4   3   8   5]
 [  2  89  40  38]
 [  4  43 209  25]
 [  2  49  33  38]]
12/18/2017 00:25:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/18/2017 00:25:44 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:25:44 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:25:44 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:25:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:25:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:25:44 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:25:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:30:28 [INFO] exp_shallowmodel: train time: 284.467s
12/18/2017 00:30:28 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 00:30:28 [INFO] exp_shallowmodel: accuracy:   0.618
12/18/2017 00:30:28 [INFO] exp_shallowmodel: f1_score:   0.451
12/18/2017 00:30:28 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:30:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.05      0.06        20
          C       0.56      0.69      0.62       169
          F       0.75      0.74      0.74       281
          R       0.43      0.34      0.38       122

avg / total       0.61      0.62      0.61       592

12/18/2017 00:30:28 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:30:28 [INFO] exp_shallowmodel: 
[[  1   6   9   4]
 [  1 117  30  21]
 [  4  40 207  30]
 [  5  45  31  41]]
12/18/2017 00:30:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/18/2017 00:30:29 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:30:29 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:30:29 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:30:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:30:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:30:29 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:30:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:34:59 [INFO] exp_shallowmodel: train time: 269.656s
12/18/2017 00:34:59 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 00:34:59 [INFO] exp_shallowmodel: accuracy:   0.618
12/18/2017 00:34:59 [INFO] exp_shallowmodel: f1_score:   0.429
12/18/2017 00:34:59 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:34:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.59      0.63      0.61       169
          F       0.71      0.79      0.75       281
          R       0.42      0.31      0.36       122

avg / total       0.59      0.62      0.60       592

12/18/2017 00:34:59 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:34:59 [INFO] exp_shallowmodel: 
[[  0   2  15   3]
 [  2 107  37  23]
 [  3  31 221  26]
 [  4  41  39  38]]
12/18/2017 00:35:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/18/2017 00:35:01 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:35:01 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:35:01 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:35:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:35:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:35:01 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:35:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:38:28 [INFO] exp_shallowmodel: train time: 207.483s
12/18/2017 00:38:28 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 00:38:28 [INFO] exp_shallowmodel: accuracy:   0.588
12/18/2017 00:38:28 [INFO] exp_shallowmodel: f1_score:   0.473
12/18/2017 00:38:28 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:38:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.20      0.29        20
          C       0.52      0.56      0.54       169
          F       0.70      0.75      0.73       281
          R       0.37      0.31      0.34       122

avg / total       0.58      0.59      0.58       592

12/18/2017 00:38:28 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:38:28 [INFO] exp_shallowmodel: 
[[  4   2  11   3]
 [  2  94  39  34]
 [  1  40 212  28]
 [  1  44  39  38]]
12/18/2017 00:38:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/18/2017 00:38:29 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:38:29 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:38:29 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:38:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:38:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:38:29 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:38:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:42:59 [INFO] exp_shallowmodel: train time: 270.036s
12/18/2017 00:42:59 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 00:42:59 [INFO] exp_shallowmodel: accuracy:   0.606
12/18/2017 00:42:59 [INFO] exp_shallowmodel: f1_score:   0.474
12/18/2017 00:42:59 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:42:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.15      0.18        20
          C       0.53      0.62      0.57       169
          F       0.73      0.73      0.73       281
          R       0.46      0.38      0.41       122

avg / total       0.60      0.61      0.60       592

12/18/2017 00:42:59 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:42:59 [INFO] exp_shallowmodel: 
[[  3   3   7   7]
 [  3 104  38  24]
 [  3  49 206  23]
 [  4  39  33  46]]
12/18/2017 00:43:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/18/2017 00:43:01 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:43:01 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:43:01 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:43:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:43:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:43:01 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:43:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:47:46 [INFO] exp_shallowmodel: train time: 285.584s
12/18/2017 00:47:46 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 00:47:46 [INFO] exp_shallowmodel: accuracy:   0.590
12/18/2017 00:47:46 [INFO] exp_shallowmodel: f1_score:   0.443
12/18/2017 00:47:46 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:47:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.10      0.14        20
          C       0.55      0.56      0.55       169
          F       0.70      0.75      0.72       281
          R       0.38      0.34      0.36       122

avg / total       0.57      0.59      0.58       592

12/18/2017 00:47:46 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:47:46 [INFO] exp_shallowmodel: 
[[  2   3   8   7]
 [  3  94  40  32]
 [  3  39 212  27]
 [  1  36  44  41]]
12/18/2017 00:47:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/18/2017 00:47:48 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:47:48 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:47:48 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:47:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:47:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:47:48 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:47:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:50:44 [INFO] exp_shallowmodel: train time: 176.437s
12/18/2017 00:50:44 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 00:50:44 [INFO] exp_shallowmodel: accuracy:   0.591
12/18/2017 00:50:44 [INFO] exp_shallowmodel: f1_score:   0.435
12/18/2017 00:50:44 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:50:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.56      0.64      0.60       169
          F       0.70      0.71      0.70       281
          R       0.38      0.34      0.36       122

avg / total       0.58      0.59      0.58       592

12/18/2017 00:50:44 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:50:44 [INFO] exp_shallowmodel: 
[[  1   5   8   6]
 [  1 108  34  26]
 [  1  45 200  35]
 [  2  34  45  41]]
12/18/2017 00:50:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/18/2017 00:50:45 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:50:45 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:50:45 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:50:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:50:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:50:45 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:50:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:55:11 [INFO] exp_shallowmodel: train time: 265.816s
12/18/2017 00:55:11 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 00:55:11 [INFO] exp_shallowmodel: accuracy:   0.590
12/18/2017 00:55:11 [INFO] exp_shallowmodel: f1_score:   0.438
12/18/2017 00:55:11 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:55:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.10      0.12        20
          C       0.51      0.57      0.54       169
          F       0.71      0.76      0.73       281
          R       0.41      0.31      0.36       122

avg / total       0.57      0.59      0.58       592

12/18/2017 00:55:11 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:55:11 [INFO] exp_shallowmodel: 
[[  2   7   9   2]
 [  3  96  39  31]
 [  4  43 213  21]
 [  3  42  39  38]]
12/18/2017 00:55:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/18/2017 00:55:12 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:55:12 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:55:12 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:55:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:55:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:55:12 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:55:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:57:28 [INFO] exp_shallowmodel: train time: 135.707s
12/18/2017 00:57:28 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 00:57:28 [INFO] exp_shallowmodel: accuracy:   0.610
12/18/2017 00:57:28 [INFO] exp_shallowmodel: f1_score:   0.467
12/18/2017 00:57:28 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:57:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.15      0.20        20
          C       0.56      0.60      0.58       169
          F       0.71      0.78      0.75       281
          R       0.39      0.30      0.34       122

avg / total       0.59      0.61      0.60       592

12/18/2017 00:57:28 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:57:28 [INFO] exp_shallowmodel: 
[[  3   0  11   6]
 [  1 101  43  24]
 [  0  34 220  27]
 [  6  44  35  37]]
12/18/2017 00:57:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/18/2017 00:57:28 [INFO] exp_shallowmodel: #(data) = 4736
12/18/2017 00:57:28 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:57:28 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:57:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:57:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:57:28 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:57:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:59:38 [INFO] exp_shallowmodel: train time: 129.778s
12/18/2017 00:59:38 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 00:59:38 [INFO] exp_shallowmodel: accuracy:   0.622
12/18/2017 00:59:38 [INFO] exp_shallowmodel: f1_score:   0.474
12/18/2017 00:59:38 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:59:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.11      0.16        28
          C       0.58      0.67      0.62       172
          F       0.74      0.77      0.75       283
          R       0.40      0.33      0.36       123

avg / total       0.61      0.62      0.61       606

12/18/2017 00:59:38 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:59:38 [INFO] exp_shallowmodel: 
[[  3   4  11  10]
 [  2 116  31  23]
 [  2  36 217  28]
 [  3  45  34  41]]
12/18/2017 00:59:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/18/2017 00:59:39 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 00:59:39 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 00:59:39 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:59:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:59:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:59:39 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:59:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:04:19 [INFO] exp_shallowmodel: train time: 280.050s
12/18/2017 01:04:19 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 01:04:19 [INFO] exp_shallowmodel: accuracy:   0.640
12/18/2017 01:04:19 [INFO] exp_shallowmodel: f1_score:   0.514
12/18/2017 01:04:19 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:04:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.20      0.28        20
          C       0.59      0.62      0.61       169
          F       0.73      0.80      0.77       281
          R       0.45      0.37      0.41       122

avg / total       0.63      0.64      0.63       592

12/18/2017 01:04:19 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:04:19 [INFO] exp_shallowmodel: 
[[  4   6   6   4]
 [  2 105  36  26]
 [  2  30 225  24]
 [  1  36  40  45]]
12/18/2017 01:04:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/18/2017 01:04:21 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:04:21 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:04:21 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:04:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:04:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:04:21 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:04:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:08:52 [INFO] exp_shallowmodel: train time: 271.624s
12/18/2017 01:08:53 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 01:08:53 [INFO] exp_shallowmodel: accuracy:   0.600
12/18/2017 01:08:53 [INFO] exp_shallowmodel: f1_score:   0.450
12/18/2017 01:08:53 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:08:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.10      0.16        20
          C       0.56      0.63      0.59       169
          F       0.74      0.75      0.75       281
          R       0.31      0.29      0.30       122

avg / total       0.59      0.60      0.59       592

12/18/2017 01:08:53 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:08:53 [INFO] exp_shallowmodel: 
[[  2   3   6   9]
 [  1 106  27  35]
 [  1  35 212  33]
 [  1  46  40  35]]
12/18/2017 01:08:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/18/2017 01:08:54 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:08:54 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:08:54 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:08:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:08:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:08:54 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:08:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:13:26 [INFO] exp_shallowmodel: train time: 271.822s
12/18/2017 01:13:26 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 01:13:26 [INFO] exp_shallowmodel: accuracy:   0.613
12/18/2017 01:13:26 [INFO] exp_shallowmodel: f1_score:   0.497
12/18/2017 01:13:26 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:13:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.20      0.29        20
          C       0.50      0.64      0.56       169
          F       0.77      0.74      0.75       281
          R       0.44      0.34      0.39       122

avg / total       0.61      0.61      0.61       592

12/18/2017 01:13:26 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:13:26 [INFO] exp_shallowmodel: 
[[  4   5   8   3]
 [  3 108  28  30]
 [  0  52 209  20]
 [  1  51  28  42]]
12/18/2017 01:13:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/18/2017 01:13:27 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:13:27 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:13:27 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:13:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:13:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:13:27 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:13:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:17:49 [INFO] exp_shallowmodel: train time: 262.207s
12/18/2017 01:17:49 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 01:17:49 [INFO] exp_shallowmodel: accuracy:   0.586
12/18/2017 01:17:49 [INFO] exp_shallowmodel: f1_score:   0.424
12/18/2017 01:17:49 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:17:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.53      0.62      0.57       169
          F       0.72      0.73      0.72       281
          R       0.37      0.30      0.33       122

avg / total       0.57      0.59      0.58       592

12/18/2017 01:17:49 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:17:49 [INFO] exp_shallowmodel: 
[[  1   4   9   6]
 [  1 105  35  28]
 [  4  43 204  30]
 [  3  46  36  37]]
12/18/2017 01:17:51 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/18/2017 01:17:51 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:17:51 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:17:51 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:17:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:17:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:17:51 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:17:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:22:12 [INFO] exp_shallowmodel: train time: 260.858s
12/18/2017 01:22:12 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 01:22:12 [INFO] exp_shallowmodel: accuracy:   0.603
12/18/2017 01:22:12 [INFO] exp_shallowmodel: f1_score:   0.442
12/18/2017 01:22:12 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:22:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        20
          C       0.56      0.51      0.53       169
          F       0.70      0.79      0.74       281
          R       0.41      0.40      0.41       122

avg / total       0.59      0.60      0.59       592

12/18/2017 01:22:12 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:22:12 [INFO] exp_shallowmodel: 
[[  1   3  11   5]
 [  0  86  47  36]
 [  1  30 221  29]
 [  1  34  38  49]]
12/18/2017 01:22:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/18/2017 01:22:13 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:22:13 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:22:13 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:22:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:22:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:22:13 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:22:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:26:24 [INFO] exp_shallowmodel: train time: 251.556s
12/18/2017 01:26:24 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 01:26:24 [INFO] exp_shallowmodel: accuracy:   0.598
12/18/2017 01:26:24 [INFO] exp_shallowmodel: f1_score:   0.476
12/18/2017 01:26:24 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:26:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.20      0.28        20
          C       0.53      0.55      0.54       169
          F       0.70      0.78      0.74       281
          R       0.39      0.31      0.35       122

avg / total       0.58      0.60      0.59       592

12/18/2017 01:26:24 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:26:24 [INFO] exp_shallowmodel: 
[[  4   2  10   4]
 [  0  93  46  30]
 [  1  35 219  26]
 [  4  44  36  38]]
12/18/2017 01:26:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/18/2017 01:26:26 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:26:26 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:26:26 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:26:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:26:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:26:26 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:26:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:30:42 [INFO] exp_shallowmodel: train time: 256.632s
12/18/2017 01:30:42 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 01:30:42 [INFO] exp_shallowmodel: accuracy:   0.562
12/18/2017 01:30:42 [INFO] exp_shallowmodel: f1_score:   0.417
12/18/2017 01:30:42 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:30:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.10      0.13        20
          C       0.48      0.60      0.53       169
          F       0.72      0.70      0.71       281
          R       0.34      0.26      0.29       122

avg / total       0.55      0.56      0.56       592

12/18/2017 01:30:42 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:30:42 [INFO] exp_shallowmodel: 
[[  2   9   4   5]
 [  3 102  33  31]
 [  3  54 197  27]
 [  3  48  39  32]]
12/18/2017 01:30:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/18/2017 01:30:44 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:30:44 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:30:44 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:30:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:30:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:30:44 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:30:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:35:07 [INFO] exp_shallowmodel: train time: 262.984s
12/18/2017 01:35:07 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 01:35:07 [INFO] exp_shallowmodel: accuracy:   0.617
12/18/2017 01:35:07 [INFO] exp_shallowmodel: f1_score:   0.499
12/18/2017 01:35:07 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:35:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.20      0.24        20
          C       0.56      0.60      0.58       169
          F       0.71      0.74      0.73       281
          R       0.48      0.41      0.44       122

avg / total       0.61      0.62      0.61       592

12/18/2017 01:35:07 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:35:07 [INFO] exp_shallowmodel: 
[[  4   2  10   4]
 [  3 102  45  19]
 [  2  38 209  32]
 [  4  39  29  50]]
12/18/2017 01:35:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/18/2017 01:35:08 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:35:08 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:35:08 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:35:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:35:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:35:08 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:35:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:39:53 [INFO] exp_shallowmodel: train time: 284.497s
12/18/2017 01:39:53 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 01:39:53 [INFO] exp_shallowmodel: accuracy:   0.591
12/18/2017 01:39:53 [INFO] exp_shallowmodel: f1_score:   0.446
12/18/2017 01:39:53 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:39:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.15      0.18        20
          C       0.53      0.58      0.55       169
          F       0.71      0.77      0.74       281
          R       0.38      0.27      0.31       122

avg / total       0.57      0.59      0.58       592

12/18/2017 01:39:53 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:39:53 [INFO] exp_shallowmodel: 
[[  3   1  14   2]
 [  1  98  36  34]
 [  3  43 216  19]
 [  6  44  39  33]]
12/18/2017 01:39:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/18/2017 01:39:54 [INFO] exp_shallowmodel: #(data) = 4736
12/18/2017 01:39:54 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:39:54 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:39:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:39:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:39:54 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:39:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:44:40 [INFO] exp_shallowmodel: train time: 285.867s
12/18/2017 01:44:40 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 01:44:40 [INFO] exp_shallowmodel: accuracy:   0.622
12/18/2017 01:44:40 [INFO] exp_shallowmodel: f1_score:   0.476
12/18/2017 01:44:40 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:44:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.07      0.12        28
          C       0.53      0.66      0.59       172
          F       0.73      0.75      0.74       283
          R       0.52      0.41      0.45       123

avg / total       0.62      0.62      0.61       606

12/18/2017 01:44:40 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:44:40 [INFO] exp_shallowmodel: 
[[  2   5  12   9]
 [  2 114  37  19]
 [  1  52 211  19]
 [  0  45  28  50]]
12/18/2017 01:44:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/18/2017 01:44:41 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:44:41 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:44:41 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:44:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:44:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:44:41 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:44:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:49:06 [INFO] exp_shallowmodel: train time: 264.436s
12/18/2017 01:49:06 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 01:49:06 [INFO] exp_shallowmodel: accuracy:   0.590
12/18/2017 01:49:06 [INFO] exp_shallowmodel: f1_score:   0.429
12/18/2017 01:49:06 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:49:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.10      0.14        20
          C       0.52      0.60      0.55       169
          F       0.75      0.77      0.76       281
          R       0.30      0.24      0.27       122

avg / total       0.57      0.59      0.58       592

12/18/2017 01:49:06 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:49:06 [INFO] exp_shallowmodel: 
[[  2   4   7   7]
 [  2 101  32  34]
 [  1  37 217  26]
 [  4  54  35  29]]
12/18/2017 01:49:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/18/2017 01:49:07 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:49:07 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:49:07 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:49:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:49:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:49:07 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:49:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:53:45 [INFO] exp_shallowmodel: train time: 277.499s
12/18/2017 01:53:45 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 01:53:45 [INFO] exp_shallowmodel: accuracy:   0.613
12/18/2017 01:53:45 [INFO] exp_shallowmodel: f1_score:   0.475
12/18/2017 01:53:45 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:53:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.15      0.21        20
          C       0.55      0.63      0.59       169
          F       0.73      0.76      0.74       281
          R       0.41      0.32      0.36       122

avg / total       0.60      0.61      0.60       592

12/18/2017 01:53:45 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:53:45 [INFO] exp_shallowmodel: 
[[  3   4   6   7]
 [  0 107  41  21]
 [  5  34 214  28]
 [  1  48  34  39]]
12/18/2017 01:53:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/18/2017 01:53:46 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:53:46 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:53:46 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:53:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:53:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:53:46 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:53:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:58:23 [INFO] exp_shallowmodel: train time: 277.489s
12/18/2017 01:58:23 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 01:58:23 [INFO] exp_shallowmodel: accuracy:   0.596
12/18/2017 01:58:23 [INFO] exp_shallowmodel: f1_score:   0.448
12/18/2017 01:58:23 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:58:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.10      0.13        20
          C       0.53      0.60      0.57       169
          F       0.71      0.74      0.73       281
          R       0.42      0.33      0.37       122

avg / total       0.58      0.60      0.59       592

12/18/2017 01:58:23 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:58:23 [INFO] exp_shallowmodel: 
[[  2   7   7   4]
 [  0 102  39  28]
 [  4  44 209  24]
 [  4  39  39  40]]
12/18/2017 01:58:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/18/2017 01:58:25 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 01:58:25 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 01:58:25 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:58:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:58:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:58:25 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:58:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:02:54 [INFO] exp_shallowmodel: train time: 269.715s
12/18/2017 02:02:54 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 02:02:54 [INFO] exp_shallowmodel: accuracy:   0.620
12/18/2017 02:02:54 [INFO] exp_shallowmodel: f1_score:   0.471
12/18/2017 02:02:54 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:02:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.10      0.12        20
          C       0.55      0.68      0.61       169
          F       0.75      0.73      0.74       281
          R       0.47      0.37      0.41       122

avg / total       0.61      0.62      0.61       592

12/18/2017 02:02:54 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:02:54 [INFO] exp_shallowmodel: 
[[  2   2  12   4]
 [  4 115  29  21]
 [  4  46 205  26]
 [  2  46  29  45]]
12/18/2017 02:02:56 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/18/2017 02:02:56 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 02:02:56 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 02:02:56 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:02:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:02:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:02:56 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:02:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:07:24 [INFO] exp_shallowmodel: train time: 268.490s
12/18/2017 02:07:24 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 02:07:24 [INFO] exp_shallowmodel: accuracy:   0.584
12/18/2017 02:07:24 [INFO] exp_shallowmodel: f1_score:   0.474
12/18/2017 02:07:24 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:07:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.25      0.27        20
          C       0.53      0.49      0.51       169
          F       0.71      0.75      0.73       281
          R       0.40      0.39      0.39       122

avg / total       0.58      0.58      0.58       592

12/18/2017 02:07:24 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:07:24 [INFO] exp_shallowmodel: 
[[  5   4   5   6]
 [  5  83  45  36]
 [  4  37 211  29]
 [  3  34  38  47]]
12/18/2017 02:07:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/18/2017 02:07:26 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 02:07:26 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 02:07:26 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:07:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:07:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:07:26 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:07:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:10:34 [INFO] exp_shallowmodel: train time: 188.309s
12/18/2017 02:10:34 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 02:10:34 [INFO] exp_shallowmodel: accuracy:   0.598
12/18/2017 02:10:34 [INFO] exp_shallowmodel: f1_score:   0.460
12/18/2017 02:10:34 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:10:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.10      0.11        20
          C       0.54      0.59      0.56       169
          F       0.69      0.72      0.70       281
          R       0.50      0.43      0.46       122

avg / total       0.59      0.60      0.59       592

12/18/2017 02:10:34 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:10:34 [INFO] exp_shallowmodel: 
[[  2   4  11   3]
 [  2  99  43  25]
 [  7  49 201  24]
 [  4  30  36  52]]
12/18/2017 02:10:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/18/2017 02:10:35 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 02:10:35 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 02:10:35 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:10:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:10:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:10:35 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:10:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:13:01 [INFO] exp_shallowmodel: train time: 146.102s
12/18/2017 02:13:01 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 02:13:01 [INFO] exp_shallowmodel: accuracy:   0.578
12/18/2017 02:13:01 [INFO] exp_shallowmodel: f1_score:   0.450
12/18/2017 02:13:01 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:13:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.15      0.21        20
          C       0.52      0.53      0.52       169
          F       0.69      0.74      0.71       281
          R       0.39      0.34      0.36       122

avg / total       0.56      0.58      0.57       592

12/18/2017 02:13:01 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:13:01 [INFO] exp_shallowmodel: 
[[  3   1  10   6]
 [  1  89  50  29]
 [  2  40 209  30]
 [  3  42  36  41]]
12/18/2017 02:13:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/18/2017 02:13:02 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 02:13:02 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 02:13:02 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:13:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:13:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:13:02 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:13:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:15:07 [INFO] exp_shallowmodel: train time: 124.782s
12/18/2017 02:15:07 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 02:15:07 [INFO] exp_shallowmodel: accuracy:   0.600
12/18/2017 02:15:07 [INFO] exp_shallowmodel: f1_score:   0.469
12/18/2017 02:15:07 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:15:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.15      0.21        20
          C       0.58      0.54      0.56       169
          F       0.72      0.77      0.74       281
          R       0.36      0.38      0.37       122

avg / total       0.59      0.60      0.59       592

12/18/2017 02:15:07 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:15:07 [INFO] exp_shallowmodel: 
[[  3   4   9   4]
 [  1  91  34  43]
 [  1  30 215  35]
 [  4  32  40  46]]
12/18/2017 02:15:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/18/2017 02:15:08 [INFO] exp_shallowmodel: #(data) = 4750
12/18/2017 02:15:08 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 02:15:08 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:15:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:15:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:15:08 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:15:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:17:52 [INFO] exp_shallowmodel: train time: 164.279s
12/18/2017 02:17:52 [INFO] exp_shallowmodel: test time:  0.003s
12/18/2017 02:17:52 [INFO] exp_shallowmodel: accuracy:   0.601
12/18/2017 02:17:52 [INFO] exp_shallowmodel: f1_score:   0.445
12/18/2017 02:17:52 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:17:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.05      0.07        20
          C       0.51      0.60      0.55       169
          F       0.73      0.73      0.73       281
          R       0.46      0.39      0.42       122

avg / total       0.59      0.60      0.59       592

12/18/2017 02:17:52 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:17:52 [INFO] exp_shallowmodel: 
[[  1   4   7   8]
 [  3 101  41  24]
 [  3  47 206  25]
 [  0  47  27  48]]
12/18/2017 02:17:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/18/2017 02:17:54 [INFO] exp_shallowmodel: #(data) = 4736
12/18/2017 02:17:54 [INFO] exp_shallowmodel: #(feature) = 3759
12/18/2017 02:17:54 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:17:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:17:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:17:54 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:17:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:22:21 [INFO] exp_shallowmodel: train time: 267.604s
12/18/2017 02:22:21 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:22:21 [INFO] exp_shallowmodel: accuracy:   0.616
12/18/2017 02:22:21 [INFO] exp_shallowmodel: f1_score:   0.476
12/18/2017 02:22:21 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:22:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.11      0.16        28
          C       0.58      0.62      0.60       172
          F       0.71      0.77      0.74       283
          R       0.44      0.38      0.41       123

avg / total       0.60      0.62      0.60       606

12/18/2017 02:22:21 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:22:21 [INFO] exp_shallowmodel: 
[[  3   5  10  10]
 [  2 106  38  26]
 [  2  39 217  25]
 [  2  33  41  47]]
12/18/2017 02:22:31 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/18/2017 02:22:31 [INFO] task_runner: context=current, feature=13-[8+1.3.4]
12/18/2017 02:22:31 [INFO] task_runner: retained feature numbers=[5, 7, 2.2, 3, 2.1, 1, 11.1, 6]
12/18/2017 02:22:31 [INFO] task_runner: #(data)=3530
12/18/2017 02:22:31 [INFO] task_runner: #(feature)=8963
12/18/2017 02:22:31 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/18/2017 02:22:33 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/18/2017 02:22:33 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:22:33 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:22:33 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:22:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:22:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:22:33 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:22:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:23:15 [INFO] exp_shallowmodel: train time: 41.827s
12/18/2017 02:23:15 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:23:15 [INFO] exp_shallowmodel: accuracy:   0.739
12/18/2017 02:23:15 [INFO] exp_shallowmodel: f1_score:   0.420
12/18/2017 02:23:15 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:23:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.22      0.30        23
          C       0.38      0.11      0.17        27
          F       0.78      0.95      0.86       250
          R       0.50      0.27      0.35        52

avg / total       0.69      0.74      0.69       352

12/18/2017 02:23:15 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:23:15 [INFO] exp_shallowmodel: 
[[  5   0  15   3]
 [  0   3  19   5]
 [  4   2 238   6]
 [  1   3  34  14]]
12/18/2017 02:23:17 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/18/2017 02:23:17 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:23:17 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:23:17 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:23:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:23:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:23:17 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:23:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:24:04 [INFO] exp_shallowmodel: train time: 47.133s
12/18/2017 02:24:04 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:24:04 [INFO] exp_shallowmodel: accuracy:   0.756
12/18/2017 02:24:04 [INFO] exp_shallowmodel: f1_score:   0.448
12/18/2017 02:24:04 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:24:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.50      0.26      0.34        27
          F       0.79      0.94      0.86       250
          R       0.62      0.44      0.52        52

avg / total       0.71      0.76      0.72       352

12/18/2017 02:24:04 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:24:04 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   7  18   2]
 [  1   4 235  10]
 [  2   2  25  23]]
12/18/2017 02:24:06 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/18/2017 02:24:06 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:24:06 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:24:06 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:24:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:24:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:24:06 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:24:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:24:46 [INFO] exp_shallowmodel: train time: 40.430s
12/18/2017 02:24:46 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:24:46 [INFO] exp_shallowmodel: accuracy:   0.753
12/18/2017 02:24:46 [INFO] exp_shallowmodel: f1_score:   0.431
12/18/2017 02:24:46 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:24:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.13      0.21        23
          C       0.30      0.11      0.16        27
          F       0.79      0.95      0.86       250
          R       0.64      0.40      0.49        52

avg / total       0.71      0.75      0.71       352

12/18/2017 02:24:46 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:24:46 [INFO] exp_shallowmodel: 
[[  3   1  18   1]
 [  0   3  18   6]
 [  2   5 238   5]
 [  1   1  29  21]]
12/18/2017 02:24:48 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/18/2017 02:24:48 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:24:48 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:24:48 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:24:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:24:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:24:48 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:24:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:25:28 [INFO] exp_shallowmodel: train time: 39.847s
12/18/2017 02:25:28 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:25:28 [INFO] exp_shallowmodel: accuracy:   0.744
12/18/2017 02:25:28 [INFO] exp_shallowmodel: f1_score:   0.424
12/18/2017 02:25:28 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:25:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.43      0.22      0.29        27
          F       0.79      0.95      0.86       250
          R       0.52      0.33      0.40        52

avg / total       0.69      0.74      0.70       352

12/18/2017 02:25:28 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:25:28 [INFO] exp_shallowmodel: 
[[  2   1  17   3]
 [  0   6  16   5]
 [  3   2 237   8]
 [  1   5  29  17]]
12/18/2017 02:25:30 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/18/2017 02:25:30 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:25:30 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:25:30 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:25:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:25:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:25:30 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:25:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:26:15 [INFO] exp_shallowmodel: train time: 45.322s
12/18/2017 02:26:15 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:26:15 [INFO] exp_shallowmodel: accuracy:   0.727
12/18/2017 02:26:15 [INFO] exp_shallowmodel: f1_score:   0.463
12/18/2017 02:26:15 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:26:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.83      0.22      0.34        23
          C       0.33      0.22      0.27        27
          F       0.78      0.91      0.84       250
          R       0.47      0.35      0.40        52

avg / total       0.71      0.73      0.70       352

12/18/2017 02:26:15 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:26:15 [INFO] exp_shallowmodel: 
[[  5   1  15   2]
 [  0   6  20   1]
 [  1   5 227  17]
 [  0   6  28  18]]
12/18/2017 02:26:17 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/18/2017 02:26:17 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:26:17 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:26:17 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:26:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:26:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:26:17 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:26:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:27:07 [INFO] exp_shallowmodel: train time: 49.382s
12/18/2017 02:27:07 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:27:07 [INFO] exp_shallowmodel: accuracy:   0.744
12/18/2017 02:27:07 [INFO] exp_shallowmodel: f1_score:   0.440
12/18/2017 02:27:07 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:27:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.09      0.13        23
          C       0.54      0.26      0.35        27
          F       0.81      0.93      0.87       250
          R       0.44      0.38      0.41        52

avg / total       0.70      0.74      0.71       352

12/18/2017 02:27:07 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:27:07 [INFO] exp_shallowmodel: 
[[  2   0  17   4]
 [  0   7  11   9]
 [  4   1 233  12]
 [  2   5  25  20]]
12/18/2017 02:27:08 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/18/2017 02:27:08 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:27:08 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:27:08 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:27:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:27:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:27:08 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:27:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:27:50 [INFO] exp_shallowmodel: train time: 41.656s
12/18/2017 02:27:50 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:27:50 [INFO] exp_shallowmodel: accuracy:   0.719
12/18/2017 02:27:50 [INFO] exp_shallowmodel: f1_score:   0.362
12/18/2017 02:27:50 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:27:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.44      0.26      0.33        27
          F       0.79      0.94      0.86       250
          R       0.37      0.21      0.27        52

avg / total       0.65      0.72      0.67       352

12/18/2017 02:27:50 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:27:50 [INFO] exp_shallowmodel: 
[[  0   2  19   2]
 [  1   7  11   8]
 [  2   4 235   9]
 [  4   3  34  11]]
12/18/2017 02:27:52 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/18/2017 02:27:52 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:27:52 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:27:52 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:27:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:27:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:27:52 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:27:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:28:38 [INFO] exp_shallowmodel: train time: 46.089s
12/18/2017 02:28:38 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:28:38 [INFO] exp_shallowmodel: accuracy:   0.736
12/18/2017 02:28:38 [INFO] exp_shallowmodel: f1_score:   0.427
12/18/2017 02:28:38 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:28:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.09      0.13        23
          C       0.55      0.22      0.32        27
          F       0.80      0.93      0.86       250
          R       0.45      0.37      0.40        52

avg / total       0.69      0.74      0.70       352

12/18/2017 02:28:38 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:28:38 [INFO] exp_shallowmodel: 
[[  2   0  16   5]
 [  1   6  14   6]
 [  3   3 232  12]
 [  2   2  29  19]]
12/18/2017 02:28:40 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/18/2017 02:28:40 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:28:40 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:28:40 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:28:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:28:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:28:40 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:28:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:29:28 [INFO] exp_shallowmodel: train time: 47.747s
12/18/2017 02:29:28 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:29:28 [INFO] exp_shallowmodel: accuracy:   0.713
12/18/2017 02:29:28 [INFO] exp_shallowmodel: f1_score:   0.434
12/18/2017 02:29:28 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:29:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.17      0.24        23
          C       0.47      0.26      0.33        27
          F       0.79      0.90      0.84       250
          R       0.38      0.29      0.33        52

avg / total       0.67      0.71      0.69       352

12/18/2017 02:29:28 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:29:28 [INFO] exp_shallowmodel: 
[[  4   0  16   3]
 [  0   7  16   4]
 [  3   4 225  18]
 [  4   4  29  15]]
12/18/2017 02:29:30 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/18/2017 02:29:30 [INFO] exp_shallowmodel: #(data) = 2816
12/18/2017 02:29:30 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:29:30 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:29:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:29:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:29:30 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:29:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:30:11 [INFO] exp_shallowmodel: train time: 41.188s
12/18/2017 02:30:11 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:30:11 [INFO] exp_shallowmodel: accuracy:   0.727
12/18/2017 02:30:11 [INFO] exp_shallowmodel: f1_score:   0.386
12/18/2017 02:30:11 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:30:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.43      0.22      0.29        27
          F       0.76      0.95      0.85       251
          R       0.60      0.31      0.40        59

avg / total       0.66      0.73      0.68       362

12/18/2017 02:30:11 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:30:11 [INFO] exp_shallowmodel: 
[[  0   0  20   5]
 [  0   6  18   3]
 [  4   4 239   4]
 [  1   4  36  18]]
12/18/2017 02:30:13 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/18/2017 02:30:13 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:30:13 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:30:13 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:30:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:30:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:30:13 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:30:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:30:41 [INFO] exp_shallowmodel: train time: 28.126s
12/18/2017 02:30:41 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:30:41 [INFO] exp_shallowmodel: accuracy:   0.744
12/18/2017 02:30:41 [INFO] exp_shallowmodel: f1_score:   0.449
12/18/2017 02:30:41 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:30:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.70      0.26      0.38        27
          F       0.80      0.93      0.86       250
          R       0.50      0.38      0.43        52

avg / total       0.71      0.74      0.71       352

12/18/2017 02:30:41 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:30:41 [INFO] exp_shallowmodel: 
[[  2   0  18   3]
 [  1   7  13   6]
 [  6   0 233  11]
 [  1   3  28  20]]
12/18/2017 02:30:43 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/18/2017 02:30:43 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:30:43 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:30:43 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:30:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:30:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:30:43 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:30:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:31:25 [INFO] exp_shallowmodel: train time: 42.467s
12/18/2017 02:31:25 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:31:25 [INFO] exp_shallowmodel: accuracy:   0.699
12/18/2017 02:31:25 [INFO] exp_shallowmodel: f1_score:   0.343
12/18/2017 02:31:25 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:31:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.29      0.15      0.20        27
          F       0.78      0.90      0.84       250
          R       0.35      0.33      0.34        52

avg / total       0.63      0.70      0.66       352

12/18/2017 02:31:25 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:31:25 [INFO] exp_shallowmodel: 
[[  0   2  14   7]
 [  0   4  18   5]
 [  2   4 225  19]
 [  1   4  30  17]]
12/18/2017 02:31:26 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/18/2017 02:31:26 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:31:26 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:31:26 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:31:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:31:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:31:26 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:31:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:31:45 [INFO] exp_shallowmodel: train time: 19.261s
12/18/2017 02:31:45 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:31:45 [INFO] exp_shallowmodel: accuracy:   0.722
12/18/2017 02:31:45 [INFO] exp_shallowmodel: f1_score:   0.412
12/18/2017 02:31:45 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:31:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.41      0.26      0.32        27
          F       0.78      0.92      0.85       250
          R       0.48      0.29      0.36        52

avg / total       0.67      0.72      0.69       352

12/18/2017 02:31:45 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:31:45 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   7  13   7]
 [  7   5 230   8]
 [  1   5  31  15]]
12/18/2017 02:31:46 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/18/2017 02:31:46 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:31:46 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:31:46 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:31:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:31:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:31:46 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:31:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:32:08 [INFO] exp_shallowmodel: train time: 22.073s
12/18/2017 02:32:08 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:32:08 [INFO] exp_shallowmodel: accuracy:   0.722
12/18/2017 02:32:08 [INFO] exp_shallowmodel: f1_score:   0.384
12/18/2017 02:32:08 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:32:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.09      0.12        23
          C       0.33      0.15      0.21        27
          F       0.79      0.93      0.86       250
          R       0.41      0.31      0.35        52

avg / total       0.66      0.72      0.68       352

12/18/2017 02:32:08 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:32:08 [INFO] exp_shallowmodel: 
[[  2   1  15   5]
 [  1   4  15   7]
 [  3   4 232  11]
 [  3   3  30  16]]
12/18/2017 02:32:09 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/18/2017 02:32:09 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:32:09 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:32:09 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:32:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:32:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:32:09 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:32:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:32:47 [INFO] exp_shallowmodel: train time: 37.285s
12/18/2017 02:32:47 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:32:47 [INFO] exp_shallowmodel: accuracy:   0.730
12/18/2017 02:32:47 [INFO] exp_shallowmodel: f1_score:   0.375
12/18/2017 02:32:47 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:32:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.45      0.19      0.26        27
          F       0.79      0.94      0.86       250
          R       0.45      0.33      0.38        52

avg / total       0.66      0.73      0.69       352

12/18/2017 02:32:47 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:32:47 [INFO] exp_shallowmodel: 
[[  0   0  18   5]
 [  0   5  16   6]
 [  3   2 235  10]
 [  2   4  29  17]]
12/18/2017 02:32:49 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/18/2017 02:32:49 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:32:49 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:32:49 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:32:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:32:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:32:49 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:32:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:33:30 [INFO] exp_shallowmodel: train time: 41.790s
12/18/2017 02:33:30 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:33:30 [INFO] exp_shallowmodel: accuracy:   0.719
12/18/2017 02:33:30 [INFO] exp_shallowmodel: f1_score:   0.360
12/18/2017 02:33:30 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:33:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.07        23
          C       0.33      0.15      0.21        27
          F       0.77      0.94      0.85       250
          R       0.43      0.25      0.32        52

avg / total       0.65      0.72      0.67       352

12/18/2017 02:33:30 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:33:30 [INFO] exp_shallowmodel: 
[[  1   2  18   2]
 [  0   4  20   3]
 [  2   1 235  12]
 [  3   5  31  13]]
12/18/2017 02:33:32 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/18/2017 02:33:32 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:33:32 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:33:32 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:33:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:33:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:33:32 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:33:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:34:16 [INFO] exp_shallowmodel: train time: 43.320s
12/18/2017 02:34:16 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:34:16 [INFO] exp_shallowmodel: accuracy:   0.759
12/18/2017 02:34:16 [INFO] exp_shallowmodel: f1_score:   0.460
12/18/2017 02:34:16 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:34:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.09      0.13        23
          C       0.47      0.33      0.39        27
          F       0.80      0.95      0.87       250
          R       0.62      0.35      0.44        52

avg / total       0.72      0.76      0.72       352

12/18/2017 02:34:16 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:34:16 [INFO] exp_shallowmodel: 
[[  2   0  18   3]
 [  0   9  15   3]
 [  2   5 238   5]
 [  3   5  26  18]]
12/18/2017 02:34:17 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/18/2017 02:34:17 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:34:17 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:34:17 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:34:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:34:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:34:17 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:34:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:35:04 [INFO] exp_shallowmodel: train time: 46.772s
12/18/2017 02:35:04 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:35:04 [INFO] exp_shallowmodel: accuracy:   0.747
12/18/2017 02:35:04 [INFO] exp_shallowmodel: f1_score:   0.461
12/18/2017 02:35:04 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:35:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.09      0.13        23
          C       0.56      0.33      0.42        27
          F       0.79      0.93      0.86       250
          R       0.54      0.37      0.44        52

avg / total       0.70      0.75      0.71       352

12/18/2017 02:35:04 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:35:04 [INFO] exp_shallowmodel: 
[[  2   1  18   2]
 [  1   9  13   4]
 [  4   3 233  10]
 [  0   3  30  19]]
12/18/2017 02:35:06 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/18/2017 02:35:06 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:35:06 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:35:06 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:35:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:35:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:35:06 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:35:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:35:54 [INFO] exp_shallowmodel: train time: 48.283s
12/18/2017 02:35:54 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:35:54 [INFO] exp_shallowmodel: accuracy:   0.707
12/18/2017 02:35:54 [INFO] exp_shallowmodel: f1_score:   0.373
12/18/2017 02:35:54 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:35:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.09      0.14        23
          C       0.33      0.15      0.21        27
          F       0.78      0.92      0.84       250
          R       0.35      0.27      0.30        52

avg / total       0.65      0.71      0.67       352

12/18/2017 02:35:54 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:35:54 [INFO] exp_shallowmodel: 
[[  2   0  19   2]
 [  0   4  16   7]
 [  1   3 229  17]
 [  2   5  31  14]]
12/18/2017 02:35:56 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/18/2017 02:35:56 [INFO] exp_shallowmodel: #(data) = 2816
12/18/2017 02:35:56 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:35:56 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:35:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:35:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:35:56 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:35:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:36:39 [INFO] exp_shallowmodel: train time: 43.151s
12/18/2017 02:36:39 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:36:39 [INFO] exp_shallowmodel: accuracy:   0.707
12/18/2017 02:36:39 [INFO] exp_shallowmodel: f1_score:   0.335
12/18/2017 02:36:39 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:36:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.06        25
          C       0.25      0.07      0.11        27
          F       0.76      0.95      0.85       251
          R       0.43      0.25      0.32        59

avg / total       0.63      0.71      0.65       362

12/18/2017 02:36:39 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:36:39 [INFO] exp_shallowmodel: 
[[  1   0  18   6]
 [  1   2  17   7]
 [  3   3 238   7]
 [  2   3  39  15]]
12/18/2017 02:36:41 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/18/2017 02:36:41 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:36:41 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:36:41 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:36:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:36:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:36:41 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:36:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:37:21 [INFO] exp_shallowmodel: train time: 39.413s
12/18/2017 02:37:21 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:37:21 [INFO] exp_shallowmodel: accuracy:   0.739
12/18/2017 02:37:21 [INFO] exp_shallowmodel: f1_score:   0.378
12/18/2017 02:37:21 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:37:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.11      0.15        27
          F       0.80      0.93      0.86       250
          R       0.53      0.46      0.49        52

avg / total       0.67      0.74      0.70       352

12/18/2017 02:37:21 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:37:21 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  0   3  15   9]
 [  4   5 233   8]
 [  1   4  23  24]]
12/18/2017 02:37:23 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/18/2017 02:37:23 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:37:23 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:37:23 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:37:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:37:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:37:23 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:37:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:38:08 [INFO] exp_shallowmodel: train time: 45.227s
12/18/2017 02:38:08 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:38:08 [INFO] exp_shallowmodel: accuracy:   0.719
12/18/2017 02:38:08 [INFO] exp_shallowmodel: f1_score:   0.362
12/18/2017 02:38:08 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:38:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.19      0.24        27
          F       0.78      0.93      0.85       250
          R       0.47      0.29      0.36        52

avg / total       0.65      0.72      0.68       352

12/18/2017 02:38:08 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:38:08 [INFO] exp_shallowmodel: 
[[  0   2  19   2]
 [  1   5  16   5]
 [  6   1 233  10]
 [  1   7  29  15]]
12/18/2017 02:38:10 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/18/2017 02:38:10 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:38:10 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:38:10 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:38:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:38:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:38:10 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:38:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:38:50 [INFO] exp_shallowmodel: train time: 40.317s
12/18/2017 02:38:50 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:38:50 [INFO] exp_shallowmodel: accuracy:   0.756
12/18/2017 02:38:50 [INFO] exp_shallowmodel: f1_score:   0.454
12/18/2017 02:38:50 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:38:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.13      0.19        23
          C       0.38      0.19      0.25        27
          F       0.82      0.94      0.87       250
          R       0.56      0.46      0.51        52

avg / total       0.71      0.76      0.73       352

12/18/2017 02:38:50 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:38:50 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  2   5  15   5]
 [  3   2 234  11]
 [  1   5  22  24]]
12/18/2017 02:38:52 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/18/2017 02:38:52 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:38:52 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:38:52 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:38:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:38:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:38:52 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:38:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:39:33 [INFO] exp_shallowmodel: train time: 41.173s
12/18/2017 02:39:33 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:39:33 [INFO] exp_shallowmodel: accuracy:   0.702
12/18/2017 02:39:33 [INFO] exp_shallowmodel: f1_score:   0.339
12/18/2017 02:39:33 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:39:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.04      0.06        23
          C       0.23      0.11      0.15        27
          F       0.78      0.92      0.85       250
          R       0.38      0.25      0.30        52

avg / total       0.64      0.70      0.66       352

12/18/2017 02:39:33 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:39:33 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  1   3  13  10]
 [  7   5 230   8]
 [  2   4  33  13]]
12/18/2017 02:39:35 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/18/2017 02:39:35 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:39:35 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:39:35 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:39:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:39:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:39:35 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:39:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:40:23 [INFO] exp_shallowmodel: train time: 47.587s
12/18/2017 02:40:23 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:40:23 [INFO] exp_shallowmodel: accuracy:   0.756
12/18/2017 02:40:23 [INFO] exp_shallowmodel: f1_score:   0.484
12/18/2017 02:40:23 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:40:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.67      0.37      0.48        27
          F       0.81      0.93      0.86       250
          R       0.50      0.42      0.46        52

avg / total       0.72      0.76      0.73       352

12/18/2017 02:40:23 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:40:23 [INFO] exp_shallowmodel: 
[[  2   0  19   2]
 [  0  10  10   7]
 [  3   2 232  13]
 [  1   3  26  22]]
12/18/2017 02:40:24 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/18/2017 02:40:24 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:40:24 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:40:24 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:40:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:40:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:40:24 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:40:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:41:04 [INFO] exp_shallowmodel: train time: 39.508s
12/18/2017 02:41:04 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:41:04 [INFO] exp_shallowmodel: accuracy:   0.722
12/18/2017 02:41:04 [INFO] exp_shallowmodel: f1_score:   0.347
12/18/2017 02:41:04 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:41:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.18      0.07      0.11        27
          F       0.77      0.94      0.85       250
          R       0.48      0.29      0.36        52

avg / total       0.65      0.72      0.67       352

12/18/2017 02:41:04 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:41:04 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   2  20   5]
 [  3   3 236   8]
 [  1   5  31  15]]
12/18/2017 02:41:06 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/18/2017 02:41:06 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:41:06 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:41:06 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:41:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:41:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:41:06 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:41:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:41:45 [INFO] exp_shallowmodel: train time: 39.349s
12/18/2017 02:41:45 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:41:45 [INFO] exp_shallowmodel: accuracy:   0.722
12/18/2017 02:41:45 [INFO] exp_shallowmodel: f1_score:   0.394
12/18/2017 02:41:45 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:41:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.60      0.22      0.32        27
          F       0.77      0.93      0.84       250
          R       0.41      0.29      0.34        52

avg / total       0.67      0.72      0.68       352

12/18/2017 02:41:45 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:41:45 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  0   6  17   4]
 [  4   0 232  14]
 [  0   3  34  15]]
12/18/2017 02:41:47 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/18/2017 02:41:47 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:41:47 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:41:47 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:41:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:41:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:41:47 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:41:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:42:29 [INFO] exp_shallowmodel: train time: 41.491s
12/18/2017 02:42:29 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:42:29 [INFO] exp_shallowmodel: accuracy:   0.722
12/18/2017 02:42:29 [INFO] exp_shallowmodel: f1_score:   0.425
12/18/2017 02:42:29 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:42:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.13      0.19        23
          C       0.53      0.33      0.41        27
          F       0.77      0.93      0.84       250
          R       0.40      0.19      0.26        52

avg / total       0.67      0.72      0.68       352

12/18/2017 02:42:29 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:42:29 [INFO] exp_shallowmodel: 
[[  3   2  16   2]
 [  1   9  14   3]
 [  3   5 232  10]
 [  2   1  39  10]]
12/18/2017 02:42:30 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/18/2017 02:42:30 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:42:30 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:42:30 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:42:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:42:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:42:30 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:42:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:43:13 [INFO] exp_shallowmodel: train time: 42.318s
12/18/2017 02:43:13 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:43:13 [INFO] exp_shallowmodel: accuracy:   0.710
12/18/2017 02:43:13 [INFO] exp_shallowmodel: f1_score:   0.405
12/18/2017 02:43:13 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:43:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.13      0.19        23
          C       0.41      0.26      0.32        27
          F       0.79      0.91      0.85       250
          R       0.31      0.23      0.26        52

avg / total       0.66      0.71      0.68       352

12/18/2017 02:43:13 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:43:13 [INFO] exp_shallowmodel: 
[[  3   0  14   6]
 [  0   7  11   9]
 [  3   7 228  12]
 [  3   3  34  12]]
12/18/2017 02:43:15 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/18/2017 02:43:15 [INFO] exp_shallowmodel: #(data) = 2816
12/18/2017 02:43:15 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:43:15 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:43:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:43:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:43:15 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:43:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:43:59 [INFO] exp_shallowmodel: train time: 43.833s
12/18/2017 02:43:59 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:43:59 [INFO] exp_shallowmodel: accuracy:   0.715
12/18/2017 02:43:59 [INFO] exp_shallowmodel: f1_score:   0.375
12/18/2017 02:43:59 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:43:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.12      0.19        25
          C       0.11      0.04      0.06        27
          F       0.76      0.94      0.84       251
          R       0.54      0.34      0.42        59

avg / total       0.65      0.72      0.67       362

12/18/2017 02:43:59 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:43:59 [INFO] exp_shallowmodel: 
[[  3   0  18   4]
 [  0   1  19   7]
 [  4   6 235   6]
 [  0   2  37  20]]
12/18/2017 02:44:00 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/18/2017 02:44:00 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:44:00 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:44:00 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:44:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:44:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:44:00 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:44:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:44:45 [INFO] exp_shallowmodel: train time: 44.406s
12/18/2017 02:44:45 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:44:45 [INFO] exp_shallowmodel: accuracy:   0.724
12/18/2017 02:44:45 [INFO] exp_shallowmodel: f1_score:   0.406
12/18/2017 02:44:45 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:44:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.38      0.19      0.25        27
          F       0.79      0.92      0.85       250
          R       0.44      0.35      0.39        52

avg / total       0.68      0.72      0.69       352

12/18/2017 02:44:45 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:44:45 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   5  14   8]
 [  3   3 230  14]
 [  1   5  28  18]]
12/18/2017 02:44:47 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/18/2017 02:44:47 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:44:47 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:44:47 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:44:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:44:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:44:47 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:44:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:45:28 [INFO] exp_shallowmodel: train time: 40.803s
12/18/2017 02:45:28 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:45:28 [INFO] exp_shallowmodel: accuracy:   0.750
12/18/2017 02:45:28 [INFO] exp_shallowmodel: f1_score:   0.464
12/18/2017 02:45:28 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:45:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.13      0.21        23
          C       0.43      0.33      0.38        27
          F       0.81      0.94      0.87       250
          R       0.49      0.35      0.40        52

avg / total       0.71      0.75      0.72       352

12/18/2017 02:45:28 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:45:28 [INFO] exp_shallowmodel: 
[[  3   1  17   2]
 [  1   9  11   6]
 [  1   4 234  11]
 [  1   7  26  18]]
12/18/2017 02:45:29 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/18/2017 02:45:29 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:45:29 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:45:29 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:45:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:45:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:45:29 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:45:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:46:13 [INFO] exp_shallowmodel: train time: 43.550s
12/18/2017 02:46:13 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:46:13 [INFO] exp_shallowmodel: accuracy:   0.730
12/18/2017 02:46:13 [INFO] exp_shallowmodel: f1_score:   0.410
12/18/2017 02:46:13 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:46:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.38      0.19      0.25        27
          F       0.79      0.93      0.85       250
          R       0.47      0.35      0.40        52

avg / total       0.68      0.73      0.69       352

12/18/2017 02:46:13 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:46:13 [INFO] exp_shallowmodel: 
[[  2   1  18   2]
 [  1   5  15   6]
 [  3   3 232  12]
 [  0   4  30  18]]
12/18/2017 02:46:15 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/18/2017 02:46:15 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:46:15 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:46:15 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:46:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:46:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:46:15 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:46:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:46:45 [INFO] exp_shallowmodel: train time: 30.329s
12/18/2017 02:46:45 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:46:45 [INFO] exp_shallowmodel: accuracy:   0.716
12/18/2017 02:46:45 [INFO] exp_shallowmodel: f1_score:   0.417
12/18/2017 02:46:45 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:46:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.09      0.15        23
          C       0.41      0.33      0.37        27
          F       0.77      0.91      0.84       250
          R       0.43      0.25      0.32        52

avg / total       0.68      0.72      0.68       352

12/18/2017 02:46:45 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:46:45 [INFO] exp_shallowmodel: 
[[  2   0  18   3]
 [  0   9  16   2]
 [  2   8 228  12]
 [  0   5  34  13]]
12/18/2017 02:46:46 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/18/2017 02:46:46 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:46:46 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:46:46 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:46:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:46:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:46:46 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:46:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:47:12 [INFO] exp_shallowmodel: train time: 25.484s
12/18/2017 02:47:12 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:47:12 [INFO] exp_shallowmodel: accuracy:   0.730
12/18/2017 02:47:12 [INFO] exp_shallowmodel: f1_score:   0.391
12/18/2017 02:47:12 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:47:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.13      0.20        23
          C       0.17      0.07      0.10        27
          F       0.79      0.94      0.86       250
          R       0.49      0.35      0.40        52

avg / total       0.67      0.73      0.69       352

12/18/2017 02:47:12 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:47:12 [INFO] exp_shallowmodel: 
[[  3   2  15   3]
 [  0   2  19   6]
 [  2   4 234  10]
 [  2   4  28  18]]
12/18/2017 02:47:13 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/18/2017 02:47:13 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:47:13 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:47:13 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:47:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:47:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:47:13 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:47:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:47:33 [INFO] exp_shallowmodel: train time: 20.764s
12/18/2017 02:47:33 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:47:33 [INFO] exp_shallowmodel: accuracy:   0.739
12/18/2017 02:47:33 [INFO] exp_shallowmodel: f1_score:   0.468
12/18/2017 02:47:33 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:47:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.26      0.35        23
          C       0.50      0.19      0.27        27
          F       0.79      0.92      0.85       250
          R       0.46      0.35      0.40        52

avg / total       0.70      0.74      0.71       352

12/18/2017 02:47:33 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:47:33 [INFO] exp_shallowmodel: 
[[  6   1  14   2]
 [  0   5  16   6]
 [  5   1 231  13]
 [  0   3  31  18]]
12/18/2017 02:47:34 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/18/2017 02:47:34 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:47:34 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:47:34 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:47:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:47:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:47:34 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:47:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:47:54 [INFO] exp_shallowmodel: train time: 20.254s
12/18/2017 02:47:54 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:47:54 [INFO] exp_shallowmodel: accuracy:   0.716
12/18/2017 02:47:54 [INFO] exp_shallowmodel: f1_score:   0.381
12/18/2017 02:47:54 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:47:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        23
          C       0.64      0.26      0.37        27
          F       0.77      0.94      0.85       250
          R       0.34      0.19      0.25        52

avg / total       0.66      0.72      0.67       352

12/18/2017 02:47:54 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:47:54 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  1   7  14   5]
 [  4   0 234  12]
 [  3   3  36  10]]
12/18/2017 02:47:55 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/18/2017 02:47:55 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:47:55 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:47:55 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:47:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:47:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:47:55 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:47:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:48:14 [INFO] exp_shallowmodel: train time: 18.119s
12/18/2017 02:48:14 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:48:14 [INFO] exp_shallowmodel: accuracy:   0.759
12/18/2017 02:48:14 [INFO] exp_shallowmodel: f1_score:   0.425
12/18/2017 02:48:14 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:48:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.07        23
          C       0.62      0.19      0.29        27
          F       0.79      0.96      0.87       250
          R       0.58      0.40      0.48        52

avg / total       0.71      0.76      0.71       352

12/18/2017 02:48:14 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:48:14 [INFO] exp_shallowmodel: 
[[  1   0  17   5]
 [  2   5  17   3]
 [  2   1 240   7]
 [  1   2  28  21]]
12/18/2017 02:48:14 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/18/2017 02:48:14 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:48:14 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:48:14 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:48:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:48:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:48:14 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:48:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:48:34 [INFO] exp_shallowmodel: train time: 19.271s
12/18/2017 02:48:34 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:48:34 [INFO] exp_shallowmodel: accuracy:   0.739
12/18/2017 02:48:34 [INFO] exp_shallowmodel: f1_score:   0.452
12/18/2017 02:48:34 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:48:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.13      0.19        23
          C       0.58      0.26      0.36        27
          F       0.80      0.92      0.86       250
          R       0.45      0.37      0.40        52

avg / total       0.70      0.74      0.71       352

12/18/2017 02:48:34 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:48:34 [INFO] exp_shallowmodel: 
[[  3   1  17   2]
 [  1   7  11   8]
 [  4   2 231  13]
 [  1   2  30  19]]
12/18/2017 02:48:35 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/18/2017 02:48:35 [INFO] exp_shallowmodel: #(data) = 2816
12/18/2017 02:48:35 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:48:35 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:48:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:48:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:48:35 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:48:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:48:57 [INFO] exp_shallowmodel: train time: 22.810s
12/18/2017 02:48:57 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:48:57 [INFO] exp_shallowmodel: accuracy:   0.721
12/18/2017 02:48:57 [INFO] exp_shallowmodel: f1_score:   0.401
12/18/2017 02:48:57 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:48:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.08      0.12        25
          C       0.36      0.15      0.21        27
          F       0.77      0.93      0.84       251
          R       0.54      0.36      0.43        59

avg / total       0.67      0.72      0.68       362

12/18/2017 02:48:57 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:48:57 [INFO] exp_shallowmodel: 
[[  2   0  19   4]
 [  0   4  19   4]
 [  4   3 234  10]
 [  1   4  33  21]]
12/18/2017 02:48:58 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/18/2017 02:48:58 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:48:58 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:48:58 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:48:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:48:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:48:58 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:48:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:49:20 [INFO] exp_shallowmodel: train time: 21.391s
12/18/2017 02:49:20 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:49:20 [INFO] exp_shallowmodel: accuracy:   0.756
12/18/2017 02:49:20 [INFO] exp_shallowmodel: f1_score:   0.444
12/18/2017 02:49:20 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:49:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.44      0.26      0.33        27
          F       0.80      0.95      0.87       250
          R       0.56      0.37      0.44        52

avg / total       0.71      0.76      0.72       352

12/18/2017 02:49:20 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:49:20 [INFO] exp_shallowmodel: 
[[  2   0  17   4]
 [  1   7  13   6]
 [  3   4 238   5]
 [  0   5  28  19]]
12/18/2017 02:49:21 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/18/2017 02:49:21 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:49:21 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:49:21 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:49:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:49:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:49:21 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:49:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:49:40 [INFO] exp_shallowmodel: train time: 19.364s
12/18/2017 02:49:40 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:49:40 [INFO] exp_shallowmodel: accuracy:   0.747
12/18/2017 02:49:40 [INFO] exp_shallowmodel: f1_score:   0.375
12/18/2017 02:49:40 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:49:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.40      0.15      0.22        27
          F       0.80      0.96      0.87       250
          R       0.51      0.35      0.41        52

avg / total       0.67      0.75      0.70       352

12/18/2017 02:49:40 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:49:40 [INFO] exp_shallowmodel: 
[[  0   2  18   3]
 [  0   4  17   6]
 [  1   0 241   8]
 [  3   4  27  18]]
12/18/2017 02:49:41 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/18/2017 02:49:41 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:49:41 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:49:41 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:49:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:49:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:49:41 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:49:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:50:01 [INFO] exp_shallowmodel: train time: 19.673s
12/18/2017 02:50:01 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:50:01 [INFO] exp_shallowmodel: accuracy:   0.744
12/18/2017 02:50:01 [INFO] exp_shallowmodel: f1_score:   0.458
12/18/2017 02:50:01 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:50:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.48      0.37      0.42        27
          F       0.81      0.92      0.86       250
          R       0.53      0.37      0.43        52

avg / total       0.70      0.74      0.72       352

12/18/2017 02:50:01 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:50:01 [INFO] exp_shallowmodel: 
[[  2   0  15   6]
 [  0  10  12   5]
 [  6   7 231   6]
 [  2   4  27  19]]
12/18/2017 02:50:02 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/18/2017 02:50:02 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:50:02 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:50:02 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:50:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:50:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:50:02 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:50:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:50:31 [INFO] exp_shallowmodel: train time: 29.322s
12/18/2017 02:50:31 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:50:31 [INFO] exp_shallowmodel: accuracy:   0.724
12/18/2017 02:50:31 [INFO] exp_shallowmodel: f1_score:   0.457
12/18/2017 02:50:31 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:50:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.26      0.38        23
          C       0.43      0.22      0.29        27
          F       0.78      0.92      0.84       250
          R       0.39      0.27      0.32        52

avg / total       0.69      0.72      0.69       352

12/18/2017 02:50:31 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:50:31 [INFO] exp_shallowmodel: 
[[  6   1  15   1]
 [  1   6  13   7]
 [  2   5 229  14]
 [  0   2  36  14]]
12/18/2017 02:50:33 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/18/2017 02:50:33 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:50:33 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:50:33 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:50:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:50:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:50:33 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:50:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:51:18 [INFO] exp_shallowmodel: train time: 45.481s
12/18/2017 02:51:18 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:51:18 [INFO] exp_shallowmodel: accuracy:   0.713
12/18/2017 02:51:18 [INFO] exp_shallowmodel: f1_score:   0.365
12/18/2017 02:51:18 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:51:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.04      0.06        23
          C       0.21      0.11      0.15        27
          F       0.79      0.92      0.85       250
          R       0.49      0.35      0.40        52

avg / total       0.65      0.71      0.68       352

12/18/2017 02:51:18 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:51:18 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   3  16   8]
 [  6   6 229   9]
 [  3   4  27  18]]
12/18/2017 02:51:20 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/18/2017 02:51:20 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:51:20 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:51:20 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:51:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:51:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:51:20 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:51:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:51:50 [INFO] exp_shallowmodel: train time: 29.510s
12/18/2017 02:51:50 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:51:50 [INFO] exp_shallowmodel: accuracy:   0.733
12/18/2017 02:51:50 [INFO] exp_shallowmodel: f1_score:   0.400
12/18/2017 02:51:50 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:51:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.41      0.26      0.32        27
          F       0.79      0.95      0.86       250
          R       0.42      0.21      0.28        52

avg / total       0.67      0.73      0.69       352

12/18/2017 02:51:50 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:51:50 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  1   7  12   7]
 [  2   3 238   7]
 [  1   7  33  11]]
12/18/2017 02:51:51 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/18/2017 02:51:51 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:51:51 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:51:51 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:51:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:51:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:51:51 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:51:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:52:10 [INFO] exp_shallowmodel: train time: 19.383s
12/18/2017 02:52:10 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:52:10 [INFO] exp_shallowmodel: accuracy:   0.707
12/18/2017 02:52:10 [INFO] exp_shallowmodel: f1_score:   0.357
12/18/2017 02:52:10 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:52:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.15      0.21        27
          F       0.76      0.91      0.83       250
          R       0.49      0.33      0.39        52

avg / total       0.64      0.71      0.66       352

12/18/2017 02:52:10 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:52:10 [INFO] exp_shallowmodel: 
[[  0   1  18   4]
 [  1   4  19   3]
 [  5   6 228  11]
 [  0   1  34  17]]
12/18/2017 02:52:11 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/18/2017 02:52:11 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:52:11 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:52:11 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:52:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:52:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:52:11 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:52:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:52:33 [INFO] exp_shallowmodel: train time: 21.708s
12/18/2017 02:52:33 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:52:33 [INFO] exp_shallowmodel: accuracy:   0.741
12/18/2017 02:52:33 [INFO] exp_shallowmodel: f1_score:   0.421
12/18/2017 02:52:33 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:52:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.09      0.15        23
          C       0.29      0.15      0.20        27
          F       0.80      0.93      0.86       250
          R       0.51      0.44      0.47        52

avg / total       0.71      0.74      0.71       352

12/18/2017 02:52:33 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:52:33 [INFO] exp_shallowmodel: 
[[  2   2  18   1]
 [  0   4  15   8]
 [  1   4 232  13]
 [  0   4  25  23]]
12/18/2017 02:52:34 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/18/2017 02:52:34 [INFO] exp_shallowmodel: #(data) = 2826
12/18/2017 02:52:34 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:52:34 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:52:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:52:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:52:34 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:52:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:52:55 [INFO] exp_shallowmodel: train time: 21.598s
12/18/2017 02:52:55 [INFO] exp_shallowmodel: test time:  0.004s
12/18/2017 02:52:55 [INFO] exp_shallowmodel: accuracy:   0.719
12/18/2017 02:52:55 [INFO] exp_shallowmodel: f1_score:   0.377
12/18/2017 02:52:55 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:52:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.09      0.13        23
          C       0.38      0.11      0.17        27
          F       0.77      0.93      0.84       250
          R       0.43      0.31      0.36        52

avg / total       0.66      0.72      0.67       352

12/18/2017 02:52:55 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:52:55 [INFO] exp_shallowmodel: 
[[  2   0  18   3]
 [  0   3  18   6]
 [  4   2 232  12]
 [  1   3  32  16]]
12/18/2017 02:52:56 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/18/2017 02:52:56 [INFO] exp_shallowmodel: #(data) = 2816
12/18/2017 02:52:56 [INFO] exp_shallowmodel: #(feature) = 8963
12/18/2017 02:52:56 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:52:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:52:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:52:56 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:52:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:53:17 [INFO] exp_shallowmodel: train time: 20.666s
12/18/2017 02:53:17 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 02:53:17 [INFO] exp_shallowmodel: accuracy:   0.715
12/18/2017 02:53:17 [INFO] exp_shallowmodel: f1_score:   0.384
12/18/2017 02:53:17 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:53:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.08      0.12        25
          C       0.44      0.15      0.22        27
          F       0.76      0.94      0.84       251
          R       0.48      0.27      0.35        59

avg / total       0.66      0.72      0.66       362

12/18/2017 02:53:17 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:53:17 [INFO] exp_shallowmodel: 
[[  2   1  20   2]
 [  1   4  17   5]
 [  3   1 237  10]
 [  1   3  39  16]]
12/18/2017 02:53:22 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/18/2017 02:53:22 [INFO] task_runner: context=current, feature=13-[8+1.3.4]
12/18/2017 02:53:22 [INFO] task_runner: retained feature numbers=[5, 7, 2.2, 3, 2.1, 1, 11.1, 6]
12/18/2017 02:53:22 [INFO] task_runner: #(data)=5241
12/18/2017 02:53:22 [INFO] task_runner: #(feature)=8480
12/18/2017 02:53:22 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/18/2017 02:53:24 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/18/2017 02:53:24 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 02:53:24 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 02:53:24 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:53:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:53:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:53:24 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:53:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:54:58 [INFO] exp_shallowmodel: train time: 94.196s
12/18/2017 02:54:58 [INFO] exp_shallowmodel: test time:  0.007s
12/18/2017 02:54:58 [INFO] exp_shallowmodel: accuracy:   0.768
12/18/2017 02:54:58 [INFO] exp_shallowmodel: f1_score:   0.433
12/18/2017 02:54:58 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:54:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.25      0.30        59
          C       0.33      0.08      0.13        12
          F       0.83      0.92      0.87       396
          R       0.51      0.36      0.43        55

avg / total       0.73      0.77      0.75       522

12/18/2017 02:54:58 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:54:58 [INFO] exp_shallowmodel: 
[[ 15   0  38   6]
 [  2   1   7   2]
 [ 19   1 365  11]
 [  5   1  29  20]]
12/18/2017 02:55:00 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/18/2017 02:55:00 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 02:55:00 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 02:55:00 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:55:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:55:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:55:00 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:55:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:56:17 [INFO] exp_shallowmodel: train time: 76.093s
12/18/2017 02:56:17 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 02:56:17 [INFO] exp_shallowmodel: accuracy:   0.755
12/18/2017 02:56:17 [INFO] exp_shallowmodel: f1_score:   0.419
12/18/2017 02:56:17 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:56:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.41      0.22      0.29        59
          C       0.33      0.17      0.22        12
          F       0.82      0.92      0.87       396
          R       0.37      0.25      0.30        55

avg / total       0.71      0.75      0.73       522

12/18/2017 02:56:17 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:56:17 [INFO] exp_shallowmodel: 
[[ 13   0  40   6]
 [  1   2   7   2]
 [ 12   3 365  16]
 [  6   1  34  14]]
12/18/2017 02:56:18 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/18/2017 02:56:18 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 02:56:18 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 02:56:18 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:56:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:56:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:56:18 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:56:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:57:13 [INFO] exp_shallowmodel: train time: 55.290s
12/18/2017 02:57:13 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 02:57:13 [INFO] exp_shallowmodel: accuracy:   0.753
12/18/2017 02:57:13 [INFO] exp_shallowmodel: f1_score:   0.375
12/18/2017 02:57:13 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:57:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.20      0.25        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.86       396
          R       0.46      0.33      0.38        55

avg / total       0.71      0.75      0.72       522

12/18/2017 02:57:13 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:57:13 [INFO] exp_shallowmodel: 
[[ 12   0  42   5]
 [  3   0   7   2]
 [ 17   2 363  14]
 [  4   0  33  18]]
12/18/2017 02:57:14 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/18/2017 02:57:14 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 02:57:14 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 02:57:14 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:57:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:57:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:57:14 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:57:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 02:58:33 [INFO] exp_shallowmodel: train time: 78.993s
12/18/2017 02:58:33 [INFO] exp_shallowmodel: test time:  0.007s
12/18/2017 02:58:33 [INFO] exp_shallowmodel: accuracy:   0.755
12/18/2017 02:58:33 [INFO] exp_shallowmodel: f1_score:   0.429
12/18/2017 02:58:33 [INFO] exp_shallowmodel: classification report:
12/18/2017 02:58:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.27      0.30        59
          C       0.50      0.17      0.25        12
          F       0.83      0.92      0.87       396
          R       0.39      0.24      0.30        55

avg / total       0.72      0.75      0.73       522

12/18/2017 02:58:33 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 02:58:33 [INFO] exp_shallowmodel: 
[[ 16   1  38   4]
 [  0   2   8   2]
 [ 19   0 363  14]
 [ 12   1  29  13]]
12/18/2017 02:58:36 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/18/2017 02:58:36 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 02:58:36 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 02:58:36 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 02:58:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 02:58:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 02:58:36 [INFO] exp_shallowmodel: Training: 
12/18/2017 02:58:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:00:04 [INFO] exp_shallowmodel: train time: 87.547s
12/18/2017 03:00:04 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:00:04 [INFO] exp_shallowmodel: accuracy:   0.739
12/18/2017 03:00:04 [INFO] exp_shallowmodel: f1_score:   0.364
12/18/2017 03:00:04 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:00:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.17      0.22        59
          C       0.25      0.08      0.12        12
          F       0.82      0.92      0.86       396
          R       0.28      0.22      0.24        55

avg / total       0.69      0.74      0.71       522

12/18/2017 03:00:04 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:00:04 [INFO] exp_shallowmodel: 
[[ 10   0  40   9]
 [  0   1   8   3]
 [ 11   3 363  19]
 [  9   0  34  12]]
12/18/2017 03:00:05 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/18/2017 03:00:05 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:00:05 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:00:05 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:00:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:00:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:00:05 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:00:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:01:27 [INFO] exp_shallowmodel: train time: 82.452s
12/18/2017 03:01:27 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:01:27 [INFO] exp_shallowmodel: accuracy:   0.743
12/18/2017 03:01:27 [INFO] exp_shallowmodel: f1_score:   0.360
12/18/2017 03:01:27 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:01:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.41      0.22      0.29        59
          C       0.00      0.00      0.00        12
          F       0.82      0.91      0.86       396
          R       0.31      0.27      0.29        55

avg / total       0.70      0.74      0.72       522

12/18/2017 03:01:27 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:01:27 [INFO] exp_shallowmodel: 
[[ 13   0  37   9]
 [  0   0   9   3]
 [ 13   2 360  21]
 [  6   1  33  15]]
12/18/2017 03:01:30 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/18/2017 03:01:30 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:01:30 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:01:30 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:01:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:01:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:01:30 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:01:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:02:54 [INFO] exp_shallowmodel: train time: 83.749s
12/18/2017 03:02:54 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:02:54 [INFO] exp_shallowmodel: accuracy:   0.774
12/18/2017 03:02:54 [INFO] exp_shallowmodel: f1_score:   0.473
12/18/2017 03:02:54 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:02:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.24      0.31        59
          C       0.75      0.25      0.38        12
          F       0.83      0.94      0.88       396
          R       0.41      0.27      0.33        55

avg / total       0.74      0.77      0.75       522

12/18/2017 03:02:54 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:02:54 [INFO] exp_shallowmodel: 
[[ 14   0  38   7]
 [  0   3   6   3]
 [ 11   1 372  12]
 [  6   0  34  15]]
12/18/2017 03:02:55 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/18/2017 03:02:55 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:02:55 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:02:55 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:02:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:02:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:02:55 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:02:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:03:59 [INFO] exp_shallowmodel: train time: 64.130s
12/18/2017 03:03:59 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:03:59 [INFO] exp_shallowmodel: accuracy:   0.764
12/18/2017 03:03:59 [INFO] exp_shallowmodel: f1_score:   0.424
12/18/2017 03:03:59 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:03:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.48      0.24      0.32        59
          C       0.29      0.17      0.21        12
          F       0.82      0.93      0.87       396
          R       0.39      0.24      0.30        55

avg / total       0.72      0.76      0.73       522

12/18/2017 03:03:59 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:03:59 [INFO] exp_shallowmodel: 
[[ 14   0  38   7]
 [  1   2   8   1]
 [ 11   3 370  12]
 [  3   2  37  13]]
12/18/2017 03:04:00 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/18/2017 03:04:00 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:04:00 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:04:00 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:04:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:04:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:04:00 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:04:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:05:00 [INFO] exp_shallowmodel: train time: 59.390s
12/18/2017 03:05:00 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:05:00 [INFO] exp_shallowmodel: accuracy:   0.768
12/18/2017 03:05:00 [INFO] exp_shallowmodel: f1_score:   0.460
12/18/2017 03:05:00 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:05:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.25      0.33        59
          C       0.60      0.25      0.35        12
          F       0.83      0.93      0.88       396
          R       0.35      0.24      0.28        55

avg / total       0.73      0.77      0.74       522

12/18/2017 03:05:00 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:05:00 [INFO] exp_shallowmodel: 
[[ 15   0  35   9]
 [  2   3   6   1]
 [ 11   1 370  14]
 [  5   1  36  13]]
12/18/2017 03:05:01 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/18/2017 03:05:01 [INFO] exp_shallowmodel: #(data) = 4176
12/18/2017 03:05:01 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:05:01 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:05:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:05:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:05:01 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:05:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:05:57 [INFO] exp_shallowmodel: train time: 55.826s
12/18/2017 03:05:57 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:05:57 [INFO] exp_shallowmodel: accuracy:   0.738
12/18/2017 03:05:57 [INFO] exp_shallowmodel: f1_score:   0.353
12/18/2017 03:05:57 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:05:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.22      0.27        64
          C       0.00      0.00      0.00        14
          F       0.81      0.93      0.87       402
          R       0.33      0.24      0.28        63

avg / total       0.68      0.74      0.70       543

12/18/2017 03:05:57 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:05:57 [INFO] exp_shallowmodel: 
[[ 14   0  41   9]
 [  2   0   6   6]
 [ 15   0 372  15]
 [ 10   0  38  15]]
12/18/2017 03:05:58 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/18/2017 03:05:58 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:05:58 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:05:58 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:05:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:05:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:05:58 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:05:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:06:49 [INFO] exp_shallowmodel: train time: 50.401s
12/18/2017 03:06:49 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:06:49 [INFO] exp_shallowmodel: accuracy:   0.747
12/18/2017 03:06:49 [INFO] exp_shallowmodel: f1_score:   0.417
12/18/2017 03:06:49 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:06:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.24      0.27        59
          C       0.50      0.17      0.25        12
          F       0.83      0.91      0.87       396
          R       0.35      0.24      0.28        55

avg / total       0.71      0.75      0.72       522

12/18/2017 03:06:49 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:06:49 [INFO] exp_shallowmodel: 
[[ 14   0  36   9]
 [  2   2   6   2]
 [ 22   0 361  13]
 [  8   2  32  13]]
12/18/2017 03:06:50 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/18/2017 03:06:50 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:06:50 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:06:50 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:06:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:06:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:06:50 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:06:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:07:51 [INFO] exp_shallowmodel: train time: 61.374s
12/18/2017 03:07:51 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:07:51 [INFO] exp_shallowmodel: accuracy:   0.759
12/18/2017 03:07:51 [INFO] exp_shallowmodel: f1_score:   0.452
12/18/2017 03:07:51 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:07:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.20      0.25        59
          C       0.75      0.25      0.38        12
          F       0.82      0.93      0.87       396
          R       0.41      0.25      0.31        55

avg / total       0.72      0.76      0.73       522

12/18/2017 03:07:51 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:07:51 [INFO] exp_shallowmodel: 
[[ 12   0  40   7]
 [  2   3   7   0]
 [ 16   0 367  13]
 [  8   1  32  14]]
12/18/2017 03:07:53 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/18/2017 03:07:53 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:07:53 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:07:53 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:07:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:07:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:07:53 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:07:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:09:51 [INFO] exp_shallowmodel: train time: 118.702s
12/18/2017 03:09:51 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:09:51 [INFO] exp_shallowmodel: accuracy:   0.728
12/18/2017 03:09:51 [INFO] exp_shallowmodel: f1_score:   0.308
12/18/2017 03:09:51 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:09:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.12      0.15        59
          C       0.00      0.00      0.00        12
          F       0.83      0.91      0.87       396
          R       0.22      0.20      0.21        55

avg / total       0.68      0.73      0.70       522

12/18/2017 03:09:51 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:09:51 [INFO] exp_shallowmodel: 
[[  7   1  39  12]
 [  1   0   5   6]
 [ 14   0 362  20]
 [ 10   2  32  11]]
12/18/2017 03:09:54 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/18/2017 03:09:54 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:09:54 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:09:54 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:09:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:09:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:09:54 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:09:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:11:56 [INFO] exp_shallowmodel: train time: 122.231s
12/18/2017 03:11:56 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:11:56 [INFO] exp_shallowmodel: accuracy:   0.764
12/18/2017 03:11:56 [INFO] exp_shallowmodel: f1_score:   0.390
12/18/2017 03:11:56 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:11:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.24      0.28        59
          C       0.00      0.00      0.00        12
          F       0.84      0.92      0.88       396
          R       0.47      0.35      0.40        55

avg / total       0.72      0.76      0.74       522

12/18/2017 03:11:56 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:11:56 [INFO] exp_shallowmodel: 
[[ 14   1  37   7]
 [  2   0   5   5]
 [ 19   2 366   9]
 [  6   1  29  19]]
12/18/2017 03:11:59 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/18/2017 03:11:59 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:11:59 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:11:59 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:11:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:11:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:11:59 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:11:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:13:54 [INFO] exp_shallowmodel: train time: 114.476s
12/18/2017 03:13:54 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:13:54 [INFO] exp_shallowmodel: accuracy:   0.761
12/18/2017 03:13:54 [INFO] exp_shallowmodel: f1_score:   0.394
12/18/2017 03:13:54 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:13:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.19      0.23        59
          C       0.33      0.08      0.13        12
          F       0.83      0.93      0.88       396
          R       0.44      0.27      0.34        55

avg / total       0.71      0.76      0.73       522

12/18/2017 03:13:54 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:13:54 [INFO] exp_shallowmodel: 
[[ 11   0  39   9]
 [  5   1   5   1]
 [ 15   2 370   9]
 [  7   0  33  15]]
12/18/2017 03:13:56 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/18/2017 03:13:56 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:13:56 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:13:56 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:13:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:13:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:13:56 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:13:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:15:52 [INFO] exp_shallowmodel: train time: 116.013s
12/18/2017 03:15:52 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:15:52 [INFO] exp_shallowmodel: accuracy:   0.764
12/18/2017 03:15:52 [INFO] exp_shallowmodel: f1_score:   0.385
12/18/2017 03:15:52 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:15:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.29      0.38        59
          C       0.00      0.00      0.00        12
          F       0.83      0.93      0.87       396
          R       0.33      0.25      0.29        55

avg / total       0.72      0.76      0.74       522

12/18/2017 03:15:52 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:15:52 [INFO] exp_shallowmodel: 
[[ 17   0  35   7]
 [  0   0   7   5]
 [ 10   2 368  16]
 [  4   1  36  14]]
12/18/2017 03:15:54 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/18/2017 03:15:54 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:15:54 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:15:54 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:15:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:15:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:15:54 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:15:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:16:58 [INFO] exp_shallowmodel: train time: 64.043s
12/18/2017 03:16:58 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:16:58 [INFO] exp_shallowmodel: accuracy:   0.734
12/18/2017 03:16:58 [INFO] exp_shallowmodel: f1_score:   0.318
12/18/2017 03:16:58 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:16:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.15      0.19        59
          C       0.00      0.00      0.00        12
          F       0.81      0.92      0.86       396
          R       0.27      0.18      0.22        55

avg / total       0.67      0.73      0.70       522

12/18/2017 03:16:58 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:16:58 [INFO] exp_shallowmodel: 
[[  9   1  42   7]
 [  1   0   9   2]
 [ 14   0 364  18]
 [ 11   0  34  10]]
12/18/2017 03:16:59 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/18/2017 03:16:59 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:16:59 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:16:59 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:16:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:16:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:16:59 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:16:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:17:58 [INFO] exp_shallowmodel: train time: 59.121s
12/18/2017 03:17:58 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:17:58 [INFO] exp_shallowmodel: accuracy:   0.749
12/18/2017 03:17:58 [INFO] exp_shallowmodel: f1_score:   0.385
12/18/2017 03:17:58 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:17:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.19      0.24        59
          C       0.33      0.08      0.13        12
          F       0.81      0.92      0.86       396
          R       0.37      0.25      0.30        55

avg / total       0.70      0.75      0.72       522

12/18/2017 03:17:58 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:17:58 [INFO] exp_shallowmodel: 
[[ 11   0  42   6]
 [  2   1   6   3]
 [ 14   2 365  15]
 [  6   0  35  14]]
12/18/2017 03:17:59 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/18/2017 03:17:59 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:17:59 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:17:59 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:17:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:17:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:17:59 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:17:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:18:57 [INFO] exp_shallowmodel: train time: 57.678s
12/18/2017 03:18:57 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:18:57 [INFO] exp_shallowmodel: accuracy:   0.741
12/18/2017 03:18:57 [INFO] exp_shallowmodel: f1_score:   0.393
12/18/2017 03:18:57 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:18:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.24      0.28        59
          C       1.00      0.17      0.29        12
          F       0.81      0.92      0.86       396
          R       0.21      0.11      0.14        55

avg / total       0.70      0.74      0.71       522

12/18/2017 03:18:57 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:18:57 [INFO] exp_shallowmodel: 
[[ 14   0  38   7]
 [  1   2   7   2]
 [ 18   0 365  13]
 [  7   0  42   6]]
12/18/2017 03:18:58 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/18/2017 03:18:58 [INFO] exp_shallowmodel: #(data) = 4176
12/18/2017 03:18:58 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:18:58 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:18:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:18:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:18:58 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:18:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:19:53 [INFO] exp_shallowmodel: train time: 54.785s
12/18/2017 03:19:53 [INFO] exp_shallowmodel: test time:  0.007s
12/18/2017 03:19:53 [INFO] exp_shallowmodel: accuracy:   0.766
12/18/2017 03:19:53 [INFO] exp_shallowmodel: f1_score:   0.443
12/18/2017 03:19:53 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:19:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.27      0.32        64
          C       0.67      0.14      0.24        14
          F       0.83      0.95      0.88       402
          R       0.45      0.27      0.34        63

avg / total       0.73      0.77      0.74       543

12/18/2017 03:19:53 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:19:53 [INFO] exp_shallowmodel: 
[[ 17   0  37  10]
 [  2   2   9   1]
 [ 11   1 380  10]
 [ 13   0  33  17]]
12/18/2017 03:19:54 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/18/2017 03:19:54 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:19:54 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:19:54 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:19:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:19:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:19:54 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:19:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:20:50 [INFO] exp_shallowmodel: train time: 55.245s
12/18/2017 03:20:50 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:20:50 [INFO] exp_shallowmodel: accuracy:   0.753
12/18/2017 03:20:50 [INFO] exp_shallowmodel: f1_score:   0.394
12/18/2017 03:20:50 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:20:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.27      0.30        59
          C       1.00      0.08      0.15        12
          F       0.83      0.92      0.87       396
          R       0.33      0.20      0.25        55

avg / total       0.73      0.75      0.73       522

12/18/2017 03:20:50 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:20:50 [INFO] exp_shallowmodel: 
[[ 16   0  35   8]
 [  3   1   6   2]
 [ 19   0 365  12]
 [ 10   0  34  11]]
12/18/2017 03:20:51 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/18/2017 03:20:51 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:20:51 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:20:51 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:20:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:20:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:20:51 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:20:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:22:45 [INFO] exp_shallowmodel: train time: 113.964s
12/18/2017 03:22:45 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:22:45 [INFO] exp_shallowmodel: accuracy:   0.757
12/18/2017 03:22:45 [INFO] exp_shallowmodel: f1_score:   0.373
12/18/2017 03:22:45 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:22:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.52      0.27      0.36        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.32      0.24      0.27        55

avg / total       0.71      0.76      0.73       522

12/18/2017 03:22:45 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:22:45 [INFO] exp_shallowmodel: 
[[ 16   0  36   7]
 [  2   0   7   3]
 [ 11   1 366  18]
 [  2   1  39  13]]
12/18/2017 03:22:48 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/18/2017 03:22:48 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:22:48 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:22:48 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:22:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:22:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:22:48 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:22:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:24:46 [INFO] exp_shallowmodel: train time: 118.477s
12/18/2017 03:24:46 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:24:46 [INFO] exp_shallowmodel: accuracy:   0.745
12/18/2017 03:24:46 [INFO] exp_shallowmodel: f1_score:   0.368
12/18/2017 03:24:46 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:24:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.14      0.18        59
          C       0.33      0.08      0.13        12
          F       0.82      0.92      0.87       396
          R       0.34      0.25      0.29        55

avg / total       0.69      0.75      0.71       522

12/18/2017 03:24:46 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:24:46 [INFO] exp_shallowmodel: 
[[  8   0  41  10]
 [  2   1   6   3]
 [ 14   2 366  14]
 [  8   0  33  14]]
12/18/2017 03:24:49 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/18/2017 03:24:49 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:24:49 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:24:49 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:24:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:24:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:24:49 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:24:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:27:01 [INFO] exp_shallowmodel: train time: 131.808s
12/18/2017 03:27:01 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:27:01 [INFO] exp_shallowmodel: accuracy:   0.747
12/18/2017 03:27:01 [INFO] exp_shallowmodel: f1_score:   0.327
12/18/2017 03:27:01 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:27:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.12      0.17        59
          C       0.00      0.00      0.00        12
          F       0.81      0.93      0.87       396
          R       0.33      0.24      0.27        55

avg / total       0.68      0.75      0.71       522

12/18/2017 03:27:01 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:27:01 [INFO] exp_shallowmodel: 
[[  7   0  44   8]
 [  2   0   6   4]
 [ 11   0 370  15]
 [  4   0  38  13]]
12/18/2017 03:27:03 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/18/2017 03:27:03 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:27:03 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:27:03 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:27:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:27:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:27:03 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:27:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:29:15 [INFO] exp_shallowmodel: train time: 131.390s
12/18/2017 03:29:15 [INFO] exp_shallowmodel: test time:  0.007s
12/18/2017 03:29:15 [INFO] exp_shallowmodel: accuracy:   0.761
12/18/2017 03:29:15 [INFO] exp_shallowmodel: f1_score:   0.387
12/18/2017 03:29:15 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:29:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.24      0.29        59
          C       0.25      0.08      0.12        12
          F       0.82      0.94      0.88       396
          R       0.34      0.20      0.25        55

avg / total       0.71      0.76      0.73       522

12/18/2017 03:29:15 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:29:15 [INFO] exp_shallowmodel: 
[[ 14   0  38   7]
 [  0   1   7   4]
 [ 14   1 371  10]
 [  8   2  34  11]]
12/18/2017 03:29:17 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/18/2017 03:29:17 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:29:17 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:29:17 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:29:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:29:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:29:17 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:29:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:31:28 [INFO] exp_shallowmodel: train time: 130.836s
12/18/2017 03:31:28 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:31:28 [INFO] exp_shallowmodel: accuracy:   0.761
12/18/2017 03:31:28 [INFO] exp_shallowmodel: f1_score:   0.402
12/18/2017 03:31:28 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:31:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.19      0.24        59
          C       0.50      0.08      0.14        12
          F       0.83      0.93      0.88       396
          R       0.40      0.31      0.35        55

avg / total       0.72      0.76      0.73       522

12/18/2017 03:31:28 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:31:28 [INFO] exp_shallowmodel: 
[[ 11   0  41   7]
 [  0   1   7   4]
 [ 12   1 368  15]
 [  9   0  29  17]]
12/18/2017 03:31:31 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/18/2017 03:31:31 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:31:31 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:31:31 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:31:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:31:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:31:31 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:31:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:33:31 [INFO] exp_shallowmodel: train time: 120.066s
12/18/2017 03:33:31 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:33:31 [INFO] exp_shallowmodel: accuracy:   0.751
12/18/2017 03:33:31 [INFO] exp_shallowmodel: f1_score:   0.384
12/18/2017 03:33:31 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:33:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.19      0.24        59
          C       0.50      0.08      0.14        12
          F       0.83      0.92      0.87       396
          R       0.33      0.25      0.29        55

avg / total       0.71      0.75      0.72       522

12/18/2017 03:33:31 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:33:31 [INFO] exp_shallowmodel: 
[[ 11   0  38  10]
 [  1   1   7   3]
 [ 13   1 366  16]
 [  9   0  32  14]]
12/18/2017 03:33:32 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/18/2017 03:33:32 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:33:32 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:33:32 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:33:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:33:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:33:32 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:33:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:34:28 [INFO] exp_shallowmodel: train time: 55.928s
12/18/2017 03:34:28 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:34:28 [INFO] exp_shallowmodel: accuracy:   0.747
12/18/2017 03:34:28 [INFO] exp_shallowmodel: f1_score:   0.396
12/18/2017 03:34:28 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:34:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.20      0.24        59
          C       0.20      0.08      0.12        12
          F       0.82      0.91      0.86       396
          R       0.42      0.31      0.36        55

avg / total       0.71      0.75      0.72       522

12/18/2017 03:34:28 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:34:28 [INFO] exp_shallowmodel: 
[[ 12   1  40   6]
 [  1   1   7   3]
 [ 19   3 360  14]
 [  8   0  30  17]]
12/18/2017 03:34:30 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/18/2017 03:34:30 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:34:30 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:34:30 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:34:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:34:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:34:30 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:34:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:35:50 [INFO] exp_shallowmodel: train time: 79.994s
12/18/2017 03:35:50 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:35:50 [INFO] exp_shallowmodel: accuracy:   0.753
12/18/2017 03:35:50 [INFO] exp_shallowmodel: f1_score:   0.365
12/18/2017 03:35:50 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:35:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.15      0.20        59
          C       0.25      0.08      0.12        12
          F       0.83      0.94      0.88       396
          R       0.31      0.22      0.26        55

avg / total       0.70      0.75      0.72       522

12/18/2017 03:35:50 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:35:50 [INFO] exp_shallowmodel: 
[[  9   0  40  10]
 [  1   1   8   2]
 [  9   1 371  15]
 [ 12   2  29  12]]
12/18/2017 03:35:52 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/18/2017 03:35:52 [INFO] exp_shallowmodel: #(data) = 4176
12/18/2017 03:35:52 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:35:52 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:35:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:35:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:35:52 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:35:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:37:40 [INFO] exp_shallowmodel: train time: 108.220s
12/18/2017 03:37:40 [INFO] exp_shallowmodel: test time:  0.007s
12/18/2017 03:37:40 [INFO] exp_shallowmodel: accuracy:   0.751
12/18/2017 03:37:40 [INFO] exp_shallowmodel: f1_score:   0.448
12/18/2017 03:37:40 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:37:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.41      0.27      0.32        64
          C       0.44      0.29      0.35        14
          F       0.82      0.93      0.87       402
          R       0.35      0.19      0.25        63

avg / total       0.71      0.75      0.72       543

12/18/2017 03:37:40 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:37:40 [INFO] exp_shallowmodel: 
[[ 17   1  39   7]
 [  0   4   8   2]
 [ 12   2 375  13]
 [ 12   2  37  12]]
12/18/2017 03:37:42 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/18/2017 03:37:42 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:37:42 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:37:42 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:37:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:37:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:37:42 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:37:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:39:25 [INFO] exp_shallowmodel: train time: 103.006s
12/18/2017 03:39:25 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:39:25 [INFO] exp_shallowmodel: accuracy:   0.759
12/18/2017 03:39:25 [INFO] exp_shallowmodel: f1_score:   0.395
12/18/2017 03:39:25 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:39:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.25      0.30        59
          C       0.25      0.08      0.12        12
          F       0.83      0.93      0.87       396
          R       0.38      0.22      0.28        55

avg / total       0.71      0.76      0.73       522

12/18/2017 03:39:25 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:39:25 [INFO] exp_shallowmodel: 
[[ 15   0  36   8]
 [  1   1   8   2]
 [ 16   2 368  10]
 [  8   1  34  12]]
12/18/2017 03:39:27 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/18/2017 03:39:27 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:39:27 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:39:27 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:39:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:39:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:39:27 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:39:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:41:40 [INFO] exp_shallowmodel: train time: 133.001s
12/18/2017 03:41:40 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:41:40 [INFO] exp_shallowmodel: accuracy:   0.734
12/18/2017 03:41:40 [INFO] exp_shallowmodel: f1_score:   0.377
12/18/2017 03:41:40 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:41:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.25      0.28        59
          C       0.25      0.08      0.12        12
          F       0.82      0.90      0.86       396
          R       0.32      0.20      0.25        55

avg / total       0.70      0.73      0.71       522

12/18/2017 03:41:40 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:41:40 [INFO] exp_shallowmodel: 
[[ 15   2  36   6]
 [  2   1   6   3]
 [ 25   1 356  14]
 [  7   0  37  11]]
12/18/2017 03:41:43 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/18/2017 03:41:43 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:41:43 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:41:43 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:41:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:41:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:41:43 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:41:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:43:44 [INFO] exp_shallowmodel: train time: 120.861s
12/18/2017 03:43:44 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:43:44 [INFO] exp_shallowmodel: accuracy:   0.749
12/18/2017 03:43:44 [INFO] exp_shallowmodel: f1_score:   0.406
12/18/2017 03:43:44 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:43:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.25      0.31        59
          C       1.00      0.08      0.15        12
          F       0.83      0.91      0.87       396
          R       0.33      0.27      0.30        55

avg / total       0.73      0.75      0.73       522

12/18/2017 03:43:44 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:43:44 [INFO] exp_shallowmodel: 
[[ 15   0  38   6]
 [  1   1   6   4]
 [ 15   0 360  21]
 [  8   0  32  15]]
12/18/2017 03:43:47 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/18/2017 03:43:47 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:43:47 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:43:47 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:43:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:43:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:43:47 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:43:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:45:46 [INFO] exp_shallowmodel: train time: 119.706s
12/18/2017 03:45:46 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:45:46 [INFO] exp_shallowmodel: accuracy:   0.778
12/18/2017 03:45:46 [INFO] exp_shallowmodel: f1_score:   0.406
12/18/2017 03:45:46 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:45:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.47      0.27      0.34        59
          C       0.00      0.00      0.00        12
          F       0.84      0.93      0.88       396
          R       0.43      0.36      0.40        55

avg / total       0.73      0.78      0.75       522

12/18/2017 03:45:46 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:45:46 [INFO] exp_shallowmodel: 
[[ 16   0  36   7]
 [  2   0   7   3]
 [ 10   0 370  16]
 [  6   0  29  20]]
12/18/2017 03:45:49 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/18/2017 03:45:49 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:45:49 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:45:49 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:45:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:45:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:45:49 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:45:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:47:47 [INFO] exp_shallowmodel: train time: 117.573s
12/18/2017 03:47:47 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:47:47 [INFO] exp_shallowmodel: accuracy:   0.745
12/18/2017 03:47:47 [INFO] exp_shallowmodel: f1_score:   0.404
12/18/2017 03:47:47 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:47:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.17      0.23        59
          C       0.33      0.17      0.22        12
          F       0.82      0.91      0.86       396
          R       0.33      0.27      0.30        55

avg / total       0.70      0.75      0.72       522

12/18/2017 03:47:47 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:47:47 [INFO] exp_shallowmodel: 
[[ 10   1  44   4]
 [  2   2   4   4]
 [  9   2 362  23]
 [  6   1  33  15]]
12/18/2017 03:47:49 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/18/2017 03:47:49 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:47:49 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:47:49 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:47:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:47:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:47:49 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:47:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:49:34 [INFO] exp_shallowmodel: train time: 105.117s
12/18/2017 03:49:34 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:49:34 [INFO] exp_shallowmodel: accuracy:   0.761
12/18/2017 03:49:34 [INFO] exp_shallowmodel: f1_score:   0.406
12/18/2017 03:49:34 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:49:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.24      0.29        59
          C       0.25      0.08      0.12        12
          F       0.83      0.92      0.88       396
          R       0.39      0.29      0.33        55

avg / total       0.72      0.76      0.74       522

12/18/2017 03:49:34 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:49:34 [INFO] exp_shallowmodel: 
[[ 14   2  36   7]
 [  2   1   7   2]
 [ 13   1 366  16]
 [  8   0  31  16]]
12/18/2017 03:49:37 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/18/2017 03:49:37 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:49:37 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:49:37 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:49:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:49:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:49:37 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:49:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:51:32 [INFO] exp_shallowmodel: train time: 115.200s
12/18/2017 03:51:32 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:51:32 [INFO] exp_shallowmodel: accuracy:   0.757
12/18/2017 03:51:32 [INFO] exp_shallowmodel: f1_score:   0.445
12/18/2017 03:51:32 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:51:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.14      0.17        59
          C       0.57      0.33      0.42        12
          F       0.84      0.93      0.88       396
          R       0.34      0.27      0.30        55

avg / total       0.72      0.76      0.73       522

12/18/2017 03:51:32 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:51:32 [INFO] exp_shallowmodel: 
[[  8   0  41  10]
 [  0   4   4   4]
 [ 13   0 368  15]
 [ 14   3  23  15]]
12/18/2017 03:51:34 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/18/2017 03:51:34 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:51:34 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:51:34 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:51:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:51:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:51:34 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:51:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:52:50 [INFO] exp_shallowmodel: train time: 75.906s
12/18/2017 03:52:50 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:52:50 [INFO] exp_shallowmodel: accuracy:   0.761
12/18/2017 03:52:50 [INFO] exp_shallowmodel: f1_score:   0.402
12/18/2017 03:52:50 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:52:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.22      0.29        59
          C       0.50      0.08      0.14        12
          F       0.83      0.93      0.88       396
          R       0.33      0.27      0.30        55

avg / total       0.72      0.76      0.73       522

12/18/2017 03:52:50 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:52:50 [INFO] exp_shallowmodel: 
[[ 13   0  40   6]
 [  0   1   5   6]
 [  9   0 368  19]
 [  8   1  31  15]]
12/18/2017 03:52:52 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/18/2017 03:52:52 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:52:52 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:52:52 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:52:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:52:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:52:52 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:52:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:54:52 [INFO] exp_shallowmodel: train time: 120.120s
12/18/2017 03:54:52 [INFO] exp_shallowmodel: test time:  0.007s
12/18/2017 03:54:52 [INFO] exp_shallowmodel: accuracy:   0.751
12/18/2017 03:54:52 [INFO] exp_shallowmodel: f1_score:   0.387
12/18/2017 03:54:52 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:54:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.17      0.22        59
          C       0.25      0.08      0.12        12
          F       0.82      0.92      0.87       396
          R       0.40      0.29      0.34        55

avg / total       0.70      0.75      0.72       522

12/18/2017 03:54:52 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:54:52 [INFO] exp_shallowmodel: 
[[ 10   0  41   8]
 [  2   1   8   1]
 [ 14   2 365  15]
 [  7   1  31  16]]
12/18/2017 03:54:55 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/18/2017 03:54:55 [INFO] exp_shallowmodel: #(data) = 4176
12/18/2017 03:54:55 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:54:55 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:54:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:54:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:54:55 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:54:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:56:43 [INFO] exp_shallowmodel: train time: 107.651s
12/18/2017 03:56:43 [INFO] exp_shallowmodel: test time:  0.007s
12/18/2017 03:56:43 [INFO] exp_shallowmodel: accuracy:   0.731
12/18/2017 03:56:43 [INFO] exp_shallowmodel: f1_score:   0.404
12/18/2017 03:56:43 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:56:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.25      0.31        64
          C       0.40      0.14      0.21        14
          F       0.80      0.91      0.85       402
          R       0.30      0.21      0.25        63

avg / total       0.69      0.73      0.70       543

12/18/2017 03:56:43 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:56:43 [INFO] exp_shallowmodel: 
[[ 16   0  40   8]
 [  3   2   6   3]
 [ 15   2 366  19]
 [  6   1  43  13]]
12/18/2017 03:56:45 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/18/2017 03:56:45 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:56:45 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:56:45 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:56:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:56:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:56:45 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:56:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 03:58:46 [INFO] exp_shallowmodel: train time: 120.740s
12/18/2017 03:58:46 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 03:58:46 [INFO] exp_shallowmodel: accuracy:   0.764
12/18/2017 03:58:46 [INFO] exp_shallowmodel: f1_score:   0.447
12/18/2017 03:58:46 [INFO] exp_shallowmodel: classification report:
12/18/2017 03:58:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.41      0.27      0.33        59
          C       1.00      0.17      0.29        12
          F       0.83      0.93      0.87       396
          R       0.37      0.25      0.30        55

avg / total       0.74      0.76      0.74       522

12/18/2017 03:58:46 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 03:58:46 [INFO] exp_shallowmodel: 
[[ 16   0  37   6]
 [  2   2   7   1]
 [ 12   0 367  17]
 [  9   0  32  14]]
12/18/2017 03:58:49 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/18/2017 03:58:49 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 03:58:49 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 03:58:49 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 03:58:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 03:58:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 03:58:49 [INFO] exp_shallowmodel: Training: 
12/18/2017 03:58:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 04:00:47 [INFO] exp_shallowmodel: train time: 118.297s
12/18/2017 04:00:47 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 04:00:47 [INFO] exp_shallowmodel: accuracy:   0.762
12/18/2017 04:00:47 [INFO] exp_shallowmodel: f1_score:   0.393
12/18/2017 04:00:47 [INFO] exp_shallowmodel: classification report:
12/18/2017 04:00:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.20      0.25        59
          C       0.33      0.08      0.13        12
          F       0.83      0.94      0.88       396
          R       0.39      0.25      0.31        55

avg / total       0.72      0.76      0.73       522

12/18/2017 04:00:47 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 04:00:47 [INFO] exp_shallowmodel: 
[[ 12   1  39   7]
 [  1   1   6   4]
 [ 13   1 371  11]
 [ 11   0  30  14]]
12/18/2017 04:00:50 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/18/2017 04:00:50 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 04:00:50 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 04:00:50 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 04:00:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 04:00:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 04:00:50 [INFO] exp_shallowmodel: Training: 
12/18/2017 04:00:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 04:02:13 [INFO] exp_shallowmodel: train time: 82.720s
12/18/2017 04:02:13 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 04:02:13 [INFO] exp_shallowmodel: accuracy:   0.759
12/18/2017 04:02:13 [INFO] exp_shallowmodel: f1_score:   0.392
12/18/2017 04:02:13 [INFO] exp_shallowmodel: classification report:
12/18/2017 04:02:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.15      0.20        59
          C       1.00      0.08      0.15        12
          F       0.82      0.93      0.87       396
          R       0.42      0.29      0.34        55

avg / total       0.72      0.76      0.73       522

12/18/2017 04:02:13 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 04:02:13 [INFO] exp_shallowmodel: 
[[  9   0  41   9]
 [  1   1   6   4]
 [ 17   0 370   9]
 [  6   0  33  16]]
12/18/2017 04:02:15 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/18/2017 04:02:15 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 04:02:15 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 04:02:15 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 04:02:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 04:02:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 04:02:15 [INFO] exp_shallowmodel: Training: 
12/18/2017 04:02:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 04:04:09 [INFO] exp_shallowmodel: train time: 113.369s
12/18/2017 04:04:09 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 04:04:09 [INFO] exp_shallowmodel: accuracy:   0.770
12/18/2017 04:04:09 [INFO] exp_shallowmodel: f1_score:   0.385
12/18/2017 04:04:09 [INFO] exp_shallowmodel: classification report:
12/18/2017 04:04:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.24      0.31        59
          C       0.00      0.00      0.00        12
          F       0.84      0.93      0.89       396
          R       0.36      0.33      0.34        55

avg / total       0.73      0.77      0.74       522

12/18/2017 04:04:09 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 04:04:09 [INFO] exp_shallowmodel: 
[[ 14   1  33  11]
 [  2   0   5   5]
 [ 10   0 370  16]
 [  5   0  32  18]]
12/18/2017 04:04:11 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/18/2017 04:04:11 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 04:04:11 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 04:04:11 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 04:04:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 04:04:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 04:04:11 [INFO] exp_shallowmodel: Training: 
12/18/2017 04:04:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 04:05:28 [INFO] exp_shallowmodel: train time: 76.500s
12/18/2017 04:05:28 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 04:05:28 [INFO] exp_shallowmodel: accuracy:   0.762
12/18/2017 04:05:28 [INFO] exp_shallowmodel: f1_score:   0.389
12/18/2017 04:05:28 [INFO] exp_shallowmodel: classification report:
12/18/2017 04:05:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.25      0.31        59
          C       0.00      0.00      0.00        12
          F       0.84      0.92      0.88       396
          R       0.43      0.33      0.37        55

avg / total       0.72      0.76      0.74       522

12/18/2017 04:05:28 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 04:05:28 [INFO] exp_shallowmodel: 
[[ 15   0  36   8]
 [  1   0   8   3]
 [ 14   4 365  13]
 [  8   1  28  18]]
12/18/2017 04:05:29 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/18/2017 04:05:29 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 04:05:29 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 04:05:29 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 04:05:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 04:05:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 04:05:29 [INFO] exp_shallowmodel: Training: 
12/18/2017 04:05:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 04:06:30 [INFO] exp_shallowmodel: train time: 60.904s
12/18/2017 04:06:30 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 04:06:30 [INFO] exp_shallowmodel: accuracy:   0.751
12/18/2017 04:06:30 [INFO] exp_shallowmodel: f1_score:   0.379
12/18/2017 04:06:30 [INFO] exp_shallowmodel: classification report:
12/18/2017 04:06:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.19      0.23        59
          C       0.33      0.08      0.13        12
          F       0.82      0.93      0.87       396
          R       0.33      0.24      0.28        55

avg / total       0.70      0.75      0.72       522

12/18/2017 04:06:30 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 04:06:30 [INFO] exp_shallowmodel: 
[[ 11   1  38   9]
 [  1   1   6   4]
 [ 16   0 367  13]
 [  7   1  34  13]]
12/18/2017 04:06:31 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/18/2017 04:06:31 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 04:06:31 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 04:06:31 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 04:06:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 04:06:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 04:06:31 [INFO] exp_shallowmodel: Training: 
12/18/2017 04:06:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 04:07:35 [INFO] exp_shallowmodel: train time: 63.980s
12/18/2017 04:07:35 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 04:07:35 [INFO] exp_shallowmodel: accuracy:   0.739
12/18/2017 04:07:35 [INFO] exp_shallowmodel: f1_score:   0.410
12/18/2017 04:07:35 [INFO] exp_shallowmodel: classification report:
12/18/2017 04:07:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.22      0.27        59
          C       0.67      0.17      0.27        12
          F       0.82      0.91      0.86       396
          R       0.28      0.22      0.24        55

avg / total       0.71      0.74      0.72       522

12/18/2017 04:07:35 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 04:07:35 [INFO] exp_shallowmodel: 
[[ 13   0  35  11]
 [  0   2   8   2]
 [ 18   1 359  18]
 [  7   0  36  12]]
12/18/2017 04:07:37 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/18/2017 04:07:37 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 04:07:37 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 04:07:37 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 04:07:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 04:07:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 04:07:37 [INFO] exp_shallowmodel: Training: 
12/18/2017 04:07:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 04:08:35 [INFO] exp_shallowmodel: train time: 58.137s
12/18/2017 04:08:35 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 04:08:35 [INFO] exp_shallowmodel: accuracy:   0.728
12/18/2017 04:08:35 [INFO] exp_shallowmodel: f1_score:   0.326
12/18/2017 04:08:35 [INFO] exp_shallowmodel: classification report:
12/18/2017 04:08:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.22      0.25        59
          C       0.00      0.00      0.00        12
          F       0.82      0.90      0.86       396
          R       0.25      0.16      0.20        55

avg / total       0.68      0.73      0.70       522

12/18/2017 04:08:35 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 04:08:35 [INFO] exp_shallowmodel: 
[[ 13   0  39   7]
 [  2   0   7   3]
 [ 19   2 358  17]
 [ 12   1  33   9]]
12/18/2017 04:08:36 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/18/2017 04:08:36 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 04:08:36 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 04:08:36 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 04:08:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 04:08:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 04:08:36 [INFO] exp_shallowmodel: Training: 
12/18/2017 04:08:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 04:09:36 [INFO] exp_shallowmodel: train time: 59.587s
12/18/2017 04:09:36 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 04:09:36 [INFO] exp_shallowmodel: accuracy:   0.745
12/18/2017 04:09:36 [INFO] exp_shallowmodel: f1_score:   0.396
12/18/2017 04:09:36 [INFO] exp_shallowmodel: classification report:
12/18/2017 04:09:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.14      0.18        59
          C       0.50      0.17      0.25        12
          F       0.82      0.92      0.87       396
          R       0.32      0.25      0.28        55

avg / total       0.70      0.75      0.71       522

12/18/2017 04:09:36 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 04:09:36 [INFO] exp_shallowmodel: 
[[  8   0  41  10]
 [  2   2   7   1]
 [ 11   1 365  19]
 [  8   1  32  14]]
12/18/2017 04:09:37 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/18/2017 04:09:37 [INFO] exp_shallowmodel: #(data) = 4176
12/18/2017 04:09:37 [INFO] exp_shallowmodel: #(feature) = 8480
12/18/2017 04:09:37 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 04:09:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 04:09:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 04:09:37 [INFO] exp_shallowmodel: Training: 
12/18/2017 04:09:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 04:11:07 [INFO] exp_shallowmodel: train time: 90.388s
12/18/2017 04:11:07 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 04:11:07 [INFO] exp_shallowmodel: accuracy:   0.751
12/18/2017 04:11:07 [INFO] exp_shallowmodel: f1_score:   0.385
12/18/2017 04:11:07 [INFO] exp_shallowmodel: classification report:
12/18/2017 04:11:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.28      0.35        64
          C       0.00      0.00      0.00        14
          F       0.81      0.93      0.86       402
          R       0.41      0.27      0.33        63

avg / total       0.70      0.75      0.72       543

12/18/2017 04:11:07 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 04:11:07 [INFO] exp_shallowmodel: 
[[ 18   0  43   3]
 [  2   0   8   4]
 [ 11   1 373  17]
 [  8   1  37  17]]
