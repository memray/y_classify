12/31/2017 18:15:53 [INFO] configuration: experiment_mode  :   feature_selection
12/31/2017 18:15:53 [INFO] configuration: deep_model  :   False
12/31/2017 18:15:53 [INFO] configuration: selected_context_id  :   0
12/31/2017 18:15:53 [INFO] configuration: selected_feature_set_id  :   11
12/31/2017 18:15:53 [INFO] configuration: similarity_feature  :   True
12/31/2017 18:15:53 [INFO] configuration: k_feature_to_keep  :   7
12/31/2017 18:15:53 [INFO] configuration: seed  :   154316847
12/31/2017 18:15:53 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/31/2017 18:15:53 [INFO] configuration: task_name  :   utterance_type
12/31/2017 18:15:53 [INFO] configuration: timemark  :   20171231-181553
12/31/2017 18:15:53 [INFO] configuration: context_set  :   next
12/31/2017 18:15:53 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/31/2017 18:15:53 [INFO] configuration: utterance_range  :   ['current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/31/2017 18:15:53 [INFO] configuration: feature_set  :   11-[6+1.3.4]
12/31/2017 18:15:53 [INFO] configuration: feature_set_number  :   ['1', '2', '3', '5', '6', '7', '9']
12/31/2017 18:15:53 [INFO] configuration: experiment_name  :   20171231-181553.feature_selection.no_regularization.feature_number=7.context=next.feature=11-[6+1.3.4].similarity=true
12/31/2017 18:15:53 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171231-181553.feature_selection.no_regularization.feature_number=7.context=next.feature=11-[6+1.3.4].similarity=true
12/31/2017 18:15:53 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171231-181553.feature_selection.no_regularization.feature_number=7.context=next.feature=11-[6+1.3.4].similarity=true/output.log
12/31/2017 18:15:53 [INFO] configuration: valid_type  :   {'F', 'A', 'R', 'C'}
12/31/2017 18:15:53 [INFO] configuration: data_name  :   
12/31/2017 18:15:53 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/31/2017 18:15:53 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/31/2017 18:15:53 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/31/2017 18:15:53 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/31/2017 18:15:53 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/31/2017 18:15:53 [INFO] configuration: do_cross_validation  :   True
12/31/2017 18:15:53 [INFO] configuration: #division  :   5
12/31/2017 18:15:53 [INFO] configuration: #cross_validation  :   10
12/31/2017 18:15:53 [INFO] configuration: cv_index_cache_path  :   
12/31/2017 18:15:53 [INFO] configuration: action_words  :   {'centr', 'list', 'item', 'reminds', 'moderate', 'temperatur', 'remove', 'watch', 'shuffl', 'any', 'address', 'food', 'reminder', 'phone', 'music', 'shuffle', 'weather', 'video', 'start', 'else', 'member', 'remov', 'next', 'song', 'alarm', 'findcare', 'findcar', 'matter', 'play', 'north', 'tell', 'room', 'clear', 'ani', 'timer', 'area', 'snooze', 'moder', 'temperature', 'delete', 'telephone', 'time', 'stop', 'cheap', 'els', 'add', 'part', 'expensive', 'help', 'volume', 'skip', 'turn', 'telephon', 'share', 'snooz', 'price', 'centre', 'reminders', 'number', 'remind', 'post', 'volum', 'light', 'cast', 'expens', 'delet', 'show', 'items', 'discard', 'south'}
12/31/2017 18:15:53 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/31/2017 18:15:53 [INFO] configuration: lda_topic_number  :   50
12/31/2017 18:15:53 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/31/2017 18:15:53 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/31/2017 18:15:53 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/31/2017 18:15:53 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/31/2017 18:15:53 [INFO] configuration: w2v_vector_length  :   300
12/31/2017 18:15:53 [INFO] configuration: d2v_vector_length  :   300
12/31/2017 18:15:53 [INFO] configuration: d2v_window_size  :   5
12/31/2017 18:15:53 [INFO] configuration: d2v_min_count  :   2
12/31/2017 18:15:53 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/31/2017 18:15:53 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/31/2017 18:15:53 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/31/2017 18:15:53 [INFO] configuration: batch_size  :   128
12/31/2017 18:15:53 [INFO] configuration: max_epoch  :   50
12/31/2017 18:15:53 [INFO] configuration: early_stop_tolerance  :   2
12/31/2017 18:15:53 [INFO] configuration: concat_sents  :   False
12/31/2017 18:15:53 [INFO] configuration: cnn_setting  :   {'model': 'rand', 'early_stopping': True, 'word_dim': 300, 'filters': [3, 4, 5], 'filter_num': [100, 100, 100], 'class_size': 4, 'batch_size': 128, 'learning_rate': 0.001, 'norm_limit': 10, 'dropout_prob': 0.5, 'sentence_num': 3}
12/31/2017 18:15:53 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 3, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/31/2017 18:15:53 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/31/2017 18:15:56 [INFO] exp_shallowmodel: 1	3

12/31/2017 18:15:56 [INFO] exp_shallowmodel: 2.1	50

12/31/2017 18:15:56 [INFO] exp_shallowmodel: 2.2	2

12/31/2017 18:15:56 [INFO] exp_shallowmodel: 2.3.1	1

12/31/2017 18:15:56 [INFO] exp_shallowmodel: 3	5

12/31/2017 18:15:56 [INFO] exp_shallowmodel: 5	2184

12/31/2017 18:15:56 [INFO] exp_shallowmodel: 6	245

12/31/2017 18:15:56 [INFO] exp_shallowmodel: 7	910

12/31/2017 18:15:56 [INFO] exp_shallowmodel: 9.1	900

12/31/2017 18:15:56 [INFO] exp_shallowmodel: 9.2.1	1

12/31/2017 18:15:56 [INFO] exp_shallowmodel: 9.3.1	1

12/31/2017 18:15:57 [INFO] exp_shallowmodel: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/31/2017 18:15:57 [INFO] exp_shallowmodel:           dataset=dstc2
12/31/2017 18:15:57 [INFO] exp_shallowmodel:           k_feature_to_keep=7
12/31/2017 18:15:57 [INFO] exp_shallowmodel:           X_new.shape=(5725, 1040)
12/31/2017 18:15:57 [INFO] exp_shallowmodel:           #(X_selected)=128
12/31/2017 18:15:57 [INFO] exp_shallowmodel:           #(X_not_selectable)=912
12/31/2017 18:15:57 [INFO] exp_shallowmodel: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/31/2017 18:15:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/31/2017 18:15:57 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 18:15:57 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 18:15:57 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 18:15:57 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 18:15:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 18:15:57 [INFO] exp_shallowmodel: Training: 
12/31/2017 18:15:57 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 18:21:55 [INFO] exp_shallowmodel: train time: 358.073s
12/31/2017 18:21:55 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 18:21:55 [INFO] exp_shallowmodel: accuracy:   0.755
12/31/2017 18:21:55 [INFO] exp_shallowmodel: f1_score:   0.615
12/31/2017 18:21:55 [INFO] exp_shallowmodel: classification report:
12/31/2017 18:21:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.29      0.25        14
          C       0.69      0.60      0.64       164
          F       0.91      0.88      0.89       268
          R       0.61      0.75      0.68       125

avg / total       0.77      0.75      0.76       571

12/31/2017 18:21:55 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 18:21:55 [INFO] exp_shallowmodel: 
[[  4   5   4   1]
 [  8  98  13  45]
 [  5  15 235  13]
 [  1  24   6  94]]
12/31/2017 18:21:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/31/2017 18:21:55 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 18:21:55 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 18:21:55 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 18:21:55 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 18:21:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 18:21:55 [INFO] exp_shallowmodel: Training: 
12/31/2017 18:21:55 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 18:32:54 [INFO] exp_shallowmodel: train time: 659.171s
12/31/2017 18:32:54 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 18:32:54 [INFO] exp_shallowmodel: accuracy:   0.706
12/31/2017 18:32:54 [INFO] exp_shallowmodel: f1_score:   0.563
12/31/2017 18:32:54 [INFO] exp_shallowmodel: classification report:
12/31/2017 18:32:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.29      0.21        14
          C       0.64      0.66      0.65       164
          F       0.88      0.84      0.86       268
          R       0.54      0.53      0.53       125

avg / total       0.72      0.71      0.71       571

12/31/2017 18:32:54 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 18:32:54 [INFO] exp_shallowmodel: 
[[  4   2   5   3]
 [  7 108  13  36]
 [  7  18 225  18]
 [  6  40  13  66]]
12/31/2017 18:32:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/31/2017 18:32:54 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 18:32:54 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 18:32:54 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 18:32:54 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 18:32:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 18:32:54 [INFO] exp_shallowmodel: Training: 
12/31/2017 18:32:54 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 18:44:22 [INFO] exp_shallowmodel: train time: 687.187s
12/31/2017 18:44:22 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 18:44:22 [INFO] exp_shallowmodel: accuracy:   0.722
12/31/2017 18:44:22 [INFO] exp_shallowmodel: f1_score:   0.621
12/31/2017 18:44:22 [INFO] exp_shallowmodel: classification report:
12/31/2017 18:44:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.57      0.43        14
          C       0.62      0.58      0.60       164
          F       0.92      0.88      0.90       268
          R       0.52      0.58      0.55       125

avg / total       0.73      0.72      0.73       571

12/31/2017 18:44:22 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 18:44:22 [INFO] exp_shallowmodel: 
[[  8   3   3   0]
 [  7  95  10  52]
 [  1  16 236  15]
 [  7  38   7  73]]
12/31/2017 18:44:22 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/31/2017 18:44:22 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 18:44:22 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 18:44:22 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 18:44:22 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 18:44:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 18:44:22 [INFO] exp_shallowmodel: Training: 
12/31/2017 18:44:22 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 18:55:21 [INFO] exp_shallowmodel: train time: 658.788s
12/31/2017 18:55:21 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 18:55:21 [INFO] exp_shallowmodel: accuracy:   0.737
12/31/2017 18:55:21 [INFO] exp_shallowmodel: f1_score:   0.667
12/31/2017 18:55:21 [INFO] exp_shallowmodel: classification report:
12/31/2017 18:55:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.64      0.56        14
          C       0.64      0.57      0.60       164
          F       0.90      0.88      0.89       268
          R       0.57      0.66      0.61       125

avg / total       0.74      0.74      0.74       571

12/31/2017 18:55:21 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 18:55:21 [INFO] exp_shallowmodel: 
[[  9   1   3   1]
 [  3  94  16  51]
 [  3  20 236   9]
 [  3  33   7  82]]
12/31/2017 18:55:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/31/2017 18:55:21 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 18:55:21 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 18:55:21 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 18:55:21 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 18:55:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 18:55:21 [INFO] exp_shallowmodel: Training: 
12/31/2017 18:55:21 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 19:10:56 [INFO] exp_shallowmodel: train time: 935.340s
12/31/2017 19:10:56 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 19:10:56 [INFO] exp_shallowmodel: accuracy:   0.743
12/31/2017 19:10:56 [INFO] exp_shallowmodel: f1_score:   0.556
12/31/2017 19:10:56 [INFO] exp_shallowmodel: classification report:
12/31/2017 19:10:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.07      0.07        14
          C       0.65      0.70      0.68       164
          F       0.88      0.89      0.89       268
          R       0.63      0.55      0.59       125

avg / total       0.74      0.74      0.74       571

12/31/2017 19:10:56 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 19:10:56 [INFO] exp_shallowmodel: 
[[  1   5   7   1]
 [  5 115  16  28]
 [  4  14 239  11]
 [  5  42   9  69]]
12/31/2017 19:10:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/31/2017 19:10:56 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 19:10:56 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 19:10:56 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 19:10:56 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 19:10:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 19:10:56 [INFO] exp_shallowmodel: Training: 
12/31/2017 19:10:56 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 19:23:45 [INFO] exp_shallowmodel: train time: 769.030s
12/31/2017 19:23:45 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 19:23:45 [INFO] exp_shallowmodel: accuracy:   0.720
12/31/2017 19:23:45 [INFO] exp_shallowmodel: f1_score:   0.606
12/31/2017 19:23:45 [INFO] exp_shallowmodel: classification report:
12/31/2017 19:23:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.43      0.36        14
          C       0.64      0.57      0.61       164
          F       0.86      0.88      0.87       268
          R       0.57      0.59      0.58       125

avg / total       0.72      0.72      0.72       571

12/31/2017 19:23:45 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 19:23:45 [INFO] exp_shallowmodel: 
[[  6   1   4   3]
 [  8  94  19  43]
 [  2  20 237   9]
 [  3  31  17  74]]
12/31/2017 19:23:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/31/2017 19:23:46 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 19:23:46 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 19:23:46 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 19:23:46 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 19:23:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 19:23:46 [INFO] exp_shallowmodel: Training: 
12/31/2017 19:23:46 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 19:40:45 [INFO] exp_shallowmodel: train time: 1019.014s
12/31/2017 19:40:45 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 19:40:45 [INFO] exp_shallowmodel: accuracy:   0.729
12/31/2017 19:40:45 [INFO] exp_shallowmodel: f1_score:   0.614
12/31/2017 19:40:45 [INFO] exp_shallowmodel: classification report:
12/31/2017 19:40:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.36      0.37        14
          C       0.63      0.63      0.63       164
          F       0.86      0.88      0.87       268
          R       0.59      0.58      0.58       125

avg / total       0.73      0.73      0.73       571

12/31/2017 19:40:45 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 19:40:45 [INFO] exp_shallowmodel: 
[[  5   1   8   0]
 [  4 103  13  44]
 [  3  23 236   6]
 [  1  36  16  72]]
12/31/2017 19:40:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/31/2017 19:40:45 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 19:40:45 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 19:40:45 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 19:40:45 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 19:40:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 19:40:45 [INFO] exp_shallowmodel: Training: 
12/31/2017 19:40:45 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 20:00:17 [INFO] exp_shallowmodel: train time: 1172.127s
12/31/2017 20:00:17 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 20:00:17 [INFO] exp_shallowmodel: accuracy:   0.734
12/31/2017 20:00:17 [INFO] exp_shallowmodel: f1_score:   0.591
12/31/2017 20:00:17 [INFO] exp_shallowmodel: classification report:
12/31/2017 20:00:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.29      0.26        14
          C       0.67      0.57      0.62       164
          F       0.88      0.91      0.90       268
          R       0.57      0.62      0.59       125

avg / total       0.74      0.73      0.73       571

12/31/2017 20:00:17 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 20:00:17 [INFO] exp_shallowmodel: 
[[  4   2   5   3]
 [  6  94  14  50]
 [  5  13 243   7]
 [  2  32  13  78]]
12/31/2017 20:00:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/31/2017 20:00:17 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 20:00:17 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 20:00:17 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 20:00:17 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 20:00:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 20:00:17 [INFO] exp_shallowmodel: Training: 
12/31/2017 20:00:17 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 20:22:54 [INFO] exp_shallowmodel: train time: 1356.860s
12/31/2017 20:22:54 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 20:22:54 [INFO] exp_shallowmodel: accuracy:   0.653
12/31/2017 20:22:54 [INFO] exp_shallowmodel: f1_score:   0.499
12/31/2017 20:22:54 [INFO] exp_shallowmodel: classification report:
12/31/2017 20:22:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.14      0.12        14
          C       0.56      0.54      0.55       164
          F       0.86      0.81      0.83       268
          R       0.46      0.53      0.49       125

avg / total       0.67      0.65      0.66       571

12/31/2017 20:22:54 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 20:22:54 [INFO] exp_shallowmodel: 
[[  2   3   4   5]
 [  4  88  18  54]
 [  5  29 217  17]
 [  8  37  14  66]]
12/31/2017 20:22:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/31/2017 20:22:54 [INFO] exp_shallowmodel: #(data) = 4568
12/31/2017 20:22:54 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 20:22:54 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 20:22:54 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 20:22:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 20:22:54 [INFO] exp_shallowmodel: Training: 
12/31/2017 20:22:54 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 20:35:37 [INFO] exp_shallowmodel: train time: 762.673s
12/31/2017 20:35:37 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 20:35:37 [INFO] exp_shallowmodel: accuracy:   0.720
12/31/2017 20:35:37 [INFO] exp_shallowmodel: f1_score:   0.612
12/31/2017 20:35:37 [INFO] exp_shallowmodel: classification report:
12/31/2017 20:35:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.44      0.38        16
          C       0.64      0.59      0.62       169
          F       0.89      0.87      0.88       271
          R       0.55      0.60      0.57       130

avg / total       0.73      0.72      0.72       586

12/31/2017 20:35:37 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 20:35:37 [INFO] exp_shallowmodel: 
[[  7   4   4   1]
 [  7 100  17  45]
 [  3  12 237  19]
 [  4  40   8  78]]
12/31/2017 20:35:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/31/2017 20:35:37 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 20:35:37 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 20:35:37 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 20:35:37 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 20:35:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 20:35:37 [INFO] exp_shallowmodel: Training: 
12/31/2017 20:35:37 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 20:51:27 [INFO] exp_shallowmodel: train time: 950.164s
12/31/2017 20:51:27 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 20:51:27 [INFO] exp_shallowmodel: accuracy:   0.737
12/31/2017 20:51:27 [INFO] exp_shallowmodel: f1_score:   0.584
12/31/2017 20:51:27 [INFO] exp_shallowmodel: classification report:
12/31/2017 20:51:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.21      0.21        14
          C       0.70      0.60      0.65       164
          F       0.85      0.90      0.87       268
          R       0.59      0.62      0.61       125

avg / total       0.74      0.74      0.73       571

12/31/2017 20:51:27 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 20:51:27 [INFO] exp_shallowmodel: 
[[  3   3   7   1]
 [  2  99  20  43]
 [  5  12 241  10]
 [  5  27  15  78]]
12/31/2017 20:51:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/31/2017 20:51:27 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 20:51:27 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 20:51:27 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 20:51:27 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 20:51:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 20:51:27 [INFO] exp_shallowmodel: Training: 
12/31/2017 20:51:27 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 21:02:58 [INFO] exp_shallowmodel: train time: 690.318s
12/31/2017 21:02:58 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 21:02:58 [INFO] exp_shallowmodel: accuracy:   0.718
12/31/2017 21:02:58 [INFO] exp_shallowmodel: f1_score:   0.581
12/31/2017 21:02:58 [INFO] exp_shallowmodel: classification report:
12/31/2017 21:02:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.29      0.27        14
          C       0.63      0.57      0.60       164
          F       0.87      0.88      0.88       268
          R       0.56      0.60      0.58       125

avg / total       0.72      0.72      0.72       571

12/31/2017 21:02:58 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 21:02:58 [INFO] exp_shallowmodel: 
[[  4   4   5   1]
 [  3  94  19  48]
 [  5  17 237   9]
 [  4  35  11  75]]
12/31/2017 21:02:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/31/2017 21:02:58 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 21:02:58 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 21:02:58 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 21:02:58 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 21:02:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 21:02:58 [INFO] exp_shallowmodel: Training: 
12/31/2017 21:02:58 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 21:14:36 [INFO] exp_shallowmodel: train time: 697.698s
12/31/2017 21:14:36 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 21:14:36 [INFO] exp_shallowmodel: accuracy:   0.713
12/31/2017 21:14:36 [INFO] exp_shallowmodel: f1_score:   0.559
12/31/2017 21:14:36 [INFO] exp_shallowmodel: classification report:
12/31/2017 21:14:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.16      0.21      0.18        14
          C       0.66      0.52      0.58       164
          F       0.88      0.88      0.88       268
          R       0.53      0.67      0.59       125

avg / total       0.73      0.71      0.71       571

12/31/2017 21:14:36 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 21:14:36 [INFO] exp_shallowmodel: 
[[  3   1   5   5]
 [  4  85  17  58]
 [  9  13 235  11]
 [  3  29   9  84]]
12/31/2017 21:14:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/31/2017 21:14:36 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 21:14:36 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 21:14:36 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 21:14:36 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 21:14:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 21:14:36 [INFO] exp_shallowmodel: Training: 
12/31/2017 21:14:36 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 21:28:09 [INFO] exp_shallowmodel: train time: 813.159s
12/31/2017 21:28:09 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 21:28:09 [INFO] exp_shallowmodel: accuracy:   0.750
12/31/2017 21:28:09 [INFO] exp_shallowmodel: f1_score:   0.626
12/31/2017 21:28:09 [INFO] exp_shallowmodel: classification report:
12/31/2017 21:28:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.36      0.31        14
          C       0.73      0.62      0.67       164
          F       0.91      0.86      0.88       268
          R       0.57      0.73      0.64       125

avg / total       0.77      0.75      0.75       571

12/31/2017 21:28:09 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 21:28:09 [INFO] exp_shallowmodel: 
[[  5   1   3   5]
 [  4 101  15  44]
 [  5  12 231  20]
 [  4  24   6  91]]
12/31/2017 21:28:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/31/2017 21:28:09 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 21:28:09 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 21:28:09 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 21:28:09 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 21:28:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 21:28:09 [INFO] exp_shallowmodel: Training: 
12/31/2017 21:28:09 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 21:41:26 [INFO] exp_shallowmodel: train time: 797.072s
12/31/2017 21:41:26 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 21:41:26 [INFO] exp_shallowmodel: accuracy:   0.715
12/31/2017 21:41:26 [INFO] exp_shallowmodel: f1_score:   0.593
12/31/2017 21:41:26 [INFO] exp_shallowmodel: classification report:
12/31/2017 21:41:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.43      0.32        14
          C       0.64      0.57      0.60       164
          F       0.89      0.87      0.88       268
          R       0.54      0.60      0.57       125

avg / total       0.73      0.71      0.72       571

12/31/2017 21:41:26 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 21:41:26 [INFO] exp_shallowmodel: 
[[  6   4   3   1]
 [  8  93  16  47]
 [  2  15 234  17]
 [  7  33  10  75]]
12/31/2017 21:41:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/31/2017 21:41:26 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 21:41:26 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 21:41:26 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 21:41:26 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 21:41:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 21:41:26 [INFO] exp_shallowmodel: Training: 
12/31/2017 21:41:26 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 22:02:46 [INFO] exp_shallowmodel: train time: 1279.130s
12/31/2017 22:02:46 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 22:02:46 [INFO] exp_shallowmodel: accuracy:   0.706
12/31/2017 22:02:46 [INFO] exp_shallowmodel: f1_score:   0.531
12/31/2017 22:02:46 [INFO] exp_shallowmodel: classification report:
12/31/2017 22:02:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.14      0.12        14
          C       0.65      0.60      0.62       164
          F       0.86      0.90      0.88       268
          R       0.51      0.49      0.50       125

avg / total       0.70      0.71      0.70       571

12/31/2017 22:02:46 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 22:02:46 [INFO] exp_shallowmodel: 
[[  2   1   8   3]
 [  7  98  16  43]
 [  2  12 242  12]
 [  8  40  16  61]]
12/31/2017 22:02:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/31/2017 22:02:46 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 22:02:46 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 22:02:46 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 22:02:46 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 22:02:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 22:02:46 [INFO] exp_shallowmodel: Training: 
12/31/2017 22:02:46 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 22:18:08 [INFO] exp_shallowmodel: train time: 922.308s
12/31/2017 22:18:08 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 22:18:08 [INFO] exp_shallowmodel: accuracy:   0.725
12/31/2017 22:18:08 [INFO] exp_shallowmodel: f1_score:   0.576
12/31/2017 22:18:08 [INFO] exp_shallowmodel: classification report:
12/31/2017 22:18:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.21      0.19        14
          C       0.66      0.54      0.59       164
          F       0.90      0.86      0.88       268
          R       0.57      0.74      0.64       125

avg / total       0.74      0.73      0.73       571

12/31/2017 22:18:08 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 22:18:08 [INFO] exp_shallowmodel: 
[[  3   5   4   2]
 [  3  88  15  58]
 [  6  21 231  10]
 [  5  20   8  92]]
12/31/2017 22:18:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/31/2017 22:18:08 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 22:18:08 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 22:18:08 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 22:18:08 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 22:18:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 22:18:08 [INFO] exp_shallowmodel: Training: 
12/31/2017 22:18:08 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 22:24:29 [INFO] exp_shallowmodel: train time: 380.548s
12/31/2017 22:24:29 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 22:24:29 [INFO] exp_shallowmodel: accuracy:   0.741
12/31/2017 22:24:29 [INFO] exp_shallowmodel: f1_score:   0.620
12/31/2017 22:24:29 [INFO] exp_shallowmodel: classification report:
12/31/2017 22:24:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.36      0.32        14
          C       0.69      0.65      0.67       164
          F       0.87      0.86      0.86       268
          R       0.60      0.65      0.63       125

avg / total       0.74      0.74      0.74       571

12/31/2017 22:24:29 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 22:24:29 [INFO] exp_shallowmodel: 
[[  5   1   6   2]
 [  1 106  18  39]
 [  6  19 231  12]
 [  5  27  12  81]]
12/31/2017 22:24:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/31/2017 22:24:29 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 22:24:29 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 22:24:29 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 22:24:29 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 22:24:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 22:24:29 [INFO] exp_shallowmodel: Training: 
12/31/2017 22:24:29 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 22:39:47 [INFO] exp_shallowmodel: train time: 918.415s
12/31/2017 22:39:47 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 22:39:47 [INFO] exp_shallowmodel: accuracy:   0.708
12/31/2017 22:39:47 [INFO] exp_shallowmodel: f1_score:   0.555
12/31/2017 22:39:47 [INFO] exp_shallowmodel: classification report:
12/31/2017 22:39:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.29      0.24        14
          C       0.61      0.66      0.63       164
          F       0.86      0.90      0.88       268
          R       0.55      0.42      0.47       125

avg / total       0.70      0.71      0.70       571

12/31/2017 22:39:47 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 22:39:47 [INFO] exp_shallowmodel: 
[[  4   0   9   1]
 [  9 108  16  31]
 [  3  15 240  10]
 [  4  55  14  52]]
12/31/2017 22:39:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/31/2017 22:39:48 [INFO] exp_shallowmodel: #(data) = 4568
12/31/2017 22:39:48 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 22:39:48 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 22:39:48 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 22:39:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 22:39:48 [INFO] exp_shallowmodel: Training: 
12/31/2017 22:39:48 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 22:54:58 [INFO] exp_shallowmodel: train time: 910.355s
12/31/2017 22:54:58 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 22:54:58 [INFO] exp_shallowmodel: accuracy:   0.701
12/31/2017 22:54:58 [INFO] exp_shallowmodel: f1_score:   0.606
12/31/2017 22:54:58 [INFO] exp_shallowmodel: classification report:
12/31/2017 22:54:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.56      0.45        16
          C       0.58      0.69      0.63       169
          F       0.87      0.85      0.86       271
          R       0.57      0.42      0.48       130

avg / total       0.71      0.70      0.70       586

12/31/2017 22:54:58 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 22:54:58 [INFO] exp_shallowmodel: 
[[  9   2   5   0]
 [  5 116  14  34]
 [  7  25 231   8]
 [  3  57  15  55]]
12/31/2017 22:54:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/31/2017 22:54:58 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 22:54:58 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 22:54:58 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 22:54:58 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 22:54:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 22:54:58 [INFO] exp_shallowmodel: Training: 
12/31/2017 22:54:58 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 23:11:27 [INFO] exp_shallowmodel: train time: 988.304s
12/31/2017 23:11:27 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 23:11:27 [INFO] exp_shallowmodel: accuracy:   0.704
12/31/2017 23:11:27 [INFO] exp_shallowmodel: f1_score:   0.612
12/31/2017 23:11:27 [INFO] exp_shallowmodel: classification report:
12/31/2017 23:11:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.43      0.43        14
          C       0.59      0.52      0.55       164
          F       0.85      0.85      0.85       268
          R       0.58      0.66      0.61       125

avg / total       0.70      0.70      0.70       571

12/31/2017 23:11:27 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 23:11:27 [INFO] exp_shallowmodel: 
[[  6   1   6   1]
 [  5  86  25  48]
 [  2  27 228  11]
 [  1  32  10  82]]
12/31/2017 23:11:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/31/2017 23:11:27 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 23:11:27 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 23:11:27 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 23:11:27 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 23:11:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 23:11:27 [INFO] exp_shallowmodel: Training: 
12/31/2017 23:11:27 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 23:25:50 [INFO] exp_shallowmodel: train time: 863.523s
12/31/2017 23:25:50 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 23:25:50 [INFO] exp_shallowmodel: accuracy:   0.657
12/31/2017 23:25:50 [INFO] exp_shallowmodel: f1_score:   0.525
12/31/2017 23:25:50 [INFO] exp_shallowmodel: classification report:
12/31/2017 23:25:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.29      0.26        14
          C       0.56      0.45      0.50       164
          F       0.87      0.85      0.86       268
          R       0.42      0.54      0.48       125

avg / total       0.67      0.66      0.66       571

12/31/2017 23:25:50 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 23:25:50 [INFO] exp_shallowmodel: 
[[  4   4   4   2]
 [  1  74  17  72]
 [  5  16 229  18]
 [  7  38  12  68]]
12/31/2017 23:25:50 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/31/2017 23:25:50 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 23:25:50 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 23:25:50 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 23:25:50 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 23:25:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 23:25:50 [INFO] exp_shallowmodel: Training: 
12/31/2017 23:25:50 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 23:34:37 [INFO] exp_shallowmodel: train time: 526.651s
12/31/2017 23:34:37 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 23:34:37 [INFO] exp_shallowmodel: accuracy:   0.711
12/31/2017 23:34:37 [INFO] exp_shallowmodel: f1_score:   0.554
12/31/2017 23:34:37 [INFO] exp_shallowmodel: classification report:
12/31/2017 23:34:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.29      0.22        14
          C       0.68      0.41      0.51       164
          F       0.90      0.93      0.92       268
          R       0.49      0.68      0.57       125

avg / total       0.73      0.71      0.71       571

12/31/2017 23:34:37 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 23:34:37 [INFO] exp_shallowmodel: 
[[  4   2   6   2]
 [  8  67  11  78]
 [  4   6 250   8]
 [  7  23  10  85]]
12/31/2017 23:34:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/31/2017 23:34:37 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 23:34:37 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 23:34:37 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 23:34:37 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 23:34:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 23:34:37 [INFO] exp_shallowmodel: Training: 
12/31/2017 23:34:37 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/31/2017 23:45:47 [INFO] exp_shallowmodel: train time: 669.481s
12/31/2017 23:45:47 [INFO] exp_shallowmodel: test time:  0.001s
12/31/2017 23:45:47 [INFO] exp_shallowmodel: accuracy:   0.701
12/31/2017 23:45:47 [INFO] exp_shallowmodel: f1_score:   0.606
12/31/2017 23:45:47 [INFO] exp_shallowmodel: classification report:
12/31/2017 23:45:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.57      0.41        14
          C       0.64      0.57      0.61       164
          F       0.89      0.83      0.86       268
          R       0.50      0.60      0.55       125

avg / total       0.72      0.70      0.71       571

12/31/2017 23:45:47 [INFO] exp_shallowmodel: confusion matrix:
12/31/2017 23:45:47 [INFO] exp_shallowmodel: 
[[  8   3   3   0]
 [  4  94  15  51]
 [  5  17 223  23]
 [  8  32  10  75]]
12/31/2017 23:45:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/31/2017 23:45:47 [INFO] exp_shallowmodel: #(data) = 4583
12/31/2017 23:45:47 [INFO] exp_shallowmodel: #(feature) = 1040
12/31/2017 23:45:47 [INFO] exp_shallowmodel: ================================================================================
12/31/2017 23:45:47 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
12/31/2017 23:45:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/31/2017 23:45:47 [INFO] exp_shallowmodel: Training: 
12/31/2017 23:45:47 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 00:01:46 [INFO] exp_shallowmodel: train time: 959.180s
01/01/2018 00:01:46 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 00:01:46 [INFO] exp_shallowmodel: accuracy:   0.723
01/01/2018 00:01:46 [INFO] exp_shallowmodel: f1_score:   0.617
01/01/2018 00:01:46 [INFO] exp_shallowmodel: classification report:
01/01/2018 00:01:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.43      0.39        14
          C       0.63      0.65      0.64       164
          F       0.89      0.85      0.87       268
          R       0.56      0.58      0.57       125

avg / total       0.73      0.72      0.73       571

01/01/2018 00:01:46 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 00:01:46 [INFO] exp_shallowmodel: 
[[  6   2   4   2]
 [  4 106  16  38]
 [  4  19 228  17]
 [  3  42   7  73]]
01/01/2018 00:01:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
01/01/2018 00:01:46 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 00:01:46 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 00:01:46 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 00:01:46 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 00:01:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 00:01:46 [INFO] exp_shallowmodel: Training: 
01/01/2018 00:01:46 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 00:13:21 [INFO] exp_shallowmodel: train time: 694.853s
01/01/2018 00:13:21 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 00:13:21 [INFO] exp_shallowmodel: accuracy:   0.692
01/01/2018 00:13:21 [INFO] exp_shallowmodel: f1_score:   0.515
01/01/2018 00:13:21 [INFO] exp_shallowmodel: classification report:
01/01/2018 00:13:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.07      0.07        14
          C       0.63      0.48      0.54       164
          F       0.86      0.87      0.86       268
          R       0.52      0.67      0.58       125

avg / total       0.70      0.69      0.69       571

01/01/2018 00:13:21 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 00:13:21 [INFO] exp_shallowmodel: 
[[  1   2   7   4]
 [  5  78  19  62]
 [  6  17 232  13]
 [  2  27  12  84]]
01/01/2018 00:13:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
01/01/2018 00:13:21 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 00:13:21 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 00:13:21 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 00:13:21 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 00:13:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 00:13:21 [INFO] exp_shallowmodel: Training: 
01/01/2018 00:13:21 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 00:31:19 [INFO] exp_shallowmodel: train time: 1077.350s
01/01/2018 00:31:19 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 00:31:19 [INFO] exp_shallowmodel: accuracy:   0.720
01/01/2018 00:31:19 [INFO] exp_shallowmodel: f1_score:   0.607
01/01/2018 00:31:19 [INFO] exp_shallowmodel: classification report:
01/01/2018 00:31:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.43      0.36        14
          C       0.67      0.57      0.62       164
          F       0.89      0.87      0.88       268
          R       0.52      0.62      0.57       125

avg / total       0.73      0.72      0.72       571

01/01/2018 00:31:19 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 00:31:19 [INFO] exp_shallowmodel: 
[[  6   0   5   3]
 [  4  93  12  55]
 [  4  15 234  15]
 [  5  30  12  78]]
01/01/2018 00:31:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
01/01/2018 00:31:19 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 00:31:19 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 00:31:19 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 00:31:19 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 00:31:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 00:31:19 [INFO] exp_shallowmodel: Training: 
01/01/2018 00:31:19 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 00:37:57 [INFO] exp_shallowmodel: train time: 397.971s
01/01/2018 00:37:57 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 00:37:57 [INFO] exp_shallowmodel: accuracy:   0.765
01/01/2018 00:37:57 [INFO] exp_shallowmodel: f1_score:   0.676
01/01/2018 00:37:57 [INFO] exp_shallowmodel: classification report:
01/01/2018 00:37:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.57      0.50        14
          C       0.65      0.70      0.67       164
          F       0.91      0.89      0.90       268
          R       0.67      0.60      0.63       125

avg / total       0.77      0.77      0.77       571

01/01/2018 00:37:57 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 00:37:57 [INFO] exp_shallowmodel: 
[[  8   3   2   1]
 [  2 115  17  30]
 [  5  18 239   6]
 [  3  41   6  75]]
01/01/2018 00:37:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
01/01/2018 00:37:57 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 00:37:57 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 00:37:57 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 00:37:57 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 00:37:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 00:37:57 [INFO] exp_shallowmodel: Training: 
01/01/2018 00:37:57 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 00:56:38 [INFO] exp_shallowmodel: train time: 1121.089s
01/01/2018 00:56:38 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 00:56:38 [INFO] exp_shallowmodel: accuracy:   0.722
01/01/2018 00:56:38 [INFO] exp_shallowmodel: f1_score:   0.596
01/01/2018 00:56:38 [INFO] exp_shallowmodel: classification report:
01/01/2018 00:56:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.36      0.37        14
          C       0.62      0.70      0.66       164
          F       0.88      0.89      0.89       268
          R       0.52      0.42      0.47       125

avg / total       0.72      0.72      0.72       571

01/01/2018 00:56:38 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 00:56:38 [INFO] exp_shallowmodel: 
[[  5   1   5   3]
 [  3 115  14  32]
 [  1  14 239  14]
 [  4  55  13  53]]
01/01/2018 00:56:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
01/01/2018 00:56:38 [INFO] exp_shallowmodel: #(data) = 4568
01/01/2018 00:56:38 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 00:56:38 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 00:56:38 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 00:56:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 00:56:38 [INFO] exp_shallowmodel: Training: 
01/01/2018 00:56:38 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 01:13:39 [INFO] exp_shallowmodel: train time: 1020.573s
01/01/2018 01:13:39 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 01:13:39 [INFO] exp_shallowmodel: accuracy:   0.683
01/01/2018 01:13:39 [INFO] exp_shallowmodel: f1_score:   0.588
01/01/2018 01:13:39 [INFO] exp_shallowmodel: classification report:
01/01/2018 01:13:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.44      0.39        16
          C       0.57      0.60      0.58       169
          F       0.87      0.82      0.84       271
          R       0.53      0.55      0.54       130

avg / total       0.69      0.68      0.69       586

01/01/2018 01:13:39 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 01:13:39 [INFO] exp_shallowmodel: 
[[  7   3   5   1]
 [  3 101  21  44]
 [  6  26 221  18]
 [  4  47   8  71]]
01/01/2018 01:13:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
01/01/2018 01:13:39 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 01:13:39 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 01:13:39 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 01:13:39 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 01:13:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 01:13:39 [INFO] exp_shallowmodel: Training: 
01/01/2018 01:13:39 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 01:28:02 [INFO] exp_shallowmodel: train time: 863.122s
01/01/2018 01:28:02 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 01:28:02 [INFO] exp_shallowmodel: accuracy:   0.743
01/01/2018 01:28:02 [INFO] exp_shallowmodel: f1_score:   0.624
01/01/2018 01:28:02 [INFO] exp_shallowmodel: classification report:
01/01/2018 01:28:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.43      0.39        14
          C       0.64      0.74      0.69       164
          F       0.90      0.88      0.89       268
          R       0.61      0.48      0.54       125

avg / total       0.74      0.74      0.74       571

01/01/2018 01:28:02 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 01:28:02 [INFO] exp_shallowmodel: 
[[  6   4   2   2]
 [  4 122  12  26]
 [  3  18 236  11]
 [  4  48  13  60]]
01/01/2018 01:28:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
01/01/2018 01:28:03 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 01:28:03 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 01:28:03 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 01:28:03 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 01:28:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 01:28:03 [INFO] exp_shallowmodel: Training: 
01/01/2018 01:28:03 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 01:51:01 [INFO] exp_shallowmodel: train time: 1378.123s
01/01/2018 01:51:01 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 01:51:01 [INFO] exp_shallowmodel: accuracy:   0.655
01/01/2018 01:51:01 [INFO] exp_shallowmodel: f1_score:   0.551
01/01/2018 01:51:01 [INFO] exp_shallowmodel: classification report:
01/01/2018 01:51:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.43      0.39        14
          C       0.53      0.37      0.43       164
          F       0.86      0.86      0.86       268
          R       0.45      0.62      0.52       125

avg / total       0.66      0.65      0.65       571

01/01/2018 01:51:01 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 01:51:01 [INFO] exp_shallowmodel: 
[[  6   2   5   1]
 [  3  60  17  84]
 [  3  25 230  10]
 [  5  26  16  78]]
01/01/2018 01:51:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
01/01/2018 01:51:01 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 01:51:01 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 01:51:01 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 01:51:01 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 01:51:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 01:51:01 [INFO] exp_shallowmodel: Training: 
01/01/2018 01:51:01 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 02:00:07 [INFO] exp_shallowmodel: train time: 546.359s
01/01/2018 02:00:07 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 02:00:07 [INFO] exp_shallowmodel: accuracy:   0.706
01/01/2018 02:00:07 [INFO] exp_shallowmodel: f1_score:   0.572
01/01/2018 02:00:07 [INFO] exp_shallowmodel: classification report:
01/01/2018 02:00:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.36      0.23        14
          C       0.62      0.60      0.61       164
          F       0.87      0.84      0.86       268
          R       0.60      0.59      0.60       125

avg / total       0.72      0.71      0.71       571

01/01/2018 02:00:07 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 02:00:07 [INFO] exp_shallowmodel: 
[[  5   7   1   1]
 [ 10  98  20  36]
 [  6  24 226  12]
 [  9  30  12  74]]
01/01/2018 02:00:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
01/01/2018 02:00:07 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 02:00:07 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 02:00:07 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 02:00:07 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 02:00:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 02:00:07 [INFO] exp_shallowmodel: Training: 
01/01/2018 02:00:07 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 02:13:30 [INFO] exp_shallowmodel: train time: 802.403s
01/01/2018 02:13:30 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 02:13:30 [INFO] exp_shallowmodel: accuracy:   0.748
01/01/2018 02:13:30 [INFO] exp_shallowmodel: f1_score:   0.631
01/01/2018 02:13:30 [INFO] exp_shallowmodel: classification report:
01/01/2018 02:13:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.43      0.38        14
          C       0.74      0.63      0.68       164
          F       0.86      0.91      0.88       268
          R       0.58      0.60      0.59       125

avg / total       0.75      0.75      0.75       571

01/01/2018 02:13:30 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 02:13:30 [INFO] exp_shallowmodel: 
[[  6   3   3   2]
 [  1 103  18  42]
 [  8   7 243  10]
 [  3  27  20  75]]
01/01/2018 02:13:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
01/01/2018 02:13:30 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 02:13:30 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 02:13:30 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 02:13:30 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 02:13:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 02:13:30 [INFO] exp_shallowmodel: Training: 
01/01/2018 02:13:30 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 02:24:48 [INFO] exp_shallowmodel: train time: 678.290s
01/01/2018 02:24:48 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 02:24:48 [INFO] exp_shallowmodel: accuracy:   0.750
01/01/2018 02:24:48 [INFO] exp_shallowmodel: f1_score:   0.610
01/01/2018 02:24:48 [INFO] exp_shallowmodel: classification report:
01/01/2018 02:24:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.29      0.28        14
          C       0.65      0.65      0.65       164
          F       0.90      0.90      0.90       268
          R       0.62      0.62      0.62       125

avg / total       0.75      0.75      0.75       571

01/01/2018 02:24:48 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 02:24:48 [INFO] exp_shallowmodel: 
[[  4   1   7   2]
 [  5 107  15  37]
 [  2  18 240   8]
 [  4  39   5  77]]
01/01/2018 02:24:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
01/01/2018 02:24:49 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 02:24:49 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 02:24:49 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 02:24:49 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 02:24:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 02:24:49 [INFO] exp_shallowmodel: Training: 
01/01/2018 02:24:49 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 02:37:25 [INFO] exp_shallowmodel: train time: 756.575s
01/01/2018 02:37:25 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 02:37:25 [INFO] exp_shallowmodel: accuracy:   0.695
01/01/2018 02:37:25 [INFO] exp_shallowmodel: f1_score:   0.573
01/01/2018 02:37:25 [INFO] exp_shallowmodel: classification report:
01/01/2018 02:37:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.43      0.34        14
          C       0.61      0.49      0.55       164
          F       0.86      0.90      0.88       268
          R       0.50      0.54      0.52       125

avg / total       0.70      0.70      0.69       571

01/01/2018 02:37:25 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 02:37:25 [INFO] exp_shallowmodel: 
[[  6   2   3   3]
 [  8  81  24  51]
 [  1  11 242  14]
 [  6  39  12  68]]
01/01/2018 02:37:25 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
01/01/2018 02:37:25 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 02:37:25 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 02:37:25 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 02:37:25 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 02:37:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 02:37:25 [INFO] exp_shallowmodel: Training: 
01/01/2018 02:37:25 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 02:44:20 [INFO] exp_shallowmodel: train time: 414.792s
01/01/2018 02:44:20 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 02:44:20 [INFO] exp_shallowmodel: accuracy:   0.730
01/01/2018 02:44:20 [INFO] exp_shallowmodel: f1_score:   0.624
01/01/2018 02:44:20 [INFO] exp_shallowmodel: classification report:
01/01/2018 02:44:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.43      0.36        14
          C       0.65      0.65      0.65       164
          F       0.90      0.83      0.86       268
          R       0.58      0.66      0.62       125

avg / total       0.74      0.73      0.74       571

01/01/2018 02:44:20 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 02:44:20 [INFO] exp_shallowmodel: 
[[  6   2   6   0]
 [  4 106  14  40]
 [  4  22 222  20]
 [  5  32   5  83]]
01/01/2018 02:44:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
01/01/2018 02:44:20 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 02:44:20 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 02:44:20 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 02:44:20 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 02:44:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 02:44:20 [INFO] exp_shallowmodel: Training: 
01/01/2018 02:44:20 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 02:53:20 [INFO] exp_shallowmodel: train time: 540.002s
01/01/2018 02:53:20 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 02:53:20 [INFO] exp_shallowmodel: accuracy:   0.744
01/01/2018 02:53:20 [INFO] exp_shallowmodel: f1_score:   0.621
01/01/2018 02:53:20 [INFO] exp_shallowmodel: classification report:
01/01/2018 02:53:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.36      0.33        14
          C       0.69      0.60      0.64       164
          F       0.88      0.89      0.88       268
          R       0.59      0.66      0.63       125

avg / total       0.75      0.74      0.74       571

01/01/2018 02:53:20 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 02:53:20 [INFO] exp_shallowmodel: 
[[  5   1   6   2]
 [  6  98  15  45]
 [  1  18 239  10]
 [  4  25  13  83]]
01/01/2018 02:53:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
01/01/2018 02:53:21 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 02:53:21 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 02:53:21 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 02:53:21 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 02:53:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 02:53:21 [INFO] exp_shallowmodel: Training: 
01/01/2018 02:53:21 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 03:08:23 [INFO] exp_shallowmodel: train time: 902.310s
01/01/2018 03:08:23 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 03:08:23 [INFO] exp_shallowmodel: accuracy:   0.736
01/01/2018 03:08:23 [INFO] exp_shallowmodel: f1_score:   0.618
01/01/2018 03:08:23 [INFO] exp_shallowmodel: classification report:
01/01/2018 03:08:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.29      0.33        14
          C       0.65      0.65      0.65       164
          F       0.86      0.85      0.86       268
          R       0.61      0.66      0.63       125

avg / total       0.74      0.74      0.74       571

01/01/2018 03:08:23 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 03:08:23 [INFO] exp_shallowmodel: 
[[  4   2   5   3]
 [  1 106  21  36]
 [  3  24 228  13]
 [  2  31  10  82]]
01/01/2018 03:08:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
01/01/2018 03:08:23 [INFO] exp_shallowmodel: #(data) = 4568
01/01/2018 03:08:23 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 03:08:23 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 03:08:23 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 03:08:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 03:08:23 [INFO] exp_shallowmodel: Training: 
01/01/2018 03:08:23 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 03:19:56 [INFO] exp_shallowmodel: train time: 693.411s
01/01/2018 03:19:56 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 03:19:56 [INFO] exp_shallowmodel: accuracy:   0.730
01/01/2018 03:19:56 [INFO] exp_shallowmodel: f1_score:   0.615
01/01/2018 03:19:56 [INFO] exp_shallowmodel: classification report:
01/01/2018 03:19:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.38      0.32        16
          C       0.67      0.66      0.66       169
          F       0.89      0.84      0.87       271
          R       0.57      0.64      0.60       130

avg / total       0.74      0.73      0.74       586

01/01/2018 03:19:56 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 03:19:56 [INFO] exp_shallowmodel: 
[[  6   2   5   3]
 [  8 111  12  38]
 [  4  18 228  21]
 [  3  34  10  83]]
01/01/2018 03:19:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
01/01/2018 03:19:57 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 03:19:57 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 03:19:57 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 03:19:57 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 03:19:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 03:19:57 [INFO] exp_shallowmodel: Training: 
01/01/2018 03:19:57 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 03:38:00 [INFO] exp_shallowmodel: train time: 1083.811s
01/01/2018 03:38:00 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 03:38:00 [INFO] exp_shallowmodel: accuracy:   0.722
01/01/2018 03:38:00 [INFO] exp_shallowmodel: f1_score:   0.608
01/01/2018 03:38:00 [INFO] exp_shallowmodel: classification report:
01/01/2018 03:38:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.43      0.34        14
          C       0.66      0.59      0.62       164
          F       0.91      0.85      0.88       268
          R       0.54      0.66      0.59       125

avg / total       0.74      0.72      0.73       571

01/01/2018 03:38:00 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 03:38:00 [INFO] exp_shallowmodel: 
[[  6   1   3   4]
 [  2  97  10  55]
 [  9  21 227  11]
 [  4  29  10  82]]
01/01/2018 03:38:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
01/01/2018 03:38:01 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 03:38:01 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 03:38:01 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 03:38:01 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 03:38:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 03:38:01 [INFO] exp_shallowmodel: Training: 
01/01/2018 03:38:01 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 03:50:12 [INFO] exp_shallowmodel: train time: 731.326s
01/01/2018 03:50:12 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 03:50:12 [INFO] exp_shallowmodel: accuracy:   0.683
01/01/2018 03:50:12 [INFO] exp_shallowmodel: f1_score:   0.529
01/01/2018 03:50:12 [INFO] exp_shallowmodel: classification report:
01/01/2018 03:50:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.21      0.17        14
          C       0.59      0.55      0.57       164
          F       0.90      0.86      0.88       268
          R       0.48      0.53      0.50       125

avg / total       0.70      0.68      0.69       571

01/01/2018 03:50:12 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 03:50:12 [INFO] exp_shallowmodel: 
[[  3   3   4   4]
 [  4  91  16  53]
 [ 10  13 230  15]
 [  5  48   6  66]]
01/01/2018 03:50:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
01/01/2018 03:50:12 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 03:50:12 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 03:50:12 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 03:50:12 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 03:50:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 03:50:12 [INFO] exp_shallowmodel: Training: 
01/01/2018 03:50:12 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 04:06:45 [INFO] exp_shallowmodel: train time: 993.062s
01/01/2018 04:06:45 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 04:06:45 [INFO] exp_shallowmodel: accuracy:   0.711
01/01/2018 04:06:45 [INFO] exp_shallowmodel: f1_score:   0.583
01/01/2018 04:06:45 [INFO] exp_shallowmodel: classification report:
01/01/2018 04:06:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.36      0.32        14
          C       0.64      0.51      0.56       164
          F       0.88      0.90      0.89       268
          R       0.51      0.61      0.55       125

avg / total       0.72      0.71      0.71       571

01/01/2018 04:06:45 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 04:06:45 [INFO] exp_shallowmodel: 
[[  5   1   6   2]
 [  1  83  13  67]
 [  5  17 242   4]
 [  6  29  14  76]]
01/01/2018 04:06:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
01/01/2018 04:06:45 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 04:06:45 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 04:06:45 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 04:06:45 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 04:06:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 04:06:45 [INFO] exp_shallowmodel: Training: 
01/01/2018 04:06:45 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 04:24:38 [INFO] exp_shallowmodel: train time: 1072.756s
01/01/2018 04:24:38 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 04:24:38 [INFO] exp_shallowmodel: accuracy:   0.716
01/01/2018 04:24:38 [INFO] exp_shallowmodel: f1_score:   0.631
01/01/2018 04:24:38 [INFO] exp_shallowmodel: classification report:
01/01/2018 04:24:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.64      0.47        14
          C       0.66      0.62      0.64       164
          F       0.90      0.85      0.87       268
          R       0.51      0.57      0.54       125

avg / total       0.73      0.72      0.72       571

01/01/2018 04:24:38 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 04:24:38 [INFO] exp_shallowmodel: 
[[  9   1   4   0]
 [  3 102  13  46]
 [  4  14 227  23]
 [  8  38   8  71]]
01/01/2018 04:24:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
01/01/2018 04:24:38 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 04:24:38 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 04:24:38 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 04:24:38 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 04:24:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 04:24:38 [INFO] exp_shallowmodel: Training: 
01/01/2018 04:24:38 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 04:39:39 [INFO] exp_shallowmodel: train time: 900.733s
01/01/2018 04:39:39 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 04:39:39 [INFO] exp_shallowmodel: accuracy:   0.723
01/01/2018 04:39:39 [INFO] exp_shallowmodel: f1_score:   0.559
01/01/2018 04:39:39 [INFO] exp_shallowmodel: classification report:
01/01/2018 04:39:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.14      0.16        14
          C       0.63      0.71      0.67       164
          F       0.86      0.86      0.86       268
          R       0.59      0.51      0.55       125

avg / total       0.72      0.72      0.72       571

01/01/2018 04:39:39 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 04:39:39 [INFO] exp_shallowmodel: 
[[  2   3   6   3]
 [  2 116  19  27]
 [  5  18 231  14]
 [  2  47  12  64]]
01/01/2018 04:39:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
01/01/2018 04:39:39 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 04:39:39 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 04:39:39 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 04:39:39 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 04:39:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 04:39:39 [INFO] exp_shallowmodel: Training: 
01/01/2018 04:39:39 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 04:54:18 [INFO] exp_shallowmodel: train time: 878.861s
01/01/2018 04:54:18 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 04:54:18 [INFO] exp_shallowmodel: accuracy:   0.764
01/01/2018 04:54:18 [INFO] exp_shallowmodel: f1_score:   0.642
01/01/2018 04:54:18 [INFO] exp_shallowmodel: classification report:
01/01/2018 04:54:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.50      0.35        14
          C       0.72      0.59      0.65       164
          F       0.89      0.92      0.90       268
          R       0.64      0.69      0.66       125

avg / total       0.77      0.76      0.76       571

01/01/2018 04:54:18 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 04:54:18 [INFO] exp_shallowmodel: 
[[  7   2   3   2]
 [  8  97  19  40]
 [  8   8 246   6]
 [  3  27   9  86]]
01/01/2018 04:54:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
01/01/2018 04:54:18 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 04:54:18 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 04:54:18 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 04:54:18 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 04:54:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 04:54:18 [INFO] exp_shallowmodel: Training: 
01/01/2018 04:54:18 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 05:03:17 [INFO] exp_shallowmodel: train time: 538.590s
01/01/2018 05:03:17 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 05:03:17 [INFO] exp_shallowmodel: accuracy:   0.722
01/01/2018 05:03:17 [INFO] exp_shallowmodel: f1_score:   0.617
01/01/2018 05:03:17 [INFO] exp_shallowmodel: classification report:
01/01/2018 05:03:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.57      0.41        14
          C       0.68      0.63      0.65       164
          F       0.85      0.88      0.86       268
          R       0.55      0.53      0.54       125

avg / total       0.72      0.72      0.72       571

01/01/2018 05:03:17 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 05:03:17 [INFO] exp_shallowmodel: 
[[  8   1   5   0]
 [  6 103  20  35]
 [  7   8 235  18]
 [  4  39  16  66]]
01/01/2018 05:03:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
01/01/2018 05:03:17 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 05:03:17 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 05:03:17 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 05:03:17 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 05:03:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 05:03:17 [INFO] exp_shallowmodel: Training: 
01/01/2018 05:03:17 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 05:14:00 [INFO] exp_shallowmodel: train time: 642.352s
01/01/2018 05:14:00 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 05:14:00 [INFO] exp_shallowmodel: accuracy:   0.718
01/01/2018 05:14:00 [INFO] exp_shallowmodel: f1_score:   0.598
01/01/2018 05:14:00 [INFO] exp_shallowmodel: classification report:
01/01/2018 05:14:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.43      0.35        14
          C       0.67      0.52      0.58       164
          F       0.86      0.90      0.88       268
          R       0.53      0.62      0.57       125

avg / total       0.72      0.72      0.72       571

01/01/2018 05:14:00 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 05:14:00 [INFO] exp_shallowmodel: 
[[  6   1   7   0]
 [  7  85  16  56]
 [  5  10 242  11]
 [  2  31  15  77]]
01/01/2018 05:14:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
01/01/2018 05:14:00 [INFO] exp_shallowmodel: #(data) = 4583
01/01/2018 05:14:00 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 05:14:00 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 05:14:00 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 05:14:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 05:14:00 [INFO] exp_shallowmodel: Training: 
01/01/2018 05:14:00 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 05:25:37 [INFO] exp_shallowmodel: train time: 697.503s
01/01/2018 05:25:37 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 05:25:37 [INFO] exp_shallowmodel: accuracy:   0.723
01/01/2018 05:25:37 [INFO] exp_shallowmodel: f1_score:   0.622
01/01/2018 05:25:37 [INFO] exp_shallowmodel: classification report:
01/01/2018 05:25:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.57      0.44        14
          C       0.62      0.73      0.67       164
          F       0.89      0.86      0.87       268
          R       0.57      0.45      0.50       125

avg / total       0.73      0.72      0.72       571

01/01/2018 05:25:37 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 05:25:37 [INFO] exp_shallowmodel: 
[[  8   2   4   0]
 [  8 119   9  28]
 [  4  19 230  15]
 [  2  52  15  56]]
01/01/2018 05:25:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
01/01/2018 05:25:37 [INFO] exp_shallowmodel: #(data) = 4568
01/01/2018 05:25:37 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 05:25:37 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 05:25:37 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 05:25:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 05:25:37 [INFO] exp_shallowmodel: Training: 
01/01/2018 05:25:37 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 05:38:41 [INFO] exp_shallowmodel: train time: 783.756s
01/01/2018 05:38:41 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 05:38:41 [INFO] exp_shallowmodel: accuracy:   0.679
01/01/2018 05:38:41 [INFO] exp_shallowmodel: f1_score:   0.500
01/01/2018 05:38:41 [INFO] exp_shallowmodel: classification report:
01/01/2018 05:38:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.06      0.07        16
          C       0.63      0.44      0.52       169
          F       0.81      0.89      0.85       271
          R       0.51      0.62      0.56       130

avg / total       0.67      0.68      0.67       586

01/01/2018 05:38:41 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 05:38:41 [INFO] exp_shallowmodel: 
[[  1   1  12   2]
 [  5  75  25  64]
 [  5  13 242  11]
 [  2  30  18  80]]
01/01/2018 05:38:45 [INFO] exp_shallowmodel: 1	3

01/01/2018 05:38:45 [INFO] exp_shallowmodel: 2.1	46

01/01/2018 05:38:45 [INFO] exp_shallowmodel: 2.2	2

01/01/2018 05:38:45 [INFO] exp_shallowmodel: 2.3.1	1

01/01/2018 05:38:45 [INFO] exp_shallowmodel: 3	5

01/01/2018 05:38:45 [INFO] exp_shallowmodel: 5	2624

01/01/2018 05:38:45 [INFO] exp_shallowmodel: 6	487

01/01/2018 05:38:45 [INFO] exp_shallowmodel: 7	1130

01/01/2018 05:38:45 [INFO] exp_shallowmodel: 9.1	900

01/01/2018 05:38:45 [INFO] exp_shallowmodel: 9.2.1	1

01/01/2018 05:38:45 [INFO] exp_shallowmodel: 9.3.1	1

01/01/2018 05:38:46 [INFO] exp_shallowmodel: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
01/01/2018 05:38:46 [INFO] exp_shallowmodel:           dataset=dstc3
01/01/2018 05:38:46 [INFO] exp_shallowmodel:           k_feature_to_keep=7
01/01/2018 05:38:46 [INFO] exp_shallowmodel:           X_new.shape=(5934, 1040)
01/01/2018 05:38:46 [INFO] exp_shallowmodel:           #(X_selected)=128
01/01/2018 05:38:46 [INFO] exp_shallowmodel:           #(X_not_selectable)=912
01/01/2018 05:38:46 [INFO] exp_shallowmodel: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
01/01/2018 05:38:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
01/01/2018 05:38:46 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 05:38:46 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 05:38:46 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 05:38:46 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 05:38:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 05:38:46 [INFO] exp_shallowmodel: Training: 
01/01/2018 05:38:46 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 05:54:35 [INFO] exp_shallowmodel: train time: 948.978s
01/01/2018 05:54:35 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 05:54:35 [INFO] exp_shallowmodel: accuracy:   0.657
01/01/2018 05:54:35 [INFO] exp_shallowmodel: f1_score:   0.553
01/01/2018 05:54:35 [INFO] exp_shallowmodel: classification report:
01/01/2018 05:54:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.55      0.39        20
          C       0.64      0.46      0.53       169
          F       0.86      0.86      0.86       281
          R       0.38      0.48      0.43       122

avg / total       0.68      0.66      0.66       592

01/01/2018 05:54:35 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 05:54:35 [INFO] exp_shallowmodel: 
[[ 11   0   6   3]
 [ 14  77  10  68]
 [  2  13 242  24]
 [  9  31  23  59]]
01/01/2018 05:54:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
01/01/2018 05:54:35 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 05:54:35 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 05:54:35 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 05:54:35 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 05:54:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 05:54:35 [INFO] exp_shallowmodel: Training: 
01/01/2018 05:54:35 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 06:14:25 [INFO] exp_shallowmodel: train time: 1189.802s
01/01/2018 06:14:25 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 06:14:25 [INFO] exp_shallowmodel: accuracy:   0.640
01/01/2018 06:14:25 [INFO] exp_shallowmodel: f1_score:   0.540
01/01/2018 06:14:25 [INFO] exp_shallowmodel: classification report:
01/01/2018 06:14:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.50      0.37        20
          C       0.63      0.66      0.65       169
          F       0.87      0.77      0.81       281
          R       0.32      0.34      0.33       122

avg / total       0.67      0.64      0.65       592

01/01/2018 06:14:25 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 06:14:25 [INFO] exp_shallowmodel: 
[[ 10   3   3   4]
 [  9 112  11  37]
 [  7  10 215  49]
 [  8  53  19  42]]
01/01/2018 06:14:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
01/01/2018 06:14:25 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 06:14:25 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 06:14:25 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 06:14:25 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 06:14:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 06:14:25 [INFO] exp_shallowmodel: Training: 
01/01/2018 06:14:25 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 06:26:28 [INFO] exp_shallowmodel: train time: 723.373s
01/01/2018 06:26:28 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 06:26:28 [INFO] exp_shallowmodel: accuracy:   0.647
01/01/2018 06:26:28 [INFO] exp_shallowmodel: f1_score:   0.541
01/01/2018 06:26:28 [INFO] exp_shallowmodel: classification report:
01/01/2018 06:26:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.40      0.32        20
          C       0.55      0.63      0.58       169
          F       0.91      0.76      0.83       281
          R       0.42      0.45      0.43       122

avg / total       0.68      0.65      0.66       592

01/01/2018 06:26:28 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 06:26:28 [INFO] exp_shallowmodel: 
[[  8   4   4   4]
 [  6 106   6  51]
 [  9  36 214  22]
 [  7  48  12  55]]
01/01/2018 06:26:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
01/01/2018 06:26:29 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 06:26:29 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 06:26:29 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 06:26:29 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 06:26:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 06:26:29 [INFO] exp_shallowmodel: Training: 
01/01/2018 06:26:29 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 06:38:32 [INFO] exp_shallowmodel: train time: 723.361s
01/01/2018 06:38:32 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 06:38:32 [INFO] exp_shallowmodel: accuracy:   0.699
01/01/2018 06:38:32 [INFO] exp_shallowmodel: f1_score:   0.560
01/01/2018 06:38:32 [INFO] exp_shallowmodel: classification report:
01/01/2018 06:38:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.30      0.27        20
          C       0.62      0.58      0.60       169
          F       0.88      0.89      0.89       281
          R       0.47      0.49      0.48       122

avg / total       0.70      0.70      0.70       592

01/01/2018 06:38:32 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 06:38:32 [INFO] exp_shallowmodel: 
[[  6   7   2   5]
 [  8  98  13  50]
 [  7  11 250  13]
 [  3  41  18  60]]
01/01/2018 06:38:32 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
01/01/2018 06:38:32 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 06:38:32 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 06:38:32 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 06:38:32 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 06:38:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 06:38:32 [INFO] exp_shallowmodel: Training: 
01/01/2018 06:38:32 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 06:46:20 [INFO] exp_shallowmodel: train time: 467.891s
01/01/2018 06:46:20 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 06:46:20 [INFO] exp_shallowmodel: accuracy:   0.672
01/01/2018 06:46:20 [INFO] exp_shallowmodel: f1_score:   0.560
01/01/2018 06:46:20 [INFO] exp_shallowmodel: classification report:
01/01/2018 06:46:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.40      0.37        20
          C       0.63      0.44      0.52       169
          F       0.85      0.88      0.87       281
          R       0.43      0.57      0.49       122

avg / total       0.68      0.67      0.67       592

01/01/2018 06:46:20 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 06:46:20 [INFO] exp_shallowmodel: 
[[  8   2   9   1]
 [  5  74  13  77]
 [  9  10 247  15]
 [  1  32  20  69]]
01/01/2018 06:46:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
01/01/2018 06:46:20 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 06:46:20 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 06:46:20 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 06:46:20 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 06:46:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 06:46:20 [INFO] exp_shallowmodel: Training: 
01/01/2018 06:46:20 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 07:01:55 [INFO] exp_shallowmodel: train time: 934.801s
01/01/2018 07:01:55 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 07:01:55 [INFO] exp_shallowmodel: accuracy:   0.679
01/01/2018 07:01:55 [INFO] exp_shallowmodel: f1_score:   0.552
01/01/2018 07:01:55 [INFO] exp_shallowmodel: classification report:
01/01/2018 07:01:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.40      0.29        20
          C       0.65      0.68      0.66       169
          F       0.88      0.82      0.85       281
          R       0.41      0.39      0.40       122

avg / total       0.69      0.68      0.69       592

01/01/2018 07:01:55 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 07:01:55 [INFO] exp_shallowmodel: 
[[  8   3   5   4]
 [  5 115  11  38]
 [ 15   8 231  27]
 [  7  51  16  48]]
01/01/2018 07:01:55 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
01/01/2018 07:01:55 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 07:01:55 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 07:01:55 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 07:01:55 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 07:01:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 07:01:55 [INFO] exp_shallowmodel: Training: 
01/01/2018 07:01:55 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 07:16:36 [INFO] exp_shallowmodel: train time: 880.486s
01/01/2018 07:16:36 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 07:16:36 [INFO] exp_shallowmodel: accuracy:   0.681
01/01/2018 07:16:36 [INFO] exp_shallowmodel: f1_score:   0.579
01/01/2018 07:16:36 [INFO] exp_shallowmodel: classification report:
01/01/2018 07:16:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.45      0.44        20
          C       0.68      0.45      0.54       169
          F       0.85      0.90      0.87       281
          R       0.41      0.54      0.46       122

avg / total       0.69      0.68      0.68       592

01/01/2018 07:16:36 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 07:16:36 [INFO] exp_shallowmodel: 
[[  9   1   7   3]
 [  5  76  15  73]
 [  2   7 252  20]
 [  5  28  23  66]]
01/01/2018 07:16:36 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
01/01/2018 07:16:36 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 07:16:36 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 07:16:36 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 07:16:36 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 07:16:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 07:16:36 [INFO] exp_shallowmodel: Training: 
01/01/2018 07:16:36 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 07:30:19 [INFO] exp_shallowmodel: train time: 823.485s
01/01/2018 07:30:19 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 07:30:19 [INFO] exp_shallowmodel: accuracy:   0.647
01/01/2018 07:30:19 [INFO] exp_shallowmodel: f1_score:   0.551
01/01/2018 07:30:19 [INFO] exp_shallowmodel: classification report:
01/01/2018 07:30:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.45      0.32        20
          C       0.63      0.62      0.62       169
          F       0.87      0.73      0.79       281
          R       0.42      0.53      0.47       122

avg / total       0.69      0.65      0.66       592

01/01/2018 07:30:19 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 07:30:19 [INFO] exp_shallowmodel: 
[[  9   2   6   3]
 [  9 105  12  43]
 [ 13  21 204  43]
 [  6  39  12  65]]
01/01/2018 07:30:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
01/01/2018 07:30:20 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 07:30:20 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 07:30:20 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 07:30:20 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 07:30:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 07:30:20 [INFO] exp_shallowmodel: Training: 
01/01/2018 07:30:20 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 07:42:17 [INFO] exp_shallowmodel: train time: 717.458s
01/01/2018 07:42:17 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 07:42:17 [INFO] exp_shallowmodel: accuracy:   0.659
01/01/2018 07:42:17 [INFO] exp_shallowmodel: f1_score:   0.555
01/01/2018 07:42:17 [INFO] exp_shallowmodel: classification report:
01/01/2018 07:42:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.45      0.32        20
          C       0.63      0.57      0.60       169
          F       0.89      0.78      0.83       281
          R       0.42      0.53      0.47       122

avg / total       0.70      0.66      0.67       592

01/01/2018 07:42:17 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 07:42:17 [INFO] exp_shallowmodel: 
[[  9   3   6   2]
 [  6  97   9  57]
 [ 14  16 219  32]
 [  7  37  13  65]]
01/01/2018 07:42:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
01/01/2018 07:42:17 [INFO] exp_shallowmodel: #(data) = 4736
01/01/2018 07:42:17 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 07:42:17 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 07:42:17 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 07:42:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 07:42:17 [INFO] exp_shallowmodel: Training: 
01/01/2018 07:42:17 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 07:59:12 [INFO] exp_shallowmodel: train time: 1014.736s
01/01/2018 07:59:12 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 07:59:12 [INFO] exp_shallowmodel: accuracy:   0.696
01/01/2018 07:59:12 [INFO] exp_shallowmodel: f1_score:   0.588
01/01/2018 07:59:12 [INFO] exp_shallowmodel: classification report:
01/01/2018 07:59:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.36      0.36        28
          C       0.66      0.60      0.63       172
          F       0.89      0.86      0.87       283
          R       0.44      0.54      0.48       123

avg / total       0.71      0.70      0.70       606

01/01/2018 07:59:12 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 07:59:12 [INFO] exp_shallowmodel: 
[[ 10   5   5   8]
 [  7 104  11  50]
 [  7   8 242  26]
 [  3  40  14  66]]
01/01/2018 07:59:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
01/01/2018 07:59:12 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 07:59:12 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 07:59:12 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 07:59:12 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 07:59:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 07:59:12 [INFO] exp_shallowmodel: Training: 
01/01/2018 07:59:12 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 08:14:53 [INFO] exp_shallowmodel: train time: 940.811s
01/01/2018 08:14:53 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 08:14:53 [INFO] exp_shallowmodel: accuracy:   0.677
01/01/2018 08:14:53 [INFO] exp_shallowmodel: f1_score:   0.564
01/01/2018 08:14:53 [INFO] exp_shallowmodel: classification report:
01/01/2018 08:14:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.35      0.36        20
          C       0.60      0.59      0.59       169
          F       0.87      0.84      0.86       281
          R       0.43      0.47      0.45       122

avg / total       0.68      0.68      0.68       592

01/01/2018 08:14:53 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 08:14:53 [INFO] exp_shallowmodel: 
[[  7   6   7   0]
 [  4 100  15  50]
 [  5  14 237  25]
 [  3  48  14  57]]
01/01/2018 08:14:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
01/01/2018 08:14:53 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 08:14:53 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 08:14:53 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 08:14:53 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 08:14:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 08:14:53 [INFO] exp_shallowmodel: Training: 
01/01/2018 08:14:53 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 08:28:25 [INFO] exp_shallowmodel: train time: 811.670s
01/01/2018 08:28:25 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 08:28:25 [INFO] exp_shallowmodel: accuracy:   0.686
01/01/2018 08:28:25 [INFO] exp_shallowmodel: f1_score:   0.574
01/01/2018 08:28:25 [INFO] exp_shallowmodel: classification report:
01/01/2018 08:28:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.40      0.34        20
          C       0.63      0.59      0.61       169
          F       0.89      0.83      0.86       281
          R       0.45      0.53      0.49       122

avg / total       0.70      0.69      0.69       592

01/01/2018 08:28:25 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 08:28:25 [INFO] exp_shallowmodel: 
[[  8   6   5   1]
 [  8 100  13  48]
 [  6  13 233  29]
 [  5  40  12  65]]
01/01/2018 08:28:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
01/01/2018 08:28:25 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 08:28:25 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 08:28:25 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 08:28:25 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 08:28:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 08:28:25 [INFO] exp_shallowmodel: Training: 
01/01/2018 08:28:25 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 08:50:26 [INFO] exp_shallowmodel: train time: 1320.566s
01/01/2018 08:50:26 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 08:50:26 [INFO] exp_shallowmodel: accuracy:   0.716
01/01/2018 08:50:26 [INFO] exp_shallowmodel: f1_score:   0.614
01/01/2018 08:50:26 [INFO] exp_shallowmodel: classification report:
01/01/2018 08:50:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.53      0.45      0.49        20
          C       0.65      0.69      0.67       169
          F       0.89      0.89      0.89       281
          R       0.43      0.40      0.42       122

avg / total       0.71      0.72      0.71       592

01/01/2018 08:50:26 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 08:50:26 [INFO] exp_shallowmodel: 
[[  9   2   6   3]
 [  4 116   6  43]
 [  1  11 250  19]
 [  3  50  20  49]]
01/01/2018 08:50:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
01/01/2018 08:50:26 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 08:50:26 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 08:50:26 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 08:50:26 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 08:50:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 08:50:26 [INFO] exp_shallowmodel: Training: 
01/01/2018 08:50:26 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 09:08:40 [INFO] exp_shallowmodel: train time: 1093.918s
01/01/2018 09:08:40 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 09:08:40 [INFO] exp_shallowmodel: accuracy:   0.672
01/01/2018 09:08:40 [INFO] exp_shallowmodel: f1_score:   0.549
01/01/2018 09:08:40 [INFO] exp_shallowmodel: classification report:
01/01/2018 09:08:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.35      0.29        20
          C       0.64      0.66      0.65       169
          F       0.88      0.80      0.84       281
          R       0.40      0.43      0.42       122

avg / total       0.69      0.67      0.68       592

01/01/2018 09:08:40 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 09:08:40 [INFO] exp_shallowmodel: 
[[  7   2   4   7]
 [  7 112  11  39]
 [ 10  13 226  32]
 [  5  47  17  53]]
01/01/2018 09:08:40 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
01/01/2018 09:08:40 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 09:08:40 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 09:08:40 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 09:08:40 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 09:08:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 09:08:40 [INFO] exp_shallowmodel: Training: 
01/01/2018 09:08:40 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 09:26:51 [INFO] exp_shallowmodel: train time: 1091.402s
01/01/2018 09:26:51 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 09:26:51 [INFO] exp_shallowmodel: accuracy:   0.664
01/01/2018 09:26:51 [INFO] exp_shallowmodel: f1_score:   0.532
01/01/2018 09:26:51 [INFO] exp_shallowmodel: classification report:
01/01/2018 09:26:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.25      0.21        20
          C       0.65      0.63      0.64       169
          F       0.85      0.79      0.82       281
          R       0.43      0.50      0.46       122

avg / total       0.69      0.66      0.67       592

01/01/2018 09:26:51 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 09:26:51 [INFO] exp_shallowmodel: 
[[  5   2  11   2]
 [ 10 106  11  42]
 [  8  15 221  37]
 [  5  40  16  61]]
01/01/2018 09:26:52 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
01/01/2018 09:26:52 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 09:26:52 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 09:26:52 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 09:26:52 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 09:26:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 09:26:52 [INFO] exp_shallowmodel: Training: 
01/01/2018 09:26:52 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 09:45:36 [INFO] exp_shallowmodel: train time: 1124.341s
01/01/2018 09:45:36 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 09:45:36 [INFO] exp_shallowmodel: accuracy:   0.671
01/01/2018 09:45:36 [INFO] exp_shallowmodel: f1_score:   0.542
01/01/2018 09:45:36 [INFO] exp_shallowmodel: classification report:
01/01/2018 09:45:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.25      0.23        20
          C       0.65      0.62      0.63       169
          F       0.87      0.79      0.83       281
          R       0.43      0.53      0.48       122

avg / total       0.69      0.67      0.68       592

01/01/2018 09:45:36 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 09:45:36 [INFO] exp_shallowmodel: 
[[  5   2   7   6]
 [  9 105  13  42]
 [  8  14 222  37]
 [  2  41  14  65]]
01/01/2018 09:45:36 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
01/01/2018 09:45:36 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 09:45:36 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 09:45:36 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 09:45:36 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 09:45:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 09:45:36 [INFO] exp_shallowmodel: Training: 
01/01/2018 09:45:36 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 10:04:35 [INFO] exp_shallowmodel: train time: 1138.582s
01/01/2018 10:04:35 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 10:04:35 [INFO] exp_shallowmodel: accuracy:   0.590
01/01/2018 10:04:35 [INFO] exp_shallowmodel: f1_score:   0.514
01/01/2018 10:04:35 [INFO] exp_shallowmodel: classification report:
01/01/2018 10:04:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.45      0.35        20
          C       0.53      0.47      0.50       169
          F       0.87      0.68      0.76       281
          R       0.37      0.57      0.45       122

avg / total       0.65      0.59      0.61       592

01/01/2018 10:04:35 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 10:04:35 [INFO] exp_shallowmodel: 
[[  9   3   7   1]
 [  5  80  14  70]
 [ 17  24 190  50]
 [  1  44   7  70]]
01/01/2018 10:04:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
01/01/2018 10:04:35 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 10:04:35 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 10:04:35 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 10:04:35 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 10:04:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 10:04:35 [INFO] exp_shallowmodel: Training: 
01/01/2018 10:04:35 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 10:27:26 [INFO] exp_shallowmodel: train time: 1371.236s
01/01/2018 10:27:26 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 10:27:26 [INFO] exp_shallowmodel: accuracy:   0.628
01/01/2018 10:27:26 [INFO] exp_shallowmodel: f1_score:   0.520
01/01/2018 10:27:26 [INFO] exp_shallowmodel: classification report:
01/01/2018 10:27:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.40      0.33        20
          C       0.59      0.45      0.51       169
          F       0.84      0.82      0.83       281
          R       0.36      0.47      0.40       122

avg / total       0.65      0.63      0.63       592

01/01/2018 10:27:26 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 10:27:26 [INFO] exp_shallowmodel: 
[[  8   3   8   1]
 [  9  76  11  73]
 [  7  14 231  29]
 [  4  35  26  57]]
01/01/2018 10:27:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
01/01/2018 10:27:26 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 10:27:26 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 10:27:26 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 10:27:26 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 10:27:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 10:27:26 [INFO] exp_shallowmodel: Training: 
01/01/2018 10:27:26 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 10:44:16 [INFO] exp_shallowmodel: train time: 1009.134s
01/01/2018 10:44:16 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 10:44:16 [INFO] exp_shallowmodel: accuracy:   0.693
01/01/2018 10:44:16 [INFO] exp_shallowmodel: f1_score:   0.585
01/01/2018 10:44:16 [INFO] exp_shallowmodel: classification report:
01/01/2018 10:44:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.45      0.38        20
          C       0.63      0.67      0.65       169
          F       0.87      0.83      0.85       281
          R       0.47      0.45      0.46       122

avg / total       0.70      0.69      0.70       592

01/01/2018 10:44:16 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 10:44:16 [INFO] exp_shallowmodel: 
[[  9   7   2   2]
 [ 10 113  12  34]
 [  6  16 233  26]
 [  2  43  22  55]]
01/01/2018 10:44:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
01/01/2018 10:44:16 [INFO] exp_shallowmodel: #(data) = 4736
01/01/2018 10:44:16 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 10:44:16 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 10:44:16 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 10:44:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 10:44:16 [INFO] exp_shallowmodel: Training: 
01/01/2018 10:44:16 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 11:01:42 [INFO] exp_shallowmodel: train time: 1045.851s
01/01/2018 11:01:42 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 11:01:42 [INFO] exp_shallowmodel: accuracy:   0.653
01/01/2018 11:01:42 [INFO] exp_shallowmodel: f1_score:   0.571
01/01/2018 11:01:42 [INFO] exp_shallowmodel: classification report:
01/01/2018 11:01:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.46      0.46        28
          C       0.60      0.36      0.45       172
          F       0.88      0.83      0.85       283
          R       0.42      0.70      0.52       123

avg / total       0.69      0.65      0.65       606

01/01/2018 11:01:42 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 11:01:42 [INFO] exp_shallowmodel: 
[[ 13   5   5   5]
 [  6  62  14  90]
 [  7  15 235  26]
 [  3  21  13  86]]
01/01/2018 11:01:42 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
01/01/2018 11:01:42 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 11:01:42 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 11:01:42 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 11:01:42 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 11:01:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 11:01:42 [INFO] exp_shallowmodel: Training: 
01/01/2018 11:01:42 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 11:18:06 [INFO] exp_shallowmodel: train time: 984.140s
01/01/2018 11:18:06 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 11:18:06 [INFO] exp_shallowmodel: accuracy:   0.704
01/01/2018 11:18:06 [INFO] exp_shallowmodel: f1_score:   0.606
01/01/2018 11:18:06 [INFO] exp_shallowmodel: classification report:
01/01/2018 11:18:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.55      0.46        20
          C       0.62      0.61      0.62       169
          F       0.87      0.88      0.87       281
          R       0.49      0.47      0.48       122

avg / total       0.71      0.70      0.70       592

01/01/2018 11:18:06 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 11:18:06 [INFO] exp_shallowmodel: 
[[ 11   2   7   0]
 [  8 103  14  44]
 [  6  13 246  16]
 [  3  47  15  57]]
01/01/2018 11:18:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
01/01/2018 11:18:06 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 11:18:06 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 11:18:06 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 11:18:06 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 11:18:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 11:18:06 [INFO] exp_shallowmodel: Training: 
01/01/2018 11:18:06 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 11:27:52 [INFO] exp_shallowmodel: train time: 586.244s
01/01/2018 11:27:52 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 11:27:52 [INFO] exp_shallowmodel: accuracy:   0.698
01/01/2018 11:27:52 [INFO] exp_shallowmodel: f1_score:   0.571
01/01/2018 11:27:52 [INFO] exp_shallowmodel: classification report:
01/01/2018 11:27:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.30      0.29        20
          C       0.72      0.68      0.70       169
          F       0.84      0.83      0.83       281
          R       0.44      0.48      0.46       122

avg / total       0.70      0.70      0.70       592

01/01/2018 11:27:52 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 11:27:52 [INFO] exp_shallowmodel: 
[[  6   2  10   2]
 [  5 115  15  34]
 [  6   4 233  38]
 [  5  38  20  59]]
01/01/2018 11:27:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
01/01/2018 11:27:53 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 11:27:53 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 11:27:53 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 11:27:53 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 11:27:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 11:27:53 [INFO] exp_shallowmodel: Training: 
01/01/2018 11:27:53 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 11:46:30 [INFO] exp_shallowmodel: train time: 1117.487s
01/01/2018 11:46:30 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 11:46:30 [INFO] exp_shallowmodel: accuracy:   0.642
01/01/2018 11:46:30 [INFO] exp_shallowmodel: f1_score:   0.512
01/01/2018 11:46:30 [INFO] exp_shallowmodel: classification report:
01/01/2018 11:46:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.25      0.22        20
          C       0.61      0.51      0.56       169
          F       0.85      0.80      0.82       281
          R       0.40      0.52      0.45       122

avg / total       0.67      0.64      0.65       592

01/01/2018 11:46:30 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 11:46:30 [INFO] exp_shallowmodel: 
[[  5   7   6   2]
 [  7  87  19  56]
 [  5  14 225  37]
 [  9  34  16  63]]
01/01/2018 11:46:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
01/01/2018 11:46:30 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 11:46:30 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 11:46:30 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 11:46:30 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 11:46:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 11:46:30 [INFO] exp_shallowmodel: Training: 
01/01/2018 11:46:30 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 11:59:44 [INFO] exp_shallowmodel: train time: 793.759s
01/01/2018 11:59:44 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 11:59:44 [INFO] exp_shallowmodel: accuracy:   0.677
01/01/2018 11:59:44 [INFO] exp_shallowmodel: f1_score:   0.598
01/01/2018 11:59:44 [INFO] exp_shallowmodel: classification report:
01/01/2018 11:59:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.50      0.43        20
          C       0.63      0.63      0.63       169
          F       0.90      0.76      0.82       281
          R       0.44      0.58      0.50       122

avg / total       0.71      0.68      0.69       592

01/01/2018 11:59:44 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 11:59:44 [INFO] exp_shallowmodel: 
[[ 10   3   4   3]
 [  5 106   8  50]
 [  7  23 214  37]
 [  4  35  12  71]]
01/01/2018 11:59:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
01/01/2018 11:59:44 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 11:59:44 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 11:59:44 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 11:59:44 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 11:59:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 11:59:44 [INFO] exp_shallowmodel: Training: 
01/01/2018 11:59:44 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 12:16:57 [INFO] exp_shallowmodel: train time: 1033.053s
01/01/2018 12:16:57 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 12:16:57 [INFO] exp_shallowmodel: accuracy:   0.637
01/01/2018 12:16:57 [INFO] exp_shallowmodel: f1_score:   0.532
01/01/2018 12:16:57 [INFO] exp_shallowmodel: classification report:
01/01/2018 12:16:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.45      0.35        20
          C       0.60      0.64      0.62       169
          F       0.87      0.77      0.82       281
          R       0.32      0.34      0.33       122

avg / total       0.66      0.64      0.65       592

01/01/2018 12:16:57 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 12:16:57 [INFO] exp_shallowmodel: 
[[  9   4   6   1]
 [ 11 109  11  38]
 [  8   7 217  49]
 [  3  62  15  42]]
01/01/2018 12:16:58 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
01/01/2018 12:16:58 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 12:16:58 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 12:16:58 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 12:16:58 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 12:16:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 12:16:58 [INFO] exp_shallowmodel: Training: 
01/01/2018 12:16:58 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 12:35:03 [INFO] exp_shallowmodel: train time: 1085.910s
01/01/2018 12:35:03 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 12:35:03 [INFO] exp_shallowmodel: accuracy:   0.655
01/01/2018 12:35:03 [INFO] exp_shallowmodel: f1_score:   0.532
01/01/2018 12:35:03 [INFO] exp_shallowmodel: classification report:
01/01/2018 12:35:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.30      0.26        20
          C       0.60      0.59      0.60       169
          F       0.88      0.80      0.84       281
          R       0.40      0.48      0.43       122

avg / total       0.68      0.66      0.67       592

01/01/2018 12:35:03 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 12:35:03 [INFO] exp_shallowmodel: 
[[  6   4   7   3]
 [  8 100  14  47]
 [  9  11 224  37]
 [  3  51  10  58]]
01/01/2018 12:35:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
01/01/2018 12:35:04 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 12:35:04 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 12:35:04 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 12:35:04 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 12:35:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 12:35:04 [INFO] exp_shallowmodel: Training: 
01/01/2018 12:35:04 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 12:46:02 [INFO] exp_shallowmodel: train time: 658.723s
01/01/2018 12:46:02 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 12:46:02 [INFO] exp_shallowmodel: accuracy:   0.627
01/01/2018 12:46:02 [INFO] exp_shallowmodel: f1_score:   0.501
01/01/2018 12:46:02 [INFO] exp_shallowmodel: classification report:
01/01/2018 12:46:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.25      0.23        20
          C       0.57      0.47      0.52       169
          F       0.86      0.80      0.83       281
          R       0.37      0.51      0.43       122

avg / total       0.65      0.63      0.64       592

01/01/2018 12:46:02 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 12:46:02 [INFO] exp_shallowmodel: 
[[  5   6   8   1]
 [  6  80   8  75]
 [  8  20 224  29]
 [  4  35  21  62]]
01/01/2018 12:46:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
01/01/2018 12:46:03 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 12:46:03 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 12:46:03 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 12:46:03 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 12:46:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 12:46:03 [INFO] exp_shallowmodel: Training: 
01/01/2018 12:46:03 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 12:59:08 [INFO] exp_shallowmodel: train time: 785.704s
01/01/2018 12:59:08 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 12:59:08 [INFO] exp_shallowmodel: accuracy:   0.699
01/01/2018 12:59:08 [INFO] exp_shallowmodel: f1_score:   0.605
01/01/2018 12:59:08 [INFO] exp_shallowmodel: classification report:
01/01/2018 12:59:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.50      0.43        20
          C       0.63      0.64      0.64       169
          F       0.92      0.82      0.86       281
          R       0.46      0.53      0.50       122

avg / total       0.72      0.70      0.71       592

01/01/2018 12:59:08 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 12:59:08 [INFO] exp_shallowmodel: 
[[ 10   5   2   3]
 [  5 109   6  49]
 [  8  20 230  23]
 [  4  40  13  65]]
01/01/2018 12:59:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
01/01/2018 12:59:09 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 12:59:09 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 12:59:09 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 12:59:09 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 12:59:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 12:59:09 [INFO] exp_shallowmodel: Training: 
01/01/2018 12:59:09 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 13:18:53 [INFO] exp_shallowmodel: train time: 1184.529s
01/01/2018 13:18:53 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 13:18:53 [INFO] exp_shallowmodel: accuracy:   0.618
01/01/2018 13:18:53 [INFO] exp_shallowmodel: f1_score:   0.482
01/01/2018 13:18:53 [INFO] exp_shallowmodel: classification report:
01/01/2018 13:18:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.20      0.19        20
          C       0.58      0.40      0.47       169
          F       0.87      0.81      0.84       281
          R       0.35      0.55      0.43       122

avg / total       0.65      0.62      0.63       592

01/01/2018 13:18:53 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 13:18:53 [INFO] exp_shallowmodel: 
[[  4   3   9   4]
 [  7  68   6  88]
 [  9  15 227  30]
 [  3  32  20  67]]
01/01/2018 13:18:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
01/01/2018 13:18:53 [INFO] exp_shallowmodel: #(data) = 4736
01/01/2018 13:18:53 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 13:18:53 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 13:18:53 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 13:18:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 13:18:53 [INFO] exp_shallowmodel: Training: 
01/01/2018 13:18:53 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 13:37:18 [INFO] exp_shallowmodel: train time: 1104.425s
01/01/2018 13:37:18 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 13:37:18 [INFO] exp_shallowmodel: accuracy:   0.672
01/01/2018 13:37:18 [INFO] exp_shallowmodel: f1_score:   0.576
01/01/2018 13:37:18 [INFO] exp_shallowmodel: classification report:
01/01/2018 13:37:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.39      0.42        28
          C       0.62      0.63      0.63       172
          F       0.84      0.83      0.83       283
          R       0.41      0.42      0.42       123

avg / total       0.67      0.67      0.67       606

01/01/2018 13:37:18 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 13:37:18 [INFO] exp_shallowmodel: 
[[ 11   6   5   6]
 [  4 109  17  42]
 [  7  14 235  27]
 [  2  46  23  52]]
01/01/2018 13:37:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
01/01/2018 13:37:18 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 13:37:18 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 13:37:18 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 13:37:18 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 13:37:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 13:37:18 [INFO] exp_shallowmodel: Training: 
01/01/2018 13:37:18 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 13:49:24 [INFO] exp_shallowmodel: train time: 726.238s
01/01/2018 13:49:24 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 13:49:24 [INFO] exp_shallowmodel: accuracy:   0.709
01/01/2018 13:49:24 [INFO] exp_shallowmodel: f1_score:   0.594
01/01/2018 13:49:24 [INFO] exp_shallowmodel: classification report:
01/01/2018 13:49:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.40      0.37        20
          C       0.70      0.66      0.68       169
          F       0.86      0.86      0.86       281
          R       0.46      0.48      0.47       122

avg / total       0.71      0.71      0.71       592

01/01/2018 13:49:24 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 13:49:24 [INFO] exp_shallowmodel: 
[[  8   2   5   5]
 [  7 111  17  34]
 [  3   5 243  30]
 [  5  41  18  58]]
01/01/2018 13:49:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
01/01/2018 13:49:24 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 13:49:24 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 13:49:24 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 13:49:24 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 13:49:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 13:49:24 [INFO] exp_shallowmodel: Training: 
01/01/2018 13:49:24 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 14:09:36 [INFO] exp_shallowmodel: train time: 1212.119s
01/01/2018 14:09:36 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 14:09:36 [INFO] exp_shallowmodel: accuracy:   0.664
01/01/2018 14:09:36 [INFO] exp_shallowmodel: f1_score:   0.549
01/01/2018 14:09:36 [INFO] exp_shallowmodel: classification report:
01/01/2018 14:09:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.45      0.39        20
          C       0.62      0.68      0.65       169
          F       0.86      0.83      0.84       281
          R       0.33      0.30      0.31       122

avg / total       0.66      0.66      0.66       592

01/01/2018 14:09:36 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 14:09:36 [INFO] exp_shallowmodel: 
[[  9   2   6   3]
 [  3 115  11  40]
 [  7  11 233  30]
 [  7  58  21  36]]
01/01/2018 14:09:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
01/01/2018 14:09:37 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 14:09:37 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 14:09:37 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 14:09:37 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 14:09:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 14:09:37 [INFO] exp_shallowmodel: Training: 
01/01/2018 14:09:37 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 14:29:04 [INFO] exp_shallowmodel: train time: 1167.653s
01/01/2018 14:29:04 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 14:29:04 [INFO] exp_shallowmodel: accuracy:   0.660
01/01/2018 14:29:04 [INFO] exp_shallowmodel: f1_score:   0.549
01/01/2018 14:29:04 [INFO] exp_shallowmodel: classification report:
01/01/2018 14:29:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.55      0.33        20
          C       0.65      0.49      0.56       169
          F       0.87      0.84      0.86       281
          R       0.41      0.50      0.45       122

avg / total       0.69      0.66      0.67       592

01/01/2018 14:29:04 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 14:29:04 [INFO] exp_shallowmodel: 
[[ 11   1   4   4]
 [ 14  82  11  62]
 [ 12  11 237  21]
 [ 10  32  19  61]]
01/01/2018 14:29:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
01/01/2018 14:29:05 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 14:29:05 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 14:29:05 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 14:29:05 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 14:29:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 14:29:05 [INFO] exp_shallowmodel: Training: 
01/01/2018 14:29:05 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 14:50:23 [INFO] exp_shallowmodel: train time: 1278.175s
01/01/2018 14:50:23 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 14:50:23 [INFO] exp_shallowmodel: accuracy:   0.660
01/01/2018 14:50:23 [INFO] exp_shallowmodel: f1_score:   0.570
01/01/2018 14:50:23 [INFO] exp_shallowmodel: classification report:
01/01/2018 14:50:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.45      0.37        20
          C       0.62      0.72      0.67       169
          F       0.89      0.72      0.79       281
          R       0.42      0.49      0.45       122

avg / total       0.70      0.66      0.67       592

01/01/2018 14:50:23 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 14:50:23 [INFO] exp_shallowmodel: 
[[  9   5   5   1]
 [  8 121   8  32]
 [  7  24 201  49]
 [  5  44  13  60]]
01/01/2018 14:50:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
01/01/2018 14:50:23 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 14:50:23 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 14:50:23 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 14:50:23 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 14:50:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 14:50:23 [INFO] exp_shallowmodel: Training: 
01/01/2018 14:50:23 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 15:10:06 [INFO] exp_shallowmodel: train time: 1183.361s
01/01/2018 15:10:06 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 15:10:06 [INFO] exp_shallowmodel: accuracy:   0.654
01/01/2018 15:10:06 [INFO] exp_shallowmodel: f1_score:   0.536
01/01/2018 15:10:06 [INFO] exp_shallowmodel: classification report:
01/01/2018 15:10:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.35      0.31        20
          C       0.56      0.50      0.53       169
          F       0.87      0.84      0.85       281
          R       0.41      0.49      0.45       122

avg / total       0.67      0.65      0.66       592

01/01/2018 15:10:06 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 15:10:06 [INFO] exp_shallowmodel: 
[[  7   5   6   2]
 [  4  85  13  67]
 [  9  21 235  16]
 [  5  42  15  60]]
01/01/2018 15:10:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
01/01/2018 15:10:06 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 15:10:06 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 15:10:06 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 15:10:06 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 15:10:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 15:10:06 [INFO] exp_shallowmodel: Training: 
01/01/2018 15:10:06 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 15:25:29 [INFO] exp_shallowmodel: train time: 922.652s
01/01/2018 15:25:29 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 15:25:29 [INFO] exp_shallowmodel: accuracy:   0.684
01/01/2018 15:25:29 [INFO] exp_shallowmodel: f1_score:   0.593
01/01/2018 15:25:29 [INFO] exp_shallowmodel: classification report:
01/01/2018 15:25:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.45      0.45        20
          C       0.60      0.62      0.61       169
          F       0.88      0.83      0.85       281
          R       0.44      0.48      0.46       122

avg / total       0.69      0.68      0.69       592

01/01/2018 15:25:29 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 15:25:29 [INFO] exp_shallowmodel: 
[[  9   3   6   2]
 [  6 105   9  49]
 [  3  23 233  22]
 [  2  45  17  58]]
01/01/2018 15:25:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
01/01/2018 15:25:29 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 15:25:29 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 15:25:29 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 15:25:29 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 15:25:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 15:25:29 [INFO] exp_shallowmodel: Training: 
01/01/2018 15:25:29 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 15:46:35 [INFO] exp_shallowmodel: train time: 1265.943s
01/01/2018 15:46:35 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 15:46:35 [INFO] exp_shallowmodel: accuracy:   0.650
01/01/2018 15:46:35 [INFO] exp_shallowmodel: f1_score:   0.499
01/01/2018 15:46:35 [INFO] exp_shallowmodel: classification report:
01/01/2018 15:46:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.15      0.14        20
          C       0.61      0.51      0.55       169
          F       0.88      0.82      0.85       281
          R       0.40      0.53      0.46       122

avg / total       0.68      0.65      0.66       592

01/01/2018 15:46:35 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 15:46:35 [INFO] exp_shallowmodel: 
[[  3   7   7   3]
 [  8  86   9  66]
 [  7  14 231  29]
 [  6  35  16  65]]
01/01/2018 15:46:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
01/01/2018 15:46:35 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 15:46:35 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 15:46:35 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 15:46:35 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 15:46:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 15:46:35 [INFO] exp_shallowmodel: Training: 
01/01/2018 15:46:35 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 16:06:45 [INFO] exp_shallowmodel: train time: 1209.579s
01/01/2018 16:06:45 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 16:06:45 [INFO] exp_shallowmodel: accuracy:   0.628
01/01/2018 16:06:45 [INFO] exp_shallowmodel: f1_score:   0.521
01/01/2018 16:06:45 [INFO] exp_shallowmodel: classification report:
01/01/2018 16:06:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.45      0.30        20
          C       0.63      0.48      0.55       169
          F       0.84      0.79      0.81       281
          R       0.38      0.49      0.43       122

avg / total       0.66      0.63      0.64       592

01/01/2018 16:06:45 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 16:06:45 [INFO] exp_shallowmodel: 
[[  9   1   7   3]
 [ 10  81  15  63]
 [ 15  11 222  33]
 [  6  35  21  60]]
01/01/2018 16:06:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
01/01/2018 16:06:45 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 16:06:45 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 16:06:45 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 16:06:45 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 16:06:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 16:06:45 [INFO] exp_shallowmodel: Training: 
01/01/2018 16:06:45 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 16:20:35 [INFO] exp_shallowmodel: train time: 829.670s
01/01/2018 16:20:35 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 16:20:35 [INFO] exp_shallowmodel: accuracy:   0.711
01/01/2018 16:20:35 [INFO] exp_shallowmodel: f1_score:   0.614
01/01/2018 16:20:35 [INFO] exp_shallowmodel: classification report:
01/01/2018 16:20:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.50      0.42        20
          C       0.70      0.62      0.66       169
          F       0.89      0.84      0.86       281
          R       0.47      0.57      0.52       122

avg / total       0.73      0.71      0.72       592

01/01/2018 16:20:35 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 16:20:35 [INFO] exp_shallowmodel: 
[[ 10   2   6   2]
 [  9 105   8  47]
 [  5  10 236  30]
 [  4  32  16  70]]
01/01/2018 16:20:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
01/01/2018 16:20:35 [INFO] exp_shallowmodel: #(data) = 4736
01/01/2018 16:20:35 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 16:20:35 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 16:20:35 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 16:20:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 16:20:35 [INFO] exp_shallowmodel: Training: 
01/01/2018 16:20:35 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 16:38:38 [INFO] exp_shallowmodel: train time: 1082.496s
01/01/2018 16:38:38 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 16:38:38 [INFO] exp_shallowmodel: accuracy:   0.673
01/01/2018 16:38:38 [INFO] exp_shallowmodel: f1_score:   0.574
01/01/2018 16:38:38 [INFO] exp_shallowmodel: classification report:
01/01/2018 16:38:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.39      0.42        28
          C       0.59      0.62      0.60       172
          F       0.85      0.84      0.85       283
          R       0.42      0.41      0.42       123

avg / total       0.67      0.67      0.67       606

01/01/2018 16:38:38 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 16:38:38 [INFO] exp_shallowmodel: 
[[ 11   5   8   4]
 [  7 107  16  42]
 [  6  15 239  23]
 [  0  55  17  51]]
01/01/2018 16:38:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
01/01/2018 16:38:38 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 16:38:38 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 16:38:38 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 16:38:38 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 16:38:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 16:38:38 [INFO] exp_shallowmodel: Training: 
01/01/2018 16:38:38 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 17:00:25 [INFO] exp_shallowmodel: train time: 1307.295s
01/01/2018 17:00:25 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 17:00:25 [INFO] exp_shallowmodel: accuracy:   0.681
01/01/2018 17:00:25 [INFO] exp_shallowmodel: f1_score:   0.566
01/01/2018 17:00:25 [INFO] exp_shallowmodel: classification report:
01/01/2018 17:00:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.40      0.32        20
          C       0.62      0.49      0.55       169
          F       0.91      0.84      0.87       281
          R       0.45      0.62      0.52       122

avg / total       0.71      0.68      0.69       592

01/01/2018 17:00:25 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 17:00:25 [INFO] exp_shallowmodel: 
[[  8   5   5   2]
 [ 10  83   7  69]
 [  7  15 236  23]
 [  5  30  11  76]]
01/01/2018 17:00:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
01/01/2018 17:00:25 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 17:00:25 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 17:00:25 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 17:00:25 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 17:00:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 17:00:25 [INFO] exp_shallowmodel: Training: 
01/01/2018 17:00:25 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 17:11:20 [INFO] exp_shallowmodel: train time: 654.545s
01/01/2018 17:11:20 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 17:11:20 [INFO] exp_shallowmodel: accuracy:   0.666
01/01/2018 17:11:20 [INFO] exp_shallowmodel: f1_score:   0.564
01/01/2018 17:11:20 [INFO] exp_shallowmodel: classification report:
01/01/2018 17:11:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.45      0.38        20
          C       0.62      0.60      0.61       169
          F       0.84      0.81      0.83       281
          R       0.42      0.45      0.44       122

avg / total       0.67      0.67      0.67       592

01/01/2018 17:11:20 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 17:11:20 [INFO] exp_shallowmodel: 
[[  9   4   5   2]
 [  9 101  11  48]
 [  5  22 229  25]
 [  4  36  27  55]]
01/01/2018 17:11:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
01/01/2018 17:11:20 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 17:11:20 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 17:11:20 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 17:11:20 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 17:11:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 17:11:20 [INFO] exp_shallowmodel: Training: 
01/01/2018 17:11:20 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 17:23:24 [INFO] exp_shallowmodel: train time: 724.032s
01/01/2018 17:23:24 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 17:23:24 [INFO] exp_shallowmodel: accuracy:   0.666
01/01/2018 17:23:24 [INFO] exp_shallowmodel: f1_score:   0.557
01/01/2018 17:23:24 [INFO] exp_shallowmodel: classification report:
01/01/2018 17:23:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.40      0.32        20
          C       0.69      0.50      0.58       169
          F       0.86      0.81      0.84       281
          R       0.42      0.60      0.49       122

avg / total       0.70      0.67      0.67       592

01/01/2018 17:23:24 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 17:23:24 [INFO] exp_shallowmodel: 
[[  8   2   6   4]
 [  5  84  13  67]
 [ 16   7 229  29]
 [  1  29  19  73]]
01/01/2018 17:23:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
01/01/2018 17:23:24 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 17:23:24 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 17:23:24 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 17:23:24 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 17:23:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 17:23:24 [INFO] exp_shallowmodel: Training: 
01/01/2018 17:23:24 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 17:32:08 [INFO] exp_shallowmodel: train time: 523.974s
01/01/2018 17:32:08 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 17:32:08 [INFO] exp_shallowmodel: accuracy:   0.703
01/01/2018 17:32:08 [INFO] exp_shallowmodel: f1_score:   0.592
01/01/2018 17:32:08 [INFO] exp_shallowmodel: classification report:
01/01/2018 17:32:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.45      0.38        20
          C       0.63      0.67      0.65       169
          F       0.88      0.84      0.86       281
          R       0.50      0.47      0.48       122

avg / total       0.71      0.70      0.71       592

01/01/2018 17:32:08 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 17:32:08 [INFO] exp_shallowmodel: 
[[  9   2   7   2]
 [  7 114  10  38]
 [  7  21 236  17]
 [  5  44  16  57]]
01/01/2018 17:32:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
01/01/2018 17:32:08 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 17:32:08 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 17:32:08 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 17:32:08 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 17:32:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 17:32:08 [INFO] exp_shallowmodel: Training: 
01/01/2018 17:32:08 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 17:47:49 [INFO] exp_shallowmodel: train time: 940.803s
01/01/2018 17:47:49 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 17:47:49 [INFO] exp_shallowmodel: accuracy:   0.660
01/01/2018 17:47:49 [INFO] exp_shallowmodel: f1_score:   0.556
01/01/2018 17:47:49 [INFO] exp_shallowmodel: classification report:
01/01/2018 17:47:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.50      0.43        20
          C       0.60      0.66      0.63       169
          F       0.87      0.82      0.85       281
          R       0.34      0.31      0.32       122

avg / total       0.67      0.66      0.66       592

01/01/2018 17:47:49 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 17:47:49 [INFO] exp_shallowmodel: 
[[ 10   3   4   3]
 [  7 112   9  41]
 [  6  13 231  31]
 [  4  59  21  38]]
01/01/2018 17:47:49 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
01/01/2018 17:47:49 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 17:47:49 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 17:47:49 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 17:47:49 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 17:47:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 17:47:49 [INFO] exp_shallowmodel: Training: 
01/01/2018 17:47:49 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 17:55:48 [INFO] exp_shallowmodel: train time: 478.778s
01/01/2018 17:55:48 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 17:55:48 [INFO] exp_shallowmodel: accuracy:   0.682
01/01/2018 17:55:48 [INFO] exp_shallowmodel: f1_score:   0.547
01/01/2018 17:55:48 [INFO] exp_shallowmodel: classification report:
01/01/2018 17:55:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.25      0.22        20
          C       0.64      0.60      0.62       169
          F       0.90      0.82      0.86       281
          R       0.45      0.56      0.50       122

avg / total       0.71      0.68      0.69       592

01/01/2018 17:55:48 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 17:55:48 [INFO] exp_shallowmodel: 
[[  5   5   5   5]
 [  6 101   6  56]
 [  5  23 230  23]
 [ 10  30  14  68]]
01/01/2018 17:55:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
01/01/2018 17:55:48 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 17:55:48 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 17:55:48 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 17:55:48 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 17:55:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 17:55:48 [INFO] exp_shallowmodel: Training: 
01/01/2018 17:55:48 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:04:03 [INFO] exp_shallowmodel: train time: 495.059s
01/01/2018 18:04:03 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:04:03 [INFO] exp_shallowmodel: accuracy:   0.681
01/01/2018 18:04:03 [INFO] exp_shallowmodel: f1_score:   0.592
01/01/2018 18:04:03 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:04:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.41      0.55      0.47        20
          C       0.65      0.39      0.49       169
          F       0.90      0.86      0.88       281
          R       0.44      0.69      0.53       122

avg / total       0.71      0.68      0.68       592

01/01/2018 18:04:03 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:04:03 [INFO] exp_shallowmodel: 
[[ 11   4   3   2]
 [  6  66  14  83]
 [  4  11 242  24]
 [  6  21  11  84]]
01/01/2018 18:04:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
01/01/2018 18:04:04 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 18:04:04 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 18:04:04 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:04:04 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:04:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:04:04 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:04:04 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:17:28 [INFO] exp_shallowmodel: train time: 804.670s
01/01/2018 18:17:28 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:17:28 [INFO] exp_shallowmodel: accuracy:   0.689
01/01/2018 18:17:28 [INFO] exp_shallowmodel: f1_score:   0.573
01/01/2018 18:17:28 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:17:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.40      0.33        20
          C       0.66      0.59      0.62       169
          F       0.84      0.85      0.85       281
          R       0.48      0.51      0.49       122

avg / total       0.70      0.69      0.69       592

01/01/2018 18:17:28 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:17:28 [INFO] exp_shallowmodel: 
[[  8   2   5   5]
 [ 10 100  20  39]
 [  7  12 238  24]
 [  3  38  19  62]]
01/01/2018 18:17:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
01/01/2018 18:17:28 [INFO] exp_shallowmodel: #(data) = 4750
01/01/2018 18:17:28 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 18:17:28 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:17:28 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:17:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:17:28 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:17:28 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:31:49 [INFO] exp_shallowmodel: train time: 860.598s
01/01/2018 18:31:49 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:31:49 [INFO] exp_shallowmodel: accuracy:   0.677
01/01/2018 18:31:49 [INFO] exp_shallowmodel: f1_score:   0.590
01/01/2018 18:31:49 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:31:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.55      0.43        20
          C       0.63      0.53      0.57       169
          F       0.86      0.82      0.84       281
          R       0.47      0.58      0.52       122

avg / total       0.70      0.68      0.68       592

01/01/2018 18:31:49 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:31:49 [INFO] exp_shallowmodel: 
[[ 11   4   5   0]
 [  5  89  14  61]
 [ 11  20 230  20]
 [  4  29  18  71]]
01/01/2018 18:31:49 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
01/01/2018 18:31:49 [INFO] exp_shallowmodel: #(data) = 4736
01/01/2018 18:31:49 [INFO] exp_shallowmodel: #(feature) = 1040
01/01/2018 18:31:49 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:31:49 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:31:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:31:49 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:31:49 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:44:10 [INFO] exp_shallowmodel: train time: 740.768s
01/01/2018 18:44:10 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:44:10 [INFO] exp_shallowmodel: accuracy:   0.660
01/01/2018 18:44:10 [INFO] exp_shallowmodel: f1_score:   0.580
01/01/2018 18:44:10 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:44:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.36      0.42        28
          C       0.58      0.66      0.62       172
          F       0.88      0.75      0.81       283
          R       0.43      0.54      0.48       123

avg / total       0.69      0.66      0.67       606

01/01/2018 18:44:10 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:44:10 [INFO] exp_shallowmodel: 
[[ 10   7   6   5]
 [  7 113  11  41]
 [  3  28 211  41]
 [  0  46  11  66]]
01/01/2018 18:44:16 [INFO] exp_shallowmodel: 1	3

01/01/2018 18:44:16 [INFO] exp_shallowmodel: 2.1	52

01/01/2018 18:44:16 [INFO] exp_shallowmodel: 2.2	2

01/01/2018 18:44:16 [INFO] exp_shallowmodel: 2.3.1	1

01/01/2018 18:44:16 [INFO] exp_shallowmodel: 3	5

01/01/2018 18:44:16 [INFO] exp_shallowmodel: 5	14903

01/01/2018 18:44:16 [INFO] exp_shallowmodel: 6	2978

01/01/2018 18:44:16 [INFO] exp_shallowmodel: 7	4659

01/01/2018 18:44:16 [INFO] exp_shallowmodel: 9.1	900

01/01/2018 18:44:16 [INFO] exp_shallowmodel: 9.2.1	1

01/01/2018 18:44:16 [INFO] exp_shallowmodel: 9.3.1	1

01/01/2018 18:44:17 [INFO] exp_shallowmodel: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
01/01/2018 18:44:17 [INFO] exp_shallowmodel:           dataset=family
01/01/2018 18:44:17 [INFO] exp_shallowmodel:           k_feature_to_keep=7
01/01/2018 18:44:17 [INFO] exp_shallowmodel:           X_new.shape=(3530, 1042)
01/01/2018 18:44:17 [INFO] exp_shallowmodel:           #(X_selected)=128
01/01/2018 18:44:17 [INFO] exp_shallowmodel:           #(X_not_selectable)=914
01/01/2018 18:44:17 [INFO] exp_shallowmodel: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
01/01/2018 18:44:17 [INFO] exp_shallowmodel: ******************** family - Round 0 
01/01/2018 18:44:17 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:44:17 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:44:17 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:44:17 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:44:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:44:17 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:44:17 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:45:24 [INFO] exp_shallowmodel: train time: 67.333s
01/01/2018 18:45:24 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:45:24 [INFO] exp_shallowmodel: accuracy:   0.793
01/01/2018 18:45:24 [INFO] exp_shallowmodel: f1_score:   0.594
01/01/2018 18:45:24 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:45:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.43      0.38        23
          C       0.46      0.59      0.52        27
          F       0.95      0.90      0.92       250
          R       0.55      0.56      0.55        52

avg / total       0.82      0.79      0.80       352

01/01/2018 18:45:24 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:45:24 [INFO] exp_shallowmodel: 
[[ 10   3   5   5]
 [  2  16   0   9]
 [ 12   4 224  10]
 [  5  12   6  29]]
01/01/2018 18:45:24 [INFO] exp_shallowmodel: ******************** family - Round 1 
01/01/2018 18:45:24 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:45:24 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:45:24 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:45:24 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:45:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:45:24 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:45:24 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:46:06 [INFO] exp_shallowmodel: train time: 41.322s
01/01/2018 18:46:06 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:46:06 [INFO] exp_shallowmodel: accuracy:   0.770
01/01/2018 18:46:06 [INFO] exp_shallowmodel: f1_score:   0.555
01/01/2018 18:46:06 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:46:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.30      0.29        23
          C       0.48      0.48      0.48        27
          F       0.92      0.88      0.90       250
          R       0.51      0.60      0.55        52

avg / total       0.78      0.77      0.78       352

01/01/2018 18:46:06 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:46:06 [INFO] exp_shallowmodel: 
[[  7   3   6   7]
 [  3  13   1  10]
 [  9   8 220  13]
 [  6   3  12  31]]
01/01/2018 18:46:06 [INFO] exp_shallowmodel: ******************** family - Round 2 
01/01/2018 18:46:06 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:46:06 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:46:06 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:46:06 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:46:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:46:06 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:46:06 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:46:53 [INFO] exp_shallowmodel: train time: 47.511s
01/01/2018 18:46:53 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:46:53 [INFO] exp_shallowmodel: accuracy:   0.824
01/01/2018 18:46:53 [INFO] exp_shallowmodel: f1_score:   0.643
01/01/2018 18:46:53 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:46:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.30      0.30        23
          C       0.56      0.74      0.63        27
          F       0.95      0.90      0.92       250
          R       0.69      0.73      0.71        52

avg / total       0.84      0.82      0.83       352

01/01/2018 18:46:53 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:46:53 [INFO] exp_shallowmodel: 
[[  7   3   8   5]
 [  1  20   1   5]
 [ 12   6 225   7]
 [  3   7   4  38]]
01/01/2018 18:46:53 [INFO] exp_shallowmodel: ******************** family - Round 3 
01/01/2018 18:46:53 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:46:53 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:46:53 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:46:53 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:46:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:46:53 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:46:53 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:47:54 [INFO] exp_shallowmodel: train time: 60.653s
01/01/2018 18:47:54 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:47:54 [INFO] exp_shallowmodel: accuracy:   0.744
01/01/2018 18:47:54 [INFO] exp_shallowmodel: f1_score:   0.513
01/01/2018 18:47:54 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:47:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.17      0.14        23
          C       0.45      0.48      0.46        27
          F       0.94      0.86      0.90       250
          R       0.53      0.60      0.56        52

avg / total       0.79      0.74      0.76       352

01/01/2018 18:47:54 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:47:54 [INFO] exp_shallowmodel: 
[[  4   4   6   9]
 [  5  13   2   7]
 [ 20   4 214  12]
 [  7   8   6  31]]
01/01/2018 18:47:54 [INFO] exp_shallowmodel: ******************** family - Round 4 
01/01/2018 18:47:54 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:47:54 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:47:54 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:47:54 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:47:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:47:54 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:47:54 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:49:04 [INFO] exp_shallowmodel: train time: 69.707s
01/01/2018 18:49:04 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:49:04 [INFO] exp_shallowmodel: accuracy:   0.770
01/01/2018 18:49:04 [INFO] exp_shallowmodel: f1_score:   0.576
01/01/2018 18:49:04 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:49:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.48      0.37        23
          C       0.48      0.48      0.48        27
          F       0.95      0.86      0.91       250
          R       0.50      0.60      0.54        52

avg / total       0.81      0.77      0.78       352

01/01/2018 18:49:04 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:49:04 [INFO] exp_shallowmodel: 
[[ 11   3   4   5]
 [  2  13   1  11]
 [ 15   4 216  15]
 [  8   7   6  31]]
01/01/2018 18:49:04 [INFO] exp_shallowmodel: ******************** family - Round 5 
01/01/2018 18:49:04 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:49:04 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:49:04 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:49:04 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:49:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:49:04 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:49:04 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:49:55 [INFO] exp_shallowmodel: train time: 51.166s
01/01/2018 18:49:55 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:49:55 [INFO] exp_shallowmodel: accuracy:   0.793
01/01/2018 18:49:55 [INFO] exp_shallowmodel: f1_score:   0.621
01/01/2018 18:49:55 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:49:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.48      0.42        23
          C       0.45      0.93      0.61        27
          F       0.96      0.87      0.91       250
          R       0.61      0.48      0.54        52

avg / total       0.83      0.79      0.80       352

01/01/2018 18:49:55 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:49:55 [INFO] exp_shallowmodel: 
[[ 11   5   3   4]
 [  1  25   0   1]
 [ 12   9 218  11]
 [  5  16   6  25]]
01/01/2018 18:49:55 [INFO] exp_shallowmodel: ******************** family - Round 6 
01/01/2018 18:49:55 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:49:55 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:49:55 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:49:55 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:49:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:49:55 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:49:55 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:50:29 [INFO] exp_shallowmodel: train time: 34.346s
01/01/2018 18:50:29 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:50:29 [INFO] exp_shallowmodel: accuracy:   0.781
01/01/2018 18:50:29 [INFO] exp_shallowmodel: f1_score:   0.577
01/01/2018 18:50:29 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:50:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.48      0.39        23
          C       0.42      0.56      0.48        27
          F       0.95      0.89      0.92       250
          R       0.54      0.50      0.52        52

avg / total       0.81      0.78      0.79       352

01/01/2018 18:50:29 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:50:29 [INFO] exp_shallowmodel: 
[[ 11   3   3   6]
 [  4  15   2   6]
 [  8   9 223  10]
 [ 10   9   7  26]]
01/01/2018 18:50:30 [INFO] exp_shallowmodel: ******************** family - Round 7 
01/01/2018 18:50:30 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:50:30 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:50:30 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:50:30 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:50:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:50:30 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:50:30 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:51:20 [INFO] exp_shallowmodel: train time: 50.906s
01/01/2018 18:51:20 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:51:20 [INFO] exp_shallowmodel: accuracy:   0.790
01/01/2018 18:51:20 [INFO] exp_shallowmodel: f1_score:   0.573
01/01/2018 18:51:20 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:51:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.43      0.40        23
          C       0.35      0.41      0.38        27
          F       0.95      0.90      0.92       250
          R       0.56      0.62      0.59        52

avg / total       0.81      0.79      0.80       352

01/01/2018 18:51:20 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:51:20 [INFO] exp_shallowmodel: 
[[ 10   6   3   4]
 [  4  11   1  11]
 [  9   6 225  10]
 [  4   8   8  32]]
01/01/2018 18:51:21 [INFO] exp_shallowmodel: ******************** family - Round 8 
01/01/2018 18:51:21 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:51:21 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:51:21 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:51:21 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:51:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:51:21 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:51:21 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:52:08 [INFO] exp_shallowmodel: train time: 47.584s
01/01/2018 18:52:08 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:52:08 [INFO] exp_shallowmodel: accuracy:   0.750
01/01/2018 18:52:08 [INFO] exp_shallowmodel: f1_score:   0.518
01/01/2018 18:52:08 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:52:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.39      0.30        23
          C       0.39      0.52      0.44        27
          F       0.94      0.88      0.91       250
          R       0.44      0.38      0.41        52

avg / total       0.78      0.75      0.76       352

01/01/2018 18:52:08 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:52:08 [INFO] exp_shallowmodel: 
[[  9   1   5   8]
 [  8  14   1   4]
 [ 11   5 221  13]
 [  9  16   7  20]]
01/01/2018 18:52:08 [INFO] exp_shallowmodel: ******************** family - Round 9 
01/01/2018 18:52:08 [INFO] exp_shallowmodel: #(data) = 2816
01/01/2018 18:52:08 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:52:08 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:52:08 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:52:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:52:08 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:52:08 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:53:26 [INFO] exp_shallowmodel: train time: 77.710s
01/01/2018 18:53:26 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:53:26 [INFO] exp_shallowmodel: accuracy:   0.757
01/01/2018 18:53:26 [INFO] exp_shallowmodel: f1_score:   0.563
01/01/2018 18:53:26 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:53:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.36      0.32        25
          C       0.50      0.59      0.54        27
          F       0.93      0.87      0.90       251
          R       0.48      0.51      0.50        59

avg / total       0.78      0.76      0.77       362

01/01/2018 18:53:26 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:53:26 [INFO] exp_shallowmodel: 
[[  9   3   6   7]
 [  1  16   1   9]
 [ 12   4 219  16]
 [ 10   9  10  30]]
01/01/2018 18:53:26 [INFO] exp_shallowmodel: ******************** family - Round 10 
01/01/2018 18:53:26 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:53:26 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:53:26 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:53:26 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:53:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:53:26 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:53:26 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:54:37 [INFO] exp_shallowmodel: train time: 70.802s
01/01/2018 18:54:37 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:54:37 [INFO] exp_shallowmodel: accuracy:   0.759
01/01/2018 18:54:37 [INFO] exp_shallowmodel: f1_score:   0.536
01/01/2018 18:54:37 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:54:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.30      0.29        23
          C       0.35      0.59      0.44        27
          F       0.96      0.87      0.91       250
          R       0.50      0.52      0.51        52

avg / total       0.80      0.76      0.78       352

01/01/2018 18:54:37 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:54:37 [INFO] exp_shallowmodel: 
[[  7   6   3   7]
 [  4  16   1   6]
 [ 13   6 217  14]
 [  2  18   5  27]]
01/01/2018 18:54:37 [INFO] exp_shallowmodel: ******************** family - Round 11 
01/01/2018 18:54:37 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:54:37 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:54:37 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:54:37 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:54:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:54:37 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:54:37 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:55:31 [INFO] exp_shallowmodel: train time: 54.022s
01/01/2018 18:55:31 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:55:31 [INFO] exp_shallowmodel: accuracy:   0.753
01/01/2018 18:55:31 [INFO] exp_shallowmodel: f1_score:   0.552
01/01/2018 18:55:31 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:55:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.39      0.33        23
          C       0.48      0.81      0.60        27
          F       0.93      0.86      0.90       250
          R       0.43      0.35      0.38        52

avg / total       0.78      0.75      0.76       352

01/01/2018 18:55:31 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:55:31 [INFO] exp_shallowmodel: 
[[  9   3   5   6]
 [  3  22   0   2]
 [ 12   6 216  16]
 [  8  15  11  18]]
01/01/2018 18:55:31 [INFO] exp_shallowmodel: ******************** family - Round 12 
01/01/2018 18:55:31 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:55:31 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:55:31 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:55:31 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:55:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:55:31 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:55:31 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:56:16 [INFO] exp_shallowmodel: train time: 44.633s
01/01/2018 18:56:16 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:56:16 [INFO] exp_shallowmodel: accuracy:   0.781
01/01/2018 18:56:16 [INFO] exp_shallowmodel: f1_score:   0.599
01/01/2018 18:56:16 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:56:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.52      0.45        23
          C       0.41      0.56      0.47        27
          F       0.94      0.87      0.90       250
          R       0.57      0.58      0.57        52

avg / total       0.81      0.78      0.79       352

01/01/2018 18:56:16 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:56:16 [INFO] exp_shallowmodel: 
[[ 12   3   5   3]
 [  3  15   1   8]
 [  9  11 218  12]
 [  6   8   8  30]]
01/01/2018 18:56:16 [INFO] exp_shallowmodel: ******************** family - Round 13 
01/01/2018 18:56:16 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:56:16 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:56:16 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:56:16 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:56:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:56:16 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:56:16 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:57:07 [INFO] exp_shallowmodel: train time: 51.304s
01/01/2018 18:57:07 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:57:07 [INFO] exp_shallowmodel: accuracy:   0.739
01/01/2018 18:57:07 [INFO] exp_shallowmodel: f1_score:   0.507
01/01/2018 18:57:07 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:57:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.22      0.19        23
          C       0.56      0.52      0.54        27
          F       0.91      0.88      0.89       250
          R       0.39      0.42      0.41        52

avg / total       0.76      0.74      0.75       352

01/01/2018 18:57:07 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:57:07 [INFO] exp_shallowmodel: 
[[  5   1   9   8]
 [  2  14   2   9]
 [ 12   2 219  17]
 [ 11   8  11  22]]
01/01/2018 18:57:07 [INFO] exp_shallowmodel: ******************** family - Round 14 
01/01/2018 18:57:07 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:57:07 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:57:07 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:57:07 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:57:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:57:07 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:57:07 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:58:22 [INFO] exp_shallowmodel: train time: 75.062s
01/01/2018 18:58:22 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:58:22 [INFO] exp_shallowmodel: accuracy:   0.773
01/01/2018 18:58:22 [INFO] exp_shallowmodel: f1_score:   0.565
01/01/2018 18:58:22 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:58:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.39      0.31        23
          C       0.45      0.52      0.48        27
          F       0.94      0.88      0.91       250
          R       0.56      0.56      0.56        52

avg / total       0.80      0.77      0.79       352

01/01/2018 18:58:22 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:58:22 [INFO] exp_shallowmodel: 
[[  9   4   6   4]
 [  4  14   2   7]
 [ 13   5 220  12]
 [  9   8   6  29]]
01/01/2018 18:58:22 [INFO] exp_shallowmodel: ******************** family - Round 15 
01/01/2018 18:58:22 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:58:22 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:58:22 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:58:22 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:58:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:58:22 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:58:22 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 18:59:18 [INFO] exp_shallowmodel: train time: 55.375s
01/01/2018 18:59:18 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 18:59:18 [INFO] exp_shallowmodel: accuracy:   0.827
01/01/2018 18:59:18 [INFO] exp_shallowmodel: f1_score:   0.667
01/01/2018 18:59:18 [INFO] exp_shallowmodel: classification report:
01/01/2018 18:59:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.39      0.39        23
          C       0.65      0.74      0.69        27
          F       0.92      0.91      0.91       250
          R       0.69      0.65      0.67        52

avg / total       0.83      0.83      0.83       352

01/01/2018 18:59:18 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 18:59:18 [INFO] exp_shallowmodel: 
[[  9   3   7   4]
 [  0  20   3   4]
 [ 10   5 228   7]
 [  4   3  11  34]]
01/01/2018 18:59:18 [INFO] exp_shallowmodel: ******************** family - Round 16 
01/01/2018 18:59:18 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 18:59:18 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 18:59:18 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 18:59:18 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 18:59:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 18:59:18 [INFO] exp_shallowmodel: Training: 
01/01/2018 18:59:18 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:00:18 [INFO] exp_shallowmodel: train time: 60.376s
01/01/2018 19:00:18 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:00:18 [INFO] exp_shallowmodel: accuracy:   0.784
01/01/2018 19:00:18 [INFO] exp_shallowmodel: f1_score:   0.611
01/01/2018 19:00:18 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:00:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.43      0.33        23
          C       0.64      0.52      0.57        27
          F       0.95      0.86      0.90       250
          R       0.58      0.73      0.64        52

avg / total       0.82      0.78      0.80       352

01/01/2018 19:00:18 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:00:18 [INFO] exp_shallowmodel: 
[[ 10   1   6   6]
 [  2  14   1  10]
 [ 20   4 214  12]
 [  6   3   5  38]]
01/01/2018 19:00:18 [INFO] exp_shallowmodel: ******************** family - Round 17 
01/01/2018 19:00:18 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:00:18 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:00:18 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:00:18 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:00:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:00:18 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:00:18 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:00:58 [INFO] exp_shallowmodel: train time: 39.306s
01/01/2018 19:00:58 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:00:58 [INFO] exp_shallowmodel: accuracy:   0.790
01/01/2018 19:00:58 [INFO] exp_shallowmodel: f1_score:   0.606
01/01/2018 19:00:58 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:00:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.43      0.37        23
          C       0.53      0.59      0.56        27
          F       0.94      0.88      0.91       250
          R       0.55      0.62      0.58        52

avg / total       0.81      0.79      0.80       352

01/01/2018 19:00:58 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:00:58 [INFO] exp_shallowmodel: 
[[ 10   2   4   7]
 [  4  16   2   5]
 [ 10   6 220  14]
 [  7   6   7  32]]
01/01/2018 19:00:58 [INFO] exp_shallowmodel: ******************** family - Round 18 
01/01/2018 19:00:58 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:00:58 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:00:58 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:00:58 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:00:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:00:58 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:00:58 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:01:48 [INFO] exp_shallowmodel: train time: 50.805s
01/01/2018 19:01:48 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:01:48 [INFO] exp_shallowmodel: accuracy:   0.807
01/01/2018 19:01:48 [INFO] exp_shallowmodel: f1_score:   0.615
01/01/2018 19:01:48 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:01:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.39      0.39        23
          C       0.53      0.63      0.58        27
          F       0.92      0.92      0.92       250
          R       0.59      0.56      0.57        52

avg / total       0.81      0.81      0.81       352

01/01/2018 19:01:48 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:01:48 [INFO] exp_shallowmodel: 
[[  9   1   7   6]
 [  0  17   4   6]
 [ 10   3 229   8]
 [  4  11   8  29]]
01/01/2018 19:01:49 [INFO] exp_shallowmodel: ******************** family - Round 19 
01/01/2018 19:01:49 [INFO] exp_shallowmodel: #(data) = 2816
01/01/2018 19:01:49 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:01:49 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:01:49 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:01:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:01:49 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:01:49 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:03:00 [INFO] exp_shallowmodel: train time: 71.670s
01/01/2018 19:03:00 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:03:00 [INFO] exp_shallowmodel: accuracy:   0.785
01/01/2018 19:03:00 [INFO] exp_shallowmodel: f1_score:   0.586
01/01/2018 19:03:00 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:03:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.41      0.44      0.42        25
          C       0.39      0.52      0.44        27
          F       0.95      0.90      0.92       251
          R       0.55      0.56      0.55        59

avg / total       0.80      0.78      0.79       362

01/01/2018 19:03:00 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:03:00 [INFO] exp_shallowmodel: 
[[ 11   2   7   5]
 [  2  14   2   9]
 [  7   5 226  13]
 [  7  15   4  33]]
01/01/2018 19:03:00 [INFO] exp_shallowmodel: ******************** family - Round 20 
01/01/2018 19:03:00 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:03:00 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:03:00 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:03:00 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:03:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:03:00 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:03:00 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:04:11 [INFO] exp_shallowmodel: train time: 70.300s
01/01/2018 19:04:11 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:04:11 [INFO] exp_shallowmodel: accuracy:   0.821
01/01/2018 19:04:11 [INFO] exp_shallowmodel: f1_score:   0.638
01/01/2018 19:04:11 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:04:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.48      0.45        23
          C       0.51      0.70      0.59        27
          F       0.95      0.92      0.94       250
          R       0.61      0.54      0.57        52

avg / total       0.83      0.82      0.82       352

01/01/2018 19:04:11 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:04:11 [INFO] exp_shallowmodel: 
[[ 11   1   6   5]
 [  3  19   0   5]
 [  6   5 231   8]
 [  6  12   6  28]]
01/01/2018 19:04:11 [INFO] exp_shallowmodel: ******************** family - Round 21 
01/01/2018 19:04:11 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:04:11 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:04:11 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:04:11 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:04:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:04:11 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:04:11 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:05:22 [INFO] exp_shallowmodel: train time: 70.794s
01/01/2018 19:05:22 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:05:22 [INFO] exp_shallowmodel: accuracy:   0.739
01/01/2018 19:05:22 [INFO] exp_shallowmodel: f1_score:   0.527
01/01/2018 19:05:22 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:05:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.30      0.29        23
          C       0.41      0.63      0.50        27
          F       0.92      0.85      0.89       250
          R       0.42      0.44      0.43        52

avg / total       0.77      0.74      0.75       352

01/01/2018 19:05:22 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:05:22 [INFO] exp_shallowmodel: 
[[  7   4   5   7]
 [  2  17   2   6]
 [ 11   7 213  19]
 [  5  13  11  23]]
01/01/2018 19:05:22 [INFO] exp_shallowmodel: ******************** family - Round 22 
01/01/2018 19:05:22 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:05:22 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:05:22 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:05:22 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:05:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:05:22 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:05:22 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:06:03 [INFO] exp_shallowmodel: train time: 41.508s
01/01/2018 19:06:03 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:06:03 [INFO] exp_shallowmodel: accuracy:   0.801
01/01/2018 19:06:03 [INFO] exp_shallowmodel: f1_score:   0.589
01/01/2018 19:06:03 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:06:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.30      0.29        23
          C       0.50      0.67      0.57        27
          F       0.95      0.91      0.93       250
          R       0.57      0.56      0.56        52

avg / total       0.82      0.80      0.81       352

01/01/2018 19:06:03 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:06:03 [INFO] exp_shallowmodel: 
[[  7   3   4   9]
 [  4  18   1   4]
 [  8   5 228   9]
 [  6  10   7  29]]
01/01/2018 19:06:03 [INFO] exp_shallowmodel: ******************** family - Round 23 
01/01/2018 19:06:03 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:06:03 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:06:03 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:06:03 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:06:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:06:03 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:06:03 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:07:34 [INFO] exp_shallowmodel: train time: 90.979s
01/01/2018 19:07:34 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:07:34 [INFO] exp_shallowmodel: accuracy:   0.719
01/01/2018 19:07:34 [INFO] exp_shallowmodel: f1_score:   0.531
01/01/2018 19:07:34 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:07:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.35      0.27        23
          C       0.47      0.56      0.51        27
          F       0.93      0.80      0.86       250
          R       0.43      0.56      0.49        52

avg / total       0.77      0.72      0.74       352

01/01/2018 19:07:34 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:07:34 [INFO] exp_shallowmodel: 
[[  8   4   4   7]
 [  2  15   1   9]
 [ 19   8 201  22]
 [  8   5  10  29]]
01/01/2018 19:07:34 [INFO] exp_shallowmodel: ******************** family - Round 24 
01/01/2018 19:07:34 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:07:34 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:07:34 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:07:34 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:07:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:07:34 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:07:34 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:08:31 [INFO] exp_shallowmodel: train time: 56.688s
01/01/2018 19:08:31 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:08:31 [INFO] exp_shallowmodel: accuracy:   0.784
01/01/2018 19:08:31 [INFO] exp_shallowmodel: f1_score:   0.570
01/01/2018 19:08:31 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:08:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.26      0.27        23
          C       0.50      0.59      0.54        27
          F       0.92      0.90      0.91       250
          R       0.55      0.58      0.56        52

avg / total       0.79      0.78      0.79       352

01/01/2018 19:08:31 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:08:31 [INFO] exp_shallowmodel: 
[[  6   4   9   4]
 [  3  16   2   6]
 [ 10   1 224  15]
 [  3  11   8  30]]
01/01/2018 19:08:31 [INFO] exp_shallowmodel: ******************** family - Round 25 
01/01/2018 19:08:31 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:08:31 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:08:31 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:08:31 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:08:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:08:31 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:08:31 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:09:28 [INFO] exp_shallowmodel: train time: 57.205s
01/01/2018 19:09:28 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:09:28 [INFO] exp_shallowmodel: accuracy:   0.767
01/01/2018 19:09:28 [INFO] exp_shallowmodel: f1_score:   0.577
01/01/2018 19:09:28 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:09:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.57      0.40        23
          C       0.43      0.44      0.44        27
          F       0.95      0.86      0.90       250
          R       0.55      0.60      0.57        52

avg / total       0.81      0.77      0.78       352

01/01/2018 19:09:28 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:09:28 [INFO] exp_shallowmodel: 
[[ 13   1   6   3]
 [  4  12   3   8]
 [ 16   6 214  14]
 [  9   9   3  31]]
01/01/2018 19:09:28 [INFO] exp_shallowmodel: ******************** family - Round 26 
01/01/2018 19:09:28 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:09:28 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:09:28 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:09:28 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:09:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:09:28 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:09:28 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:10:20 [INFO] exp_shallowmodel: train time: 51.158s
01/01/2018 19:10:20 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:10:20 [INFO] exp_shallowmodel: accuracy:   0.764
01/01/2018 19:10:20 [INFO] exp_shallowmodel: f1_score:   0.548
01/01/2018 19:10:20 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:10:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.48      0.38        23
          C       0.41      0.33      0.37        27
          F       0.92      0.88      0.90       250
          R       0.52      0.58      0.55        52

avg / total       0.78      0.76      0.77       352

01/01/2018 19:10:20 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:10:20 [INFO] exp_shallowmodel: 
[[ 11   3   4   5]
 [  7   9   3   8]
 [ 13   3 219  15]
 [  4   7  11  30]]
01/01/2018 19:10:20 [INFO] exp_shallowmodel: ******************** family - Round 27 
01/01/2018 19:10:20 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:10:20 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:10:20 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:10:20 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:10:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:10:20 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:10:20 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:11:04 [INFO] exp_shallowmodel: train time: 44.295s
01/01/2018 19:11:04 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:11:04 [INFO] exp_shallowmodel: accuracy:   0.787
01/01/2018 19:11:04 [INFO] exp_shallowmodel: f1_score:   0.600
01/01/2018 19:11:04 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:11:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.43      0.35        23
          C       0.59      0.63      0.61        27
          F       0.94      0.89      0.92       250
          R       0.52      0.54      0.53        52

avg / total       0.81      0.79      0.80       352

01/01/2018 19:11:04 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:11:04 [INFO] exp_shallowmodel: 
[[ 10   2   4   7]
 [  5  17   0   5]
 [  9   5 222  14]
 [ 10   5   9  28]]
01/01/2018 19:11:04 [INFO] exp_shallowmodel: ******************** family - Round 28 
01/01/2018 19:11:04 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:11:04 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:11:04 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:11:04 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:11:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:11:04 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:11:04 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:11:46 [INFO] exp_shallowmodel: train time: 42.403s
01/01/2018 19:11:46 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:11:46 [INFO] exp_shallowmodel: accuracy:   0.795
01/01/2018 19:11:46 [INFO] exp_shallowmodel: f1_score:   0.606
01/01/2018 19:11:46 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:11:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.43      0.34        23
          C       0.64      0.67      0.65        27
          F       0.94      0.91      0.92       250
          R       0.53      0.48      0.51        52

avg / total       0.82      0.80      0.80       352

01/01/2018 19:11:46 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:11:46 [INFO] exp_shallowmodel: 
[[ 10   2   4   7]
 [  3  18   1   5]
 [ 11   2 227  10]
 [ 12   6   9  25]]
01/01/2018 19:11:47 [INFO] exp_shallowmodel: ******************** family - Round 29 
01/01/2018 19:11:47 [INFO] exp_shallowmodel: #(data) = 2816
01/01/2018 19:11:47 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:11:47 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:11:47 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:11:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:11:47 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:11:47 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:12:32 [INFO] exp_shallowmodel: train time: 45.073s
01/01/2018 19:12:32 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:12:32 [INFO] exp_shallowmodel: accuracy:   0.793
01/01/2018 19:12:32 [INFO] exp_shallowmodel: f1_score:   0.594
01/01/2018 19:12:32 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:12:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.44      0.39        25
          C       0.47      0.63      0.54        27
          F       0.93      0.92      0.93       251
          R       0.59      0.46      0.51        59

avg / total       0.80      0.79      0.79       362

01/01/2018 19:12:32 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:12:32 [INFO] exp_shallowmodel: 
[[ 11   3   4   7]
 [  2  17   4   4]
 [  9   2 232   8]
 [  9  14   9  27]]
01/01/2018 19:12:32 [INFO] exp_shallowmodel: ******************** family - Round 30 
01/01/2018 19:12:32 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:12:32 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:12:32 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:12:32 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:12:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:12:32 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:12:32 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:13:25 [INFO] exp_shallowmodel: train time: 53.245s
01/01/2018 19:13:25 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:13:25 [INFO] exp_shallowmodel: accuracy:   0.773
01/01/2018 19:13:25 [INFO] exp_shallowmodel: f1_score:   0.551
01/01/2018 19:13:25 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:13:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.30      0.28        23
          C       0.41      0.59      0.48        27
          F       0.93      0.89      0.91       250
          R       0.55      0.50      0.53        52

avg / total       0.79      0.77      0.78       352

01/01/2018 19:13:25 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:13:25 [INFO] exp_shallowmodel: 
[[  7   3   9   4]
 [  4  16   0   7]
 [ 10   7 223  10]
 [  6  13   7  26]]
01/01/2018 19:13:25 [INFO] exp_shallowmodel: ******************** family - Round 31 
01/01/2018 19:13:25 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:13:25 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:13:25 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:13:25 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:13:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:13:25 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:13:25 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:14:26 [INFO] exp_shallowmodel: train time: 60.448s
01/01/2018 19:14:26 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:14:26 [INFO] exp_shallowmodel: accuracy:   0.767
01/01/2018 19:14:26 [INFO] exp_shallowmodel: f1_score:   0.544
01/01/2018 19:14:26 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:14:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.30      0.26        23
          C       0.42      0.52      0.47        27
          F       0.93      0.88      0.91       250
          R       0.55      0.54      0.54        52

avg / total       0.79      0.77      0.78       352

01/01/2018 19:14:26 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:14:26 [INFO] exp_shallowmodel: 
[[  7   0   9   7]
 [  8  14   1   4]
 [  9   8 221  12]
 [  7  11   6  28]]
01/01/2018 19:14:26 [INFO] exp_shallowmodel: ******************** family - Round 32 
01/01/2018 19:14:26 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:14:26 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:14:26 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:14:26 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:14:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:14:26 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:14:26 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:15:25 [INFO] exp_shallowmodel: train time: 59.545s
01/01/2018 19:15:25 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:15:25 [INFO] exp_shallowmodel: accuracy:   0.773
01/01/2018 19:15:25 [INFO] exp_shallowmodel: f1_score:   0.563
01/01/2018 19:15:25 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:15:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.35      0.28        23
          C       0.44      0.63      0.52        27
          F       0.94      0.88      0.91       250
          R       0.62      0.50      0.55        52

avg / total       0.80      0.77      0.79       352

01/01/2018 19:15:25 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:15:25 [INFO] exp_shallowmodel: 
[[  8   1   5   9]
 [  6  17   2   2]
 [ 18   6 221   5]
 [  3  15   8  26]]
01/01/2018 19:15:25 [INFO] exp_shallowmodel: ******************** family - Round 33 
01/01/2018 19:15:25 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:15:25 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:15:25 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:15:25 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:15:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:15:25 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:15:25 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:16:17 [INFO] exp_shallowmodel: train time: 52.143s
01/01/2018 19:16:17 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:16:17 [INFO] exp_shallowmodel: accuracy:   0.784
01/01/2018 19:16:17 [INFO] exp_shallowmodel: f1_score:   0.577
01/01/2018 19:16:17 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:16:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.39      0.38        23
          C       0.45      0.48      0.46        27
          F       0.94      0.89      0.92       250
          R       0.50      0.60      0.54        52

avg / total       0.80      0.78      0.79       352

01/01/2018 19:16:17 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:16:17 [INFO] exp_shallowmodel: 
[[  9   2   5   7]
 [  2  13   2  10]
 [  9   4 223  14]
 [  4  10   7  31]]
01/01/2018 19:16:18 [INFO] exp_shallowmodel: ******************** family - Round 34 
01/01/2018 19:16:18 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:16:18 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:16:18 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:16:18 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:16:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:16:18 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:16:18 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:17:30 [INFO] exp_shallowmodel: train time: 72.871s
01/01/2018 19:17:30 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:17:30 [INFO] exp_shallowmodel: accuracy:   0.807
01/01/2018 19:17:30 [INFO] exp_shallowmodel: f1_score:   0.585
01/01/2018 19:17:30 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:17:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.43      0.38        23
          C       0.37      0.48      0.42        27
          F       0.96      0.93      0.94       250
          R       0.63      0.56      0.59        52

avg / total       0.83      0.81      0.81       352

01/01/2018 19:17:30 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:17:30 [INFO] exp_shallowmodel: 
[[ 10   5   2   6]
 [  5  13   3   6]
 [  7   6 232   5]
 [  7  11   5  29]]
01/01/2018 19:17:30 [INFO] exp_shallowmodel: ******************** family - Round 35 
01/01/2018 19:17:30 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:17:30 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:17:30 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:17:30 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:17:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:17:30 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:17:30 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:18:12 [INFO] exp_shallowmodel: train time: 41.548s
01/01/2018 19:18:12 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:18:12 [INFO] exp_shallowmodel: accuracy:   0.767
01/01/2018 19:18:12 [INFO] exp_shallowmodel: f1_score:   0.564
01/01/2018 19:18:12 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:18:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.39      0.31        23
          C       0.49      0.63      0.55        27
          F       0.94      0.88      0.91       250
          R       0.51      0.48      0.50        52

avg / total       0.80      0.77      0.78       352

01/01/2018 19:18:12 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:18:12 [INFO] exp_shallowmodel: 
[[  9   4   3   7]
 [  5  17   1   4]
 [ 11   7 219  13]
 [ 11   7   9  25]]
01/01/2018 19:18:12 [INFO] exp_shallowmodel: ******************** family - Round 36 
01/01/2018 19:18:12 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:18:12 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:18:12 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:18:12 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:18:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:18:12 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:18:12 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:19:17 [INFO] exp_shallowmodel: train time: 65.091s
01/01/2018 19:19:17 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:19:17 [INFO] exp_shallowmodel: accuracy:   0.793
01/01/2018 19:19:17 [INFO] exp_shallowmodel: f1_score:   0.598
01/01/2018 19:19:17 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:19:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.52      0.44        23
          C       0.47      0.59      0.52        27
          F       0.93      0.91      0.92       250
          R       0.56      0.46      0.51        52

avg / total       0.80      0.79      0.80       352

01/01/2018 19:19:17 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:19:17 [INFO] exp_shallowmodel: 
[[ 12   3   4   4]
 [  4  16   0   7]
 [  9   6 227   8]
 [  6   9  13  24]]
01/01/2018 19:19:17 [INFO] exp_shallowmodel: ******************** family - Round 37 
01/01/2018 19:19:17 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:19:17 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:19:17 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:19:17 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:19:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:19:17 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:19:17 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:20:12 [INFO] exp_shallowmodel: train time: 55.136s
01/01/2018 19:20:12 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:20:12 [INFO] exp_shallowmodel: accuracy:   0.767
01/01/2018 19:20:12 [INFO] exp_shallowmodel: f1_score:   0.569
01/01/2018 19:20:12 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:20:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.48      0.34        23
          C       0.44      0.41      0.42        27
          F       0.93      0.86      0.90       250
          R       0.60      0.63      0.62        52

avg / total       0.80      0.77      0.78       352

01/01/2018 19:20:12 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:20:12 [INFO] exp_shallowmodel: 
[[ 11   4   6   2]
 [  5  11   4   7]
 [ 17   5 215  13]
 [  9   5   5  33]]
01/01/2018 19:20:13 [INFO] exp_shallowmodel: ******************** family - Round 38 
01/01/2018 19:20:13 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:20:13 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:20:13 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:20:13 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:20:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:20:13 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:20:13 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:21:14 [INFO] exp_shallowmodel: train time: 61.575s
01/01/2018 19:21:14 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:21:14 [INFO] exp_shallowmodel: accuracy:   0.753
01/01/2018 19:21:14 [INFO] exp_shallowmodel: f1_score:   0.540
01/01/2018 19:21:14 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:21:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.48      0.34        23
          C       0.39      0.56      0.46        27
          F       0.94      0.87      0.91       250
          R       0.50      0.40      0.45        52

avg / total       0.79      0.75      0.77       352

01/01/2018 19:21:14 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:21:14 [INFO] exp_shallowmodel: 
[[ 11   3   2   7]
 [  5  15   2   5]
 [ 16   7 218   9]
 [  9  13   9  21]]
01/01/2018 19:21:14 [INFO] exp_shallowmodel: ******************** family - Round 39 
01/01/2018 19:21:14 [INFO] exp_shallowmodel: #(data) = 2816
01/01/2018 19:21:14 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:21:14 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:21:14 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:21:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:21:14 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:21:14 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:22:13 [INFO] exp_shallowmodel: train time: 58.834s
01/01/2018 19:22:13 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:22:13 [INFO] exp_shallowmodel: accuracy:   0.768
01/01/2018 19:22:13 [INFO] exp_shallowmodel: f1_score:   0.572
01/01/2018 19:22:13 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:22:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.44      0.34        25
          C       0.58      0.52      0.55        27
          F       0.91      0.90      0.91       251
          R       0.53      0.46      0.49        59

avg / total       0.78      0.77      0.77       362

01/01/2018 19:22:13 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:22:13 [INFO] exp_shallowmodel: 
[[ 11   0  10   4]
 [  4  14   4   5]
 [  9   1 226  15]
 [ 15   9   8  27]]
01/01/2018 19:22:13 [INFO] exp_shallowmodel: ******************** family - Round 40 
01/01/2018 19:22:13 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:22:13 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:22:13 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:22:13 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:22:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:22:13 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:22:13 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:23:25 [INFO] exp_shallowmodel: train time: 72.053s
01/01/2018 19:23:25 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:23:25 [INFO] exp_shallowmodel: accuracy:   0.759
01/01/2018 19:23:25 [INFO] exp_shallowmodel: f1_score:   0.558
01/01/2018 19:23:25 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:23:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.48      0.42        23
          C       0.43      0.48      0.46        27
          F       0.92      0.87      0.90       250
          R       0.45      0.48      0.47        52

avg / total       0.78      0.76      0.77       352

01/01/2018 19:23:25 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:23:25 [INFO] exp_shallowmodel: 
[[ 11   1   3   8]
 [  5  13   3   6]
 [  9   7 218  16]
 [  5   9  13  25]]
01/01/2018 19:23:25 [INFO] exp_shallowmodel: ******************** family - Round 41 
01/01/2018 19:23:25 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:23:25 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:23:25 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:23:25 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:23:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:23:25 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:23:25 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:24:31 [INFO] exp_shallowmodel: train time: 65.669s
01/01/2018 19:24:31 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:24:31 [INFO] exp_shallowmodel: accuracy:   0.764
01/01/2018 19:24:31 [INFO] exp_shallowmodel: f1_score:   0.551
01/01/2018 19:24:31 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:24:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.43      0.33        23
          C       0.40      0.37      0.38        27
          F       0.93      0.87      0.90       250
          R       0.56      0.62      0.59        52

avg / total       0.79      0.76      0.78       352

01/01/2018 19:24:31 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:24:31 [INFO] exp_shallowmodel: 
[[ 10   5   4   4]
 [  2  10   4  11]
 [ 18   5 217  10]
 [  7   5   8  32]]
01/01/2018 19:24:31 [INFO] exp_shallowmodel: ******************** family - Round 42 
01/01/2018 19:24:31 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:24:31 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:24:31 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:24:31 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:24:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:24:31 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:24:31 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:25:37 [INFO] exp_shallowmodel: train time: 66.142s
01/01/2018 19:25:37 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:25:37 [INFO] exp_shallowmodel: accuracy:   0.781
01/01/2018 19:25:37 [INFO] exp_shallowmodel: f1_score:   0.595
01/01/2018 19:25:37 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:25:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.52      0.39        23
          C       0.46      0.67      0.55        27
          F       0.96      0.88      0.92       250
          R       0.55      0.50      0.53        52

avg / total       0.82      0.78      0.80       352

01/01/2018 19:25:37 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:25:37 [INFO] exp_shallowmodel: 
[[ 12   1   4   6]
 [  4  18   0   5]
 [ 14   7 219  10]
 [  8  13   5  26]]
01/01/2018 19:25:37 [INFO] exp_shallowmodel: ******************** family - Round 43 
01/01/2018 19:25:37 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:25:37 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:25:37 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:25:37 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:25:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:25:37 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:25:37 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:26:20 [INFO] exp_shallowmodel: train time: 42.774s
01/01/2018 19:26:20 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:26:20 [INFO] exp_shallowmodel: accuracy:   0.787
01/01/2018 19:26:20 [INFO] exp_shallowmodel: f1_score:   0.604
01/01/2018 19:26:20 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:26:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.41      0.48      0.44        23
          C       0.52      0.52      0.52        27
          F       0.93      0.88      0.91       250
          R       0.51      0.60      0.55        52

avg / total       0.80      0.79      0.79       352

01/01/2018 19:26:20 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:26:20 [INFO] exp_shallowmodel: 
[[ 11   3   6   3]
 [  0  14   1  12]
 [ 12   2 221  15]
 [  4   8   9  31]]
01/01/2018 19:26:20 [INFO] exp_shallowmodel: ******************** family - Round 44 
01/01/2018 19:26:20 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:26:20 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:26:20 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:26:20 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:26:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:26:20 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:26:20 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:26:58 [INFO] exp_shallowmodel: train time: 37.869s
01/01/2018 19:26:58 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:26:58 [INFO] exp_shallowmodel: accuracy:   0.790
01/01/2018 19:26:58 [INFO] exp_shallowmodel: f1_score:   0.557
01/01/2018 19:26:58 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:26:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.35      0.39        23
          C       0.37      0.37      0.37        27
          F       0.93      0.92      0.93       250
          R       0.50      0.60      0.54        52

avg / total       0.80      0.79      0.79       352

01/01/2018 19:26:58 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:26:58 [INFO] exp_shallowmodel: 
[[  8   0   5  10]
 [  1  10   4  12]
 [  4   8 229   9]
 [  5   9   7  31]]
01/01/2018 19:26:58 [INFO] exp_shallowmodel: ******************** family - Round 45 
01/01/2018 19:26:58 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:26:58 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:26:58 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:26:58 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:26:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:26:58 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:26:58 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:27:35 [INFO] exp_shallowmodel: train time: 37.075s
01/01/2018 19:27:35 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:27:35 [INFO] exp_shallowmodel: accuracy:   0.784
01/01/2018 19:27:35 [INFO] exp_shallowmodel: f1_score:   0.574
01/01/2018 19:27:35 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:27:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.30      0.27        23
          C       0.55      0.63      0.59        27
          F       0.93      0.90      0.92       250
          R       0.53      0.52      0.52        52

avg / total       0.80      0.78      0.79       352

01/01/2018 19:27:35 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:27:35 [INFO] exp_shallowmodel: 
[[  7   3   7   6]
 [  4  17   0   6]
 [  7   6 225  12]
 [ 11   5   9  27]]
01/01/2018 19:27:35 [INFO] exp_shallowmodel: ******************** family - Round 46 
01/01/2018 19:27:35 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:27:35 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:27:35 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:27:35 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:27:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:27:35 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:27:35 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:28:49 [INFO] exp_shallowmodel: train time: 74.119s
01/01/2018 19:28:49 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:28:49 [INFO] exp_shallowmodel: accuracy:   0.807
01/01/2018 19:28:49 [INFO] exp_shallowmodel: f1_score:   0.619
01/01/2018 19:28:49 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:28:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.39      0.33        23
          C       0.51      0.74      0.61        27
          F       0.95      0.90      0.92       250
          R       0.67      0.56      0.61        52

avg / total       0.83      0.81      0.81       352

01/01/2018 19:28:49 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:28:49 [INFO] exp_shallowmodel: 
[[  9   5   6   3]
 [  1  20   1   5]
 [ 13   5 226   6]
 [  8   9   6  29]]
01/01/2018 19:28:50 [INFO] exp_shallowmodel: ******************** family - Round 47 
01/01/2018 19:28:50 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:28:50 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:28:50 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:28:50 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:28:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:28:50 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:28:50 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:29:52 [INFO] exp_shallowmodel: train time: 62.742s
01/01/2018 19:29:52 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:29:52 [INFO] exp_shallowmodel: accuracy:   0.778
01/01/2018 19:29:52 [INFO] exp_shallowmodel: f1_score:   0.588
01/01/2018 19:29:52 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:29:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.48      0.39        23
          C       0.46      0.59      0.52        27
          F       0.94      0.88      0.91       250
          R       0.55      0.52      0.53        52

avg / total       0.80      0.78      0.79       352

01/01/2018 19:29:52 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:29:52 [INFO] exp_shallowmodel: 
[[ 11   3   4   5]
 [  2  16   2   7]
 [ 14   6 220  10]
 [  6  10   9  27]]
01/01/2018 19:29:52 [INFO] exp_shallowmodel: ******************** family - Round 48 
01/01/2018 19:29:52 [INFO] exp_shallowmodel: #(data) = 2826
01/01/2018 19:29:52 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:29:52 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:29:52 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:29:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:29:52 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:29:52 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:30:46 [INFO] exp_shallowmodel: train time: 53.569s
01/01/2018 19:30:46 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:30:46 [INFO] exp_shallowmodel: accuracy:   0.778
01/01/2018 19:30:46 [INFO] exp_shallowmodel: f1_score:   0.599
01/01/2018 19:30:46 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:30:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.57      0.38        23
          C       0.45      0.52      0.48        27
          F       0.94      0.86      0.90       250
          R       0.67      0.60      0.63        52

avg / total       0.82      0.78      0.80       352

01/01/2018 19:30:46 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:30:46 [INFO] exp_shallowmodel: 
[[ 13   4   4   2]
 [  8  14   2   3]
 [ 15   9 216  10]
 [ 10   4   7  31]]
01/01/2018 19:30:46 [INFO] exp_shallowmodel: ******************** family - Round 49 
01/01/2018 19:30:46 [INFO] exp_shallowmodel: #(data) = 2816
01/01/2018 19:30:46 [INFO] exp_shallowmodel: #(feature) = 1042
01/01/2018 19:30:46 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:30:46 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:30:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:30:46 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:30:46 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:31:43 [INFO] exp_shallowmodel: train time: 57.377s
01/01/2018 19:31:43 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:31:43 [INFO] exp_shallowmodel: accuracy:   0.787
01/01/2018 19:31:43 [INFO] exp_shallowmodel: f1_score:   0.595
01/01/2018 19:31:43 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:31:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.40      0.36        25
          C       0.48      0.56      0.52        27
          F       0.92      0.90      0.91       251
          R       0.63      0.56      0.59        59

avg / total       0.80      0.79      0.79       362

01/01/2018 19:31:43 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:31:43 [INFO] exp_shallowmodel: 
[[ 10   5   7   3]
 [  1  15   1  10]
 [ 14   4 227   6]
 [  6   7  13  33]]
01/01/2018 19:31:51 [INFO] exp_shallowmodel: 1	3

01/01/2018 19:31:51 [INFO] exp_shallowmodel: 2.1	82

01/01/2018 19:31:51 [INFO] exp_shallowmodel: 2.2	2

01/01/2018 19:31:51 [INFO] exp_shallowmodel: 2.3.1	1

01/01/2018 19:31:51 [INFO] exp_shallowmodel: 3	5

01/01/2018 19:31:51 [INFO] exp_shallowmodel: 5	14947

01/01/2018 19:31:51 [INFO] exp_shallowmodel: 6	3530

01/01/2018 19:31:51 [INFO] exp_shallowmodel: 7	4335

01/01/2018 19:31:51 [INFO] exp_shallowmodel: 9.1	900

01/01/2018 19:31:51 [INFO] exp_shallowmodel: 9.2.1	1

01/01/2018 19:31:51 [INFO] exp_shallowmodel: 9.3.1	1

01/01/2018 19:31:52 [INFO] exp_shallowmodel: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
01/01/2018 19:31:52 [INFO] exp_shallowmodel:           dataset=ghome
01/01/2018 19:31:52 [INFO] exp_shallowmodel:           k_feature_to_keep=7
01/01/2018 19:31:52 [INFO] exp_shallowmodel:           X_new.shape=(5241, 1041)
01/01/2018 19:31:52 [INFO] exp_shallowmodel:           #(X_selected)=128
01/01/2018 19:31:52 [INFO] exp_shallowmodel:           #(X_not_selectable)=913
01/01/2018 19:31:52 [INFO] exp_shallowmodel: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
01/01/2018 19:31:52 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
01/01/2018 19:31:52 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:31:52 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:31:52 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:31:52 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:31:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:31:52 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:31:52 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:32:46 [INFO] exp_shallowmodel: train time: 54.515s
01/01/2018 19:32:46 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:32:46 [INFO] exp_shallowmodel: accuracy:   0.828
01/01/2018 19:32:46 [INFO] exp_shallowmodel: f1_score:   0.525
01/01/2018 19:32:46 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:32:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.46      0.50        59
          C       0.06      0.08      0.07        12
          F       0.94      0.93      0.94       396
          R       0.56      0.64      0.60        55

avg / total       0.83      0.83      0.83       522

01/01/2018 19:32:46 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:32:46 [INFO] exp_shallowmodel: 
[[ 27   8  12  12]
 [  2   1   5   4]
 [ 10   6 369  11]
 [ 11   2   7  35]]
01/01/2018 19:32:47 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
01/01/2018 19:32:47 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:32:47 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:32:47 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:32:47 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:32:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:32:47 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:32:47 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:33:43 [INFO] exp_shallowmodel: train time: 56.163s
01/01/2018 19:33:43 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:33:43 [INFO] exp_shallowmodel: accuracy:   0.814
01/01/2018 19:33:43 [INFO] exp_shallowmodel: f1_score:   0.558
01/01/2018 19:33:43 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:33:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.53      0.49        59
          C       0.24      0.33      0.28        12
          F       0.97      0.90      0.93       396
          R       0.47      0.60      0.53        55

avg / total       0.84      0.81      0.83       522

01/01/2018 19:33:43 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:33:43 [INFO] exp_shallowmodel: 
[[ 31   5   7  16]
 [  4   4   1   3]
 [ 19   2 357  18]
 [ 13   6   3  33]]
01/01/2018 19:33:43 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
01/01/2018 19:33:43 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:33:43 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:33:43 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:33:43 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:33:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:33:43 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:33:43 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:34:21 [INFO] exp_shallowmodel: train time: 38.510s
01/01/2018 19:34:21 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:34:21 [INFO] exp_shallowmodel: accuracy:   0.816
01/01/2018 19:34:21 [INFO] exp_shallowmodel: f1_score:   0.486
01/01/2018 19:34:21 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:34:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.51      0.49      0.50        59
          C       0.00      0.00      0.00        12
          F       0.94      0.93      0.93       396
          R       0.48      0.55      0.51        55

avg / total       0.82      0.82      0.82       522

01/01/2018 19:34:21 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:34:21 [INFO] exp_shallowmodel: 
[[ 29   4  11  15]
 [  4   0   4   4]
 [ 13   3 367  13]
 [ 11   4  10  30]]
01/01/2018 19:34:22 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
01/01/2018 19:34:22 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:34:22 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:34:22 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:34:22 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:34:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:34:22 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:34:22 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:35:08 [INFO] exp_shallowmodel: train time: 46.139s
01/01/2018 19:35:08 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:35:08 [INFO] exp_shallowmodel: accuracy:   0.839
01/01/2018 19:35:08 [INFO] exp_shallowmodel: f1_score:   0.580
01/01/2018 19:35:08 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:35:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.63      0.60        59
          C       0.21      0.25      0.23        12
          F       0.95      0.93      0.94       396
          R       0.54      0.56      0.55        55

avg / total       0.85      0.84      0.84       522

01/01/2018 19:35:08 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:35:08 [INFO] exp_shallowmodel: 
[[ 37   4  10   8]
 [  4   3   1   4]
 [ 11   4 367  14]
 [ 13   3   8  31]]
01/01/2018 19:35:08 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
01/01/2018 19:35:08 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:35:08 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:35:08 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:35:08 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:35:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:35:08 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:35:08 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:35:47 [INFO] exp_shallowmodel: train time: 38.910s
01/01/2018 19:35:47 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:35:47 [INFO] exp_shallowmodel: accuracy:   0.805
01/01/2018 19:35:47 [INFO] exp_shallowmodel: f1_score:   0.516
01/01/2018 19:35:47 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:35:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.51      0.58      0.54        59
          C       0.10      0.17      0.12        12
          F       0.95      0.90      0.92       396
          R       0.46      0.49      0.47        55

avg / total       0.83      0.80      0.82       522

01/01/2018 19:35:47 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:35:47 [INFO] exp_shallowmodel: 
[[ 34   5   8  12]
 [  3   2   3   4]
 [ 18   5 357  16]
 [ 12   8   8  27]]
01/01/2018 19:35:47 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
01/01/2018 19:35:47 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:35:47 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:35:47 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:35:47 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:35:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:35:47 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:35:47 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:36:32 [INFO] exp_shallowmodel: train time: 45.039s
01/01/2018 19:36:32 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:36:32 [INFO] exp_shallowmodel: accuracy:   0.824
01/01/2018 19:36:32 [INFO] exp_shallowmodel: f1_score:   0.520
01/01/2018 19:36:32 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:36:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.54      0.55        59
          C       0.06      0.08      0.07        12
          F       0.96      0.92      0.94       396
          R       0.48      0.58      0.52        55

avg / total       0.84      0.82      0.83       522

01/01/2018 19:36:32 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:36:32 [INFO] exp_shallowmodel: 
[[ 32   4   6  17]
 [  4   1   2   5]
 [ 11   7 365  13]
 [ 11   6   6  32]]
01/01/2018 19:36:32 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
01/01/2018 19:36:32 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:36:32 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:36:32 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:36:32 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:36:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:36:32 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:36:32 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:37:09 [INFO] exp_shallowmodel: train time: 36.420s
01/01/2018 19:37:09 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:37:09 [INFO] exp_shallowmodel: accuracy:   0.837
01/01/2018 19:37:09 [INFO] exp_shallowmodel: f1_score:   0.621
01/01/2018 19:37:09 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:37:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.59      0.58        59
          C       0.50      0.42      0.45        12
          F       0.95      0.93      0.94       396
          R       0.48      0.55      0.51        55

avg / total       0.84      0.84      0.84       522

01/01/2018 19:37:09 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:37:09 [INFO] exp_shallowmodel: 
[[ 35   2  10  12]
 [  1   5   4   2]
 [ 11   0 367  18]
 [ 15   3   7  30]]
01/01/2018 19:37:09 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
01/01/2018 19:37:09 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:37:09 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:37:09 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:37:09 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:37:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:37:09 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:37:09 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:37:45 [INFO] exp_shallowmodel: train time: 36.774s
01/01/2018 19:37:45 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:37:45 [INFO] exp_shallowmodel: accuracy:   0.843
01/01/2018 19:37:45 [INFO] exp_shallowmodel: f1_score:   0.580
01/01/2018 19:37:45 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:37:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.53      0.55        59
          C       0.19      0.25      0.21        12
          F       0.94      0.94      0.94       396
          R       0.59      0.64      0.61        55

avg / total       0.85      0.84      0.84       522

01/01/2018 19:37:45 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:37:45 [INFO] exp_shallowmodel: 
[[ 31   8  10  10]
 [  4   3   3   2]
 [  9   4 371  12]
 [  9   1  10  35]]
01/01/2018 19:37:46 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
01/01/2018 19:37:46 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:37:46 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:37:46 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:37:46 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:37:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:37:46 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:37:46 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:38:20 [INFO] exp_shallowmodel: train time: 34.283s
01/01/2018 19:38:20 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:38:20 [INFO] exp_shallowmodel: accuracy:   0.839
01/01/2018 19:38:20 [INFO] exp_shallowmodel: f1_score:   0.527
01/01/2018 19:38:20 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:38:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.58      0.58        59
          C       0.07      0.08      0.07        12
          F       0.95      0.95      0.95       396
          R       0.53      0.49      0.51        55

avg / total       0.84      0.84      0.84       522

01/01/2018 19:38:20 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:38:20 [INFO] exp_shallowmodel: 
[[ 34   3   8  14]
 [  6   1   3   2]
 [  8   4 376   8]
 [ 11   7  10  27]]
01/01/2018 19:38:20 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
01/01/2018 19:38:20 [INFO] exp_shallowmodel: #(data) = 4176
01/01/2018 19:38:20 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:38:20 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:38:20 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:38:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:38:20 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:38:20 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:38:57 [INFO] exp_shallowmodel: train time: 36.755s
01/01/2018 19:38:57 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:38:57 [INFO] exp_shallowmodel: accuracy:   0.831
01/01/2018 19:38:57 [INFO] exp_shallowmodel: f1_score:   0.579
01/01/2018 19:38:57 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:38:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.52      0.69      0.59        64
          C       0.20      0.21      0.21        14
          F       0.96      0.92      0.94       402
          R       0.60      0.56      0.58        63

avg / total       0.84      0.83      0.84       543

01/01/2018 19:38:57 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:38:57 [INFO] exp_shallowmodel: 
[[ 44   5   6   9]
 [  2   3   3   6]
 [ 23   2 369   8]
 [ 15   5   8  35]]
01/01/2018 19:38:57 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
01/01/2018 19:38:57 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:38:57 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:38:57 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:38:57 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:38:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:38:57 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:38:57 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:39:26 [INFO] exp_shallowmodel: train time: 28.602s
01/01/2018 19:39:26 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:39:26 [INFO] exp_shallowmodel: accuracy:   0.812
01/01/2018 19:39:26 [INFO] exp_shallowmodel: f1_score:   0.537
01/01/2018 19:39:26 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:39:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.64      0.51      0.57        59
          C       0.15      0.25      0.19        12
          F       0.92      0.92      0.92       396
          R       0.46      0.49      0.47        55

avg / total       0.82      0.81      0.82       522

01/01/2018 19:39:26 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:39:26 [INFO] exp_shallowmodel: 
[[ 30   5  11  13]
 [  0   3   4   5]
 [ 12   6 364  14]
 [  5   6  17  27]]
01/01/2018 19:39:26 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
01/01/2018 19:39:26 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:39:26 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:39:26 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:39:26 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:39:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:39:26 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:39:26 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:40:14 [INFO] exp_shallowmodel: train time: 48.264s
01/01/2018 19:40:14 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:40:14 [INFO] exp_shallowmodel: accuracy:   0.837
01/01/2018 19:40:14 [INFO] exp_shallowmodel: f1_score:   0.584
01/01/2018 19:40:14 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:40:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.61      0.57        59
          C       0.25      0.33      0.29        12
          F       0.96      0.93      0.94       396
          R       0.53      0.55      0.54        55

avg / total       0.85      0.84      0.84       522

01/01/2018 19:40:14 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:40:14 [INFO] exp_shallowmodel: 
[[ 36   4   8  11]
 [  4   4   1   3]
 [ 13   3 367  13]
 [ 14   5   6  30]]
01/01/2018 19:40:14 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
01/01/2018 19:40:14 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:40:14 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:40:14 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:40:14 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:40:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:40:14 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:40:14 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:40:59 [INFO] exp_shallowmodel: train time: 44.432s
01/01/2018 19:40:59 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:40:59 [INFO] exp_shallowmodel: accuracy:   0.820
01/01/2018 19:40:59 [INFO] exp_shallowmodel: f1_score:   0.514
01/01/2018 19:40:59 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:40:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.44      0.43        59
          C       0.14      0.17      0.15        12
          F       0.95      0.94      0.94       396
          R       0.53      0.53      0.53        55

avg / total       0.82      0.82      0.82       522

01/01/2018 19:40:59 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:40:59 [INFO] exp_shallowmodel: 
[[ 26   6  12  15]
 [  4   2   3   3]
 [ 16   1 371   8]
 [ 15   5   6  29]]
01/01/2018 19:40:59 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
01/01/2018 19:40:59 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:40:59 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:40:59 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:40:59 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:40:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:40:59 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:40:59 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:41:47 [INFO] exp_shallowmodel: train time: 48.029s
01/01/2018 19:41:47 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:41:47 [INFO] exp_shallowmodel: accuracy:   0.833
01/01/2018 19:41:47 [INFO] exp_shallowmodel: f1_score:   0.583
01/01/2018 19:41:47 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:41:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.59      0.58        59
          C       0.17      0.33      0.23        12
          F       0.97      0.91      0.94       396
          R       0.54      0.64      0.58        55

avg / total       0.86      0.83      0.85       522

01/01/2018 19:41:47 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:41:47 [INFO] exp_shallowmodel: 
[[ 35   6   6  12]
 [  3   4   2   3]
 [ 12   8 361  15]
 [ 12   5   3  35]]
01/01/2018 19:41:47 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
01/01/2018 19:41:47 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:41:47 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:41:47 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:41:47 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:41:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:41:47 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:41:47 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:42:42 [INFO] exp_shallowmodel: train time: 55.119s
01/01/2018 19:42:42 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:42:42 [INFO] exp_shallowmodel: accuracy:   0.824
01/01/2018 19:42:42 [INFO] exp_shallowmodel: f1_score:   0.540
01/01/2018 19:42:42 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:42:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.52      0.54      0.53        59
          C       0.15      0.17      0.16        12
          F       0.94      0.92      0.93       396
          R       0.51      0.56      0.53        55

avg / total       0.83      0.82      0.83       522

01/01/2018 19:42:42 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:42:42 [INFO] exp_shallowmodel: 
[[ 32   2  12  13]
 [  4   2   3   3]
 [ 10   7 365  14]
 [ 15   2   7  31]]
01/01/2018 19:42:42 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
01/01/2018 19:42:42 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:42:42 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:42:42 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:42:42 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:42:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:42:42 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:42:42 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:43:24 [INFO] exp_shallowmodel: train time: 41.828s
01/01/2018 19:43:24 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:43:24 [INFO] exp_shallowmodel: accuracy:   0.845
01/01/2018 19:43:24 [INFO] exp_shallowmodel: f1_score:   0.586
01/01/2018 19:43:24 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:43:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.52      0.64      0.58        59
          C       0.21      0.25      0.23        12
          F       0.96      0.93      0.95       396
          R       0.60      0.58      0.59        55

avg / total       0.86      0.84      0.85       522

01/01/2018 19:43:24 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:43:24 [INFO] exp_shallowmodel: 
[[ 38   3  11   7]
 [  5   3   0   4]
 [ 14   4 368  10]
 [ 16   4   3  32]]
01/01/2018 19:43:24 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
01/01/2018 19:43:24 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:43:24 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:43:24 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:43:24 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:43:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:43:24 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:43:24 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:44:13 [INFO] exp_shallowmodel: train time: 48.768s
01/01/2018 19:44:13 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:44:13 [INFO] exp_shallowmodel: accuracy:   0.845
01/01/2018 19:44:13 [INFO] exp_shallowmodel: f1_score:   0.573
01/01/2018 19:44:13 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:44:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.63      0.60        59
          C       0.12      0.17      0.14        12
          F       0.97      0.92      0.95       396
          R       0.56      0.65      0.61        55

avg / total       0.86      0.84      0.85       522

01/01/2018 19:44:13 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:44:13 [INFO] exp_shallowmodel: 
[[ 37   5   5  12]
 [  3   2   2   5]
 [ 12   7 366  11]
 [ 12   3   4  36]]
01/01/2018 19:44:13 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
01/01/2018 19:44:13 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:44:13 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:44:13 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:44:13 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:44:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:44:13 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:44:13 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:44:53 [INFO] exp_shallowmodel: train time: 39.833s
01/01/2018 19:44:53 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:44:53 [INFO] exp_shallowmodel: accuracy:   0.808
01/01/2018 19:44:53 [INFO] exp_shallowmodel: f1_score:   0.538
01/01/2018 19:44:53 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:44:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.48      0.49      0.48        59
          C       0.23      0.25      0.24        12
          F       0.94      0.91      0.92       396
          R       0.48      0.55      0.51        55

avg / total       0.82      0.81      0.81       522

01/01/2018 19:44:53 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:44:53 [INFO] exp_shallowmodel: 
[[ 29   5  11  14]
 [  2   3   5   2]
 [ 17   2 360  17]
 [ 13   3   9  30]]
01/01/2018 19:44:53 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
01/01/2018 19:44:53 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:44:53 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:44:53 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:44:53 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:44:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:44:53 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:44:53 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:45:32 [INFO] exp_shallowmodel: train time: 38.723s
01/01/2018 19:45:32 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:45:32 [INFO] exp_shallowmodel: accuracy:   0.839
01/01/2018 19:45:32 [INFO] exp_shallowmodel: f1_score:   0.584
01/01/2018 19:45:32 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:45:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.56      0.55        59
          C       0.30      0.25      0.27        12
          F       0.95      0.93      0.94       396
          R       0.53      0.62      0.57        55

avg / total       0.85      0.84      0.84       522

01/01/2018 19:45:32 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:45:32 [INFO] exp_shallowmodel: 
[[ 33   3  10  13]
 [  5   3   1   3]
 [ 12   2 368  14]
 [ 11   2   8  34]]
01/01/2018 19:45:32 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
01/01/2018 19:45:32 [INFO] exp_shallowmodel: #(data) = 4176
01/01/2018 19:45:32 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:45:32 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:45:32 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:45:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:45:32 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:45:32 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:46:04 [INFO] exp_shallowmodel: train time: 31.475s
01/01/2018 19:46:04 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:46:04 [INFO] exp_shallowmodel: accuracy:   0.820
01/01/2018 19:46:04 [INFO] exp_shallowmodel: f1_score:   0.539
01/01/2018 19:46:04 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:46:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.55      0.52        64
          C       0.18      0.14      0.16        14
          F       0.94      0.93      0.94       402
          R       0.52      0.56      0.54        63

avg / total       0.82      0.82      0.82       543

01/01/2018 19:46:04 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:46:04 [INFO] exp_shallowmodel: 
[[ 35   2  10  17]
 [  4   2   5   3]
 [ 15   2 373  12]
 [ 16   5   7  35]]
01/01/2018 19:46:04 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
01/01/2018 19:46:04 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:46:04 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:46:04 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:46:04 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:46:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:46:04 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:46:04 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:46:56 [INFO] exp_shallowmodel: train time: 51.851s
01/01/2018 19:46:56 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:46:56 [INFO] exp_shallowmodel: accuracy:   0.833
01/01/2018 19:46:56 [INFO] exp_shallowmodel: f1_score:   0.546
01/01/2018 19:46:56 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:46:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.68      0.63        59
          C       0.08      0.08      0.08        12
          F       0.95      0.92      0.93       396
          R       0.50      0.56      0.53        55

avg / total       0.84      0.83      0.84       522

01/01/2018 19:46:56 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:46:56 [INFO] exp_shallowmodel: 
[[ 40   3   8   8]
 [  4   1   3   4]
 [ 10   4 363  19]
 [ 13   4   7  31]]
01/01/2018 19:46:56 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
01/01/2018 19:46:56 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:46:56 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:46:56 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:46:56 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:46:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:46:56 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:46:56 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:47:47 [INFO] exp_shallowmodel: train time: 51.484s
01/01/2018 19:47:47 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:47:47 [INFO] exp_shallowmodel: accuracy:   0.818
01/01/2018 19:47:47 [INFO] exp_shallowmodel: f1_score:   0.543
01/01/2018 19:47:47 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:47:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.53      0.64      0.58        59
          C       0.13      0.17      0.15        12
          F       0.96      0.90      0.93       396
          R       0.47      0.56      0.51        55

avg / total       0.84      0.82      0.83       522

01/01/2018 19:47:47 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:47:47 [INFO] exp_shallowmodel: 
[[ 38   4   7  10]
 [  0   2   1   9]
 [ 18   6 356  16]
 [ 16   3   5  31]]
01/01/2018 19:47:47 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
01/01/2018 19:47:47 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:47:47 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:47:47 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:47:47 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:47:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:47:47 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:47:47 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:48:23 [INFO] exp_shallowmodel: train time: 35.651s
01/01/2018 19:48:23 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:48:23 [INFO] exp_shallowmodel: accuracy:   0.814
01/01/2018 19:48:23 [INFO] exp_shallowmodel: f1_score:   0.561
01/01/2018 19:48:23 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:48:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.52      0.61      0.56        59
          C       0.43      0.25      0.32        12
          F       0.94      0.91      0.92       396
          R       0.41      0.47      0.44        55

avg / total       0.83      0.81      0.82       522

01/01/2018 19:48:23 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:48:23 [INFO] exp_shallowmodel: 
[[ 36   1   8  14]
 [  5   3   2   2]
 [ 15   0 360  21]
 [ 13   3  13  26]]
01/01/2018 19:48:23 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
01/01/2018 19:48:23 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:48:23 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:48:23 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:48:23 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:48:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:48:23 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:48:23 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:48:58 [INFO] exp_shallowmodel: train time: 34.777s
01/01/2018 19:48:58 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:48:58 [INFO] exp_shallowmodel: accuracy:   0.839
01/01/2018 19:48:58 [INFO] exp_shallowmodel: f1_score:   0.545
01/01/2018 19:48:58 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:48:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.53      0.54      0.54        59
          C       0.12      0.17      0.14        12
          F       0.96      0.94      0.95       396
          R       0.53      0.56      0.55        55

avg / total       0.85      0.84      0.84       522

01/01/2018 19:48:58 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:48:58 [INFO] exp_shallowmodel: 
[[ 32   5   9  13]
 [  3   2   3   4]
 [  8   5 373  10]
 [ 17   4   3  31]]
01/01/2018 19:48:58 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
01/01/2018 19:48:58 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:48:58 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:48:58 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:48:58 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:48:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:48:58 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:48:58 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:49:31 [INFO] exp_shallowmodel: train time: 32.928s
01/01/2018 19:49:31 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:49:31 [INFO] exp_shallowmodel: accuracy:   0.826
01/01/2018 19:49:31 [INFO] exp_shallowmodel: f1_score:   0.528
01/01/2018 19:49:31 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:49:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.61      0.59      0.60        59
          C       0.08      0.08      0.08        12
          F       0.94      0.92      0.93       396
          R       0.48      0.53      0.50        55

avg / total       0.83      0.83      0.83       522

01/01/2018 19:49:31 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:49:31 [INFO] exp_shallowmodel: 
[[ 35   0   9  15]
 [  2   1   4   5]
 [ 12   6 366  12]
 [  8   6  12  29]]
01/01/2018 19:49:31 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
01/01/2018 19:49:31 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:49:31 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:49:31 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:49:31 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:49:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:49:31 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:49:31 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:50:26 [INFO] exp_shallowmodel: train time: 54.671s
01/01/2018 19:50:26 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:50:26 [INFO] exp_shallowmodel: accuracy:   0.830
01/01/2018 19:50:26 [INFO] exp_shallowmodel: f1_score:   0.573
01/01/2018 19:50:26 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:50:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.56      0.55        59
          C       0.15      0.25      0.19        12
          F       0.95      0.91      0.93       396
          R       0.60      0.65      0.63        55

avg / total       0.85      0.83      0.84       522

01/01/2018 19:50:26 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:50:26 [INFO] exp_shallowmodel: 
[[ 33   7  11   8]
 [  3   3   4   2]
 [ 13   8 361  14]
 [ 12   2   5  36]]
01/01/2018 19:50:26 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
01/01/2018 19:50:26 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:50:26 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:50:26 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:50:26 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:50:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:50:26 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:50:26 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:51:06 [INFO] exp_shallowmodel: train time: 39.850s
01/01/2018 19:51:06 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:51:06 [INFO] exp_shallowmodel: accuracy:   0.831
01/01/2018 19:51:06 [INFO] exp_shallowmodel: f1_score:   0.589
01/01/2018 19:51:06 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:51:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.63      0.59        59
          C       0.30      0.25      0.27        12
          F       0.95      0.91      0.93       396
          R       0.51      0.64      0.56        55

avg / total       0.85      0.83      0.84       522

01/01/2018 19:51:06 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:51:06 [INFO] exp_shallowmodel: 
[[ 37   2   7  13]
 [  5   3   1   3]
 [ 15   4 359  18]
 [ 10   1   9  35]]
01/01/2018 19:51:06 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
01/01/2018 19:51:06 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:51:06 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:51:06 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:51:06 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:51:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:51:06 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:51:06 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:51:47 [INFO] exp_shallowmodel: train time: 40.766s
01/01/2018 19:51:47 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:51:47 [INFO] exp_shallowmodel: accuracy:   0.843
01/01/2018 19:51:47 [INFO] exp_shallowmodel: f1_score:   0.568
01/01/2018 19:51:47 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:51:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.53      0.56        59
          C       0.15      0.17      0.16        12
          F       0.95      0.93      0.94       396
          R       0.55      0.69      0.61        55

avg / total       0.85      0.84      0.85       522

01/01/2018 19:51:47 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:51:47 [INFO] exp_shallowmodel: 
[[ 31   7   9  12]
 [  2   2   3   5]
 [ 11   2 369  14]
 [  8   2   7  38]]
01/01/2018 19:51:47 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
01/01/2018 19:51:47 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:51:47 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:51:47 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:51:47 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:51:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:51:47 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:51:47 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:52:34 [INFO] exp_shallowmodel: train time: 47.046s
01/01/2018 19:52:34 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:52:34 [INFO] exp_shallowmodel: accuracy:   0.831
01/01/2018 19:52:34 [INFO] exp_shallowmodel: f1_score:   0.569
01/01/2018 19:52:34 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:52:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.64      0.46      0.53        59
          C       0.17      0.33      0.22        12
          F       0.95      0.93      0.94       396
          R       0.52      0.65      0.58        55

avg / total       0.85      0.83      0.84       522

01/01/2018 19:52:34 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:52:34 [INFO] exp_shallowmodel: 
[[ 27   9   9  14]
 [  1   4   3   4]
 [  8   6 367  15]
 [  6   5   8  36]]
01/01/2018 19:52:34 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
01/01/2018 19:52:34 [INFO] exp_shallowmodel: #(data) = 4176
01/01/2018 19:52:34 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:52:34 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:52:34 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:52:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:52:34 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:52:34 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:53:24 [INFO] exp_shallowmodel: train time: 49.789s
01/01/2018 19:53:24 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:53:24 [INFO] exp_shallowmodel: accuracy:   0.821
01/01/2018 19:53:24 [INFO] exp_shallowmodel: f1_score:   0.551
01/01/2018 19:53:24 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:53:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.52      0.56      0.54        64
          C       0.13      0.21      0.16        14
          F       0.94      0.93      0.94       402
          R       0.61      0.52      0.56        63

avg / total       0.83      0.82      0.83       543

01/01/2018 19:53:24 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:53:24 [INFO] exp_shallowmodel: 
[[ 36   6  11  11]
 [  7   3   3   1]
 [ 14   5 374   9]
 [ 12   9   9  33]]
01/01/2018 19:53:24 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
01/01/2018 19:53:24 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:53:24 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:53:24 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:53:24 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:53:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:53:24 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:53:24 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:54:05 [INFO] exp_shallowmodel: train time: 40.984s
01/01/2018 19:54:05 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:54:05 [INFO] exp_shallowmodel: accuracy:   0.843
01/01/2018 19:54:05 [INFO] exp_shallowmodel: f1_score:   0.600
01/01/2018 19:54:05 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:54:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.59      0.66      0.62        59
          C       0.33      0.33      0.33        12
          F       0.95      0.93      0.94       396
          R       0.49      0.51      0.50        55

avg / total       0.85      0.84      0.85       522

01/01/2018 19:54:05 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:54:05 [INFO] exp_shallowmodel: 
[[ 39   3   6  11]
 [  4   4   2   2]
 [  9   2 369  16]
 [ 14   3  10  28]]
01/01/2018 19:54:05 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
01/01/2018 19:54:05 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:54:05 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:54:05 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:54:05 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:54:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:54:05 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:54:05 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:54:44 [INFO] exp_shallowmodel: train time: 38.253s
01/01/2018 19:54:44 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:54:44 [INFO] exp_shallowmodel: accuracy:   0.835
01/01/2018 19:54:44 [INFO] exp_shallowmodel: f1_score:   0.579
01/01/2018 19:54:44 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:54:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.51      0.54      0.52        59
          C       0.23      0.25      0.24        12
          F       0.95      0.92      0.94       396
          R       0.58      0.65      0.62        55

avg / total       0.84      0.84      0.84       522

01/01/2018 19:54:44 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:54:44 [INFO] exp_shallowmodel: 
[[ 32   2   9  16]
 [  2   3   3   4]
 [ 20   5 365   6]
 [  9   3   7  36]]
01/01/2018 19:54:44 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
01/01/2018 19:54:44 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:54:44 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:54:44 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:54:44 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:54:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:54:44 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:54:44 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:55:17 [INFO] exp_shallowmodel: train time: 33.744s
01/01/2018 19:55:17 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:55:17 [INFO] exp_shallowmodel: accuracy:   0.835
01/01/2018 19:55:17 [INFO] exp_shallowmodel: f1_score:   0.622
01/01/2018 19:55:17 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:55:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.61      0.59        59
          C       0.36      0.42      0.38        12
          F       0.95      0.91      0.93       396
          R       0.54      0.65      0.59        55

avg / total       0.85      0.84      0.84       522

01/01/2018 19:55:17 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:55:17 [INFO] exp_shallowmodel: 
[[ 36   3   4  16]
 [  2   5   2   3]
 [ 21   4 359  12]
 [  5   2  12  36]]
01/01/2018 19:55:18 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
01/01/2018 19:55:18 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:55:18 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:55:18 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:55:18 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:55:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:55:18 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:55:18 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:55:57 [INFO] exp_shallowmodel: train time: 39.658s
01/01/2018 19:55:57 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:55:57 [INFO] exp_shallowmodel: accuracy:   0.870
01/01/2018 19:55:57 [INFO] exp_shallowmodel: f1_score:   0.654
01/01/2018 19:55:57 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:55:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.65      0.61      0.63        59
          C       0.44      0.33      0.38        12
          F       0.95      0.95      0.95       396
          R       0.62      0.69      0.66        55

avg / total       0.87      0.87      0.87       522

01/01/2018 19:55:57 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:55:57 [INFO] exp_shallowmodel: 
[[ 36   2  11  10]
 [  3   4   2   3]
 [  9   1 376  10]
 [  7   2   8  38]]
01/01/2018 19:55:57 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
01/01/2018 19:55:57 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:55:57 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:55:57 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:55:57 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:55:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:55:57 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:55:57 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:56:39 [INFO] exp_shallowmodel: train time: 41.423s
01/01/2018 19:56:39 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:56:39 [INFO] exp_shallowmodel: accuracy:   0.833
01/01/2018 19:56:39 [INFO] exp_shallowmodel: f1_score:   0.557
01/01/2018 19:56:39 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:56:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.59      0.61      0.60        59
          C       0.12      0.17      0.14        12
          F       0.95      0.92      0.94       396
          R       0.52      0.58      0.55        55

avg / total       0.85      0.83      0.84       522

01/01/2018 19:56:39 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:56:39 [INFO] exp_shallowmodel: 
[[ 36   4   9  10]
 [  3   2   3   4]
 [  8   8 365  15]
 [ 14   3   6  32]]
01/01/2018 19:56:39 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
01/01/2018 19:56:39 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:56:39 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:56:39 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:56:39 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:56:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:56:39 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:56:39 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:57:25 [INFO] exp_shallowmodel: train time: 45.605s
01/01/2018 19:57:25 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:57:25 [INFO] exp_shallowmodel: accuracy:   0.854
01/01/2018 19:57:25 [INFO] exp_shallowmodel: f1_score:   0.565
01/01/2018 19:57:25 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:57:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.59      0.69      0.64        59
          C       0.14      0.08      0.11        12
          F       0.97      0.94      0.95       396
          R       0.54      0.60      0.57        55

avg / total       0.86      0.85      0.86       522

01/01/2018 19:57:25 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:57:25 [INFO] exp_shallowmodel: 
[[ 41   2   5  11]
 [  7   1   2   2]
 [  8   2 371  15]
 [ 14   2   6  33]]
01/01/2018 19:57:25 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
01/01/2018 19:57:25 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:57:25 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:57:25 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:57:25 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:57:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:57:25 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:57:25 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:58:09 [INFO] exp_shallowmodel: train time: 44.264s
01/01/2018 19:58:09 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:58:09 [INFO] exp_shallowmodel: accuracy:   0.835
01/01/2018 19:58:09 [INFO] exp_shallowmodel: f1_score:   0.575
01/01/2018 19:58:09 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:58:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.51      0.53      0.52        59
          C       0.23      0.25      0.24        12
          F       0.95      0.92      0.94       396
          R       0.56      0.65      0.61        55

avg / total       0.85      0.84      0.84       522

01/01/2018 19:58:09 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:58:09 [INFO] exp_shallowmodel: 
[[ 31   3   9  16]
 [  4   3   4   1]
 [ 15   4 366  11]
 [ 11   3   5  36]]
01/01/2018 19:58:09 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
01/01/2018 19:58:09 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:58:09 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:58:09 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:58:09 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:58:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:58:09 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:58:09 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:58:45 [INFO] exp_shallowmodel: train time: 35.557s
01/01/2018 19:58:45 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:58:45 [INFO] exp_shallowmodel: accuracy:   0.810
01/01/2018 19:58:45 [INFO] exp_shallowmodel: f1_score:   0.503
01/01/2018 19:58:45 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:58:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.53      0.53        59
          C       0.09      0.08      0.09        12
          F       0.93      0.92      0.92       396
          R       0.43      0.51      0.47        55

avg / total       0.82      0.81      0.81       522

01/01/2018 19:58:45 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:58:45 [INFO] exp_shallowmodel: 
[[ 31   4  12  12]
 [  2   1   5   4]
 [  9   3 363  21]
 [ 15   3   9  28]]
01/01/2018 19:58:45 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
01/01/2018 19:58:45 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 19:58:45 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:58:45 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:58:45 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:58:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:58:45 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:58:45 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 19:59:43 [INFO] exp_shallowmodel: train time: 58.459s
01/01/2018 19:59:43 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 19:59:43 [INFO] exp_shallowmodel: accuracy:   0.830
01/01/2018 19:59:43 [INFO] exp_shallowmodel: f1_score:   0.579
01/01/2018 19:59:43 [INFO] exp_shallowmodel: classification report:
01/01/2018 19:59:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.61      0.58        59
          C       0.23      0.25      0.24        12
          F       0.94      0.91      0.93       396
          R       0.55      0.60      0.57        55

avg / total       0.84      0.83      0.83       522

01/01/2018 19:59:43 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 19:59:43 [INFO] exp_shallowmodel: 
[[ 36   4   8  11]
 [  4   3   2   3]
 [ 17   5 361  13]
 [  9   1  12  33]]
01/01/2018 19:59:44 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
01/01/2018 19:59:44 [INFO] exp_shallowmodel: #(data) = 4176
01/01/2018 19:59:44 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 19:59:44 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 19:59:44 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 19:59:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 19:59:44 [INFO] exp_shallowmodel: Training: 
01/01/2018 19:59:44 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:00:38 [INFO] exp_shallowmodel: train time: 54.750s
01/01/2018 20:00:38 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:00:38 [INFO] exp_shallowmodel: accuracy:   0.808
01/01/2018 20:00:38 [INFO] exp_shallowmodel: f1_score:   0.546
01/01/2018 20:00:38 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:00:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.49      0.53      0.51        64
          C       0.19      0.21      0.20        14
          F       0.94      0.91      0.93       402
          R       0.53      0.57      0.55        63

avg / total       0.82      0.81      0.81       543

01/01/2018 20:00:38 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:00:38 [INFO] exp_shallowmodel: 
[[ 34   6  12  12]
 [  2   3   3   6]
 [ 16   6 366  14]
 [ 18   1   8  36]]
01/01/2018 20:00:38 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
01/01/2018 20:00:38 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 20:00:38 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 20:00:38 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 20:00:38 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 20:00:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 20:00:38 [INFO] exp_shallowmodel: Training: 
01/01/2018 20:00:38 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:01:23 [INFO] exp_shallowmodel: train time: 44.361s
01/01/2018 20:01:23 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:01:23 [INFO] exp_shallowmodel: accuracy:   0.793
01/01/2018 20:01:23 [INFO] exp_shallowmodel: f1_score:   0.486
01/01/2018 20:01:23 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:01:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.48      0.49      0.49        59
          C       0.05      0.08      0.06        12
          F       0.94      0.90      0.92       396
          R       0.45      0.51      0.48        55

avg / total       0.82      0.79      0.80       522

01/01/2018 20:01:23 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:01:23 [INFO] exp_shallowmodel: 
[[ 29   8   9  13]
 [  7   1   3   1]
 [ 14   6 356  20]
 [ 10   7  10  28]]
01/01/2018 20:01:23 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
01/01/2018 20:01:23 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 20:01:23 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 20:01:23 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 20:01:23 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 20:01:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 20:01:23 [INFO] exp_shallowmodel: Training: 
01/01/2018 20:01:23 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:02:20 [INFO] exp_shallowmodel: train time: 57.201s
01/01/2018 20:02:20 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:02:20 [INFO] exp_shallowmodel: accuracy:   0.828
01/01/2018 20:02:20 [INFO] exp_shallowmodel: f1_score:   0.503
01/01/2018 20:02:20 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:02:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.59      0.58        59
          C       0.00      0.00      0.00        12
          F       0.95      0.93      0.94       396
          R       0.47      0.51      0.49        55

avg / total       0.84      0.83      0.83       522

01/01/2018 20:02:20 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:02:20 [INFO] exp_shallowmodel: 
[[ 35   3   8  13]
 [  5   0   3   4]
 [ 10   3 369  14]
 [ 12   8   7  28]]
01/01/2018 20:02:20 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
01/01/2018 20:02:20 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 20:02:20 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 20:02:20 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 20:02:20 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 20:02:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 20:02:20 [INFO] exp_shallowmodel: Training: 
01/01/2018 20:02:20 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:03:00 [INFO] exp_shallowmodel: train time: 39.285s
01/01/2018 20:03:00 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:03:00 [INFO] exp_shallowmodel: accuracy:   0.837
01/01/2018 20:03:00 [INFO] exp_shallowmodel: f1_score:   0.539
01/01/2018 20:03:00 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:03:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.63      0.60        59
          C       0.17      0.08      0.11        12
          F       0.95      0.93      0.94       396
          R       0.48      0.55      0.51        55

avg / total       0.84      0.84      0.84       522

01/01/2018 20:03:00 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:03:00 [INFO] exp_shallowmodel: 
[[ 37   2   8  12]
 [  3   1   1   7]
 [ 12   1 369  14]
 [ 13   2  10  30]]
01/01/2018 20:03:00 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
01/01/2018 20:03:00 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 20:03:00 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 20:03:00 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 20:03:00 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 20:03:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 20:03:00 [INFO] exp_shallowmodel: Training: 
01/01/2018 20:03:00 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:03:45 [INFO] exp_shallowmodel: train time: 44.735s
01/01/2018 20:03:45 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:03:45 [INFO] exp_shallowmodel: accuracy:   0.822
01/01/2018 20:03:45 [INFO] exp_shallowmodel: f1_score:   0.524
01/01/2018 20:03:45 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:03:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.63      0.60        59
          C       0.08      0.08      0.08        12
          F       0.95      0.91      0.93       396
          R       0.45      0.53      0.48        55

avg / total       0.84      0.82      0.83       522

01/01/2018 20:03:45 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:03:45 [INFO] exp_shallowmodel: 
[[ 37   2   7  13]
 [  3   1   2   6]
 [ 14   3 362  17]
 [ 11   6   9  29]]
01/01/2018 20:03:45 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
01/01/2018 20:03:45 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 20:03:45 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 20:03:45 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 20:03:45 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 20:03:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 20:03:45 [INFO] exp_shallowmodel: Training: 
01/01/2018 20:03:45 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:04:38 [INFO] exp_shallowmodel: train time: 53.615s
01/01/2018 20:04:38 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:04:38 [INFO] exp_shallowmodel: accuracy:   0.858
01/01/2018 20:04:38 [INFO] exp_shallowmodel: f1_score:   0.586
01/01/2018 20:04:38 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:04:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.68      0.65        59
          C       0.14      0.08      0.11        12
          F       0.95      0.93      0.94       396
          R       0.61      0.69      0.65        55

avg / total       0.86      0.86      0.86       522

01/01/2018 20:04:38 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:04:38 [INFO] exp_shallowmodel: 
[[ 40   3   6  10]
 [  3   1   5   3]
 [ 14   2 369  11]
 [  7   1   9  38]]
01/01/2018 20:04:39 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
01/01/2018 20:04:39 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 20:04:39 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 20:04:39 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 20:04:39 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 20:04:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 20:04:39 [INFO] exp_shallowmodel: Training: 
01/01/2018 20:04:39 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:05:27 [INFO] exp_shallowmodel: train time: 48.390s
01/01/2018 20:05:27 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:05:27 [INFO] exp_shallowmodel: accuracy:   0.828
01/01/2018 20:05:27 [INFO] exp_shallowmodel: f1_score:   0.557
01/01/2018 20:05:27 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:05:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.53      0.54      0.54        59
          C       0.19      0.25      0.21        12
          F       0.97      0.92      0.94       396
          R       0.48      0.60      0.53        55

avg / total       0.85      0.83      0.84       522

01/01/2018 20:05:27 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:05:27 [INFO] exp_shallowmodel: 
[[ 32   3   6  18]
 [  3   3   1   5]
 [ 15   4 364  13]
 [ 10   6   6  33]]
01/01/2018 20:05:27 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
01/01/2018 20:05:27 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 20:05:27 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 20:05:27 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 20:05:27 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 20:05:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 20:05:27 [INFO] exp_shallowmodel: Training: 
01/01/2018 20:05:27 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:06:04 [INFO] exp_shallowmodel: train time: 37.088s
01/01/2018 20:06:04 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:06:04 [INFO] exp_shallowmodel: accuracy:   0.833
01/01/2018 20:06:04 [INFO] exp_shallowmodel: f1_score:   0.562
01/01/2018 20:06:04 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:06:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.52      0.53      0.52        59
          C       0.19      0.25      0.21        12
          F       0.94      0.93      0.94       396
          R       0.58      0.56      0.57        55

avg / total       0.84      0.83      0.84       522

01/01/2018 20:06:04 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:06:04 [INFO] exp_shallowmodel: 
[[ 31   7  12   9]
 [  5   3   3   1]
 [ 12   2 370  12]
 [ 12   4   8  31]]
01/01/2018 20:06:04 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
01/01/2018 20:06:04 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 20:06:04 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 20:06:04 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 20:06:04 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 20:06:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 20:06:04 [INFO] exp_shallowmodel: Training: 
01/01/2018 20:06:04 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:06:41 [INFO] exp_shallowmodel: train time: 36.381s
01/01/2018 20:06:41 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:06:41 [INFO] exp_shallowmodel: accuracy:   0.791
01/01/2018 20:06:41 [INFO] exp_shallowmodel: f1_score:   0.505
01/01/2018 20:06:41 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:06:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.53      0.48        59
          C       0.12      0.17      0.14        12
          F       0.95      0.89      0.92       396
          R       0.45      0.53      0.49        55

avg / total       0.82      0.79      0.80       522

01/01/2018 20:06:41 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:06:41 [INFO] exp_shallowmodel: 
[[ 31   5  10  13]
 [  5   2   4   1]
 [ 19   5 351  21]
 [ 16   5   5  29]]
01/01/2018 20:06:41 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
01/01/2018 20:06:41 [INFO] exp_shallowmodel: #(data) = 4197
01/01/2018 20:06:41 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 20:06:41 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 20:06:41 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 20:06:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 20:06:41 [INFO] exp_shallowmodel: Training: 
01/01/2018 20:06:41 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:07:22 [INFO] exp_shallowmodel: train time: 41.066s
01/01/2018 20:07:22 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:07:22 [INFO] exp_shallowmodel: accuracy:   0.833
01/01/2018 20:07:22 [INFO] exp_shallowmodel: f1_score:   0.600
01/01/2018 20:07:22 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:07:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.54      0.56        59
          C       0.26      0.50      0.34        12
          F       0.96      0.92      0.94       396
          R       0.52      0.60      0.56        55

avg / total       0.85      0.83      0.84       522

01/01/2018 20:07:22 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:07:22 [INFO] exp_shallowmodel: 
[[ 32   2   9  16]
 [  2   6   1   3]
 [ 11  10 364  11]
 [ 10   5   7  33]]
01/01/2018 20:07:22 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
01/01/2018 20:07:22 [INFO] exp_shallowmodel: #(data) = 4176
01/01/2018 20:07:22 [INFO] exp_shallowmodel: #(feature) = 1041
01/01/2018 20:07:22 [INFO] exp_shallowmodel: ================================================================================
01/01/2018 20:07:22 [INFO] exp_shallowmodel: LR.pen=l2.C=100000000000000000000.000000
01/01/2018 20:07:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
01/01/2018 20:07:22 [INFO] exp_shallowmodel: Training: 
01/01/2018 20:07:22 [INFO] exp_shallowmodel: LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
01/01/2018 20:08:03 [INFO] exp_shallowmodel: train time: 40.434s
01/01/2018 20:08:03 [INFO] exp_shallowmodel: test time:  0.001s
01/01/2018 20:08:03 [INFO] exp_shallowmodel: accuracy:   0.825
01/01/2018 20:08:03 [INFO] exp_shallowmodel: f1_score:   0.530
01/01/2018 20:08:03 [INFO] exp_shallowmodel: classification report:
01/01/2018 20:08:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.59      0.58        64
          C       0.06      0.07      0.07        14
          F       0.94      0.94      0.94       402
          R       0.53      0.52      0.53        63

avg / total       0.83      0.83      0.83       543

01/01/2018 20:08:03 [INFO] exp_shallowmodel: confusion matrix:
01/01/2018 20:08:03 [INFO] exp_shallowmodel: 
[[ 38   3   9  14]
 [  4   1   3   6]
 [  9   8 376   9]
 [ 15   4  11  33]]
