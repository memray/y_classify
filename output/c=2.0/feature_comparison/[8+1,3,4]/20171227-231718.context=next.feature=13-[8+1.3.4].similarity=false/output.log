12/27/2017 23:17:18 [INFO] configuration: deep_model  :   False
12/27/2017 23:17:18 [INFO] configuration: selected_context_id  :   0
12/27/2017 23:17:18 [INFO] configuration: selected_feature_set_id  :   13
12/27/2017 23:17:18 [INFO] configuration: similarity_feature  :   False
12/27/2017 23:17:18 [INFO] configuration: seed  :   154316847
12/27/2017 23:17:18 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/27/2017 23:17:18 [INFO] configuration: task_name  :   utterance_type
12/27/2017 23:17:18 [INFO] configuration: timemark  :   20171227-231718
12/27/2017 23:17:18 [INFO] configuration: context_set  :   next
12/27/2017 23:17:18 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/27/2017 23:17:18 [INFO] configuration: utterance_range  :   ['current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/27/2017 23:17:18 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/27/2017 23:17:18 [INFO] configuration: feature_set  :   13-[8+1.3.4]
12/27/2017 23:17:18 [INFO] configuration: feature_set_number  :   ['1', '2', '3', '5', '6', '7', '11']
12/27/2017 23:17:18 [INFO] configuration: experiment_name  :   20171227-231718.context=next.feature=13-[8+1.3.4].similarity=false
12/27/2017 23:17:18 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171227-231718.context=next.feature=13-[8+1.3.4].similarity=false
12/27/2017 23:17:18 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171227-231718.context=next.feature=13-[8+1.3.4].similarity=false/output.log
12/27/2017 23:17:18 [INFO] configuration: valid_type  :   {'R', 'F', 'A', 'C'}
12/27/2017 23:17:18 [INFO] configuration: data_name  :   
12/27/2017 23:17:18 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/27/2017 23:17:18 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/27/2017 23:17:18 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/27/2017 23:17:18 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/27/2017 23:17:18 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/27/2017 23:17:18 [INFO] configuration: do_cross_validation  :   True
12/27/2017 23:17:18 [INFO] configuration: #division  :   5
12/27/2017 23:17:18 [INFO] configuration: #cross_validation  :   10
12/27/2017 23:17:18 [INFO] configuration: cv_index_cache_path  :   
12/27/2017 23:17:18 [INFO] configuration: action_words  :   {'share', 'phone', 'light', 'telephon', 'delet', 'remov', 'weather', 'alarm', 'music', 'item', 'shuffle', 'findcar', 'temperature', 'matter', 'watch', 'address', 'number', 'volum', 'delete', 'room', 'time', 'discard', 'items', 'song', 'help', 'expens', 'add', 'timer', 'area', 'cheap', 'volume', 'moder', 'temperatur', 'post', 'remind', 'video', 'telephone', 'tell', 'reminder', 'start', 'centr', 'price', 'any', 'snooze', 'clear', 'reminders', 'turn', 'ani', 'reminds', 'play', 'cast', 'food', 'stop', 'member', 'show', 'list', 'findcare', 'part', 'shuffl', 'else', 'moderate', 'north', 'next', 'skip', 'south', 'els', 'snooz', 'expensive', 'centre', 'remove'}
12/27/2017 23:17:18 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/27/2017 23:17:18 [INFO] configuration: lda_topic_number  :   50
12/27/2017 23:17:18 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/27/2017 23:17:18 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/27/2017 23:17:18 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/27/2017 23:17:18 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/27/2017 23:17:18 [INFO] configuration: w2v_vector_length  :   300
12/27/2017 23:17:18 [INFO] configuration: d2v_vector_length  :   300
12/27/2017 23:17:18 [INFO] configuration: d2v_window_size  :   5
12/27/2017 23:17:18 [INFO] configuration: d2v_min_count  :   2
12/27/2017 23:17:18 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/27/2017 23:17:18 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/27/2017 23:17:18 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/27/2017 23:17:18 [INFO] configuration: batch_size  :   128
12/27/2017 23:17:18 [INFO] configuration: max_epoch  :   50
12/27/2017 23:17:18 [INFO] configuration: early_stop_tolerance  :   2
12/27/2017 23:17:18 [INFO] configuration: concat_sents  :   True
12/27/2017 23:17:18 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/27/2017 23:17:18 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 3, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/27/2017 23:17:18 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/27/2017 23:17:24 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/27/2017 23:17:24 [INFO] task_runner: context=next, feature=13-[8+1.3.4], similarity=False
12/27/2017 23:17:24 [INFO] task_runner: Before filtering, #(feature)=30328
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 1 : 5
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		2.1 : 76
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 2 : 81
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		2.2 : 3
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		2.3.1 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		2.3.2 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 3 : 5
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		4.1 : 9227
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 4 : 9231
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		4.2.1 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		4.2.2 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		4.3.1 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		4.3.2 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 5 : 3801
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 6 : 452
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 7 : 1493
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		8.1 : 250
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 8 : 252
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		8.2.1 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		8.2.2 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		9.1 : 1500
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 9 : 1504
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		9.2.1 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		9.2.2 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		9.3.1 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		9.3.2 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		10.1 : 1500
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 10 : 1502
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		10.2.1 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		10.2.2 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		11.1 : 12000
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 11 : 12002
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		11.2.1 : 1
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		11.2.2 : 1
12/27/2017 23:17:24 [INFO] task_runner: After filtering, #(feature)=10590
12/27/2017 23:17:24 [INFO] task_runner: retained feature id=[1, 11.1, 2.1, 2.2, 3, 5, 6, 7]
12/27/2017 23:17:24 [INFO] task_runner: #(data)=5725
12/27/2017 23:17:24 [INFO] task_runner: #(feature)=10590/30328
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 1 : 3
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		2.1 : 50
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 2 : 52
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		2.2 : 2
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 3 : 5
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 5 : 2181
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 6 : 242
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 7 : 907
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 		11.1 : 7200
12/27/2017 23:17:24 [INFO] exp_shallowmodel: 11 : 7200
12/27/2017 23:17:24 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/27/2017 23:17:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/27/2017 23:17:27 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:17:27 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:17:27 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:17:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:17:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:17:27 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:17:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:18:27 [INFO] exp_shallowmodel: train time: 60.091s
12/27/2017 23:18:27 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:18:27 [INFO] exp_shallowmodel: accuracy:   0.809
12/27/2017 23:18:27 [INFO] exp_shallowmodel: f1_score:   0.680
12/27/2017 23:18:27 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:18:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.29      0.38        14
          C       0.74      0.77      0.75       164
          F       0.93      0.94      0.93       268
          R       0.66      0.65      0.65       125

avg / total       0.81      0.81      0.81       571

12/27/2017 23:18:27 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:18:27 [INFO] exp_shallowmodel: 
[[  4   2   5   3]
 [  2 126   7  29]
 [  1   6 251  10]
 [  0  37   7  81]]
12/27/2017 23:18:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/27/2017 23:18:30 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:18:30 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:18:30 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:18:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:18:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:18:30 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:18:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:19:48 [INFO] exp_shallowmodel: train time: 78.105s
12/27/2017 23:19:48 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:19:48 [INFO] exp_shallowmodel: accuracy:   0.765
12/27/2017 23:19:48 [INFO] exp_shallowmodel: f1_score:   0.649
12/27/2017 23:19:48 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:19:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.29      0.40        14
          C       0.69      0.66      0.68       164
          F       0.86      0.92      0.89       268
          R       0.64      0.62      0.63       125

avg / total       0.76      0.77      0.76       571

12/27/2017 23:19:48 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:19:48 [INFO] exp_shallowmodel: 
[[  4   1   4   5]
 [  1 109  20  34]
 [  1  15 247   5]
 [  0  33  15  77]]
12/27/2017 23:19:50 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/27/2017 23:19:50 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:19:50 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:19:50 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:19:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:19:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:19:50 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:19:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:20:30 [INFO] exp_shallowmodel: train time: 39.440s
12/27/2017 23:20:30 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:20:30 [INFO] exp_shallowmodel: accuracy:   0.783
12/27/2017 23:20:30 [INFO] exp_shallowmodel: f1_score:   0.697
12/27/2017 23:20:30 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:20:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.43      0.55        14
          C       0.70      0.67      0.69       164
          F       0.93      0.93      0.93       268
          R       0.59      0.66      0.63       125

avg / total       0.79      0.78      0.78       571

12/27/2017 23:20:30 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:20:30 [INFO] exp_shallowmodel: 
[[  6   1   2   5]
 [  1 110   9  44]
 [  1  11 248   8]
 [  0  35   7  83]]
12/27/2017 23:20:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/27/2017 23:20:31 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:20:31 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:20:31 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:20:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:20:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:20:31 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:20:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:21:07 [INFO] exp_shallowmodel: train time: 35.460s
12/27/2017 23:21:07 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:21:07 [INFO] exp_shallowmodel: accuracy:   0.771
12/27/2017 23:21:07 [INFO] exp_shallowmodel: f1_score:   0.727
12/27/2017 23:21:07 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:21:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.82      0.64      0.72        14
          C       0.68      0.69      0.68       164
          F       0.90      0.91      0.91       268
          R       0.60      0.59      0.59       125

avg / total       0.77      0.77      0.77       571

12/27/2017 23:21:07 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:21:07 [INFO] exp_shallowmodel: 
[[  9   0   2   3]
 [  0 113  11  40]
 [  1  16 244   7]
 [  1  37  13  74]]
12/27/2017 23:21:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/27/2017 23:21:08 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:21:08 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:21:08 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:21:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:21:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:21:08 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:21:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:22:06 [INFO] exp_shallowmodel: train time: 57.552s
12/27/2017 23:22:06 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:22:06 [INFO] exp_shallowmodel: accuracy:   0.758
12/27/2017 23:22:06 [INFO] exp_shallowmodel: f1_score:   0.614
12/27/2017 23:22:06 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:22:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.21      0.26        14
          C       0.70      0.73      0.71       164
          F       0.86      0.88      0.87       268
          R       0.63      0.58      0.61       125

avg / total       0.75      0.76      0.75       571

12/27/2017 23:22:06 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:22:06 [INFO] exp_shallowmodel: 
[[  3   3   5   3]
 [  1 120  17  26]
 [  2  15 237  14]
 [  3  34  15  73]]
12/27/2017 23:22:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/27/2017 23:22:09 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:22:09 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:22:09 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:22:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:22:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:22:09 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:22:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:23:02 [INFO] exp_shallowmodel: train time: 53.021s
12/27/2017 23:23:03 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:23:03 [INFO] exp_shallowmodel: accuracy:   0.781
12/27/2017 23:23:03 [INFO] exp_shallowmodel: f1_score:   0.660
12/27/2017 23:23:03 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:23:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.29      0.40        14
          C       0.72      0.73      0.73       164
          F       0.90      0.92      0.91       268
          R       0.60      0.60      0.60       125

avg / total       0.78      0.78      0.78       571

12/27/2017 23:23:03 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:23:03 [INFO] exp_shallowmodel: 
[[  4   0   5   5]
 [  0 120  12  32]
 [  0   9 247  12]
 [  2  37  11  75]]
12/27/2017 23:23:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/27/2017 23:23:06 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:23:06 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:23:06 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:23:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:23:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:23:06 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:23:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:23:54 [INFO] exp_shallowmodel: train time: 48.592s
12/27/2017 23:23:54 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:23:54 [INFO] exp_shallowmodel: accuracy:   0.786
12/27/2017 23:23:54 [INFO] exp_shallowmodel: f1_score:   0.668
12/27/2017 23:23:54 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:23:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.80      0.29      0.42        14
          C       0.72      0.78      0.75       164
          F       0.90      0.92      0.91       268
          R       0.62      0.57      0.59       125

avg / total       0.78      0.79      0.78       571

12/27/2017 23:23:54 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:23:54 [INFO] exp_shallowmodel: 
[[  4   0   7   3]
 [  1 128   9  26]
 [  0   8 246  14]
 [  0  42  12  71]]
12/27/2017 23:23:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/27/2017 23:23:58 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:23:58 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:23:58 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:23:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:23:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:23:58 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:23:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:25:35 [INFO] exp_shallowmodel: train time: 97.306s
12/27/2017 23:25:35 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:25:35 [INFO] exp_shallowmodel: accuracy:   0.748
12/27/2017 23:25:35 [INFO] exp_shallowmodel: f1_score:   0.605
12/27/2017 23:25:35 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:25:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.21      0.29        14
          C       0.65      0.69      0.67       164
          F       0.90      0.90      0.90       268
          R       0.58      0.56      0.57       125

avg / total       0.74      0.75      0.74       571

12/27/2017 23:25:35 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:25:35 [INFO] exp_shallowmodel: 
[[  3   3   4   4]
 [  1 113  15  35]
 [  2  14 241  11]
 [  1  45   9  70]]
12/27/2017 23:25:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/27/2017 23:25:37 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:25:37 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:25:37 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:25:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:25:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:25:37 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:25:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:26:16 [INFO] exp_shallowmodel: train time: 38.617s
12/27/2017 23:26:16 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:26:16 [INFO] exp_shallowmodel: accuracy:   0.797
12/27/2017 23:26:16 [INFO] exp_shallowmodel: f1_score:   0.654
12/27/2017 23:26:16 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:26:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.21      0.29        14
          C       0.75      0.71      0.73       164
          F       0.90      0.91      0.91       268
          R       0.67      0.72      0.69       125

avg / total       0.79      0.80      0.79       571

12/27/2017 23:26:16 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:26:16 [INFO] exp_shallowmodel: 
[[  3   1   5   5]
 [  1 117  14  32]
 [  2  13 245   8]
 [  1  26   8  90]]
12/27/2017 23:26:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/27/2017 23:26:17 [INFO] exp_shallowmodel: #(data) = 4568
12/27/2017 23:26:17 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:26:17 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:26:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:26:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:26:17 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:26:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:26:53 [INFO] exp_shallowmodel: train time: 35.893s
12/27/2017 23:26:53 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:26:53 [INFO] exp_shallowmodel: accuracy:   0.744
12/27/2017 23:26:53 [INFO] exp_shallowmodel: f1_score:   0.607
12/27/2017 23:26:53 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:26:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.25      0.31        16
          C       0.64      0.67      0.65       169
          F       0.91      0.92      0.91       271
          R       0.57      0.55      0.56       130

avg / total       0.74      0.74      0.74       586

12/27/2017 23:26:53 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:26:53 [INFO] exp_shallowmodel: 
[[  4   3   4   5]
 [  0 113  11  45]
 [  4  15 248   4]
 [  2  46  11  71]]
12/27/2017 23:26:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/27/2017 23:26:55 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:26:55 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:26:55 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:26:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:26:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:26:55 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:26:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:27:30 [INFO] exp_shallowmodel: train time: 35.207s
12/27/2017 23:27:30 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:27:30 [INFO] exp_shallowmodel: accuracy:   0.774
12/27/2017 23:27:30 [INFO] exp_shallowmodel: f1_score:   0.611
12/27/2017 23:27:30 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:27:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.14      0.21        14
          C       0.69      0.74      0.71       164
          F       0.89      0.91      0.90       268
          R       0.64      0.60      0.62       125

avg / total       0.77      0.77      0.77       571

12/27/2017 23:27:30 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:27:30 [INFO] exp_shallowmodel: 
[[  2   3   7   2]
 [  1 121  11  31]
 [  2  13 244   9]
 [  0  38  12  75]]
12/27/2017 23:27:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/27/2017 23:27:32 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:27:32 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:27:32 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:27:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:27:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:27:32 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:27:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:28:20 [INFO] exp_shallowmodel: train time: 48.500s
12/27/2017 23:28:20 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:28:20 [INFO] exp_shallowmodel: accuracy:   0.781
12/27/2017 23:28:20 [INFO] exp_shallowmodel: f1_score:   0.652
12/27/2017 23:28:20 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:28:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.36      0.34        14
          C       0.73      0.67      0.70       164
          F       0.94      0.92      0.93       268
          R       0.60      0.68      0.64       125

avg / total       0.79      0.78      0.78       571

12/27/2017 23:28:20 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:28:20 [INFO] exp_shallowmodel: 
[[  5   0   5   4]
 [  3 110   8  43]
 [  4   8 246  10]
 [  3  33   4  85]]
12/27/2017 23:28:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/27/2017 23:28:24 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:28:24 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:28:24 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:28:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:28:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:28:24 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:28:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:29:03 [INFO] exp_shallowmodel: train time: 38.690s
12/27/2017 23:29:03 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:29:03 [INFO] exp_shallowmodel: accuracy:   0.771
12/27/2017 23:29:03 [INFO] exp_shallowmodel: f1_score:   0.685
12/27/2017 23:29:03 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:29:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.43      0.55        14
          C       0.68      0.70      0.69       164
          F       0.91      0.91      0.91       268
          R       0.59      0.59      0.59       125

avg / total       0.77      0.77      0.77       571

12/27/2017 23:29:03 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:29:03 [INFO] exp_shallowmodel: 
[[  6   0   4   4]
 [  0 115  11  38]
 [  1  13 245   9]
 [  1  40  10  74]]
12/27/2017 23:29:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/27/2017 23:29:06 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:29:06 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:29:06 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:29:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:29:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:29:06 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:29:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:30:05 [INFO] exp_shallowmodel: train time: 58.641s
12/27/2017 23:30:05 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:30:05 [INFO] exp_shallowmodel: accuracy:   0.755
12/27/2017 23:30:05 [INFO] exp_shallowmodel: f1_score:   0.587
12/27/2017 23:30:05 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:30:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.14      0.18        14
          C       0.64      0.71      0.67       164
          F       0.91      0.90      0.91       268
          R       0.60      0.57      0.58       125

avg / total       0.75      0.75      0.75       571

12/27/2017 23:30:05 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:30:05 [INFO] exp_shallowmodel: 
[[  2   3   2   7]
 [  1 116  12  35]
 [  3  18 242   5]
 [  2  43   9  71]]
12/27/2017 23:30:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/27/2017 23:30:08 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:30:08 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:30:08 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:30:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:30:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:30:08 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:30:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:31:26 [INFO] exp_shallowmodel: train time: 77.513s
12/27/2017 23:31:26 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:31:26 [INFO] exp_shallowmodel: accuracy:   0.762
12/27/2017 23:31:26 [INFO] exp_shallowmodel: f1_score:   0.678
12/27/2017 23:31:26 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:31:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.50      0.54        14
          C       0.68      0.65      0.66       164
          F       0.92      0.91      0.91       268
          R       0.57      0.62      0.60       125

avg / total       0.76      0.76      0.76       571

12/27/2017 23:31:26 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:31:26 [INFO] exp_shallowmodel: 
[[  7   3   2   2]
 [  1 107  10  46]
 [  1  14 243  10]
 [  3  34  10  78]]
12/27/2017 23:31:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/27/2017 23:31:29 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:31:29 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:31:29 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:31:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:31:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:31:29 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:31:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:32:13 [INFO] exp_shallowmodel: train time: 43.390s
12/27/2017 23:32:13 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:32:13 [INFO] exp_shallowmodel: accuracy:   0.772
12/27/2017 23:32:13 [INFO] exp_shallowmodel: f1_score:   0.643
12/27/2017 23:32:13 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:32:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.29      0.36        14
          C       0.71      0.73      0.72       164
          F       0.89      0.92      0.90       268
          R       0.60      0.56      0.58       125

avg / total       0.77      0.77      0.77       571

12/27/2017 23:32:13 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:32:13 [INFO] exp_shallowmodel: 
[[  4   1   5   4]
 [  1 120  12  31]
 [  0  10 247  11]
 [  3  38  14  70]]
12/27/2017 23:32:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/27/2017 23:32:16 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:32:16 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:32:16 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:32:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:32:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:32:16 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:32:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:33:42 [INFO] exp_shallowmodel: train time: 85.884s
12/27/2017 23:33:42 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:33:42 [INFO] exp_shallowmodel: accuracy:   0.776
12/27/2017 23:33:42 [INFO] exp_shallowmodel: f1_score:   0.640
12/27/2017 23:33:42 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:33:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.21      0.32        14
          C       0.72      0.72      0.72       164
          F       0.89      0.90      0.90       268
          R       0.62      0.64      0.63       125

avg / total       0.77      0.78      0.77       571

12/27/2017 23:33:42 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:33:42 [INFO] exp_shallowmodel: 
[[  3   4   5   2]
 [  0 118  12  34]
 [  2  11 242  13]
 [  0  32  13  80]]
12/27/2017 23:33:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/27/2017 23:33:46 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:33:46 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:33:46 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:33:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:33:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:33:46 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:33:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:34:46 [INFO] exp_shallowmodel: train time: 60.081s
12/27/2017 23:34:46 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:34:46 [INFO] exp_shallowmodel: accuracy:   0.765
12/27/2017 23:34:46 [INFO] exp_shallowmodel: f1_score:   0.691
12/27/2017 23:34:46 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:34:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.64      0.50      0.56        14
          C       0.69      0.66      0.68       164
          F       0.90      0.89      0.89       268
          R       0.60      0.66      0.63       125

avg / total       0.77      0.77      0.77       571

12/27/2017 23:34:46 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:34:46 [INFO] exp_shallowmodel: 
[[  7   2   3   2]
 [  0 109  17  38]
 [  1  14 238  15]
 [  3  32   7  83]]
12/27/2017 23:34:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/27/2017 23:34:49 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:34:49 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:34:49 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:34:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:34:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:34:49 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:34:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:35:57 [INFO] exp_shallowmodel: train time: 68.186s
12/27/2017 23:35:57 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:35:57 [INFO] exp_shallowmodel: accuracy:   0.757
12/27/2017 23:35:57 [INFO] exp_shallowmodel: f1_score:   0.599
12/27/2017 23:35:57 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:35:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.14      0.24        14
          C       0.71      0.73      0.72       164
          F       0.87      0.90      0.89       268
          R       0.56      0.55      0.56       125

avg / total       0.75      0.76      0.75       571

12/27/2017 23:35:57 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:35:57 [INFO] exp_shallowmodel: 
[[  2   0   7   5]
 [  0 119  10  35]
 [  1  11 242  14]
 [  0  38  18  69]]
12/27/2017 23:35:59 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/27/2017 23:35:59 [INFO] exp_shallowmodel: #(data) = 4568
12/27/2017 23:35:59 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:35:59 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:35:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:35:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:35:59 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:35:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:36:39 [INFO] exp_shallowmodel: train time: 40.147s
12/27/2017 23:36:39 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:36:39 [INFO] exp_shallowmodel: accuracy:   0.780
12/27/2017 23:36:39 [INFO] exp_shallowmodel: f1_score:   0.665
12/27/2017 23:36:39 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:36:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.31      0.42        16
          C       0.70      0.72      0.71       169
          F       0.91      0.93      0.92       271
          R       0.62      0.61      0.61       130

avg / total       0.78      0.78      0.78       586

12/27/2017 23:36:39 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:36:39 [INFO] exp_shallowmodel: 
[[  5   1   6   4]
 [  2 122   8  37]
 [  1  11 251   8]
 [  0  40  11  79]]
12/27/2017 23:36:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/27/2017 23:36:43 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:36:43 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:36:43 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:36:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:36:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:36:43 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:36:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:37:47 [INFO] exp_shallowmodel: train time: 64.081s
12/27/2017 23:37:47 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:37:47 [INFO] exp_shallowmodel: accuracy:   0.771
12/27/2017 23:37:47 [INFO] exp_shallowmodel: f1_score:   0.643
12/27/2017 23:37:47 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:37:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.29      0.35        14
          C       0.68      0.66      0.67       164
          F       0.91      0.91      0.91       268
          R       0.63      0.67      0.65       125

avg / total       0.77      0.77      0.77       571

12/27/2017 23:37:47 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:37:47 [INFO] exp_shallowmodel: 
[[  4   3   3   4]
 [  3 108  14  39]
 [  2  15 244   7]
 [  0  33   8  84]]
12/27/2017 23:37:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/27/2017 23:37:48 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:37:48 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:37:48 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:37:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:37:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:37:48 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:37:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:38:25 [INFO] exp_shallowmodel: train time: 36.426s
12/27/2017 23:38:25 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:38:25 [INFO] exp_shallowmodel: accuracy:   0.734
12/27/2017 23:38:25 [INFO] exp_shallowmodel: f1_score:   0.593
12/27/2017 23:38:25 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:38:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.21      0.29        14
          C       0.65      0.66      0.66       164
          F       0.87      0.90      0.88       268
          R       0.55      0.54      0.54       125

avg / total       0.73      0.73      0.73       571

12/27/2017 23:38:25 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:38:25 [INFO] exp_shallowmodel: 
[[  3   4   5   2]
 [  2 109  16  37]
 [  2  10 240  16]
 [  0  44  14  67]]
12/27/2017 23:38:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/27/2017 23:38:27 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:38:27 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:38:27 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:38:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:38:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:38:27 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:38:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:39:02 [INFO] exp_shallowmodel: train time: 35.481s
12/27/2017 23:39:02 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:39:02 [INFO] exp_shallowmodel: accuracy:   0.781
12/27/2017 23:39:02 [INFO] exp_shallowmodel: f1_score:   0.634
12/27/2017 23:39:02 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:39:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.21      0.30        14
          C       0.67      0.76      0.71       164
          F       0.93      0.93      0.93       268
          R       0.63      0.57      0.60       125

avg / total       0.78      0.78      0.78       571

12/27/2017 23:39:02 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:39:02 [INFO] exp_shallowmodel: 
[[  3   2   4   5]
 [  0 124   9  31]
 [  1  13 248   6]
 [  2  46   6  71]]
12/27/2017 23:39:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/27/2017 23:39:04 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:39:04 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:39:04 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:39:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:39:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:39:04 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:39:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:39:48 [INFO] exp_shallowmodel: train time: 44.005s
12/27/2017 23:39:48 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:39:48 [INFO] exp_shallowmodel: accuracy:   0.765
12/27/2017 23:39:48 [INFO] exp_shallowmodel: f1_score:   0.665
12/27/2017 23:39:48 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:39:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.43      0.46        14
          C       0.71      0.71      0.71       164
          F       0.89      0.90      0.89       268
          R       0.60      0.59      0.60       125

avg / total       0.76      0.77      0.76       571

12/27/2017 23:39:48 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:39:48 [INFO] exp_shallowmodel: 
[[  6   0   6   2]
 [  0 116  12  36]
 [  2  14 241  11]
 [  4  34  13  74]]
12/27/2017 23:39:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/27/2017 23:39:49 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:39:49 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:39:49 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:39:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:39:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:39:49 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:39:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:41:08 [INFO] exp_shallowmodel: train time: 78.093s
12/27/2017 23:41:08 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:41:08 [INFO] exp_shallowmodel: accuracy:   0.788
12/27/2017 23:41:08 [INFO] exp_shallowmodel: f1_score:   0.676
12/27/2017 23:41:08 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:41:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.29      0.44        14
          C       0.69      0.73      0.71       164
          F       0.90      0.93      0.92       268
          R       0.66      0.61      0.63       125

avg / total       0.79      0.79      0.78       571

12/27/2017 23:41:08 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:41:08 [INFO] exp_shallowmodel: 
[[  4   2   4   4]
 [  0 120  14  30]
 [  0  13 250   5]
 [  0  39  10  76]]
12/27/2017 23:41:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/27/2017 23:41:12 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:41:12 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:41:12 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:41:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:41:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:41:12 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:41:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:42:11 [INFO] exp_shallowmodel: train time: 58.966s
12/27/2017 23:42:11 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:42:11 [INFO] exp_shallowmodel: accuracy:   0.792
12/27/2017 23:42:11 [INFO] exp_shallowmodel: f1_score:   0.621
12/27/2017 23:42:11 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:42:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.14      0.20        14
          C       0.73      0.75      0.74       164
          F       0.91      0.93      0.92       268
          R       0.63      0.62      0.62       125

avg / total       0.78      0.79      0.79       571

12/27/2017 23:42:11 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:42:11 [INFO] exp_shallowmodel: 
[[  2   2   6   4]
 [  1 123   8  32]
 [  1   8 250   9]
 [  2  36  10  77]]
12/27/2017 23:42:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/27/2017 23:42:15 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:42:15 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:42:15 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:42:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:42:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:42:15 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:42:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:43:25 [INFO] exp_shallowmodel: train time: 70.485s
12/27/2017 23:43:25 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:43:25 [INFO] exp_shallowmodel: accuracy:   0.765
12/27/2017 23:43:25 [INFO] exp_shallowmodel: f1_score:   0.653
12/27/2017 23:43:25 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:43:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.36      0.43        14
          C       0.69      0.72      0.71       164
          F       0.90      0.91      0.91       268
          R       0.57      0.55      0.56       125

avg / total       0.76      0.77      0.76       571

12/27/2017 23:43:25 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:43:25 [INFO] exp_shallowmodel: 
[[  5   1   6   2]
 [  0 118   9  37]
 [  2   9 245  12]
 [  2  42  12  69]]
12/27/2017 23:43:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/27/2017 23:43:27 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:43:27 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:43:27 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:43:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:43:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:43:27 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:43:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:44:03 [INFO] exp_shallowmodel: train time: 35.535s
12/27/2017 23:44:03 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:44:03 [INFO] exp_shallowmodel: accuracy:   0.783
12/27/2017 23:44:03 [INFO] exp_shallowmodel: f1_score:   0.700
12/27/2017 23:44:03 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:44:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.43      0.55        14
          C       0.70      0.73      0.71       164
          F       0.91      0.90      0.91       268
          R       0.63      0.64      0.64       125

avg / total       0.78      0.78      0.78       571

12/27/2017 23:44:03 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:44:03 [INFO] exp_shallowmodel: 
[[  6   2   2   4]
 [  1 119  11  33]
 [  1  16 242   9]
 [  0  34  11  80]]
12/27/2017 23:44:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/27/2017 23:44:07 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:44:07 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:44:07 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:44:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:44:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:44:07 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:44:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:45:20 [INFO] exp_shallowmodel: train time: 73.074s
12/27/2017 23:45:20 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:45:20 [INFO] exp_shallowmodel: accuracy:   0.750
12/27/2017 23:45:20 [INFO] exp_shallowmodel: f1_score:   0.610
12/27/2017 23:45:20 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:45:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.21      0.29        14
          C       0.69      0.67      0.68       164
          F       0.90      0.89      0.89       268
          R       0.55      0.61      0.58       125

avg / total       0.75      0.75      0.75       571

12/27/2017 23:45:20 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:45:20 [INFO] exp_shallowmodel: 
[[  3   0   5   6]
 [  0 110  14  40]
 [  2  12 239  15]
 [  2  38   9  76]]
12/27/2017 23:45:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/27/2017 23:45:24 [INFO] exp_shallowmodel: #(data) = 4568
12/27/2017 23:45:24 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:45:24 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:45:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:45:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:45:24 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:45:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:46:38 [INFO] exp_shallowmodel: train time: 74.566s
12/27/2017 23:46:38 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:46:38 [INFO] exp_shallowmodel: accuracy:   0.754
12/27/2017 23:46:38 [INFO] exp_shallowmodel: f1_score:   0.679
12/27/2017 23:46:38 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:46:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.78      0.44      0.56        16
          C       0.66      0.70      0.68       169
          F       0.88      0.89      0.88       271
          R       0.61      0.57      0.59       130

avg / total       0.75      0.75      0.75       586

12/27/2017 23:46:38 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:46:38 [INFO] exp_shallowmodel: 
[[  7   3   5   1]
 [  0 119  15  35]
 [  0  17 242  12]
 [  2  40  14  74]]
12/27/2017 23:46:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/27/2017 23:46:42 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:46:42 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:46:42 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:46:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:46:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:46:42 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:46:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:47:53 [INFO] exp_shallowmodel: train time: 71.587s
12/27/2017 23:47:53 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:47:53 [INFO] exp_shallowmodel: accuracy:   0.758
12/27/2017 23:47:53 [INFO] exp_shallowmodel: f1_score:   0.623
12/27/2017 23:47:53 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:47:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.21      0.32        14
          C       0.66      0.70      0.68       164
          F       0.91      0.90      0.90       268
          R       0.59      0.60      0.60       125

avg / total       0.76      0.76      0.76       571

12/27/2017 23:47:53 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:47:53 [INFO] exp_shallowmodel: 
[[  3   1   6   4]
 [  1 114  11  38]
 [  1  16 241  10]
 [  0  42   8  75]]
12/27/2017 23:47:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/27/2017 23:47:57 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:47:57 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:47:57 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:47:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:47:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:47:57 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:47:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:49:02 [INFO] exp_shallowmodel: train time: 65.100s
12/27/2017 23:49:02 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:49:02 [INFO] exp_shallowmodel: accuracy:   0.769
12/27/2017 23:49:02 [INFO] exp_shallowmodel: f1_score:   0.603
12/27/2017 23:49:02 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:49:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.14      0.20        14
          C       0.71      0.67      0.69       164
          F       0.90      0.93      0.91       268
          R       0.59      0.63      0.61       125

avg / total       0.76      0.77      0.76       571

12/27/2017 23:49:02 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:49:02 [INFO] exp_shallowmodel: 
[[  2   1   2   9]
 [  3 110  14  37]
 [  0  10 248  10]
 [  1  34  11  79]]
12/27/2017 23:49:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/27/2017 23:49:04 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:49:04 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:49:04 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:49:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:49:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:49:04 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:49:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:50:33 [INFO] exp_shallowmodel: train time: 89.240s
12/27/2017 23:50:33 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:50:33 [INFO] exp_shallowmodel: accuracy:   0.762
12/27/2017 23:50:33 [INFO] exp_shallowmodel: f1_score:   0.662
12/27/2017 23:50:33 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:50:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.43      0.48        14
          C       0.66      0.66      0.66       164
          F       0.90      0.92      0.91       268
          R       0.60      0.59      0.60       125

avg / total       0.76      0.76      0.76       571

12/27/2017 23:50:33 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:50:33 [INFO] exp_shallowmodel: 
[[  6   2   3   3]
 [  2 108  13  41]
 [  2  14 247   5]
 [  1  40  10  74]]
12/27/2017 23:50:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/27/2017 23:50:37 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:50:37 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:50:37 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:50:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:50:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:50:37 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:50:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:51:19 [INFO] exp_shallowmodel: train time: 42.221s
12/27/2017 23:51:19 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:51:19 [INFO] exp_shallowmodel: accuracy:   0.774
12/27/2017 23:51:19 [INFO] exp_shallowmodel: f1_score:   0.650
12/27/2017 23:51:19 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:51:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.29      0.40        14
          C       0.70      0.71      0.71       164
          F       0.89      0.94      0.91       268
          R       0.60      0.56      0.58       125

avg / total       0.77      0.77      0.77       571

12/27/2017 23:51:19 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:51:19 [INFO] exp_shallowmodel: 
[[  4   4   2   4]
 [  0 116  12  36]
 [  1   8 252   7]
 [  1  37  17  70]]
12/27/2017 23:51:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/27/2017 23:51:21 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:51:21 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:51:21 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:51:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:51:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:51:21 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:51:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:52:13 [INFO] exp_shallowmodel: train time: 51.382s
12/27/2017 23:52:13 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:52:13 [INFO] exp_shallowmodel: accuracy:   0.809
12/27/2017 23:52:13 [INFO] exp_shallowmodel: f1_score:   0.697
12/27/2017 23:52:13 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:52:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.36      0.45        14
          C       0.74      0.78      0.76       164
          F       0.92      0.94      0.93       268
          R       0.67      0.62      0.65       125

avg / total       0.81      0.81      0.81       571

12/27/2017 23:52:13 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:52:13 [INFO] exp_shallowmodel: 
[[  5   2   4   3]
 [  0 128   7  29]
 [  3   8 251   6]
 [  0  36  11  78]]
12/27/2017 23:52:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/27/2017 23:52:16 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:52:16 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:52:16 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:52:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:52:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:52:16 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:52:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:53:35 [INFO] exp_shallowmodel: train time: 79.017s
12/27/2017 23:53:35 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:53:35 [INFO] exp_shallowmodel: accuracy:   0.767
12/27/2017 23:53:35 [INFO] exp_shallowmodel: f1_score:   0.652
12/27/2017 23:53:35 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:53:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.80      0.29      0.42        14
          C       0.65      0.71      0.68       164
          F       0.90      0.92      0.91       268
          R       0.63      0.57      0.60       125

avg / total       0.77      0.77      0.76       571

12/27/2017 23:53:35 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:53:35 [INFO] exp_shallowmodel: 
[[  4   1   6   3]
 [  0 117  15  32]
 [  0  16 246   6]
 [  1  46   7  71]]
12/27/2017 23:53:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/27/2017 23:53:38 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:53:38 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:53:38 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:53:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:53:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:53:38 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:53:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:54:51 [INFO] exp_shallowmodel: train time: 72.178s
12/27/2017 23:54:51 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:54:51 [INFO] exp_shallowmodel: accuracy:   0.732
12/27/2017 23:54:51 [INFO] exp_shallowmodel: f1_score:   0.618
12/27/2017 23:54:51 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:54:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.36      0.38        14
          C       0.63      0.65      0.64       164
          F       0.88      0.88      0.88       268
          R       0.57      0.55      0.56       125

avg / total       0.73      0.73      0.73       571

12/27/2017 23:54:51 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:54:51 [INFO] exp_shallowmodel: 
[[  5   1   6   2]
 [  4 107  14  39]
 [  0  21 237  10]
 [  3  42  11  69]]
12/27/2017 23:54:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/27/2017 23:54:54 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:54:54 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:54:54 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:54:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:54:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:54:54 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:54:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:56:00 [INFO] exp_shallowmodel: train time: 65.610s
12/27/2017 23:56:00 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:56:00 [INFO] exp_shallowmodel: accuracy:   0.790
12/27/2017 23:56:00 [INFO] exp_shallowmodel: f1_score:   0.711
12/27/2017 23:56:00 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:56:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.70      0.50      0.58        14
          C       0.73      0.76      0.74       164
          F       0.89      0.92      0.91       268
          R       0.64      0.58      0.61       125

avg / total       0.79      0.79      0.79       571

12/27/2017 23:56:00 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:56:00 [INFO] exp_shallowmodel: 
[[  7   2   4   1]
 [  0 124   9  31]
 [  0  12 247   9]
 [  3  33  16  73]]
12/27/2017 23:56:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/27/2017 23:56:03 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:56:03 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:56:03 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:56:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:56:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:56:03 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:56:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:57:22 [INFO] exp_shallowmodel: train time: 79.344s
12/27/2017 23:57:23 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:57:23 [INFO] exp_shallowmodel: accuracy:   0.771
12/27/2017 23:57:23 [INFO] exp_shallowmodel: f1_score:   0.661
12/27/2017 23:57:23 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:57:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.36      0.42        14
          C       0.68      0.69      0.69       164
          F       0.91      0.90      0.90       268
          R       0.63      0.66      0.64       125

avg / total       0.77      0.77      0.77       571

12/27/2017 23:57:23 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:57:23 [INFO] exp_shallowmodel: 
[[  5   2   5   2]
 [  1 113  11  39]
 [  2  18 240   8]
 [  2  32   9  82]]
12/27/2017 23:57:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/27/2017 23:57:26 [INFO] exp_shallowmodel: #(data) = 4568
12/27/2017 23:57:26 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:57:26 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:57:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:57:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:57:26 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:57:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:58:16 [INFO] exp_shallowmodel: train time: 50.073s
12/27/2017 23:58:16 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:58:16 [INFO] exp_shallowmodel: accuracy:   0.778
12/27/2017 23:58:16 [INFO] exp_shallowmodel: f1_score:   0.652
12/27/2017 23:58:16 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:58:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.25      0.36        16
          C       0.70      0.75      0.72       169
          F       0.89      0.92      0.90       271
          R       0.64      0.59      0.62       130

avg / total       0.77      0.78      0.77       586

12/27/2017 23:58:16 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:58:16 [INFO] exp_shallowmodel: 
[[  4   2   7   3]
 [  0 127  13  29]
 [  1  11 248  11]
 [  1  42  10  77]]
12/27/2017 23:58:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/27/2017 23:58:19 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:58:19 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:58:19 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:58:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:58:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:58:19 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:58:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/27/2017 23:59:14 [INFO] exp_shallowmodel: train time: 54.300s
12/27/2017 23:59:14 [INFO] exp_shallowmodel: test time:  0.008s
12/27/2017 23:59:14 [INFO] exp_shallowmodel: accuracy:   0.762
12/27/2017 23:59:14 [INFO] exp_shallowmodel: f1_score:   0.602
12/27/2017 23:59:14 [INFO] exp_shallowmodel: classification report:
12/27/2017 23:59:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.14      0.20        14
          C       0.69      0.68      0.68       164
          F       0.90      0.90      0.90       268
          R       0.60      0.66      0.63       125

avg / total       0.76      0.76      0.76       571

12/27/2017 23:59:14 [INFO] exp_shallowmodel: confusion matrix:
12/27/2017 23:59:14 [INFO] exp_shallowmodel: 
[[  2   5   3   4]
 [  0 111  13  40]
 [  3  15 240  10]
 [  1  30  12  82]]
12/27/2017 23:59:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/27/2017 23:59:17 [INFO] exp_shallowmodel: #(data) = 4583
12/27/2017 23:59:17 [INFO] exp_shallowmodel: #(feature) = 10590
12/27/2017 23:59:17 [INFO] exp_shallowmodel: ================================================================================
12/27/2017 23:59:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/27/2017 23:59:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/27/2017 23:59:17 [INFO] exp_shallowmodel: Training: 
12/27/2017 23:59:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:00:32 [INFO] exp_shallowmodel: train time: 74.783s
12/28/2017 00:00:32 [INFO] exp_shallowmodel: test time:  0.008s
12/28/2017 00:00:32 [INFO] exp_shallowmodel: accuracy:   0.767
12/28/2017 00:00:32 [INFO] exp_shallowmodel: f1_score:   0.649
12/28/2017 00:00:32 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:00:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.29      0.40        14
          C       0.68      0.65      0.66       164
          F       0.90      0.93      0.91       268
          R       0.61      0.64      0.62       125

avg / total       0.76      0.77      0.76       571

12/28/2017 00:00:32 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:00:32 [INFO] exp_shallowmodel: 
[[  4   2   5   3]
 [  0 106  17  41]
 [  1  11 248   8]
 [  1  38   6  80]]
12/28/2017 00:00:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/28/2017 00:00:35 [INFO] exp_shallowmodel: #(data) = 4583
12/28/2017 00:00:35 [INFO] exp_shallowmodel: #(feature) = 10590
12/28/2017 00:00:35 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:00:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:00:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:00:35 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:00:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:01:52 [INFO] exp_shallowmodel: train time: 76.395s
12/28/2017 00:01:52 [INFO] exp_shallowmodel: test time:  0.008s
12/28/2017 00:01:52 [INFO] exp_shallowmodel: accuracy:   0.779
12/28/2017 00:01:52 [INFO] exp_shallowmodel: f1_score:   0.612
12/28/2017 00:01:52 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:01:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.14      0.21        14
          C       0.70      0.68      0.69       164
          F       0.90      0.94      0.92       268
          R       0.63      0.62      0.63       125

avg / total       0.77      0.78      0.77       571

12/28/2017 00:01:52 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:01:52 [INFO] exp_shallowmodel: 
[[  2   1   3   8]
 [  0 112  18  34]
 [  2   9 253   4]
 [  1  39   7  78]]
12/28/2017 00:01:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/28/2017 00:01:55 [INFO] exp_shallowmodel: #(data) = 4583
12/28/2017 00:01:55 [INFO] exp_shallowmodel: #(feature) = 10590
12/28/2017 00:01:55 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:01:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:01:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:01:55 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:01:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:03:11 [INFO] exp_shallowmodel: train time: 75.585s
12/28/2017 00:03:11 [INFO] exp_shallowmodel: test time:  0.008s
12/28/2017 00:03:11 [INFO] exp_shallowmodel: accuracy:   0.743
12/28/2017 00:03:11 [INFO] exp_shallowmodel: f1_score:   0.667
12/28/2017 00:03:11 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:03:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.70      0.50      0.58        14
          C       0.63      0.69      0.66       164
          F       0.90      0.90      0.90       268
          R       0.55      0.50      0.53       125

avg / total       0.74      0.74      0.74       571

12/28/2017 00:03:11 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:03:11 [INFO] exp_shallowmodel: 
[[  7   1   4   2]
 [  1 113  11  39]
 [  0  17 241  10]
 [  2  48  12  63]]
12/28/2017 00:03:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/28/2017 00:03:14 [INFO] exp_shallowmodel: #(data) = 4583
12/28/2017 00:03:14 [INFO] exp_shallowmodel: #(feature) = 10590
12/28/2017 00:03:14 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:03:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:03:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:03:14 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:03:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:04:39 [INFO] exp_shallowmodel: train time: 84.796s
12/28/2017 00:04:39 [INFO] exp_shallowmodel: test time:  0.008s
12/28/2017 00:04:39 [INFO] exp_shallowmodel: accuracy:   0.755
12/28/2017 00:04:39 [INFO] exp_shallowmodel: f1_score:   0.567
12/28/2017 00:04:39 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:04:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.71      0.72      0.72       164
          F       0.87      0.90      0.88       268
          R       0.59      0.56      0.57       125

avg / total       0.74      0.75      0.75       571

12/28/2017 00:04:39 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:04:39 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  1 118  15  30]
 [  4   8 242  14]
 [  1  37  17  70]]
12/28/2017 00:04:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/28/2017 00:04:44 [INFO] exp_shallowmodel: #(data) = 4583
12/28/2017 00:04:44 [INFO] exp_shallowmodel: #(feature) = 10590
12/28/2017 00:04:44 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:04:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:04:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:04:44 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:04:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:05:42 [INFO] exp_shallowmodel: train time: 58.449s
12/28/2017 00:05:42 [INFO] exp_shallowmodel: test time:  0.008s
12/28/2017 00:05:42 [INFO] exp_shallowmodel: accuracy:   0.771
12/28/2017 00:05:42 [INFO] exp_shallowmodel: f1_score:   0.650
12/28/2017 00:05:42 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:05:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.36      0.40        14
          C       0.67      0.76      0.71       164
          F       0.93      0.91      0.92       268
          R       0.60      0.54      0.57       125

avg / total       0.77      0.77      0.77       571

12/28/2017 00:05:42 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:05:42 [INFO] exp_shallowmodel: 
[[  5   4   3   2]
 [  1 124   6  33]
 [  2  12 243  11]
 [  3  45   9  68]]
12/28/2017 00:05:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/28/2017 00:05:44 [INFO] exp_shallowmodel: #(data) = 4583
12/28/2017 00:05:44 [INFO] exp_shallowmodel: #(feature) = 10590
12/28/2017 00:05:44 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:05:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:05:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:05:44 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:05:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:06:28 [INFO] exp_shallowmodel: train time: 43.670s
12/28/2017 00:06:28 [INFO] exp_shallowmodel: test time:  0.008s
12/28/2017 00:06:28 [INFO] exp_shallowmodel: accuracy:   0.753
12/28/2017 00:06:28 [INFO] exp_shallowmodel: f1_score:   0.660
12/28/2017 00:06:28 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:06:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.43      0.50        14
          C       0.67      0.67      0.67       164
          F       0.89      0.91      0.90       268
          R       0.57      0.57      0.57       125

avg / total       0.75      0.75      0.75       571

12/28/2017 00:06:28 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:06:28 [INFO] exp_shallowmodel: 
[[  6   0   5   3]
 [  2 110  14  38]
 [  1  12 243  12]
 [  1  42  11  71]]
12/28/2017 00:06:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/28/2017 00:06:29 [INFO] exp_shallowmodel: #(data) = 4583
12/28/2017 00:06:29 [INFO] exp_shallowmodel: #(feature) = 10590
12/28/2017 00:06:29 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:06:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:06:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:06:29 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:06:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:07:18 [INFO] exp_shallowmodel: train time: 48.857s
12/28/2017 00:07:18 [INFO] exp_shallowmodel: test time:  0.008s
12/28/2017 00:07:18 [INFO] exp_shallowmodel: accuracy:   0.776
12/28/2017 00:07:18 [INFO] exp_shallowmodel: f1_score:   0.692
12/28/2017 00:07:18 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:07:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.64      0.50      0.56        14
          C       0.68      0.71      0.70       164
          F       0.92      0.92      0.92       268
          R       0.59      0.58      0.59       125

avg / total       0.78      0.78      0.78       571

12/28/2017 00:07:18 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:07:18 [INFO] exp_shallowmodel: 
[[  7   1   4   2]
 [  0 117  11  36]
 [  1   9 246  12]
 [  3  44   5  73]]
12/28/2017 00:07:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/28/2017 00:07:20 [INFO] exp_shallowmodel: #(data) = 4583
12/28/2017 00:07:20 [INFO] exp_shallowmodel: #(feature) = 10590
12/28/2017 00:07:20 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:07:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:07:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:07:20 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:07:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:07:57 [INFO] exp_shallowmodel: train time: 36.839s
12/28/2017 00:07:57 [INFO] exp_shallowmodel: test time:  0.008s
12/28/2017 00:07:57 [INFO] exp_shallowmodel: accuracy:   0.797
12/28/2017 00:07:57 [INFO] exp_shallowmodel: f1_score:   0.658
12/28/2017 00:07:57 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:07:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.21      0.30        14
          C       0.74      0.78      0.76       164
          F       0.89      0.90      0.89       268
          R       0.70      0.66      0.68       125

avg / total       0.79      0.80      0.79       571

12/28/2017 00:07:57 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:07:57 [INFO] exp_shallowmodel: 
[[  3   2   6   3]
 [  1 128  13  22]
 [  2  14 241  11]
 [  0  30  12  83]]
12/28/2017 00:08:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/28/2017 00:08:00 [INFO] exp_shallowmodel: #(data) = 4568
12/28/2017 00:08:00 [INFO] exp_shallowmodel: #(feature) = 10590
12/28/2017 00:08:00 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:08:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:08:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:08:00 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:08:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:09:22 [INFO] exp_shallowmodel: train time: 81.901s
12/28/2017 00:09:22 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:09:22 [INFO] exp_shallowmodel: accuracy:   0.773
12/28/2017 00:09:22 [INFO] exp_shallowmodel: f1_score:   0.661
12/28/2017 00:09:22 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:09:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.31      0.42        16
          C       0.69      0.70      0.70       169
          F       0.89      0.92      0.90       271
          R       0.63      0.62      0.63       130

avg / total       0.77      0.77      0.77       586

12/28/2017 00:09:22 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:09:22 [INFO] exp_shallowmodel: 
[[  5   1   7   3]
 [  1 119  11  38]
 [  0  17 248   6]
 [  2  35  12  81]]
12/28/2017 00:09:26 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/28/2017 00:09:26 [INFO] task_runner: context=next, feature=13-[8+1.3.4], similarity=False
12/28/2017 00:09:26 [INFO] task_runner: Before filtering, #(feature)=36306
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 1 : 5
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		2.1 : 69
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 2 : 74
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		2.2 : 3
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		2.3.1 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		2.3.2 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 3 : 5
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		4.1 : 13863
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 4 : 13867
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		4.2.1 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		4.2.2 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		4.3.1 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		4.3.2 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 5 : 4308
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 6 : 942
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 7 : 1845
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		8.1 : 250
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 8 : 252
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		8.2.1 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		8.2.2 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		9.1 : 1500
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 9 : 1504
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		9.2.1 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		9.2.2 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		9.3.1 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		9.3.2 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		10.1 : 1500
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 10 : 1502
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		10.2.1 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		10.2.2 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		11.1 : 12000
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 11 : 12002
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		11.2.1 : 1
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		11.2.2 : 1
12/28/2017 00:09:26 [INFO] task_runner: After filtering, #(feature)=11488
12/28/2017 00:09:26 [INFO] task_runner: retained feature id=[1, 11.1, 2.1, 2.2, 3, 5, 6, 7]
12/28/2017 00:09:26 [INFO] task_runner: #(data)=5934
12/28/2017 00:09:26 [INFO] task_runner: #(feature)=11488/36306
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 1 : 3
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		2.1 : 46
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 2 : 48
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		2.2 : 2
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 3 : 5
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 5 : 2621
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 6 : 484
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 7 : 1127
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 		11.1 : 7200
12/28/2017 00:09:26 [INFO] exp_shallowmodel: 11 : 7200
12/28/2017 00:09:26 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/28/2017 00:09:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/28/2017 00:09:30 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:09:30 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:09:30 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:09:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:09:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:09:30 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:09:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:11:05 [INFO] exp_shallowmodel: train time: 95.485s
12/28/2017 00:11:05 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:11:05 [INFO] exp_shallowmodel: accuracy:   0.720
12/28/2017 00:11:05 [INFO] exp_shallowmodel: f1_score:   0.628
12/28/2017 00:11:05 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:11:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.69      0.45      0.55        20
          C       0.65      0.63      0.64       169
          F       0.87      0.92      0.90       281
          R       0.43      0.43      0.43       122

avg / total       0.71      0.72      0.72       592

12/28/2017 00:11:05 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:11:05 [INFO] exp_shallowmodel: 
[[  9   1   8   2]
 [  1 107   9  52]
 [  1   8 258  14]
 [  2  48  20  52]]
12/28/2017 00:11:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/28/2017 00:11:07 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:11:07 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:11:07 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:11:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:11:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:11:07 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:11:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:12:20 [INFO] exp_shallowmodel: train time: 73.079s
12/28/2017 00:12:20 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:12:20 [INFO] exp_shallowmodel: accuracy:   0.750
12/28/2017 00:12:20 [INFO] exp_shallowmodel: f1_score:   0.643
12/28/2017 00:12:20 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:12:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.40      0.47        20
          C       0.69      0.67      0.68       169
          F       0.89      0.93      0.91       281
          R       0.51      0.51      0.51       122

avg / total       0.75      0.75      0.75       592

12/28/2017 00:12:20 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:12:20 [INFO] exp_shallowmodel: 
[[  8   4   5   3]
 [  2 114  10  43]
 [  1   6 260  14]
 [  3  41  16  62]]
12/28/2017 00:12:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/28/2017 00:12:24 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:12:24 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:12:24 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:12:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:12:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:12:24 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:12:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:14:04 [INFO] exp_shallowmodel: train time: 99.508s
12/28/2017 00:14:04 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:14:04 [INFO] exp_shallowmodel: accuracy:   0.742
12/28/2017 00:14:04 [INFO] exp_shallowmodel: f1_score:   0.610
12/28/2017 00:14:04 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:14:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.25      0.34        20
          C       0.72      0.71      0.72       169
          F       0.87      0.90      0.88       281
          R       0.49      0.50      0.49       122

avg / total       0.74      0.74      0.74       592

12/28/2017 00:14:04 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:14:04 [INFO] exp_shallowmodel: 
[[  5   2   8   5]
 [  0 120   9  40]
 [  1   8 253  19]
 [  3  36  22  61]]
12/28/2017 00:14:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/28/2017 00:14:07 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:14:07 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:14:07 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:14:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:14:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:14:07 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:14:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:15:08 [INFO] exp_shallowmodel: train time: 60.722s
12/28/2017 00:15:08 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:15:08 [INFO] exp_shallowmodel: accuracy:   0.757
12/28/2017 00:15:08 [INFO] exp_shallowmodel: f1_score:   0.658
12/28/2017 00:15:08 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:15:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.40      0.50        20
          C       0.71      0.72      0.71       169
          F       0.88      0.91      0.90       281
          R       0.53      0.52      0.52       122

avg / total       0.75      0.76      0.75       592

12/28/2017 00:15:08 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:15:08 [INFO] exp_shallowmodel: 
[[  8   1   5   6]
 [  0 121  11  37]
 [  2  10 256  13]
 [  2  38  19  63]]
12/28/2017 00:15:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/28/2017 00:15:10 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:15:10 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:15:10 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:15:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:15:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:15:10 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:15:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:15:57 [INFO] exp_shallowmodel: train time: 46.898s
12/28/2017 00:15:57 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:15:57 [INFO] exp_shallowmodel: accuracy:   0.701
12/28/2017 00:15:57 [INFO] exp_shallowmodel: f1_score:   0.569
12/28/2017 00:15:57 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:15:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.25      0.33        20
          C       0.64      0.66      0.65       169
          F       0.87      0.88      0.87       281
          R       0.41      0.42      0.42       122

avg / total       0.70      0.70      0.70       592

12/28/2017 00:15:57 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:15:57 [INFO] exp_shallowmodel: 
[[  5   1   8   6]
 [  2 112   8  47]
 [  3  12 247  19]
 [  0  50  21  51]]
12/28/2017 00:15:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/28/2017 00:15:59 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:15:59 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:15:59 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:15:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:15:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:15:59 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:15:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:17:25 [INFO] exp_shallowmodel: train time: 85.848s
12/28/2017 00:17:25 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:17:25 [INFO] exp_shallowmodel: accuracy:   0.723
12/28/2017 00:17:25 [INFO] exp_shallowmodel: f1_score:   0.581
12/28/2017 00:17:25 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:17:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.25      0.29        20
          C       0.68      0.67      0.67       169
          F       0.87      0.90      0.88       281
          R       0.47      0.47      0.47       122

avg / total       0.72      0.72      0.72       592

12/28/2017 00:17:25 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:17:25 [INFO] exp_shallowmodel: 
[[  5   4   9   2]
 [  0 113   8  48]
 [  4  11 253  13]
 [  5  39  21  57]]
12/28/2017 00:17:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/28/2017 00:17:29 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:17:29 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:17:29 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:17:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:17:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:17:29 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:17:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:18:49 [INFO] exp_shallowmodel: train time: 80.525s
12/28/2017 00:18:49 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:18:49 [INFO] exp_shallowmodel: accuracy:   0.725
12/28/2017 00:18:49 [INFO] exp_shallowmodel: f1_score:   0.611
12/28/2017 00:18:49 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:18:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.35      0.42        20
          C       0.64      0.66      0.65       169
          F       0.90      0.90      0.90       281
          R       0.47      0.48      0.47       122

avg / total       0.72      0.72      0.72       592

12/28/2017 00:18:49 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:18:49 [INFO] exp_shallowmodel: 
[[  7   6   4   3]
 [  2 111  10  46]
 [  3   8 253  17]
 [  1  48  15  58]]
12/28/2017 00:18:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/28/2017 00:18:53 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:18:53 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:18:53 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:18:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:18:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:18:53 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:18:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:20:20 [INFO] exp_shallowmodel: train time: 87.090s
12/28/2017 00:20:20 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 00:20:20 [INFO] exp_shallowmodel: accuracy:   0.721
12/28/2017 00:20:20 [INFO] exp_shallowmodel: f1_score:   0.628
12/28/2017 00:20:20 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:20:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.40      0.50        20
          C       0.68      0.65      0.67       169
          F       0.86      0.89      0.88       281
          R       0.46      0.48      0.47       122

avg / total       0.72      0.72      0.72       592

12/28/2017 00:20:20 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:20:20 [INFO] exp_shallowmodel: 
[[  8   4   5   3]
 [  0 110  12  47]
 [  2   9 250  20]
 [  2  38  23  59]]
12/28/2017 00:20:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/28/2017 00:20:24 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:20:24 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:20:24 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:20:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:20:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:20:24 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:20:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:21:34 [INFO] exp_shallowmodel: train time: 69.747s
12/28/2017 00:21:34 [INFO] exp_shallowmodel: test time:  0.018s
12/28/2017 00:21:34 [INFO] exp_shallowmodel: accuracy:   0.738
12/28/2017 00:21:34 [INFO] exp_shallowmodel: f1_score:   0.650
12/28/2017 00:21:34 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:21:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.45      0.56        20
          C       0.68      0.64      0.66       169
          F       0.85      0.94      0.89       281
          R       0.51      0.47      0.49       122

avg / total       0.73      0.74      0.73       592

12/28/2017 00:21:34 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:21:34 [INFO] exp_shallowmodel: 
[[  9   3   7   1]
 [  1 108  18  42]
 [  1   6 263  11]
 [  1  43  21  57]]
12/28/2017 00:21:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/28/2017 00:21:38 [INFO] exp_shallowmodel: #(data) = 4736
12/28/2017 00:21:38 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:21:38 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:21:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:21:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:21:38 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:21:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:23:08 [INFO] exp_shallowmodel: train time: 90.226s
12/28/2017 00:23:08 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:23:08 [INFO] exp_shallowmodel: accuracy:   0.734
12/28/2017 00:23:08 [INFO] exp_shallowmodel: f1_score:   0.614
12/28/2017 00:23:08 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:23:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.29      0.38        28
          C       0.67      0.69      0.68       172
          F       0.88      0.91      0.89       283
          R       0.50      0.50      0.50       123

avg / total       0.73      0.73      0.73       606

12/28/2017 00:23:08 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:23:08 [INFO] exp_shallowmodel: 
[[  8   7  10   3]
 [  1 118   9  44]
 [  4   7 257  15]
 [  1  43  17  62]]
12/28/2017 00:23:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/28/2017 00:23:10 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:23:10 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:23:10 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:23:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:23:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:23:10 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:23:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:24:01 [INFO] exp_shallowmodel: train time: 51.658s
12/28/2017 00:24:02 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:24:02 [INFO] exp_shallowmodel: accuracy:   0.747
12/28/2017 00:24:02 [INFO] exp_shallowmodel: f1_score:   0.646
12/28/2017 00:24:02 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:24:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.40      0.48        20
          C       0.71      0.69      0.70       169
          F       0.87      0.91      0.89       281
          R       0.52      0.51      0.51       122

avg / total       0.74      0.75      0.74       592

12/28/2017 00:24:02 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:24:02 [INFO] exp_shallowmodel: 
[[  8   1   8   3]
 [  2 117  14  36]
 [  0   7 255  19]
 [  3  40  17  62]]
12/28/2017 00:24:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/28/2017 00:24:05 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:24:05 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:24:05 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:24:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:24:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:24:05 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:24:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:25:39 [INFO] exp_shallowmodel: train time: 93.771s
12/28/2017 00:25:39 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:25:39 [INFO] exp_shallowmodel: accuracy:   0.713
12/28/2017 00:25:39 [INFO] exp_shallowmodel: f1_score:   0.580
12/28/2017 00:25:39 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:25:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.25      0.33        20
          C       0.64      0.62      0.63       169
          F       0.89      0.90      0.90       281
          R       0.43      0.48      0.46       122

avg / total       0.71      0.71      0.71       592

12/28/2017 00:25:39 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:25:39 [INFO] exp_shallowmodel: 
[[  5   4   7   4]
 [  2 105   9  53]
 [  1   7 253  20]
 [  2  47  14  59]]
12/28/2017 00:25:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/28/2017 00:25:43 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:25:43 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:25:43 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:25:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:25:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:25:43 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:25:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:27:00 [INFO] exp_shallowmodel: train time: 76.905s
12/28/2017 00:27:00 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:27:00 [INFO] exp_shallowmodel: accuracy:   0.733
12/28/2017 00:27:00 [INFO] exp_shallowmodel: f1_score:   0.643
12/28/2017 00:27:00 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:27:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.69      0.45      0.55        20
          C       0.67      0.70      0.69       169
          F       0.88      0.90      0.89       281
          R       0.46      0.43      0.45       122

avg / total       0.73      0.73      0.73       592

12/28/2017 00:27:00 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:27:00 [INFO] exp_shallowmodel: 
[[  9   5   4   2]
 [  1 119   9  40]
 [  2   7 253  19]
 [  1  47  21  53]]
12/28/2017 00:27:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/28/2017 00:27:04 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:27:04 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:27:04 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:27:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:27:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:27:04 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:27:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:28:34 [INFO] exp_shallowmodel: train time: 90.102s
12/28/2017 00:28:34 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:28:34 [INFO] exp_shallowmodel: accuracy:   0.753
12/28/2017 00:28:34 [INFO] exp_shallowmodel: f1_score:   0.663
12/28/2017 00:28:34 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:28:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.69      0.45      0.55        20
          C       0.69      0.72      0.70       169
          F       0.90      0.91      0.90       281
          R       0.51      0.49      0.50       122

avg / total       0.75      0.75      0.75       592

12/28/2017 00:28:34 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:28:34 [INFO] exp_shallowmodel: 
[[  9   2   6   3]
 [  0 122   7  40]
 [  2  10 255  14]
 [  2  44  16  60]]
12/28/2017 00:28:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/28/2017 00:28:38 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:28:38 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:28:38 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:28:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:28:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:28:38 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:28:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:29:56 [INFO] exp_shallowmodel: train time: 78.333s
12/28/2017 00:29:56 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:29:56 [INFO] exp_shallowmodel: accuracy:   0.755
12/28/2017 00:29:56 [INFO] exp_shallowmodel: f1_score:   0.604
12/28/2017 00:29:56 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:29:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.20      0.27        20
          C       0.73      0.69      0.71       169
          F       0.89      0.92      0.90       281
          R       0.52      0.56      0.54       122

avg / total       0.75      0.76      0.75       592

12/28/2017 00:29:56 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:29:56 [INFO] exp_shallowmodel: 
[[  4   4   9   3]
 [  4 117   6  42]
 [  1   5 258  17]
 [  1  35  18  68]]
12/28/2017 00:29:58 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/28/2017 00:29:58 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:29:58 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:29:58 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:29:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:29:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:29:58 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:29:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:30:48 [INFO] exp_shallowmodel: train time: 49.589s
12/28/2017 00:30:48 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:30:48 [INFO] exp_shallowmodel: accuracy:   0.733
12/28/2017 00:30:48 [INFO] exp_shallowmodel: f1_score:   0.622
12/28/2017 00:30:48 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:30:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.35      0.44        20
          C       0.71      0.67      0.69       169
          F       0.86      0.91      0.88       281
          R       0.47      0.48      0.47       122

avg / total       0.73      0.73      0.73       592

12/28/2017 00:30:48 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:30:48 [INFO] exp_shallowmodel: 
[[  7   4   3   6]
 [  1 114  12  42]
 [  3   6 255  17]
 [  1  36  27  58]]
12/28/2017 00:30:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/28/2017 00:30:50 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:30:50 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:30:50 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:30:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:30:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:30:50 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:30:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:32:03 [INFO] exp_shallowmodel: train time: 73.485s
12/28/2017 00:32:03 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:32:03 [INFO] exp_shallowmodel: accuracy:   0.755
12/28/2017 00:32:03 [INFO] exp_shallowmodel: f1_score:   0.629
12/28/2017 00:32:03 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:32:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.30      0.36        20
          C       0.72      0.72      0.72       169
          F       0.88      0.90      0.89       281
          R       0.54      0.55      0.54       122

avg / total       0.75      0.76      0.75       592

12/28/2017 00:32:03 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:32:03 [INFO] exp_shallowmodel: 
[[  6   1  10   3]
 [  1 121   8  39]
 [  3  10 253  15]
 [  3  35  17  67]]
12/28/2017 00:32:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/28/2017 00:32:05 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:32:05 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:32:05 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:32:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:32:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:32:05 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:32:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:33:03 [INFO] exp_shallowmodel: train time: 58.093s
12/28/2017 00:33:03 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:33:03 [INFO] exp_shallowmodel: accuracy:   0.748
12/28/2017 00:33:03 [INFO] exp_shallowmodel: f1_score:   0.661
12/28/2017 00:33:03 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:33:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.59      0.50      0.54        20
          C       0.71      0.68      0.70       169
          F       0.87      0.91      0.89       281
          R       0.52      0.52      0.52       122

avg / total       0.74      0.75      0.75       592

12/28/2017 00:33:03 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:33:03 [INFO] exp_shallowmodel: 
[[ 10   3   5   2]
 [  4 115   8  42]
 [  3   9 255  14]
 [  0  34  25  63]]
12/28/2017 00:33:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/28/2017 00:33:05 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:33:05 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:33:05 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:33:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:33:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:33:05 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:33:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:34:24 [INFO] exp_shallowmodel: train time: 78.489s
12/28/2017 00:34:24 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:34:24 [INFO] exp_shallowmodel: accuracy:   0.745
12/28/2017 00:34:24 [INFO] exp_shallowmodel: f1_score:   0.664
12/28/2017 00:34:24 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:34:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.45      0.56        20
          C       0.71      0.72      0.71       169
          F       0.87      0.89      0.88       281
          R       0.51      0.50      0.50       122

avg / total       0.74      0.74      0.74       592

12/28/2017 00:34:24 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:34:24 [INFO] exp_shallowmodel: 
[[  9   4   4   3]
 [  0 121  10  38]
 [  1  12 250  18]
 [  2  34  25  61]]
12/28/2017 00:34:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/28/2017 00:34:26 [INFO] exp_shallowmodel: #(data) = 4736
12/28/2017 00:34:26 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:34:26 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:34:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:34:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:34:26 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:34:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:35:19 [INFO] exp_shallowmodel: train time: 53.062s
12/28/2017 00:35:19 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:35:19 [INFO] exp_shallowmodel: accuracy:   0.721
12/28/2017 00:35:19 [INFO] exp_shallowmodel: f1_score:   0.622
12/28/2017 00:35:19 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:35:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.65      0.39      0.49        28
          C       0.65      0.70      0.67       172
          F       0.86      0.90      0.88       283
          R       0.47      0.42      0.44       123

avg / total       0.71      0.72      0.72       606

12/28/2017 00:35:19 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:35:19 [INFO] exp_shallowmodel: 
[[ 11   6   9   2]
 [  0 120  14  38]
 [  3   7 254  19]
 [  3  51  17  52]]
12/28/2017 00:35:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/28/2017 00:35:21 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:35:21 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:35:21 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:35:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:35:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:35:21 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:35:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:36:55 [INFO] exp_shallowmodel: train time: 93.519s
12/28/2017 00:36:55 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 00:36:55 [INFO] exp_shallowmodel: accuracy:   0.740
12/28/2017 00:36:55 [INFO] exp_shallowmodel: f1_score:   0.655
12/28/2017 00:36:55 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:36:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.50      0.56        20
          C       0.68      0.64      0.66       169
          F       0.89      0.91      0.90       281
          R       0.49      0.52      0.50       122

avg / total       0.74      0.74      0.74       592

12/28/2017 00:36:55 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:36:55 [INFO] exp_shallowmodel: 
[[ 10   2   5   3]
 [  3 109  11  46]
 [  1   7 256  17]
 [  2  42  15  63]]
12/28/2017 00:36:58 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/28/2017 00:36:58 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:36:58 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:36:58 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:36:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:36:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:36:58 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:36:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:39:02 [INFO] exp_shallowmodel: train time: 124.063s
12/28/2017 00:39:02 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:39:02 [INFO] exp_shallowmodel: accuracy:   0.750
12/28/2017 00:39:02 [INFO] exp_shallowmodel: f1_score:   0.633
12/28/2017 00:39:02 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:39:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.30      0.40        20
          C       0.71      0.69      0.70       169
          F       0.87      0.90      0.89       281
          R       0.54      0.56      0.55       122

avg / total       0.75      0.75      0.75       592

12/28/2017 00:39:02 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:39:02 [INFO] exp_shallowmodel: 
[[  6   3   8   3]
 [  1 116  13  39]
 [  2   8 254  17]
 [  1  37  16  68]]
12/28/2017 00:39:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/28/2017 00:39:04 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:39:04 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:39:04 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:39:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:39:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:39:04 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:39:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:40:06 [INFO] exp_shallowmodel: train time: 61.241s
12/28/2017 00:40:06 [INFO] exp_shallowmodel: test time:  0.043s
12/28/2017 00:40:06 [INFO] exp_shallowmodel: accuracy:   0.721
12/28/2017 00:40:06 [INFO] exp_shallowmodel: f1_score:   0.601
12/28/2017 00:40:06 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:40:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.35      0.41        20
          C       0.65      0.63      0.64       169
          F       0.86      0.93      0.89       281
          R       0.49      0.44      0.46       122

avg / total       0.71      0.72      0.71       592

12/28/2017 00:40:06 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:40:06 [INFO] exp_shallowmodel: 
[[  7   2   6   5]
 [  3 106  18  42]
 [  1  10 260  10]
 [  3  45  20  54]]
12/28/2017 00:40:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/28/2017 00:40:11 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:40:11 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:40:11 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:40:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:40:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:40:11 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:40:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:41:20 [INFO] exp_shallowmodel: train time: 68.546s
12/28/2017 00:41:20 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:41:20 [INFO] exp_shallowmodel: accuracy:   0.738
12/28/2017 00:41:20 [INFO] exp_shallowmodel: f1_score:   0.660
12/28/2017 00:41:20 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:41:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.82      0.45      0.58        20
          C       0.69      0.67      0.68       169
          F       0.89      0.90      0.90       281
          R       0.46      0.50      0.48       122

avg / total       0.74      0.74      0.74       592

12/28/2017 00:41:20 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:41:20 [INFO] exp_shallowmodel: 
[[  9   3   6   2]
 [  0 114   5  50]
 [  2   7 253  19]
 [  0  41  20  61]]
12/28/2017 00:41:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/28/2017 00:41:24 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:41:24 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:41:24 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:41:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:41:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:41:24 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:41:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:42:11 [INFO] exp_shallowmodel: train time: 47.491s
12/28/2017 00:42:11 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:42:11 [INFO] exp_shallowmodel: accuracy:   0.725
12/28/2017 00:42:11 [INFO] exp_shallowmodel: f1_score:   0.649
12/28/2017 00:42:11 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:42:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.71      0.50      0.59        20
          C       0.64      0.62      0.63       169
          F       0.89      0.90      0.90       281
          R       0.47      0.49      0.48       122

avg / total       0.73      0.72      0.72       592

12/28/2017 00:42:11 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:42:11 [INFO] exp_shallowmodel: 
[[ 10   4   3   3]
 [  2 105   9  53]
 [  1  13 254  13]
 [  1  43  18  60]]
12/28/2017 00:42:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/28/2017 00:42:13 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:42:13 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:42:13 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:42:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:42:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:42:13 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:42:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:43:32 [INFO] exp_shallowmodel: train time: 78.642s
12/28/2017 00:43:32 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:43:32 [INFO] exp_shallowmodel: accuracy:   0.726
12/28/2017 00:43:32 [INFO] exp_shallowmodel: f1_score:   0.581
12/28/2017 00:43:32 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:43:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.20      0.30        20
          C       0.66      0.72      0.69       169
          F       0.86      0.89      0.88       281
          R       0.48      0.43      0.46       122

avg / total       0.72      0.73      0.72       592

12/28/2017 00:43:32 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:43:32 [INFO] exp_shallowmodel: 
[[  4   6   8   2]
 [  2 122  10  35]
 [  1   9 251  20]
 [  0  47  22  53]]
12/28/2017 00:43:36 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/28/2017 00:43:36 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:43:36 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:43:36 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:43:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:43:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:43:36 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:43:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:45:01 [INFO] exp_shallowmodel: train time: 84.400s
12/28/2017 00:45:01 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:45:01 [INFO] exp_shallowmodel: accuracy:   0.758
12/28/2017 00:45:01 [INFO] exp_shallowmodel: f1_score:   0.619
12/28/2017 00:45:01 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:45:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.80      0.20      0.32        20
          C       0.73      0.71      0.72       169
          F       0.87      0.92      0.89       281
          R       0.54      0.55      0.54       122

avg / total       0.76      0.76      0.75       592

12/28/2017 00:45:01 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:45:01 [INFO] exp_shallowmodel: 
[[  4   5   6   5]
 [  1 120  11  37]
 [  0   8 258  15]
 [  0  32  23  67]]
12/28/2017 00:45:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/28/2017 00:45:04 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:45:04 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:45:04 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:45:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:45:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:45:04 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:45:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:46:43 [INFO] exp_shallowmodel: train time: 98.018s
12/28/2017 00:46:43 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:46:43 [INFO] exp_shallowmodel: accuracy:   0.748
12/28/2017 00:46:43 [INFO] exp_shallowmodel: f1_score:   0.654
12/28/2017 00:46:43 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:46:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.45      0.51        20
          C       0.69      0.67      0.68       169
          F       0.89      0.91      0.90       281
          R       0.52      0.52      0.52       122

avg / total       0.75      0.75      0.75       592

12/28/2017 00:46:43 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:46:43 [INFO] exp_shallowmodel: 
[[  9   6   4   1]
 [  1 114   9  45]
 [  3   9 256  13]
 [  2  37  19  64]]
12/28/2017 00:46:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/28/2017 00:46:46 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:46:46 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:46:46 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:46:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:46:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:46:46 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:46:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:48:31 [INFO] exp_shallowmodel: train time: 104.730s
12/28/2017 00:48:31 [INFO] exp_shallowmodel: test time:  0.018s
12/28/2017 00:48:31 [INFO] exp_shallowmodel: accuracy:   0.733
12/28/2017 00:48:31 [INFO] exp_shallowmodel: f1_score:   0.562
12/28/2017 00:48:31 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:48:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.15      0.19        20
          C       0.68      0.75      0.72       169
          F       0.88      0.90      0.89       281
          R       0.48      0.43      0.45       122

avg / total       0.72      0.73      0.73       592

12/28/2017 00:48:31 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:48:31 [INFO] exp_shallowmodel: 
[[  3   5   8   4]
 [  1 127   7  34]
 [  1   9 252  19]
 [  6  45  19  52]]
12/28/2017 00:48:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/28/2017 00:48:37 [INFO] exp_shallowmodel: #(data) = 4736
12/28/2017 00:48:37 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:48:37 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:48:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:48:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:48:37 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:48:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:50:11 [INFO] exp_shallowmodel: train time: 94.481s
12/28/2017 00:50:11 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:50:11 [INFO] exp_shallowmodel: accuracy:   0.733
12/28/2017 00:50:11 [INFO] exp_shallowmodel: f1_score:   0.643
12/28/2017 00:50:11 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:50:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.63      0.43      0.51        28
          C       0.67      0.69      0.68       172
          F       0.86      0.90      0.88       283
          R       0.53      0.49      0.51       123

avg / total       0.73      0.73      0.73       606

12/28/2017 00:50:11 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:50:11 [INFO] exp_shallowmodel: 
[[ 12   8   6   2]
 [  3 118  13  38]
 [  4  11 254  14]
 [  0  40  23  60]]
12/28/2017 00:50:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/28/2017 00:50:15 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:50:15 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:50:15 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:50:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:50:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:50:15 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:50:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:51:29 [INFO] exp_shallowmodel: train time: 74.254s
12/28/2017 00:51:29 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:51:29 [INFO] exp_shallowmodel: accuracy:   0.736
12/28/2017 00:51:29 [INFO] exp_shallowmodel: f1_score:   0.628
12/28/2017 00:51:29 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:51:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.45      0.47        20
          C       0.68      0.66      0.67       169
          F       0.90      0.93      0.91       281
          R       0.46      0.45      0.45       122

avg / total       0.73      0.74      0.73       592

12/28/2017 00:51:29 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:51:29 [INFO] exp_shallowmodel: 
[[  9   2   5   4]
 [  3 112   5  49]
 [  4   5 260  12]
 [  2  46  19  55]]
12/28/2017 00:51:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/28/2017 00:51:31 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:51:31 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:51:31 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:51:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:51:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:51:31 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:51:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:52:40 [INFO] exp_shallowmodel: train time: 68.335s
12/28/2017 00:52:40 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:52:40 [INFO] exp_shallowmodel: accuracy:   0.765
12/28/2017 00:52:40 [INFO] exp_shallowmodel: f1_score:   0.667
12/28/2017 00:52:40 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:52:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.45      0.51        20
          C       0.73      0.73      0.73       169
          F       0.88      0.92      0.90       281
          R       0.54      0.51      0.53       122

avg / total       0.76      0.77      0.76       592

12/28/2017 00:52:40 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:52:40 [INFO] exp_shallowmodel: 
[[  9   1   6   4]
 [  2 124   8  35]
 [  1   9 258  13]
 [  3  37  20  62]]
12/28/2017 00:52:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/28/2017 00:52:44 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:52:44 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:52:44 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:52:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:52:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:52:44 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:52:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:54:16 [INFO] exp_shallowmodel: train time: 92.658s
12/28/2017 00:54:16 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:54:16 [INFO] exp_shallowmodel: accuracy:   0.728
12/28/2017 00:54:16 [INFO] exp_shallowmodel: f1_score:   0.612
12/28/2017 00:54:16 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:54:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.40      0.44        20
          C       0.66      0.69      0.68       169
          F       0.89      0.91      0.90       281
          R       0.45      0.41      0.43       122

avg / total       0.72      0.73      0.72       592

12/28/2017 00:54:16 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:54:16 [INFO] exp_shallowmodel: 
[[  8   3   5   4]
 [  2 117   8  42]
 [  3   6 256  16]
 [  3  51  18  50]]
12/28/2017 00:54:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/28/2017 00:54:20 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:54:20 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:54:20 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:54:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:54:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:54:20 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:54:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:55:40 [INFO] exp_shallowmodel: train time: 79.220s
12/28/2017 00:55:40 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:55:40 [INFO] exp_shallowmodel: accuracy:   0.716
12/28/2017 00:55:40 [INFO] exp_shallowmodel: f1_score:   0.606
12/28/2017 00:55:40 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:55:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.40      0.44        20
          C       0.66      0.68      0.67       169
          F       0.87      0.89      0.88       281
          R       0.45      0.42      0.43       122

avg / total       0.71      0.72      0.71       592

12/28/2017 00:55:40 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:55:40 [INFO] exp_shallowmodel: 
[[  8   3   7   2]
 [  0 115   9  45]
 [  6   9 250  16]
 [  2  47  22  51]]
12/28/2017 00:55:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/28/2017 00:55:41 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:55:41 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:55:41 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:55:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:55:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:55:41 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:55:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:56:31 [INFO] exp_shallowmodel: train time: 49.062s
12/28/2017 00:56:31 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:56:31 [INFO] exp_shallowmodel: accuracy:   0.725
12/28/2017 00:56:31 [INFO] exp_shallowmodel: f1_score:   0.588
12/28/2017 00:56:31 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:56:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.25      0.29        20
          C       0.70      0.64      0.67       169
          F       0.87      0.89      0.88       281
          R       0.49      0.54      0.51       122

avg / total       0.72      0.72      0.72       592

12/28/2017 00:56:31 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:56:31 [INFO] exp_shallowmodel: 
[[  5   4   8   3]
 [  2 108   9  50]
 [  3  11 250  17]
 [  4  31  21  66]]
12/28/2017 00:56:34 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/28/2017 00:56:34 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:56:34 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:56:34 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:56:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:56:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:56:34 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:56:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:58:04 [INFO] exp_shallowmodel: train time: 90.076s
12/28/2017 00:58:04 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:58:05 [INFO] exp_shallowmodel: accuracy:   0.748
12/28/2017 00:58:05 [INFO] exp_shallowmodel: f1_score:   0.650
12/28/2017 00:58:05 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:58:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.73      0.40      0.52        20
          C       0.68      0.67      0.67       169
          F       0.88      0.93      0.90       281
          R       0.52      0.49      0.50       122

avg / total       0.74      0.75      0.74       592

12/28/2017 00:58:05 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:58:05 [INFO] exp_shallowmodel: 
[[  8   3   7   2]
 [  2 113  13  41]
 [  1   5 262  13]
 [  0  45  17  60]]
12/28/2017 00:58:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/28/2017 00:58:08 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:58:08 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:58:08 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:58:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:58:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:58:08 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:58:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 00:59:35 [INFO] exp_shallowmodel: train time: 86.806s
12/28/2017 00:59:35 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 00:59:35 [INFO] exp_shallowmodel: accuracy:   0.752
12/28/2017 00:59:35 [INFO] exp_shallowmodel: f1_score:   0.641
12/28/2017 00:59:35 [INFO] exp_shallowmodel: classification report:
12/28/2017 00:59:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.64      0.35      0.45        20
          C       0.67      0.70      0.69       169
          F       0.89      0.92      0.90       281
          R       0.54      0.51      0.52       122

avg / total       0.75      0.75      0.75       592

12/28/2017 00:59:35 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 00:59:35 [INFO] exp_shallowmodel: 
[[  7   3   7   3]
 [  2 118   9  40]
 [  0  13 258  10]
 [  2  41  17  62]]
12/28/2017 00:59:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/28/2017 00:59:39 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 00:59:39 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 00:59:39 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 00:59:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 00:59:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 00:59:39 [INFO] exp_shallowmodel: Training: 
12/28/2017 00:59:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 01:01:08 [INFO] exp_shallowmodel: train time: 88.588s
12/28/2017 01:01:08 [INFO] exp_shallowmodel: test time:  0.018s
12/28/2017 01:01:08 [INFO] exp_shallowmodel: accuracy:   0.721
12/28/2017 01:01:08 [INFO] exp_shallowmodel: f1_score:   0.643
12/28/2017 01:01:08 [INFO] exp_shallowmodel: classification report:
12/28/2017 01:01:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.45      0.56        20
          C       0.67      0.66      0.66       169
          F       0.86      0.88      0.87       281
          R       0.47      0.48      0.48       122

avg / total       0.72      0.72      0.72       592

12/28/2017 01:01:08 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 01:01:08 [INFO] exp_shallowmodel: 
[[  9   2   7   2]
 [  2 111  11  45]
 [  0  14 248  19]
 [  1  38  24  59]]
12/28/2017 01:01:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/28/2017 01:01:12 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 01:01:12 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 01:01:12 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 01:01:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 01:01:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 01:01:12 [INFO] exp_shallowmodel: Training: 
12/28/2017 01:01:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 01:02:39 [INFO] exp_shallowmodel: train time: 87.151s
12/28/2017 01:02:39 [INFO] exp_shallowmodel: test time:  0.018s
12/28/2017 01:02:39 [INFO] exp_shallowmodel: accuracy:   0.750
12/28/2017 01:02:39 [INFO] exp_shallowmodel: f1_score:   0.649
12/28/2017 01:02:39 [INFO] exp_shallowmodel: classification report:
12/28/2017 01:02:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.40      0.48        20
          C       0.69      0.73      0.71       169
          F       0.91      0.89      0.90       281
          R       0.49      0.50      0.50       122

avg / total       0.75      0.75      0.75       592

12/28/2017 01:02:39 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 01:02:39 [INFO] exp_shallowmodel: 
[[  8   4   5   3]
 [  2 124   5  38]
 [  1   7 251  22]
 [  2  45  14  61]]
12/28/2017 01:02:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/28/2017 01:02:43 [INFO] exp_shallowmodel: #(data) = 4736
12/28/2017 01:02:43 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 01:02:43 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 01:02:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 01:02:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 01:02:43 [INFO] exp_shallowmodel: Training: 
12/28/2017 01:02:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 01:03:55 [INFO] exp_shallowmodel: train time: 72.529s
12/28/2017 01:03:55 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 01:03:55 [INFO] exp_shallowmodel: accuracy:   0.701
12/28/2017 01:03:55 [INFO] exp_shallowmodel: f1_score:   0.595
12/28/2017 01:03:55 [INFO] exp_shallowmodel: classification report:
12/28/2017 01:03:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.32      0.45        28
          C       0.62      0.61      0.62       172
          F       0.84      0.91      0.87       283
          R       0.45      0.43      0.44       123

avg / total       0.69      0.70      0.69       606

12/28/2017 01:03:55 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 01:03:55 [INFO] exp_shallowmodel: 
[[  9   6   8   5]
 [  1 105  23  43]
 [  1   7 258  17]
 [  1  51  18  53]]
12/28/2017 01:03:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/28/2017 01:03:57 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 01:03:57 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 01:03:57 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 01:03:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 01:03:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 01:03:57 [INFO] exp_shallowmodel: Training: 
12/28/2017 01:03:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 01:04:50 [INFO] exp_shallowmodel: train time: 53.255s
12/28/2017 01:04:50 [INFO] exp_shallowmodel: test time:  0.018s
12/28/2017 01:04:50 [INFO] exp_shallowmodel: accuracy:   0.743
12/28/2017 01:04:50 [INFO] exp_shallowmodel: f1_score:   0.622
12/28/2017 01:04:50 [INFO] exp_shallowmodel: classification report:
12/28/2017 01:04:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.30      0.40        20
          C       0.69      0.69      0.69       169
          F       0.89      0.91      0.90       281
          R       0.49      0.51      0.50       122

avg / total       0.74      0.74      0.74       592

12/28/2017 01:04:50 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 01:04:50 [INFO] exp_shallowmodel: 
[[  6   4   7   3]
 [  1 116   5  47]
 [  1   9 256  15]
 [  2  38  20  62]]
12/28/2017 01:04:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/28/2017 01:04:54 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 01:04:54 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 01:04:54 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 01:04:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 01:04:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 01:04:54 [INFO] exp_shallowmodel: Training: 
12/28/2017 01:04:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 01:06:23 [INFO] exp_shallowmodel: train time: 89.000s
12/28/2017 01:06:23 [INFO] exp_shallowmodel: test time:  0.018s
12/28/2017 01:06:23 [INFO] exp_shallowmodel: accuracy:   0.740
12/28/2017 01:06:23 [INFO] exp_shallowmodel: f1_score:   0.652
12/28/2017 01:06:23 [INFO] exp_shallowmodel: classification report:
12/28/2017 01:06:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.50      0.56        20
          C       0.67      0.68      0.68       169
          F       0.89      0.91      0.90       281
          R       0.49      0.47      0.48       122

avg / total       0.73      0.74      0.74       592

12/28/2017 01:06:23 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 01:06:23 [INFO] exp_shallowmodel: 
[[ 10   3   5   2]
 [  1 115   8  45]
 [  2  11 256  12]
 [  3  42  20  57]]
12/28/2017 01:06:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/28/2017 01:06:27 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 01:06:27 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 01:06:27 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 01:06:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 01:06:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 01:06:27 [INFO] exp_shallowmodel: Training: 
12/28/2017 01:06:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:18:02 [INFO] exp_shallowmodel: train time: 11494.947s
12/28/2017 04:18:02 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 04:18:02 [INFO] exp_shallowmodel: accuracy:   0.733
12/28/2017 04:18:02 [INFO] exp_shallowmodel: f1_score:   0.617
12/28/2017 04:18:02 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:18:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.30      0.40        20
          C       0.69      0.63      0.66       169
          F       0.87      0.90      0.89       281
          R       0.50      0.55      0.52       122

avg / total       0.73      0.73      0.73       592

12/28/2017 04:18:02 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:18:02 [INFO] exp_shallowmodel: 
[[  6   4   5   5]
 [  1 107  18  43]
 [  2   6 254  19]
 [  1  39  15  67]]
12/28/2017 04:18:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/28/2017 04:18:06 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 04:18:06 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 04:18:06 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:18:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:18:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:18:06 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:18:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:19:28 [INFO] exp_shallowmodel: train time: 81.989s
12/28/2017 04:19:28 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 04:19:28 [INFO] exp_shallowmodel: accuracy:   0.748
12/28/2017 04:19:28 [INFO] exp_shallowmodel: f1_score:   0.648
12/28/2017 04:19:28 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:19:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.55      0.50        20
          C       0.68      0.74      0.71       169
          F       0.91      0.90      0.90       281
          R       0.51      0.45      0.48       122

avg / total       0.75      0.75      0.75       592

12/28/2017 04:19:28 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:19:28 [INFO] exp_shallowmodel: 
[[ 11   3   5   1]
 [  7 125   4  33]
 [  2   9 252  18]
 [  4  47  16  55]]
12/28/2017 04:19:32 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/28/2017 04:19:32 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 04:19:32 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 04:19:32 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:19:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:19:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:19:32 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:19:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:20:50 [INFO] exp_shallowmodel: train time: 78.155s
12/28/2017 04:20:50 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 04:20:50 [INFO] exp_shallowmodel: accuracy:   0.750
12/28/2017 04:20:50 [INFO] exp_shallowmodel: f1_score:   0.656
12/28/2017 04:20:50 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:20:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.45      0.51        20
          C       0.71      0.72      0.71       169
          F       0.86      0.90      0.88       281
          R       0.54      0.49      0.52       122

avg / total       0.74      0.75      0.75       592

12/28/2017 04:20:50 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:20:50 [INFO] exp_shallowmodel: 
[[  9   1   7   3]
 [  3 121  13  32]
 [  3   8 254  16]
 [  0  40  22  60]]
12/28/2017 04:20:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/28/2017 04:20:54 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 04:20:54 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 04:20:54 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:20:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:20:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:20:54 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:20:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:21:44 [INFO] exp_shallowmodel: train time: 49.639s
12/28/2017 04:21:44 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 04:21:44 [INFO] exp_shallowmodel: accuracy:   0.731
12/28/2017 04:21:44 [INFO] exp_shallowmodel: f1_score:   0.586
12/28/2017 04:21:44 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:21:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.20      0.29        20
          C       0.67      0.66      0.66       169
          F       0.88      0.91      0.89       281
          R       0.49      0.52      0.50       122

avg / total       0.73      0.73      0.73       592

12/28/2017 04:21:44 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:21:44 [INFO] exp_shallowmodel: 
[[  4   5   8   3]
 [  1 111  11  46]
 [  2   7 255  17]
 [  1  43  15  63]]
12/28/2017 04:21:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/28/2017 04:21:46 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 04:21:46 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 04:21:46 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:21:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:21:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:21:46 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:21:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:23:52 [INFO] exp_shallowmodel: train time: 126.327s
12/28/2017 04:23:52 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 04:23:52 [INFO] exp_shallowmodel: accuracy:   0.738
12/28/2017 04:23:52 [INFO] exp_shallowmodel: f1_score:   0.644
12/28/2017 04:23:52 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:23:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.50      0.53        20
          C       0.68      0.71      0.69       169
          F       0.90      0.90      0.90       281
          R       0.47      0.44      0.46       122

avg / total       0.73      0.74      0.74       592

12/28/2017 04:23:52 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:23:52 [INFO] exp_shallowmodel: 
[[ 10   1   5   4]
 [  1 120   8  40]
 [  2   9 253  17]
 [  5  47  16  54]]
12/28/2017 04:23:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/28/2017 04:23:54 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 04:23:54 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 04:23:54 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:23:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:23:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:23:54 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:23:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:24:55 [INFO] exp_shallowmodel: train time: 60.795s
12/28/2017 04:24:55 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 04:24:55 [INFO] exp_shallowmodel: accuracy:   0.711
12/28/2017 04:24:55 [INFO] exp_shallowmodel: f1_score:   0.618
12/28/2017 04:24:55 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:24:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.59      0.50      0.54        20
          C       0.66      0.64      0.65       169
          F       0.84      0.91      0.88       281
          R       0.44      0.38      0.41       122

avg / total       0.70      0.71      0.70       592

12/28/2017 04:24:55 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:24:55 [INFO] exp_shallowmodel: 
[[ 10   2   5   3]
 [  1 109  18  41]
 [  2   8 256  15]
 [  4  47  25  46]]
12/28/2017 04:24:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/28/2017 04:24:57 [INFO] exp_shallowmodel: #(data) = 4750
12/28/2017 04:24:57 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 04:24:57 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:24:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:24:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:24:57 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:24:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:25:58 [INFO] exp_shallowmodel: train time: 61.394s
12/28/2017 04:25:58 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 04:25:58 [INFO] exp_shallowmodel: accuracy:   0.731
12/28/2017 04:25:58 [INFO] exp_shallowmodel: f1_score:   0.598
12/28/2017 04:25:58 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:25:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.25      0.34        20
          C       0.66      0.67      0.67       169
          F       0.88      0.91      0.89       281
          R       0.48      0.48      0.48       122

avg / total       0.73      0.73      0.73       592

12/28/2017 04:25:58 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:25:58 [INFO] exp_shallowmodel: 
[[  5   6   6   3]
 [  1 114  10  44]
 [  2   8 255  16]
 [  1  44  18  59]]
12/28/2017 04:26:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/28/2017 04:26:02 [INFO] exp_shallowmodel: #(data) = 4736
12/28/2017 04:26:02 [INFO] exp_shallowmodel: #(feature) = 11488
12/28/2017 04:26:02 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:26:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:26:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:26:02 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:26:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:27:28 [INFO] exp_shallowmodel: train time: 85.796s
12/28/2017 04:27:28 [INFO] exp_shallowmodel: test time:  0.009s
12/28/2017 04:27:28 [INFO] exp_shallowmodel: accuracy:   0.726
12/28/2017 04:27:28 [INFO] exp_shallowmodel: f1_score:   0.640
12/28/2017 04:27:28 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:27:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.85      0.39      0.54        28
          C       0.64      0.65      0.65       172
          F       0.91      0.90      0.91       283
          R       0.45      0.50      0.47       123

avg / total       0.74      0.73      0.73       606

12/28/2017 04:27:28 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:27:28 [INFO] exp_shallowmodel: 
[[ 11   6   7   4]
 [  0 112   5  55]
 [  0  10 256  17]
 [  2  46  14  61]]
12/28/2017 04:27:38 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/28/2017 04:27:38 [INFO] task_runner: context=next, feature=13-[8+1.3.4], similarity=False
12/28/2017 04:27:38 [INFO] task_runner: Before filtering, #(feature)=93356
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 1 : 5
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		2.1 : 77
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 2 : 82
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		2.2 : 3
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		2.3.1 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		2.3.2 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 3 : 5
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		4.1 : 40990
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 4 : 40994
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		4.2.1 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		4.2.2 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		4.3.1 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		4.3.2 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 5 : 24655
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 6 : 4698
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 7 : 7657
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		8.1 : 250
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 8 : 252
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		8.2.1 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		8.2.2 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		9.1 : 1500
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 9 : 1504
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		9.2.1 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		9.2.2 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		9.3.1 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		9.3.2 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		10.1 : 1500
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 10 : 1502
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		10.2.1 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		10.2.2 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		11.1 : 12000
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 11 : 12002
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		11.2.1 : 1
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		11.2.2 : 1
12/28/2017 04:27:38 [INFO] task_runner: After filtering, #(feature)=29791
12/28/2017 04:27:38 [INFO] task_runner: retained feature id=[1, 11.1, 2.1, 2.2, 3, 5, 6, 7]
12/28/2017 04:27:38 [INFO] task_runner: #(data)=3530
12/28/2017 04:27:38 [INFO] task_runner: #(feature)=29791/93356
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 1 : 3
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		2.1 : 52
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 2 : 54
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		2.2 : 2
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 3 : 5
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 5 : 14898
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 6 : 2975
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 7 : 4656
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 		11.1 : 7200
12/28/2017 04:27:38 [INFO] exp_shallowmodel: 11 : 7200
12/28/2017 04:27:38 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/28/2017 04:27:44 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/28/2017 04:27:44 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:27:44 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:27:44 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:27:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:27:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:27:44 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:27:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:28:17 [INFO] exp_shallowmodel: train time: 32.256s
12/28/2017 04:28:17 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:28:17 [INFO] exp_shallowmodel: accuracy:   0.858
12/28/2017 04:28:17 [INFO] exp_shallowmodel: f1_score:   0.630
12/28/2017 04:28:17 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:28:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.22      0.29        23
          C       0.59      0.70      0.64        27
          F       0.94      0.99      0.96       250
          R       0.68      0.58      0.62        52

avg / total       0.84      0.86      0.85       352

12/28/2017 04:28:17 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:28:17 [INFO] exp_shallowmodel: 
[[  5   4   6   8]
 [  3  19   0   5]
 [  1   0 248   1]
 [  3   9  10  30]]
12/28/2017 04:28:23 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/28/2017 04:28:23 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:28:23 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:28:23 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:28:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:28:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:28:23 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:28:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:28:49 [INFO] exp_shallowmodel: train time: 25.648s
12/28/2017 04:28:49 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:28:49 [INFO] exp_shallowmodel: accuracy:   0.878
12/28/2017 04:28:49 [INFO] exp_shallowmodel: f1_score:   0.694
12/28/2017 04:28:49 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:28:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.71      0.22      0.33        23
          C       0.75      0.89      0.81        27
          F       0.92      0.99      0.95       250
          R       0.74      0.62      0.67        52

avg / total       0.87      0.88      0.86       352

12/28/2017 04:28:49 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:28:49 [INFO] exp_shallowmodel: 
[[  5   2   8   8]
 [  0  24   1   2]
 [  1   0 248   1]
 [  1   6  13  32]]
12/28/2017 04:28:52 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/28/2017 04:28:52 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:28:52 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:28:52 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:28:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:28:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:28:52 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:28:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:29:23 [INFO] exp_shallowmodel: train time: 31.739s
12/28/2017 04:29:23 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:29:23 [INFO] exp_shallowmodel: accuracy:   0.866
12/28/2017 04:29:23 [INFO] exp_shallowmodel: f1_score:   0.663
12/28/2017 04:29:23 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:29:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.71      0.22      0.33        23
          C       0.67      0.74      0.70        27
          F       0.92      0.99      0.95       250
          R       0.73      0.62      0.67        52

avg / total       0.86      0.87      0.85       352

12/28/2017 04:29:23 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:29:23 [INFO] exp_shallowmodel: 
[[  5   3  10   5]
 [  0  20   2   5]
 [  0   0 248   2]
 [  2   7  11  32]]
12/28/2017 04:29:26 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/28/2017 04:29:26 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:29:26 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:29:26 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:29:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:29:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:29:26 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:29:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:30:18 [INFO] exp_shallowmodel: train time: 51.727s
12/28/2017 04:30:18 [INFO] exp_shallowmodel: test time:  0.023s
12/28/2017 04:30:18 [INFO] exp_shallowmodel: accuracy:   0.855
12/28/2017 04:30:18 [INFO] exp_shallowmodel: f1_score:   0.621
12/28/2017 04:30:18 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:30:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.17      0.25        23
          C       0.60      0.67      0.63        27
          F       0.92      0.99      0.96       250
          R       0.70      0.60      0.65        52

avg / total       0.83      0.86      0.84       352

12/28/2017 04:30:18 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:30:18 [INFO] exp_shallowmodel: 
[[  4   4   6   9]
 [  1  18   4   4]
 [  1   1 248   0]
 [  3   7  11  31]]
12/28/2017 04:30:21 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/28/2017 04:30:21 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:30:21 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:30:21 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:30:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:30:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:30:21 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:30:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:30:47 [INFO] exp_shallowmodel: train time: 26.138s
12/28/2017 04:30:47 [INFO] exp_shallowmodel: test time:  0.023s
12/28/2017 04:30:47 [INFO] exp_shallowmodel: accuracy:   0.869
12/28/2017 04:30:47 [INFO] exp_shallowmodel: f1_score:   0.679
12/28/2017 04:30:47 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:30:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.30      0.39        23
          C       0.70      0.70      0.70        27
          F       0.93      0.99      0.96       250
          R       0.73      0.62      0.67        52

avg / total       0.85      0.87      0.86       352

12/28/2017 04:30:47 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:30:47 [INFO] exp_shallowmodel: 
[[  7   2   7   7]
 [  1  19   3   4]
 [  1   0 248   1]
 [  4   6  10  32]]
12/28/2017 04:30:54 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/28/2017 04:30:54 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:30:54 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:30:54 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:30:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:30:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:30:54 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:30:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:31:59 [INFO] exp_shallowmodel: train time: 65.658s
12/28/2017 04:31:59 [INFO] exp_shallowmodel: test time:  0.013s
12/28/2017 04:31:59 [INFO] exp_shallowmodel: accuracy:   0.849
12/28/2017 04:31:59 [INFO] exp_shallowmodel: f1_score:   0.600
12/28/2017 04:31:59 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:31:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.66      0.78      0.71        27
          F       0.91      0.99      0.95       250
          R       0.68      0.54      0.60        52

avg / total       0.82      0.85      0.83       352

12/28/2017 04:31:59 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:31:59 [INFO] exp_shallowmodel: 
[[  2   5  10   6]
 [  0  21   0   6]
 [  1   0 248   1]
 [  3   6  15  28]]
12/28/2017 04:32:05 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/28/2017 04:32:05 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:32:05 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:32:05 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:32:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:32:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:32:05 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:32:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:32:35 [INFO] exp_shallowmodel: train time: 29.589s
12/28/2017 04:32:35 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:32:35 [INFO] exp_shallowmodel: accuracy:   0.869
12/28/2017 04:32:35 [INFO] exp_shallowmodel: f1_score:   0.667
12/28/2017 04:32:35 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:32:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.26      0.36        23
          C       0.65      0.74      0.69        27
          F       0.93      1.00      0.96       250
          R       0.72      0.60      0.65        52

avg / total       0.86      0.87      0.86       352

12/28/2017 04:32:35 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:32:35 [INFO] exp_shallowmodel: 
[[  6   4   4   9]
 [  1  20   3   3]
 [  1   0 249   0]
 [  2   7  12  31]]
12/28/2017 04:32:38 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/28/2017 04:32:38 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:32:38 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:32:38 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:32:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:32:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:32:38 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:32:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:33:24 [INFO] exp_shallowmodel: train time: 45.921s
12/28/2017 04:33:24 [INFO] exp_shallowmodel: test time:  0.023s
12/28/2017 04:33:24 [INFO] exp_shallowmodel: accuracy:   0.892
12/28/2017 04:33:24 [INFO] exp_shallowmodel: f1_score:   0.735
12/28/2017 04:33:24 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:33:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.35      0.52        23
          C       0.69      0.81      0.75        27
          F       0.94      1.00      0.97       250
          R       0.76      0.67      0.71        52

avg / total       0.90      0.89      0.88       352

12/28/2017 04:33:24 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:33:24 [INFO] exp_shallowmodel: 
[[  8   1   6   8]
 [  0  22   2   3]
 [  0   1 249   0]
 [  0   8   9  35]]
12/28/2017 04:33:30 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/28/2017 04:33:30 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:33:30 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:33:30 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:33:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:33:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:33:30 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:33:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:34:06 [INFO] exp_shallowmodel: train time: 35.272s
12/28/2017 04:34:06 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:34:06 [INFO] exp_shallowmodel: accuracy:   0.875
12/28/2017 04:34:06 [INFO] exp_shallowmodel: f1_score:   0.690
12/28/2017 04:34:06 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:34:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.70      0.30      0.42        23
          C       0.68      0.70      0.69        27
          F       0.93      0.99      0.96       250
          R       0.72      0.65      0.69        52

avg / total       0.86      0.88      0.86       352

12/28/2017 04:34:06 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:34:06 [INFO] exp_shallowmodel: 
[[  7   2   7   7]
 [  1  19   2   5]
 [  1   0 248   1]
 [  1   7  10  34]]
12/28/2017 04:34:09 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/28/2017 04:34:09 [INFO] exp_shallowmodel: #(data) = 2816
12/28/2017 04:34:09 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:34:09 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:34:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:34:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:34:09 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:34:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:34:58 [INFO] exp_shallowmodel: train time: 48.463s
12/28/2017 04:34:58 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:34:58 [INFO] exp_shallowmodel: accuracy:   0.865
12/28/2017 04:34:58 [INFO] exp_shallowmodel: f1_score:   0.703
12/28/2017 04:34:58 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:34:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.73      0.32      0.44        25
          C       0.73      0.81      0.77        27
          F       0.90      1.00      0.94       251
          R       0.79      0.56      0.65        59

avg / total       0.85      0.86      0.85       362

12/28/2017 04:34:58 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:34:58 [INFO] exp_shallowmodel: 
[[  8   4   8   5]
 [  0  22   2   3]
 [  0   0 250   1]
 [  3   4  19  33]]
12/28/2017 04:35:01 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/28/2017 04:35:01 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:35:01 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:35:01 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:35:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:35:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:35:01 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:35:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:35:28 [INFO] exp_shallowmodel: train time: 27.452s
12/28/2017 04:35:28 [INFO] exp_shallowmodel: test time:  0.023s
12/28/2017 04:35:28 [INFO] exp_shallowmodel: accuracy:   0.855
12/28/2017 04:35:28 [INFO] exp_shallowmodel: f1_score:   0.617
12/28/2017 04:35:28 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:35:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.17      0.24        23
          C       0.58      0.67      0.62        27
          F       0.93      0.99      0.96       250
          R       0.70      0.60      0.65        52

avg / total       0.83      0.86      0.84       352

12/28/2017 04:35:28 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:35:28 [INFO] exp_shallowmodel: 
[[  4   8   6   5]
 [  1  18   1   7]
 [  1   0 248   1]
 [  4   5  12  31]]
12/28/2017 04:35:35 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/28/2017 04:35:35 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:35:35 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:35:35 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:35:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:35:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:35:35 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:35:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:36:26 [INFO] exp_shallowmodel: train time: 51.415s
12/28/2017 04:36:26 [INFO] exp_shallowmodel: test time:  0.022s
12/28/2017 04:36:26 [INFO] exp_shallowmodel: accuracy:   0.838
12/28/2017 04:36:26 [INFO] exp_shallowmodel: f1_score:   0.597
12/28/2017 04:36:26 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:36:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.13      0.20        23
          C       0.66      0.78      0.71        27
          F       0.91      0.98      0.94       250
          R       0.60      0.48      0.53        52

avg / total       0.81      0.84      0.82       352

12/28/2017 04:36:26 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:36:26 [INFO] exp_shallowmodel: 
[[  3   1   9  10]
 [  1  21   0   5]
 [  1   1 246   2]
 [  2   9  16  25]]
12/28/2017 04:36:32 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/28/2017 04:36:32 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:36:32 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:36:32 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:36:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:36:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:36:32 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:36:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:37:24 [INFO] exp_shallowmodel: train time: 51.388s
12/28/2017 04:37:24 [INFO] exp_shallowmodel: test time:  0.023s
12/28/2017 04:37:24 [INFO] exp_shallowmodel: accuracy:   0.884
12/28/2017 04:37:24 [INFO] exp_shallowmodel: f1_score:   0.712
12/28/2017 04:37:24 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:37:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.35      0.43        23
          C       0.70      0.78      0.74        27
          F       0.94      0.99      0.96       250
          R       0.79      0.65      0.72        52

avg / total       0.87      0.88      0.87       352

12/28/2017 04:37:24 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:37:24 [INFO] exp_shallowmodel: 
[[  8   3   6   6]
 [  0  21   3   3]
 [  2   0 248   0]
 [  4   6   8  34]]
12/28/2017 04:37:33 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/28/2017 04:37:33 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:37:33 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:37:33 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:37:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:37:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:37:33 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:37:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:38:11 [INFO] exp_shallowmodel: train time: 37.774s
12/28/2017 04:38:11 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:38:11 [INFO] exp_shallowmodel: accuracy:   0.838
12/28/2017 04:38:11 [INFO] exp_shallowmodel: f1_score:   0.606
12/28/2017 04:38:11 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:38:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.17      0.28        23
          C       0.63      0.70      0.67        27
          F       0.89      0.99      0.94       250
          R       0.67      0.46      0.55        52

avg / total       0.82      0.84      0.81       352

12/28/2017 04:38:11 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:38:11 [INFO] exp_shallowmodel: 
[[  4   2  10   7]
 [  0  19   5   3]
 [  0   0 248   2]
 [  2   9  17  24]]
12/28/2017 04:38:14 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/28/2017 04:38:14 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:38:14 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:38:14 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:38:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:38:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:38:14 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:38:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:38:39 [INFO] exp_shallowmodel: train time: 25.506s
12/28/2017 04:38:39 [INFO] exp_shallowmodel: test time:  0.013s
12/28/2017 04:38:39 [INFO] exp_shallowmodel: accuracy:   0.892
12/28/2017 04:38:39 [INFO] exp_shallowmodel: f1_score:   0.734
12/28/2017 04:38:39 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:38:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.91      0.43      0.59        23
          C       0.71      0.63      0.67        27
          F       0.94      1.00      0.97       250
          R       0.71      0.71      0.71        52

avg / total       0.89      0.89      0.88       352

12/28/2017 04:38:39 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:38:39 [INFO] exp_shallowmodel: 
[[ 10   2   3   8]
 [  1  17   2   7]
 [  0   0 250   0]
 [  0   5  10  37]]
12/28/2017 04:38:42 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/28/2017 04:38:42 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:38:42 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:38:42 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:38:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:38:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:38:42 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:38:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:39:08 [INFO] exp_shallowmodel: train time: 25.627s
12/28/2017 04:39:08 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:39:08 [INFO] exp_shallowmodel: accuracy:   0.884
12/28/2017 04:39:08 [INFO] exp_shallowmodel: f1_score:   0.706
12/28/2017 04:39:08 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:39:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.71      0.22      0.33        23
          C       0.80      0.89      0.84        27
          F       0.91      1.00      0.95       250
          R       0.80      0.62      0.70        52

avg / total       0.87      0.88      0.87       352

12/28/2017 04:39:08 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:39:08 [INFO] exp_shallowmodel: 
[[  5   3   8   7]
 [  0  24   2   1]
 [  0   0 250   0]
 [  2   3  15  32]]
12/28/2017 04:39:11 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/28/2017 04:39:11 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:39:11 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:39:11 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:39:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:39:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:39:11 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:39:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:39:37 [INFO] exp_shallowmodel: train time: 25.441s
12/28/2017 04:39:37 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:39:37 [INFO] exp_shallowmodel: accuracy:   0.864
12/28/2017 04:39:37 [INFO] exp_shallowmodel: f1_score:   0.663
12/28/2017 04:39:37 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:39:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.26      0.36        23
          C       0.65      0.81      0.72        27
          F       0.92      1.00      0.95       250
          R       0.75      0.52      0.61        52

avg / total       0.85      0.86      0.85       352

12/28/2017 04:39:37 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:39:37 [INFO] exp_shallowmodel: 
[[  6   5   7   5]
 [  0  22   2   3]
 [  0   0 249   1]
 [  4   7  14  27]]
12/28/2017 04:39:40 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/28/2017 04:39:40 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:39:40 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:39:40 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:39:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:39:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:39:40 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:39:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:40:05 [INFO] exp_shallowmodel: train time: 25.576s
12/28/2017 04:40:05 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:40:05 [INFO] exp_shallowmodel: accuracy:   0.855
12/28/2017 04:40:05 [INFO] exp_shallowmodel: f1_score:   0.637
12/28/2017 04:40:05 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:40:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.17      0.24        23
          C       0.71      0.74      0.73        27
          F       0.91      0.99      0.95       250
          R       0.70      0.58      0.63        52

avg / total       0.83      0.86      0.84       352

12/28/2017 04:40:05 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:40:05 [INFO] exp_shallowmodel: 
[[  4   4   8   7]
 [  1  20   2   4]
 [  1   0 247   2]
 [  4   4  14  30]]
12/28/2017 04:40:08 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/28/2017 04:40:08 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:40:08 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:40:08 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:40:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:40:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:40:08 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:40:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:40:49 [INFO] exp_shallowmodel: train time: 40.517s
12/28/2017 04:40:49 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:40:49 [INFO] exp_shallowmodel: accuracy:   0.875
12/28/2017 04:40:49 [INFO] exp_shallowmodel: f1_score:   0.676
12/28/2017 04:40:49 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:40:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.22      0.32        23
          C       0.72      0.78      0.75        27
          F       0.93      1.00      0.96       250
          R       0.72      0.63      0.67        52

avg / total       0.86      0.88      0.86       352

12/28/2017 04:40:49 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:40:49 [INFO] exp_shallowmodel: 
[[  5   3   6   9]
 [  0  21   2   4]
 [  1   0 249   0]
 [  2   5  12  33]]
12/28/2017 04:40:52 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/28/2017 04:40:52 [INFO] exp_shallowmodel: #(data) = 2816
12/28/2017 04:40:52 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:40:52 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:40:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:40:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:40:52 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:40:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:41:39 [INFO] exp_shallowmodel: train time: 46.849s
12/28/2017 04:41:39 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:41:39 [INFO] exp_shallowmodel: accuracy:   0.856
12/28/2017 04:41:39 [INFO] exp_shallowmodel: f1_score:   0.645
12/28/2017 04:41:39 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:41:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.24      0.33        25
          C       0.55      0.78      0.65        27
          F       0.94      0.99      0.97       251
          R       0.71      0.58      0.64        59

avg / total       0.85      0.86      0.84       362

12/28/2017 04:41:39 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:41:39 [INFO] exp_shallowmodel: 
[[  6   3   7   9]
 [  1  21   1   4]
 [  1   0 249   1]
 [  3  14   8  34]]
12/28/2017 04:41:45 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/28/2017 04:41:45 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:41:45 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:41:45 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:41:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:41:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:41:45 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:41:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:42:37 [INFO] exp_shallowmodel: train time: 51.748s
12/28/2017 04:42:37 [INFO] exp_shallowmodel: test time:  0.025s
12/28/2017 04:42:37 [INFO] exp_shallowmodel: accuracy:   0.895
12/28/2017 04:42:37 [INFO] exp_shallowmodel: f1_score:   0.735
12/28/2017 04:42:37 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:42:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.26      0.39        23
          C       0.81      0.96      0.88        27
          F       0.93      1.00      0.96       250
          R       0.77      0.65      0.71        52

avg / total       0.89      0.89      0.88       352

12/28/2017 04:42:37 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:42:37 [INFO] exp_shallowmodel: 
[[  6   3   5   9]
 [  0  26   0   1]
 [  1   0 249   0]
 [  1   3  14  34]]
12/28/2017 04:42:43 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/28/2017 04:42:43 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:42:43 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:42:43 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:42:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:42:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:42:43 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:42:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:43:43 [INFO] exp_shallowmodel: train time: 60.408s
12/28/2017 04:43:43 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:43:43 [INFO] exp_shallowmodel: accuracy:   0.878
12/28/2017 04:43:43 [INFO] exp_shallowmodel: f1_score:   0.711
12/28/2017 04:43:43 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:43:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.80      0.35      0.48        23
          C       0.70      0.78      0.74        27
          F       0.92      1.00      0.96       250
          R       0.76      0.60      0.67        52

avg / total       0.87      0.88      0.87       352

12/28/2017 04:43:43 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:43:43 [INFO] exp_shallowmodel: 
[[  8   2   7   6]
 [  0  21   3   3]
 [  0   0 249   1]
 [  2   7  12  31]]
12/28/2017 04:43:50 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/28/2017 04:43:50 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:43:50 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:43:50 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:43:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:43:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:43:50 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:43:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:44:37 [INFO] exp_shallowmodel: train time: 47.194s
12/28/2017 04:44:37 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:44:37 [INFO] exp_shallowmodel: accuracy:   0.869
12/28/2017 04:44:37 [INFO] exp_shallowmodel: f1_score:   0.635
12/28/2017 04:44:37 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:44:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.13      0.21        23
          C       0.65      0.74      0.69        27
          F       0.93      1.00      0.96       250
          R       0.69      0.65      0.67        52

avg / total       0.85      0.87      0.85       352

12/28/2017 04:44:37 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:44:37 [INFO] exp_shallowmodel: 
[[  3   3   9   8]
 [  0  20   1   6]
 [  0   0 249   1]
 [  2   8   8  34]]
12/28/2017 04:44:40 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/28/2017 04:44:40 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:44:40 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:44:40 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:44:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:44:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:44:40 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:44:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:45:33 [INFO] exp_shallowmodel: train time: 53.007s
12/28/2017 04:45:33 [INFO] exp_shallowmodel: test time:  0.032s
12/28/2017 04:45:33 [INFO] exp_shallowmodel: accuracy:   0.847
12/28/2017 04:45:33 [INFO] exp_shallowmodel: f1_score:   0.603
12/28/2017 04:45:33 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:45:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.13      0.19        23
          C       0.64      0.67      0.65        27
          F       0.91      0.99      0.95       250
          R       0.65      0.58      0.61        52

avg / total       0.82      0.85      0.83       352

12/28/2017 04:45:33 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:45:33 [INFO] exp_shallowmodel: 
[[  3   4   9   7]
 [  0  18   2   7]
 [  1   0 247   2]
 [  4   6  12  30]]
12/28/2017 04:45:39 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/28/2017 04:45:40 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:45:40 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:45:40 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:45:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:45:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:45:40 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:45:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:46:23 [INFO] exp_shallowmodel: train time: 43.714s
12/28/2017 04:46:23 [INFO] exp_shallowmodel: test time:  0.025s
12/28/2017 04:46:23 [INFO] exp_shallowmodel: accuracy:   0.864
12/28/2017 04:46:23 [INFO] exp_shallowmodel: f1_score:   0.658
12/28/2017 04:46:23 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:46:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.26      0.38        23
          C       0.62      0.67      0.64        27
          F       0.92      1.00      0.95       250
          R       0.74      0.60      0.66        52

avg / total       0.85      0.86      0.85       352

12/28/2017 04:46:23 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:46:23 [INFO] exp_shallowmodel: 
[[  6   3   8   6]
 [  1  18   3   5]
 [  1   0 249   0]
 [  1   8  12  31]]
12/28/2017 04:46:29 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/28/2017 04:46:29 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:46:29 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:46:29 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:46:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:46:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:46:29 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:46:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:46:57 [INFO] exp_shallowmodel: train time: 27.132s
12/28/2017 04:46:57 [INFO] exp_shallowmodel: test time:  0.013s
12/28/2017 04:46:57 [INFO] exp_shallowmodel: accuracy:   0.864
12/28/2017 04:46:57 [INFO] exp_shallowmodel: f1_score:   0.616
12/28/2017 04:46:57 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:46:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.13      0.21        23
          C       0.57      0.63      0.60        27
          F       0.93      1.00      0.96       250
          R       0.73      0.67      0.70        52

avg / total       0.84      0.86      0.85       352

12/28/2017 04:46:57 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:46:57 [INFO] exp_shallowmodel: 
[[  3   5   6   9]
 [  2  17   5   3]
 [  0   0 249   1]
 [  1   8   8  35]]
12/28/2017 04:47:00 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/28/2017 04:47:00 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:47:00 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:47:00 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:47:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:47:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:47:00 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:47:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:47:34 [INFO] exp_shallowmodel: train time: 34.510s
12/28/2017 04:47:34 [INFO] exp_shallowmodel: test time:  0.023s
12/28/2017 04:47:34 [INFO] exp_shallowmodel: accuracy:   0.869
12/28/2017 04:47:34 [INFO] exp_shallowmodel: f1_score:   0.682
12/28/2017 04:47:34 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:47:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.35      0.44        23
          C       0.68      0.70      0.69        27
          F       0.93      1.00      0.96       250
          R       0.70      0.58      0.63        52

avg / total       0.86      0.87      0.86       352

12/28/2017 04:47:34 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:47:34 [INFO] exp_shallowmodel: 
[[  8   1   6   8]
 [  3  19   0   5]
 [  0   1 249   0]
 [  2   7  13  30]]
12/28/2017 04:47:40 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/28/2017 04:47:40 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:47:40 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:47:40 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:47:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:47:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:47:40 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:47:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:48:13 [INFO] exp_shallowmodel: train time: 32.564s
12/28/2017 04:48:13 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:48:13 [INFO] exp_shallowmodel: accuracy:   0.884
12/28/2017 04:48:13 [INFO] exp_shallowmodel: f1_score:   0.747
12/28/2017 04:48:13 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:48:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.43      0.53        23
          C       0.84      0.78      0.81        27
          F       0.93      0.98      0.95       250
          R       0.73      0.67      0.70        52

avg / total       0.87      0.88      0.88       352

12/28/2017 04:48:13 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:48:13 [INFO] exp_shallowmodel: 
[[ 10   1   4   8]
 [  0  21   3   3]
 [  3   0 245   2]
 [  2   3  12  35]]
12/28/2017 04:48:18 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/28/2017 04:48:18 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:48:18 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:48:18 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:48:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:48:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:48:18 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:48:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:48:51 [INFO] exp_shallowmodel: train time: 33.741s
12/28/2017 04:48:51 [INFO] exp_shallowmodel: test time:  0.013s
12/28/2017 04:48:51 [INFO] exp_shallowmodel: accuracy:   0.847
12/28/2017 04:48:51 [INFO] exp_shallowmodel: f1_score:   0.598
12/28/2017 04:48:51 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:48:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.22      0.29        23
          C       0.52      0.56      0.54        27
          F       0.93      1.00      0.96       250
          R       0.64      0.56      0.60        52

avg / total       0.83      0.85      0.83       352

12/28/2017 04:48:51 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:48:51 [INFO] exp_shallowmodel: 
[[  5   6   5   7]
 [  2  15   1   9]
 [  1   0 249   0]
 [  3   8  12  29]]
12/28/2017 04:48:54 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/28/2017 04:48:54 [INFO] exp_shallowmodel: #(data) = 2816
12/28/2017 04:48:54 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:48:54 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:48:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:48:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:48:54 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:48:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:49:36 [INFO] exp_shallowmodel: train time: 41.946s
12/28/2017 04:49:36 [INFO] exp_shallowmodel: test time:  0.025s
12/28/2017 04:49:36 [INFO] exp_shallowmodel: accuracy:   0.859
12/28/2017 04:49:36 [INFO] exp_shallowmodel: f1_score:   0.656
12/28/2017 04:49:36 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:49:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.86      0.24      0.38        25
          C       0.58      0.70      0.63        27
          F       0.91      1.00      0.95       251
          R       0.74      0.59      0.66        59

avg / total       0.86      0.86      0.84       362

12/28/2017 04:49:36 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:49:36 [INFO] exp_shallowmodel: 
[[  6   4   7   8]
 [  1  19   3   4]
 [  0   0 251   0]
 [  0  10  14  35]]
12/28/2017 04:49:43 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/28/2017 04:49:43 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:49:43 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:49:43 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:49:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:49:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:49:43 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:49:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:50:34 [INFO] exp_shallowmodel: train time: 51.716s
12/28/2017 04:50:34 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:50:34 [INFO] exp_shallowmodel: accuracy:   0.849
12/28/2017 04:50:34 [INFO] exp_shallowmodel: f1_score:   0.613
12/28/2017 04:50:34 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:50:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.17      0.24        23
          C       0.54      0.78      0.64        27
          F       0.93      0.98      0.96       250
          R       0.72      0.54      0.62        52

avg / total       0.84      0.85      0.84       352

12/28/2017 04:50:34 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:50:34 [INFO] exp_shallowmodel: 
[[  4   5   7   7]
 [  1  21   1   4]
 [  3   1 246   0]
 [  2  12  10  28]]
12/28/2017 04:50:41 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/28/2017 04:50:41 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:50:41 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:50:41 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:50:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:50:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:50:41 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:50:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:51:13 [INFO] exp_shallowmodel: train time: 31.935s
12/28/2017 04:51:13 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:51:13 [INFO] exp_shallowmodel: accuracy:   0.849
12/28/2017 04:51:13 [INFO] exp_shallowmodel: f1_score:   0.610
12/28/2017 04:51:13 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:51:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.17      0.28        23
          C       0.57      0.74      0.65        27
          F       0.93      0.99      0.96       250
          R       0.60      0.52      0.56        52

avg / total       0.84      0.85      0.83       352

12/28/2017 04:51:13 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:51:13 [INFO] exp_shallowmodel: 
[[  4   2   7  10]
 [  0  20   1   6]
 [  0   0 248   2]
 [  2  13  10  27]]
12/28/2017 04:51:16 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/28/2017 04:51:16 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:51:16 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:51:16 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:51:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:51:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:51:16 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:51:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:51:49 [INFO] exp_shallowmodel: train time: 33.030s
12/28/2017 04:51:49 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:51:49 [INFO] exp_shallowmodel: accuracy:   0.864
12/28/2017 04:51:49 [INFO] exp_shallowmodel: f1_score:   0.645
12/28/2017 04:51:49 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:51:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.17      0.28        23
          C       0.70      0.70      0.70        27
          F       0.92      1.00      0.95       250
          R       0.68      0.62      0.65        52

avg / total       0.85      0.86      0.85       352

12/28/2017 04:51:49 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:51:49 [INFO] exp_shallowmodel: 
[[  4   2   8   9]
 [  1  19   2   5]
 [  0   0 249   1]
 [  1   6  13  32]]
12/28/2017 04:51:52 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/28/2017 04:51:52 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:51:52 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:51:52 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:51:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:51:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:51:52 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:51:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:52:34 [INFO] exp_shallowmodel: train time: 42.276s
12/28/2017 04:52:34 [INFO] exp_shallowmodel: test time:  0.013s
12/28/2017 04:52:34 [INFO] exp_shallowmodel: accuracy:   0.878
12/28/2017 04:52:34 [INFO] exp_shallowmodel: f1_score:   0.711
12/28/2017 04:52:34 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:52:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.82      0.39      0.53        23
          C       0.61      0.81      0.70        27
          F       0.94      0.99      0.96       250
          R       0.75      0.58      0.65        52

avg / total       0.88      0.88      0.87       352

12/28/2017 04:52:34 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:52:34 [INFO] exp_shallowmodel: 
[[  9   5   3   6]
 [  0  22   2   3]
 [  1   0 248   1]
 [  1   9  12  30]]
12/28/2017 04:52:38 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/28/2017 04:52:38 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:52:38 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:52:38 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:52:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:52:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:52:38 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:52:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:53:03 [INFO] exp_shallowmodel: train time: 25.085s
12/28/2017 04:53:03 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:53:03 [INFO] exp_shallowmodel: accuracy:   0.875
12/28/2017 04:53:03 [INFO] exp_shallowmodel: f1_score:   0.664
12/28/2017 04:53:03 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:53:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.26      0.35        23
          C       0.61      0.74      0.67        27
          F       0.96      1.00      0.98       250
          R       0.69      0.63      0.66        52

avg / total       0.86      0.88      0.87       352

12/28/2017 04:53:03 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:53:03 [INFO] exp_shallowmodel: 
[[  6   5   3   9]
 [  1  20   1   5]
 [  0   0 249   1]
 [  4   8   7  33]]
12/28/2017 04:53:06 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/28/2017 04:53:06 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:53:06 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:53:06 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:53:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:53:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:53:06 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:53:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:53:53 [INFO] exp_shallowmodel: train time: 46.048s
12/28/2017 04:53:53 [INFO] exp_shallowmodel: test time:  0.013s
12/28/2017 04:53:53 [INFO] exp_shallowmodel: accuracy:   0.864
12/28/2017 04:53:53 [INFO] exp_shallowmodel: f1_score:   0.680
12/28/2017 04:53:53 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:53:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.35      0.46        23
          C       0.74      0.63      0.68        27
          F       0.90      1.00      0.95       250
          R       0.74      0.56      0.64        52

avg / total       0.85      0.86      0.85       352

12/28/2017 04:53:53 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:53:53 [INFO] exp_shallowmodel: 
[[  8   1   9   5]
 [  1  17   4   5]
 [  0   0 250   0]
 [  3   5  15  29]]
12/28/2017 04:53:59 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/28/2017 04:53:59 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:53:59 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:53:59 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:53:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:53:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:53:59 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:53:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:54:51 [INFO] exp_shallowmodel: train time: 51.839s
12/28/2017 04:54:51 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:54:51 [INFO] exp_shallowmodel: accuracy:   0.866
12/28/2017 04:54:51 [INFO] exp_shallowmodel: f1_score:   0.673
12/28/2017 04:54:51 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:54:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.30      0.40        23
          C       0.69      0.74      0.71        27
          F       0.92      1.00      0.96       250
          R       0.74      0.54      0.62        52

avg / total       0.85      0.87      0.85       352

12/28/2017 04:54:51 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:54:51 [INFO] exp_shallowmodel: 
[[  7   4   6   6]
 [  2  20   1   4]
 [  0   0 250   0]
 [  3   5  16  28]]
12/28/2017 04:54:57 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/28/2017 04:54:57 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:54:57 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:54:57 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:54:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:54:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:54:57 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:54:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:55:32 [INFO] exp_shallowmodel: train time: 34.599s
12/28/2017 04:55:32 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:55:32 [INFO] exp_shallowmodel: accuracy:   0.866
12/28/2017 04:55:32 [INFO] exp_shallowmodel: f1_score:   0.658
12/28/2017 04:55:32 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:55:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.17      0.27        23
          C       0.73      0.70      0.72        27
          F       0.91      0.99      0.95       250
          R       0.73      0.67      0.70        52

avg / total       0.85      0.87      0.85       352

12/28/2017 04:55:32 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:55:32 [INFO] exp_shallowmodel: 
[[  4   3   9   7]
 [  1  19   4   3]
 [  0   0 247   3]
 [  2   4  11  35]]
12/28/2017 04:55:37 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/28/2017 04:55:37 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:55:37 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:55:37 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:55:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:55:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:55:37 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:55:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:56:28 [INFO] exp_shallowmodel: train time: 51.264s
12/28/2017 04:56:28 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:56:28 [INFO] exp_shallowmodel: accuracy:   0.878
12/28/2017 04:56:28 [INFO] exp_shallowmodel: f1_score:   0.692
12/28/2017 04:56:28 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:56:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.26      0.39        23
          C       0.71      0.81      0.76        27
          F       0.93      1.00      0.96       250
          R       0.71      0.62      0.66        52

avg / total       0.87      0.88      0.86       352

12/28/2017 04:56:28 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:56:28 [INFO] exp_shallowmodel: 
[[  6   4   4   9]
 [  0  22   1   4]
 [  1   0 249   0]
 [  1   5  14  32]]
12/28/2017 04:56:35 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/28/2017 04:56:35 [INFO] exp_shallowmodel: #(data) = 2816
12/28/2017 04:56:35 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:56:35 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:56:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:56:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:56:35 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:56:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:57:31 [INFO] exp_shallowmodel: train time: 56.668s
12/28/2017 04:57:31 [INFO] exp_shallowmodel: test time:  0.023s
12/28/2017 04:57:31 [INFO] exp_shallowmodel: accuracy:   0.870
12/28/2017 04:57:31 [INFO] exp_shallowmodel: f1_score:   0.697
12/28/2017 04:57:31 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:57:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.24      0.32        25
          C       0.79      0.81      0.80        27
          F       0.91      0.99      0.95       251
          R       0.80      0.66      0.72        59

avg / total       0.85      0.87      0.86       362

12/28/2017 04:57:31 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:57:31 [INFO] exp_shallowmodel: 
[[  6   1  12   6]
 [  0  22   2   3]
 [  2   0 248   1]
 [  5   5  10  39]]
12/28/2017 04:57:38 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/28/2017 04:57:38 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:57:38 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:57:38 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:57:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:57:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:57:38 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:57:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:58:23 [INFO] exp_shallowmodel: train time: 45.782s
12/28/2017 04:58:23 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 04:58:23 [INFO] exp_shallowmodel: accuracy:   0.872
12/28/2017 04:58:23 [INFO] exp_shallowmodel: f1_score:   0.677
12/28/2017 04:58:23 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:58:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.78      0.30      0.44        23
          C       0.61      0.70      0.66        27
          F       0.95      0.99      0.97       250
          R       0.66      0.63      0.65        52

avg / total       0.87      0.87      0.86       352

12/28/2017 04:58:23 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:58:23 [INFO] exp_shallowmodel: 
[[  7   3   2  11]
 [  1  19   2   5]
 [  0   1 248   1]
 [  1   8  10  33]]
12/28/2017 04:58:26 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/28/2017 04:58:26 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:58:26 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:58:26 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:58:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:58:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:58:26 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:58:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 04:59:14 [INFO] exp_shallowmodel: train time: 47.829s
12/28/2017 04:59:14 [INFO] exp_shallowmodel: test time:  0.022s
12/28/2017 04:59:14 [INFO] exp_shallowmodel: accuracy:   0.855
12/28/2017 04:59:14 [INFO] exp_shallowmodel: f1_score:   0.615
12/28/2017 04:59:14 [INFO] exp_shallowmodel: classification report:
12/28/2017 04:59:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.17      0.27        23
          C       0.64      0.52      0.57        27
          F       0.90      1.00      0.95       250
          R       0.72      0.63      0.67        52

avg / total       0.83      0.86      0.83       352

12/28/2017 04:59:14 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 04:59:14 [INFO] exp_shallowmodel: 
[[  4   4   8   7]
 [  1  14   6   6]
 [  0   0 250   0]
 [  2   4  13  33]]
12/28/2017 04:59:20 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/28/2017 04:59:20 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 04:59:20 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 04:59:20 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 04:59:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 04:59:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 04:59:20 [INFO] exp_shallowmodel: Training: 
12/28/2017 04:59:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:00:04 [INFO] exp_shallowmodel: train time: 43.705s
12/28/2017 05:00:04 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 05:00:04 [INFO] exp_shallowmodel: accuracy:   0.881
12/28/2017 05:00:04 [INFO] exp_shallowmodel: f1_score:   0.696
12/28/2017 05:00:04 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:00:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.30      0.40        23
          C       0.72      0.85      0.78        27
          F       0.94      1.00      0.97       250
          R       0.70      0.58      0.63        52

avg / total       0.87      0.88      0.87       352

12/28/2017 05:00:04 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:00:04 [INFO] exp_shallowmodel: 
[[  7   2   5   9]
 [  0  23   0   4]
 [  0   0 250   0]
 [  5   7  10  30]]
12/28/2017 05:00:10 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/28/2017 05:00:10 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 05:00:10 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 05:00:10 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:00:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:00:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:00:10 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:00:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:01:04 [INFO] exp_shallowmodel: train time: 53.691s
12/28/2017 05:01:04 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 05:01:04 [INFO] exp_shallowmodel: accuracy:   0.869
12/28/2017 05:01:04 [INFO] exp_shallowmodel: f1_score:   0.636
12/28/2017 05:01:04 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:01:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.69      0.81      0.75        27
          F       0.91      1.00      0.95       250
          R       0.80      0.63      0.71        52

avg / total       0.84      0.87      0.85       352

12/28/2017 05:01:04 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:01:04 [INFO] exp_shallowmodel: 
[[  2   6   9   6]
 [  0  22   3   2]
 [  1   0 249   0]
 [  3   4  12  33]]
12/28/2017 05:01:10 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/28/2017 05:01:10 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 05:01:10 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 05:01:10 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:01:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:01:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:01:10 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:01:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:02:04 [INFO] exp_shallowmodel: train time: 53.397s
12/28/2017 05:02:04 [INFO] exp_shallowmodel: test time:  0.031s
12/28/2017 05:02:04 [INFO] exp_shallowmodel: accuracy:   0.861
12/28/2017 05:02:04 [INFO] exp_shallowmodel: f1_score:   0.647
12/28/2017 05:02:04 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:02:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.22      0.28        23
          C       0.75      0.67      0.71        27
          F       0.93      0.99      0.96       250
          R       0.68      0.62      0.65        52

avg / total       0.84      0.86      0.85       352

12/28/2017 05:02:04 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:02:04 [INFO] exp_shallowmodel: 
[[  5   2   8   8]
 [  1  18   3   5]
 [  0   0 248   2]
 [  7   4   9  32]]
12/28/2017 05:02:13 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/28/2017 05:02:13 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 05:02:13 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 05:02:13 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:02:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:02:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:02:13 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:02:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:03:01 [INFO] exp_shallowmodel: train time: 48.156s
12/28/2017 05:03:01 [INFO] exp_shallowmodel: test time:  0.025s
12/28/2017 05:03:01 [INFO] exp_shallowmodel: accuracy:   0.855
12/28/2017 05:03:01 [INFO] exp_shallowmodel: f1_score:   0.634
12/28/2017 05:03:01 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:03:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.26      0.34        23
          C       0.57      0.63      0.60        27
          F       0.93      0.99      0.96       250
          R       0.71      0.58      0.64        52

avg / total       0.84      0.86      0.84       352

12/28/2017 05:03:01 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:03:01 [INFO] exp_shallowmodel: 
[[  6   3   9   5]
 [  3  17   1   6]
 [  1   0 248   1]
 [  2  10  10  30]]
12/28/2017 05:03:10 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/28/2017 05:03:10 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 05:03:10 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 05:03:10 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:03:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:03:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:03:10 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:03:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:03:51 [INFO] exp_shallowmodel: train time: 41.170s
12/28/2017 05:03:51 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 05:03:51 [INFO] exp_shallowmodel: accuracy:   0.884
12/28/2017 05:03:51 [INFO] exp_shallowmodel: f1_score:   0.707
12/28/2017 05:03:51 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:03:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.78      0.30      0.44        23
          C       0.69      0.81      0.75        27
          F       0.93      1.00      0.96       250
          R       0.76      0.62      0.68        52

avg / total       0.88      0.88      0.87       352

12/28/2017 05:03:51 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:03:51 [INFO] exp_shallowmodel: 
[[  7   2   7   7]
 [  0  22   2   3]
 [  0   0 250   0]
 [  2   8  10  32]]
12/28/2017 05:03:54 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/28/2017 05:03:54 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 05:03:54 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 05:03:54 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:03:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:03:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:03:54 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:03:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:04:19 [INFO] exp_shallowmodel: train time: 25.146s
12/28/2017 05:04:19 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 05:04:19 [INFO] exp_shallowmodel: accuracy:   0.875
12/28/2017 05:04:19 [INFO] exp_shallowmodel: f1_score:   0.673
12/28/2017 05:04:19 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:04:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.71      0.22      0.33        23
          C       0.71      0.74      0.73        27
          F       0.92      1.00      0.96       250
          R       0.72      0.63      0.67        52

avg / total       0.86      0.88      0.86       352

12/28/2017 05:04:19 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:04:19 [INFO] exp_shallowmodel: 
[[  5   2   9   7]
 [  0  20   1   6]
 [  0   0 250   0]
 [  2   6  11  33]]
12/28/2017 05:04:22 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/28/2017 05:04:22 [INFO] exp_shallowmodel: #(data) = 2826
12/28/2017 05:04:22 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 05:04:22 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:04:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:04:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:04:22 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:04:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:04:54 [INFO] exp_shallowmodel: train time: 31.379s
12/28/2017 05:04:54 [INFO] exp_shallowmodel: test time:  0.031s
12/28/2017 05:04:54 [INFO] exp_shallowmodel: accuracy:   0.858
12/28/2017 05:04:54 [INFO] exp_shallowmodel: f1_score:   0.679
12/28/2017 05:04:54 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:04:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.69      0.39      0.50        23
          C       0.66      0.70      0.68        27
          F       0.92      0.98      0.95       250
          R       0.64      0.54      0.58        52

avg / total       0.85      0.86      0.85       352

12/28/2017 05:04:54 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:04:54 [INFO] exp_shallowmodel: 
[[  9   2   4   8]
 [  0  19   2   6]
 [  2   0 246   2]
 [  2   8  14  28]]
12/28/2017 05:05:03 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/28/2017 05:05:03 [INFO] exp_shallowmodel: #(data) = 2816
12/28/2017 05:05:03 [INFO] exp_shallowmodel: #(feature) = 29791
12/28/2017 05:05:03 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:05:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:05:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:05:03 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:05:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:05:45 [INFO] exp_shallowmodel: train time: 42.256s
12/28/2017 05:05:45 [INFO] exp_shallowmodel: test time:  0.014s
12/28/2017 05:05:45 [INFO] exp_shallowmodel: accuracy:   0.831
12/28/2017 05:05:45 [INFO] exp_shallowmodel: f1_score:   0.585
12/28/2017 05:05:45 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:05:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.08      0.13        25
          C       0.62      0.78      0.69        27
          F       0.90      0.98      0.94       251
          R       0.65      0.53      0.58        59

avg / total       0.80      0.83      0.81       362

12/28/2017 05:05:45 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:05:45 [INFO] exp_shallowmodel: 
[[  2   4   9  10]
 [  0  21   1   5]
 [  1   1 247   2]
 [  2   8  18  31]]
12/28/2017 05:05:56 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/28/2017 05:05:56 [INFO] task_runner: context=next, feature=13-[8+1.3.4], similarity=False
12/28/2017 05:05:56 [INFO] task_runner: Before filtering, #(feature)=70017
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 1 : 5
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		2.1 : 123
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 2 : 128
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		2.2 : 3
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		2.3.1 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		2.3.2 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 3 : 5
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		4.1 : 18621
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 4 : 18625
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		4.2.1 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		4.2.2 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		4.3.1 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		4.3.2 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 5 : 23579
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 6 : 5520
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 7 : 6895
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		8.1 : 250
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 8 : 252
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		8.2.1 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		8.2.2 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		9.1 : 1500
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 9 : 1504
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		9.2.1 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		9.2.2 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		9.3.1 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		9.3.2 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		10.1 : 1500
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 10 : 1502
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		10.2.1 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		10.2.2 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		11.1 : 12000
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 11 : 12002
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		11.2.1 : 1
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		11.2.2 : 1
12/28/2017 05:05:56 [INFO] task_runner: After filtering, #(feature)=30094
12/28/2017 05:05:56 [INFO] task_runner: retained feature id=[1, 11.1, 2.1, 2.2, 3, 5, 6, 7]
12/28/2017 05:05:56 [INFO] task_runner: #(data)=5241
12/28/2017 05:05:56 [INFO] task_runner: #(feature)=30094/70017
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 1 : 3
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		2.1 : 82
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 2 : 84
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		2.2 : 2
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 3 : 5
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 5 : 14943
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 6 : 3527
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 7 : 4332
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 		11.1 : 7200
12/28/2017 05:05:56 [INFO] exp_shallowmodel: 11 : 7200
12/28/2017 05:05:56 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/28/2017 05:06:01 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/28/2017 05:06:01 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:06:01 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:06:01 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:06:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:06:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:06:01 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:06:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:06:54 [INFO] exp_shallowmodel: train time: 52.950s
12/28/2017 05:06:54 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:06:54 [INFO] exp_shallowmodel: accuracy:   0.862
12/28/2017 05:06:54 [INFO] exp_shallowmodel: f1_score:   0.581
12/28/2017 05:06:54 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:06:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.51      0.53        59
          C       0.67      0.17      0.27        12
          F       0.93      0.98      0.96       396
          R       0.60      0.55      0.57        55

avg / total       0.85      0.86      0.85       522

12/28/2017 05:06:54 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:06:54 [INFO] exp_shallowmodel: 
[[ 30   0  14  15]
 [  3   2   6   1]
 [  3   1 388   4]
 [ 18   0   7  30]]
12/28/2017 05:06:59 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/28/2017 05:06:59 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:06:59 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:06:59 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:06:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:06:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:06:59 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:06:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:07:58 [INFO] exp_shallowmodel: train time: 58.180s
12/28/2017 05:07:58 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:07:58 [INFO] exp_shallowmodel: accuracy:   0.862
12/28/2017 05:07:58 [INFO] exp_shallowmodel: f1_score:   0.515
12/28/2017 05:07:58 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:07:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.61      0.58      0.59        59
          C       0.00      0.00      0.00        12
          F       0.94      0.98      0.96       396
          R       0.53      0.49      0.51        55

avg / total       0.84      0.86      0.85       522

12/28/2017 05:07:58 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:07:58 [INFO] exp_shallowmodel: 
[[ 34   1   7  17]
 [  4   0   5   3]
 [  3   0 389   4]
 [ 15   0  13  27]]
12/28/2017 05:08:05 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/28/2017 05:08:05 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:08:05 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:08:05 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:08:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:08:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:08:05 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:08:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:09:29 [INFO] exp_shallowmodel: train time: 84.291s
12/28/2017 05:09:29 [INFO] exp_shallowmodel: test time:  0.038s
12/28/2017 05:09:29 [INFO] exp_shallowmodel: accuracy:   0.875
12/28/2017 05:09:29 [INFO] exp_shallowmodel: f1_score:   0.578
12/28/2017 05:09:29 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:09:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.63      0.54      0.58        59
          C       1.00      0.08      0.15        12
          F       0.93      0.99      0.96       396
          R       0.65      0.58      0.62        55

avg / total       0.87      0.88      0.86       522

12/28/2017 05:09:29 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:09:30 [INFO] exp_shallowmodel: 
[[ 32   0  13  14]
 [  6   1   4   1]
 [  2   0 392   2]
 [ 11   0  12  32]]
12/28/2017 05:09:39 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/28/2017 05:09:39 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:09:39 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:09:39 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:09:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:09:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:09:39 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:09:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:11:03 [INFO] exp_shallowmodel: train time: 83.840s
12/28/2017 05:11:03 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:11:03 [INFO] exp_shallowmodel: accuracy:   0.875
12/28/2017 05:11:03 [INFO] exp_shallowmodel: f1_score:   0.614
12/28/2017 05:11:03 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:11:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.65      0.68      0.66        59
          C       0.60      0.25      0.35        12
          F       0.95      0.99      0.97       396
          R       0.55      0.42      0.47        55

avg / total       0.86      0.88      0.87       522

12/28/2017 05:11:03 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:11:03 [INFO] exp_shallowmodel: 
[[ 40   0   8  11]
 [  1   3   3   5]
 [  2   0 391   3]
 [ 19   2  11  23]]
12/28/2017 05:11:07 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/28/2017 05:11:07 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:11:07 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:11:07 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:11:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:11:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:11:07 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:11:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:12:03 [INFO] exp_shallowmodel: train time: 55.386s
12/28/2017 05:12:03 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 05:12:03 [INFO] exp_shallowmodel: accuracy:   0.858
12/28/2017 05:12:03 [INFO] exp_shallowmodel: f1_score:   0.527
12/28/2017 05:12:03 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:12:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.59      0.66      0.62        59
          C       0.20      0.08      0.12        12
          F       0.94      0.98      0.96       396
          R       0.49      0.35      0.40        55

avg / total       0.84      0.86      0.85       522

12/28/2017 05:12:03 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:12:03 [INFO] exp_shallowmodel: 
[[ 39   1   6  13]
 [  4   1   3   4]
 [  3   1 389   3]
 [ 20   2  14  19]]
12/28/2017 05:12:15 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/28/2017 05:12:15 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:12:15 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:12:15 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:12:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:12:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:12:15 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:12:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:13:40 [INFO] exp_shallowmodel: train time: 84.590s
12/28/2017 05:13:40 [INFO] exp_shallowmodel: test time:  0.038s
12/28/2017 05:13:40 [INFO] exp_shallowmodel: accuracy:   0.881
12/28/2017 05:13:40 [INFO] exp_shallowmodel: f1_score:   0.623
12/28/2017 05:13:40 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:13:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.63      0.62        59
          C       0.75      0.25      0.38        12
          F       0.95      0.99      0.97       396
          R       0.58      0.47      0.52        55

avg / total       0.87      0.88      0.87       522

12/28/2017 05:13:40 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:13:40 [INFO] exp_shallowmodel: 
[[ 37   1   7  14]
 [  2   3   3   4]
 [  1   0 394   1]
 [ 20   0   9  26]]
12/28/2017 05:13:51 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/28/2017 05:13:51 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:13:51 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:13:51 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:13:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:13:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:13:51 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:13:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:15:22 [INFO] exp_shallowmodel: train time: 91.109s
12/28/2017 05:15:22 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:15:22 [INFO] exp_shallowmodel: accuracy:   0.881
12/28/2017 05:15:22 [INFO] exp_shallowmodel: f1_score:   0.636
12/28/2017 05:15:22 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:15:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.63      0.58      0.60        59
          C       1.00      0.25      0.40        12
          F       0.95      0.99      0.97       396
          R       0.60      0.55      0.57        55

avg / total       0.88      0.88      0.87       522

12/28/2017 05:15:22 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:15:22 [INFO] exp_shallowmodel: 
[[ 34   0  10  15]
 [  4   3   2   3]
 [  1   0 393   2]
 [ 15   0  10  30]]
12/28/2017 05:15:27 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/28/2017 05:15:27 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:15:27 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:15:27 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:15:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:15:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:15:27 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:15:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:16:15 [INFO] exp_shallowmodel: train time: 48.176s
12/28/2017 05:16:15 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:16:15 [INFO] exp_shallowmodel: accuracy:   0.872
12/28/2017 05:16:15 [INFO] exp_shallowmodel: f1_score:   0.628
12/28/2017 05:16:15 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:16:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.63      0.56      0.59        59
          C       1.00      0.25      0.40        12
          F       0.93      0.99      0.96       396
          R       0.62      0.51      0.56        55

avg / total       0.86      0.87      0.86       522

12/28/2017 05:16:15 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:16:15 [INFO] exp_shallowmodel: 
[[ 33   0  13  13]
 [  3   3   5   1]
 [  2   0 391   3]
 [ 14   0  13  28]]
12/28/2017 05:16:20 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/28/2017 05:16:20 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:16:20 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:16:20 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:16:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:16:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:16:20 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:16:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:17:30 [INFO] exp_shallowmodel: train time: 70.345s
12/28/2017 05:17:30 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 05:17:30 [INFO] exp_shallowmodel: accuracy:   0.874
12/28/2017 05:17:30 [INFO] exp_shallowmodel: f1_score:   0.565
12/28/2017 05:17:30 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:17:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.66      0.67        59
          C       0.25      0.08      0.12        12
          F       0.95      0.98      0.97       396
          R       0.54      0.47      0.50        55

avg / total       0.86      0.87      0.86       522

12/28/2017 05:17:30 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:17:30 [INFO] exp_shallowmodel: 
[[ 39   0   7  13]
 [  2   1   4   5]
 [  2   0 390   4]
 [ 15   3  11  26]]
12/28/2017 05:17:39 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/28/2017 05:17:39 [INFO] exp_shallowmodel: #(data) = 4176
12/28/2017 05:17:39 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:17:39 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:17:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:17:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:17:39 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:17:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:19:04 [INFO] exp_shallowmodel: train time: 84.404s
12/28/2017 05:19:04 [INFO] exp_shallowmodel: test time:  0.030s
12/28/2017 05:19:04 [INFO] exp_shallowmodel: accuracy:   0.849
12/28/2017 05:19:04 [INFO] exp_shallowmodel: f1_score:   0.502
12/28/2017 05:19:04 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:19:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.61      0.56      0.59        64
          C       0.00      0.00      0.00        14
          F       0.93      0.99      0.96       402
          R       0.51      0.43      0.47        63

avg / total       0.82      0.85      0.83       543

12/28/2017 05:19:04 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:19:04 [INFO] exp_shallowmodel: 
[[ 36   0  10  18]
 [  2   0   6   6]
 [  2   0 398   2]
 [ 19   2  15  27]]
12/28/2017 05:19:13 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/28/2017 05:19:13 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:19:13 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:19:13 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:19:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:19:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:19:13 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:19:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:20:33 [INFO] exp_shallowmodel: train time: 79.902s
12/28/2017 05:20:33 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 05:20:33 [INFO] exp_shallowmodel: accuracy:   0.849
12/28/2017 05:20:33 [INFO] exp_shallowmodel: f1_score:   0.490
12/28/2017 05:20:33 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:20:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.54      0.60        59
          C       0.00      0.00      0.00        12
          F       0.92      0.98      0.95       396
          R       0.45      0.38      0.41        55

avg / total       0.82      0.85      0.83       522

12/28/2017 05:20:33 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:20:33 [INFO] exp_shallowmodel: 
[[ 32   1   8  18]
 [  3   0   3   6]
 [  4   0 390   2]
 [  9   0  25  21]]
12/28/2017 05:20:43 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/28/2017 05:20:43 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:20:43 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:20:43 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:20:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:20:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:20:43 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:20:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:21:50 [INFO] exp_shallowmodel: train time: 67.762s
12/28/2017 05:21:50 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:21:50 [INFO] exp_shallowmodel: accuracy:   0.872
12/28/2017 05:21:50 [INFO] exp_shallowmodel: f1_score:   0.568
12/28/2017 05:21:50 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:21:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.66      0.56      0.61        59
          C       0.50      0.08      0.14        12
          F       0.94      0.98      0.96       396
          R       0.56      0.56      0.56        55

avg / total       0.86      0.87      0.86       522

12/28/2017 05:21:50 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:21:50 [INFO] exp_shallowmodel: 
[[ 33   0   8  18]
 [  2   1   7   2]
 [  2   0 390   4]
 [ 13   1  10  31]]
12/28/2017 05:21:56 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/28/2017 05:21:56 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:21:56 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:21:56 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:21:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:21:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:21:56 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:21:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:22:41 [INFO] exp_shallowmodel: train time: 44.799s
12/28/2017 05:22:41 [INFO] exp_shallowmodel: test time:  0.038s
12/28/2017 05:22:41 [INFO] exp_shallowmodel: accuracy:   0.847
12/28/2017 05:22:41 [INFO] exp_shallowmodel: f1_score:   0.520
12/28/2017 05:22:41 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:22:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.46      0.50        59
          C       1.00      0.08      0.15        12
          F       0.94      0.98      0.96       396
          R       0.46      0.49      0.47        55

avg / total       0.84      0.85      0.84       522

12/28/2017 05:22:41 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:22:41 [INFO] exp_shallowmodel: 
[[ 27   0   9  23]
 [  3   1   6   2]
 [  2   0 387   7]
 [ 18   0  10  27]]
12/28/2017 05:22:47 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/28/2017 05:22:47 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:22:47 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:22:47 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:22:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:22:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:22:47 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:22:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:23:36 [INFO] exp_shallowmodel: train time: 49.547s
12/28/2017 05:23:36 [INFO] exp_shallowmodel: test time:  0.038s
12/28/2017 05:23:37 [INFO] exp_shallowmodel: accuracy:   0.879
12/28/2017 05:23:37 [INFO] exp_shallowmodel: f1_score:   0.538
12/28/2017 05:23:37 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:23:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.68      0.63        59
          C       0.00      0.00      0.00        12
          F       0.96      0.99      0.97       396
          R       0.61      0.51      0.55        55

avg / total       0.86      0.88      0.87       522

12/28/2017 05:23:37 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:23:37 [INFO] exp_shallowmodel: 
[[ 40   0   8  11]
 [  3   0   3   6]
 [  4   0 391   1]
 [ 22   0   5  28]]
12/28/2017 05:23:46 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/28/2017 05:23:46 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:23:46 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:23:46 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:23:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:23:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:23:46 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:23:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:24:32 [INFO] exp_shallowmodel: train time: 45.990s
12/28/2017 05:24:32 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:24:32 [INFO] exp_shallowmodel: accuracy:   0.868
12/28/2017 05:24:32 [INFO] exp_shallowmodel: f1_score:   0.587
12/28/2017 05:24:32 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:24:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.58      0.60        59
          C       0.50      0.17      0.25        12
          F       0.94      0.98      0.96       396
          R       0.58      0.51      0.54        55

avg / total       0.85      0.87      0.86       522

12/28/2017 05:24:32 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:24:32 [INFO] exp_shallowmodel: 
[[ 34   1  10  14]
 [  2   2   6   2]
 [  2   1 389   4]
 [ 17   0  10  28]]
12/28/2017 05:24:37 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/28/2017 05:24:37 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:24:37 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:24:37 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:24:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:24:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:24:37 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:24:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:25:32 [INFO] exp_shallowmodel: train time: 55.122s
12/28/2017 05:25:32 [INFO] exp_shallowmodel: test time:  0.031s
12/28/2017 05:25:32 [INFO] exp_shallowmodel: accuracy:   0.875
12/28/2017 05:25:32 [INFO] exp_shallowmodel: f1_score:   0.545
12/28/2017 05:25:32 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:25:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.63      0.64      0.64        59
          C       0.00      0.00      0.00        12
          F       0.93      0.99      0.96       396
          R       0.68      0.51      0.58        55

avg / total       0.85      0.88      0.86       522

12/28/2017 05:25:32 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:25:32 [INFO] exp_shallowmodel: 
[[ 38   1  12   8]
 [  3   0   5   4]
 [  3   1 391   1]
 [ 16   0  11  28]]
12/28/2017 05:25:41 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/28/2017 05:25:41 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:25:41 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:25:41 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:25:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:25:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:25:41 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:25:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:26:31 [INFO] exp_shallowmodel: train time: 49.265s
12/28/2017 05:26:31 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:26:31 [INFO] exp_shallowmodel: accuracy:   0.868
12/28/2017 05:26:31 [INFO] exp_shallowmodel: f1_score:   0.507
12/28/2017 05:26:31 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:26:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.58      0.57        59
          C       0.00      0.00      0.00        12
          F       0.95      0.99      0.97       396
          R       0.53      0.45      0.49        55

avg / total       0.84      0.87      0.85       522

12/28/2017 05:26:31 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:26:31 [INFO] exp_shallowmodel: 
[[ 34   0   8  17]
 [  5   0   3   4]
 [  1   0 394   1]
 [ 21   0   9  25]]
12/28/2017 05:26:35 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/28/2017 05:26:35 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:26:35 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:26:35 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:26:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:26:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:26:35 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:26:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:27:46 [INFO] exp_shallowmodel: train time: 71.092s
12/28/2017 05:27:47 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:27:47 [INFO] exp_shallowmodel: accuracy:   0.874
12/28/2017 05:27:47 [INFO] exp_shallowmodel: f1_score:   0.627
12/28/2017 05:27:47 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:27:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.59      0.58      0.58        59
          C       0.57      0.33      0.42        12
          F       0.94      0.99      0.97       396
          R       0.63      0.47      0.54        55

avg / total       0.86      0.87      0.86       522

12/28/2017 05:27:47 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:27:47 [INFO] exp_shallowmodel: 
[[ 34   1  12  12]
 [  3   4   4   1]
 [  2   0 392   2]
 [ 19   2   8  26]]
12/28/2017 05:27:51 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/28/2017 05:27:51 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:27:51 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:27:51 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:27:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:27:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:27:51 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:27:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:28:56 [INFO] exp_shallowmodel: train time: 65.330s
12/28/2017 05:28:56 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:28:56 [INFO] exp_shallowmodel: accuracy:   0.851
12/28/2017 05:28:56 [INFO] exp_shallowmodel: f1_score:   0.487
12/28/2017 05:28:56 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:28:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.56      0.55        59
          C       0.00      0.00      0.00        12
          F       0.94      0.98      0.96       396
          R       0.49      0.40      0.44        55

avg / total       0.82      0.85      0.84       522

12/28/2017 05:28:56 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:28:56 [INFO] exp_shallowmodel: 
[[ 33   0  10  16]
 [  3   0   4   5]
 [  5   0 389   2]
 [ 20   0  13  22]]
12/28/2017 05:29:01 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/28/2017 05:29:01 [INFO] exp_shallowmodel: #(data) = 4176
12/28/2017 05:29:01 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:29:01 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:29:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:29:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:29:01 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:29:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:29:42 [INFO] exp_shallowmodel: train time: 41.226s
12/28/2017 05:29:42 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:29:42 [INFO] exp_shallowmodel: accuracy:   0.851
12/28/2017 05:29:42 [INFO] exp_shallowmodel: f1_score:   0.558
12/28/2017 05:29:42 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:29:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.53      0.54        64
          C       0.67      0.14      0.24        14
          F       0.94      0.99      0.96       402
          R       0.53      0.46      0.49        63

avg / total       0.84      0.85      0.84       543

12/28/2017 05:29:42 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:29:42 [INFO] exp_shallowmodel: 
[[ 34   0   9  21]
 [  1   2   8   3]
 [  3   0 397   2]
 [ 23   1  10  29]]
12/28/2017 05:29:47 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/28/2017 05:29:47 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:29:47 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:29:47 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:29:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:29:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:29:47 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:29:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:30:47 [INFO] exp_shallowmodel: train time: 60.415s
12/28/2017 05:30:47 [INFO] exp_shallowmodel: test time:  0.033s
12/28/2017 05:30:47 [INFO] exp_shallowmodel: accuracy:   0.874
12/28/2017 05:30:47 [INFO] exp_shallowmodel: f1_score:   0.546
12/28/2017 05:30:47 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:30:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.69      0.61      0.65        59
          C       0.00      0.00      0.00        12
          F       0.94      0.98      0.96       396
          R       0.58      0.56      0.57        55

avg / total       0.85      0.87      0.86       522

12/28/2017 05:30:47 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:30:47 [INFO] exp_shallowmodel: 
[[ 36   1   9  13]
 [  3   0   4   5]
 [  3   0 389   4]
 [ 10   1  13  31]]
12/28/2017 05:30:56 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/28/2017 05:30:56 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:30:56 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:30:56 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:30:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:30:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:30:56 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:30:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:31:40 [INFO] exp_shallowmodel: train time: 43.933s
12/28/2017 05:31:40 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:31:40 [INFO] exp_shallowmodel: accuracy:   0.895
12/28/2017 05:31:40 [INFO] exp_shallowmodel: f1_score:   0.601
12/28/2017 05:31:40 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:31:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.68      0.73      0.70        59
          C       1.00      0.08      0.15        12
          F       0.95      1.00      0.97       396
          R       0.65      0.51      0.57        55

avg / total       0.89      0.89      0.88       522

12/28/2017 05:31:40 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:31:40 [INFO] exp_shallowmodel: 
[[ 43   0   7   9]
 [  3   1   2   6]
 [  1   0 395   0]
 [ 16   0  11  28]]
12/28/2017 05:31:44 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/28/2017 05:31:44 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:31:44 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:31:44 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:31:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:31:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:31:44 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:31:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:32:40 [INFO] exp_shallowmodel: train time: 55.832s
12/28/2017 05:32:40 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 05:32:40 [INFO] exp_shallowmodel: accuracy:   0.851
12/28/2017 05:32:40 [INFO] exp_shallowmodel: f1_score:   0.528
12/28/2017 05:32:40 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:32:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.54      0.56        59
          C       1.00      0.08      0.15        12
          F       0.93      0.98      0.95       396
          R       0.48      0.42      0.45        55

avg / total       0.84      0.85      0.84       522

12/28/2017 05:32:40 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:32:40 [INFO] exp_shallowmodel: 
[[ 32   0   9  18]
 [  4   1   4   3]
 [  4   0 388   4]
 [ 16   0  16  23]]
12/28/2017 05:32:49 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/28/2017 05:32:49 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:32:49 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:32:49 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:32:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:32:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:32:49 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:32:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:34:03 [INFO] exp_shallowmodel: train time: 73.838s
12/28/2017 05:34:03 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 05:34:03 [INFO] exp_shallowmodel: accuracy:   0.864
12/28/2017 05:34:03 [INFO] exp_shallowmodel: f1_score:   0.509
12/28/2017 05:34:03 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:34:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.53      0.56      0.55        59
          C       0.00      0.00      0.00        12
          F       0.96      0.98      0.97       396
          R       0.53      0.51      0.52        55

avg / total       0.85      0.86      0.86       522

12/28/2017 05:34:03 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:34:03 [INFO] exp_shallowmodel: 
[[ 33   1   7  18]
 [  5   0   3   4]
 [  3   0 390   3]
 [ 21   1   5  28]]
12/28/2017 05:34:10 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/28/2017 05:34:10 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:34:10 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:34:10 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:34:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:34:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:34:10 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:34:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:34:52 [INFO] exp_shallowmodel: train time: 41.597s
12/28/2017 05:34:52 [INFO] exp_shallowmodel: test time:  0.022s
12/28/2017 05:34:52 [INFO] exp_shallowmodel: accuracy:   0.864
12/28/2017 05:34:52 [INFO] exp_shallowmodel: f1_score:   0.550
12/28/2017 05:34:52 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:34:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.63      0.58      0.60        59
          C       0.33      0.08      0.13        12
          F       0.94      0.98      0.96       396
          R       0.54      0.47      0.50        55

avg / total       0.85      0.86      0.85       522

12/28/2017 05:34:52 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:34:52 [INFO] exp_shallowmodel: 
[[ 34   1   8  16]
 [  2   1   4   5]
 [  4   1 390   1]
 [ 14   0  15  26]]
12/28/2017 05:34:56 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/28/2017 05:34:56 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:34:56 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:34:56 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:34:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:34:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:34:56 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:34:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:35:50 [INFO] exp_shallowmodel: train time: 54.009s
12/28/2017 05:35:50 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 05:35:50 [INFO] exp_shallowmodel: accuracy:   0.877
12/28/2017 05:35:50 [INFO] exp_shallowmodel: f1_score:   0.536
12/28/2017 05:35:50 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:35:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.63      0.62        59
          C       0.00      0.00      0.00        12
          F       0.95      0.99      0.97       396
          R       0.61      0.51      0.55        55

avg / total       0.85      0.88      0.86       522

12/28/2017 05:35:50 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:35:50 [INFO] exp_shallowmodel: 
[[ 37   0   9  13]
 [  3   0   6   3]
 [  1   0 393   2]
 [ 19   1   7  28]]
12/28/2017 05:36:00 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/28/2017 05:36:00 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:36:00 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:36:00 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:36:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:36:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:36:00 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:36:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:37:25 [INFO] exp_shallowmodel: train time: 85.585s
12/28/2017 05:37:25 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:37:25 [INFO] exp_shallowmodel: accuracy:   0.864
12/28/2017 05:37:25 [INFO] exp_shallowmodel: f1_score:   0.547
12/28/2017 05:37:25 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:37:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.63      0.61        59
          C       0.50      0.08      0.14        12
          F       0.93      0.99      0.96       396
          R       0.59      0.40      0.48        55

avg / total       0.85      0.86      0.85       522

12/28/2017 05:37:25 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:37:25 [INFO] exp_shallowmodel: 
[[ 37   1  10  11]
 [  2   1   7   2]
 [  3   0 391   2]
 [ 20   0  13  22]]
12/28/2017 05:37:30 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/28/2017 05:37:30 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:37:30 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:37:30 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:37:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:37:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:37:30 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:37:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:38:22 [INFO] exp_shallowmodel: train time: 52.346s
12/28/2017 05:38:22 [INFO] exp_shallowmodel: test time:  0.039s
12/28/2017 05:38:22 [INFO] exp_shallowmodel: accuracy:   0.864
12/28/2017 05:38:22 [INFO] exp_shallowmodel: f1_score:   0.547
12/28/2017 05:38:22 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:38:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.59      0.58        59
          C       1.00      0.08      0.15        12
          F       0.95      0.98      0.97       396
          R       0.52      0.45      0.49        55

avg / total       0.86      0.86      0.85       522

12/28/2017 05:38:22 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:38:22 [INFO] exp_shallowmodel: 
[[ 35   0   9  15]
 [  4   1   2   5]
 [  3   0 390   3]
 [ 19   0  11  25]]
12/28/2017 05:38:32 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/28/2017 05:38:32 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:38:32 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:38:32 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:38:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:38:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:38:32 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:38:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:39:46 [INFO] exp_shallowmodel: train time: 74.567s
12/28/2017 05:39:46 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:39:46 [INFO] exp_shallowmodel: accuracy:   0.870
12/28/2017 05:39:46 [INFO] exp_shallowmodel: f1_score:   0.577
12/28/2017 05:39:46 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:39:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.65      0.61      0.63        59
          C       0.50      0.17      0.25        12
          F       0.93      0.99      0.96       396
          R       0.55      0.40      0.46        55

avg / total       0.85      0.87      0.86       522

12/28/2017 05:39:46 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:39:46 [INFO] exp_shallowmodel: 
[[ 36   0   9  14]
 [  1   2   6   3]
 [  1   0 394   1]
 [ 17   2  14  22]]
12/28/2017 05:39:59 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/28/2017 05:39:59 [INFO] exp_shallowmodel: #(data) = 4176
12/28/2017 05:39:59 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:39:59 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:39:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:39:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:39:59 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:39:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:40:58 [INFO] exp_shallowmodel: train time: 59.508s
12/28/2017 05:40:58 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:40:58 [INFO] exp_shallowmodel: accuracy:   0.877
12/28/2017 05:40:58 [INFO] exp_shallowmodel: f1_score:   0.617
12/28/2017 05:40:58 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:40:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.66      0.64      0.65        64
          C       1.00      0.14      0.25        14
          F       0.93      0.99      0.96       402
          R       0.69      0.54      0.61        63

avg / total       0.87      0.88      0.86       543

12/28/2017 05:40:58 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:40:58 [INFO] exp_shallowmodel: 
[[ 41   0  13  10]
 [  3   2   6   3]
 [  1   0 399   2]
 [ 17   0  12  34]]
12/28/2017 05:41:03 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/28/2017 05:41:03 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:41:03 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:41:03 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:41:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:41:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:41:03 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:41:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:41:47 [INFO] exp_shallowmodel: train time: 44.372s
12/28/2017 05:41:47 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:41:47 [INFO] exp_shallowmodel: accuracy:   0.866
12/28/2017 05:41:47 [INFO] exp_shallowmodel: f1_score:   0.540
12/28/2017 05:41:47 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:41:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.61      0.68      0.64        59
          C       0.33      0.08      0.13        12
          F       0.94      0.99      0.96       396
          R       0.54      0.35      0.42        55

avg / total       0.84      0.87      0.85       522

12/28/2017 05:41:47 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:41:47 [INFO] exp_shallowmodel: 
[[ 40   1   8  10]
 [  3   1   5   3]
 [  1   0 392   3]
 [ 22   1  13  19]]
12/28/2017 05:41:52 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/28/2017 05:41:52 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:41:52 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:41:52 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:41:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:41:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:41:52 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:41:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:42:36 [INFO] exp_shallowmodel: train time: 44.204s
12/28/2017 05:42:36 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:42:36 [INFO] exp_shallowmodel: accuracy:   0.860
12/28/2017 05:42:36 [INFO] exp_shallowmodel: f1_score:   0.549
12/28/2017 05:42:36 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:42:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.53      0.51      0.52        59
          C       0.33      0.08      0.13        12
          F       0.93      0.98      0.96       396
          R       0.64      0.55      0.59        55

avg / total       0.84      0.86      0.85       522

12/28/2017 05:42:36 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:42:36 [INFO] exp_shallowmodel: 
[[ 30   2  14  13]
 [  4   1   6   1]
 [  5   0 388   3]
 [ 18   0   7  30]]
12/28/2017 05:42:41 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/28/2017 05:42:41 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:42:41 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:42:41 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:42:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:42:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:42:41 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:42:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:43:21 [INFO] exp_shallowmodel: train time: 40.079s
12/28/2017 05:43:21 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:43:21 [INFO] exp_shallowmodel: accuracy:   0.862
12/28/2017 05:43:21 [INFO] exp_shallowmodel: f1_score:   0.522
12/28/2017 05:43:21 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:43:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.64      0.61      0.63        59
          C       0.00      0.00      0.00        12
          F       0.93      0.98      0.95       396
          R       0.55      0.47      0.51        55

avg / total       0.83      0.86      0.85       522

12/28/2017 05:43:21 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:43:21 [INFO] exp_shallowmodel: 
[[ 36   0   9  14]
 [  2   0   8   2]
 [  3   0 388   5]
 [ 15   0  14  26]]
12/28/2017 05:43:25 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/28/2017 05:43:25 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:43:25 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:43:25 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:43:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:43:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:43:25 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:43:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:44:08 [INFO] exp_shallowmodel: train time: 42.311s
12/28/2017 05:44:08 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:44:08 [INFO] exp_shallowmodel: accuracy:   0.877
12/28/2017 05:44:08 [INFO] exp_shallowmodel: f1_score:   0.545
12/28/2017 05:44:08 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:44:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.61      0.61      0.61        59
          C       0.00      0.00      0.00        12
          F       0.95      0.99      0.97       396
          R       0.65      0.56      0.60        55

avg / total       0.86      0.88      0.87       522

12/28/2017 05:44:08 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:44:08 [INFO] exp_shallowmodel: 
[[ 36   1  12  10]
 [  4   0   3   5]
 [  3   0 391   2]
 [ 16   1   7  31]]
12/28/2017 05:44:12 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/28/2017 05:44:12 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:44:12 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:44:12 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:44:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:44:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:44:12 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:44:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:45:18 [INFO] exp_shallowmodel: train time: 65.335s
12/28/2017 05:45:18 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 05:45:18 [INFO] exp_shallowmodel: accuracy:   0.858
12/28/2017 05:45:18 [INFO] exp_shallowmodel: f1_score:   0.501
12/28/2017 05:45:18 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:45:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.51      0.54        59
          C       0.00      0.00      0.00        12
          F       0.95      0.98      0.97       396
          R       0.50      0.51      0.50        55

avg / total       0.83      0.86      0.85       522

12/28/2017 05:45:18 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:45:18 [INFO] exp_shallowmodel: 
[[ 30   1   8  20]
 [  2   0   5   5]
 [  3   0 390   3]
 [ 18   0   9  28]]
12/28/2017 05:45:27 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/28/2017 05:45:27 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:45:27 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:45:27 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:45:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:45:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:45:27 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:45:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:46:51 [INFO] exp_shallowmodel: train time: 84.375s
12/28/2017 05:46:51 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 05:46:51 [INFO] exp_shallowmodel: accuracy:   0.887
12/28/2017 05:46:51 [INFO] exp_shallowmodel: f1_score:   0.624
12/28/2017 05:46:51 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:46:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.69      0.72        59
          C       0.50      0.17      0.25        12
          F       0.94      0.99      0.96       396
          R       0.60      0.53      0.56        55

avg / total       0.87      0.89      0.88       522

12/28/2017 05:46:51 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:46:51 [INFO] exp_shallowmodel: 
[[ 41   1   3  14]
 [  2   2   5   3]
 [  2   1 391   2]
 [ 10   0  16  29]]
12/28/2017 05:47:01 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/28/2017 05:47:01 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:47:01 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:47:01 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:47:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:47:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:47:01 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:47:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:48:21 [INFO] exp_shallowmodel: train time: 80.264s
12/28/2017 05:48:21 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 05:48:21 [INFO] exp_shallowmodel: accuracy:   0.877
12/28/2017 05:48:21 [INFO] exp_shallowmodel: f1_score:   0.625
12/28/2017 05:48:21 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:48:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.54      0.60        59
          C       0.50      0.25      0.33        12
          F       0.95      0.98      0.97       396
          R       0.59      0.62      0.60        55

avg / total       0.87      0.88      0.87       522

12/28/2017 05:48:21 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:48:21 [INFO] exp_shallowmodel: 
[[ 32   1   9  17]
 [  1   3   5   3]
 [  3   0 389   4]
 [ 12   2   7  34]]
12/28/2017 05:48:31 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/28/2017 05:48:31 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:48:31 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:48:31 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:48:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:48:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:48:31 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:48:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:50:08 [INFO] exp_shallowmodel: train time: 97.475s
12/28/2017 05:50:08 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:50:08 [INFO] exp_shallowmodel: accuracy:   0.870
12/28/2017 05:50:08 [INFO] exp_shallowmodel: f1_score:   0.529
12/28/2017 05:50:08 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:50:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.54      0.57        59
          C       0.00      0.00      0.00        12
          F       0.93      0.99      0.96       396
          R       0.62      0.55      0.58        55

avg / total       0.84      0.87      0.85       522

12/28/2017 05:50:08 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:50:08 [INFO] exp_shallowmodel: 
[[ 32   0  15  12]
 [  5   0   4   3]
 [  1   0 392   3]
 [ 15   1   9  30]]
12/28/2017 05:50:18 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/28/2017 05:50:18 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:50:18 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:50:18 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:50:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:50:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:50:18 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:50:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:51:07 [INFO] exp_shallowmodel: train time: 49.164s
12/28/2017 05:51:07 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:51:07 [INFO] exp_shallowmodel: accuracy:   0.864
12/28/2017 05:51:07 [INFO] exp_shallowmodel: f1_score:   0.548
12/28/2017 05:51:07 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:51:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.65      0.54      0.59        59
          C       0.50      0.08      0.14        12
          F       0.93      0.99      0.96       396
          R       0.52      0.47      0.50        55

avg / total       0.85      0.86      0.85       522

12/28/2017 05:51:07 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:51:07 [INFO] exp_shallowmodel: 
[[ 32   0   9  18]
 [  4   1   4   3]
 [  1   0 392   3]
 [ 12   1  16  26]]
12/28/2017 05:51:11 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/28/2017 05:51:11 [INFO] exp_shallowmodel: #(data) = 4176
12/28/2017 05:51:11 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:51:11 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:51:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:51:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:51:11 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:51:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:52:08 [INFO] exp_shallowmodel: train time: 56.604s
12/28/2017 05:52:08 [INFO] exp_shallowmodel: test time:  0.039s
12/28/2017 05:52:08 [INFO] exp_shallowmodel: accuracy:   0.877
12/28/2017 05:52:08 [INFO] exp_shallowmodel: f1_score:   0.558
12/28/2017 05:52:08 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:52:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.67      0.67        64
          C       0.00      0.00      0.00        14
          F       0.94      0.99      0.96       402
          R       0.67      0.54      0.60        63

avg / total       0.85      0.88      0.86       543

12/28/2017 05:52:08 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:52:08 [INFO] exp_shallowmodel: 
[[ 43   1   8  12]
 [  3   0   7   4]
 [  2   0 399   1]
 [ 16   1  12  34]]
12/28/2017 05:52:13 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/28/2017 05:52:13 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:52:13 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:52:13 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:52:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:52:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:52:13 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:52:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:52:54 [INFO] exp_shallowmodel: train time: 41.233s
12/28/2017 05:52:54 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 05:52:54 [INFO] exp_shallowmodel: accuracy:   0.866
12/28/2017 05:52:54 [INFO] exp_shallowmodel: f1_score:   0.528
12/28/2017 05:52:54 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:52:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.59      0.59        59
          C       0.00      0.00      0.00        12
          F       0.93      0.98      0.96       396
          R       0.64      0.51      0.57        55

avg / total       0.84      0.87      0.85       522

12/28/2017 05:52:54 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:52:54 [INFO] exp_shallowmodel: 
[[ 35   0  12  12]
 [  4   0   7   1]
 [  4   0 389   3]
 [ 17   1   9  28]]
12/28/2017 05:52:59 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/28/2017 05:52:59 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:52:59 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:52:59 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:52:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:52:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:52:59 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:52:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:54:03 [INFO] exp_shallowmodel: train time: 64.357s
12/28/2017 05:54:03 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:54:03 [INFO] exp_shallowmodel: accuracy:   0.872
12/28/2017 05:54:03 [INFO] exp_shallowmodel: f1_score:   0.565
12/28/2017 05:54:03 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:54:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.56      0.59        59
          C       0.50      0.08      0.14        12
          F       0.95      0.98      0.97       396
          R       0.56      0.56      0.56        55

avg / total       0.86      0.87      0.86       522

12/28/2017 05:54:03 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:54:03 [INFO] exp_shallowmodel: 
[[ 33   1  11  14]
 [  0   1   4   7]
 [  3   0 390   3]
 [ 17   0   7  31]]
12/28/2017 05:54:13 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/28/2017 05:54:13 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:54:13 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:54:13 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:54:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:54:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:54:13 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:54:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:55:27 [INFO] exp_shallowmodel: train time: 74.186s
12/28/2017 05:55:27 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 05:55:27 [INFO] exp_shallowmodel: accuracy:   0.872
12/28/2017 05:55:27 [INFO] exp_shallowmodel: f1_score:   0.553
12/28/2017 05:55:27 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:55:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.61      0.53      0.56        59
          C       0.33      0.08      0.13        12
          F       0.95      0.99      0.97       396
          R       0.55      0.55      0.55        55

avg / total       0.86      0.87      0.86       522

12/28/2017 05:55:27 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:55:27 [INFO] exp_shallowmodel: 
[[ 31   1   9  18]
 [  3   1   2   6]
 [  2   0 393   1]
 [ 15   1   9  30]]
12/28/2017 05:55:36 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/28/2017 05:55:36 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:55:36 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:55:36 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:55:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:55:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:55:36 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:55:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:57:00 [INFO] exp_shallowmodel: train time: 84.376s
12/28/2017 05:57:01 [INFO] exp_shallowmodel: test time:  0.031s
12/28/2017 05:57:01 [INFO] exp_shallowmodel: accuracy:   0.872
12/28/2017 05:57:01 [INFO] exp_shallowmodel: f1_score:   0.530
12/28/2017 05:57:01 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:57:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.68      0.58      0.62        59
          C       0.00      0.00      0.00        12
          F       0.93      0.99      0.96       396
          R       0.56      0.51      0.53        55

avg / total       0.84      0.87      0.86       522

12/28/2017 05:57:01 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:57:01 [INFO] exp_shallowmodel: 
[[ 34   1   9  15]
 [  3   0   4   5]
 [  1   0 393   2]
 [ 12   0  15  28]]
12/28/2017 05:57:10 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/28/2017 05:57:10 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:57:10 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:57:10 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:57:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:57:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:57:10 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:57:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:58:07 [INFO] exp_shallowmodel: train time: 57.501s
12/28/2017 05:58:07 [INFO] exp_shallowmodel: test time:  0.038s
12/28/2017 05:58:07 [INFO] exp_shallowmodel: accuracy:   0.874
12/28/2017 05:58:07 [INFO] exp_shallowmodel: f1_score:   0.606
12/28/2017 05:58:07 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:58:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.61      0.64      0.63        59
          C       0.75      0.25      0.38        12
          F       0.94      0.99      0.97       396
          R       0.55      0.38      0.45        55

avg / total       0.86      0.87      0.86       522

12/28/2017 05:58:07 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:58:07 [INFO] exp_shallowmodel: 
[[ 38   0   8  13]
 [  2   3   4   3]
 [  1   0 394   1]
 [ 21   1  12  21]]
12/28/2017 05:58:16 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/28/2017 05:58:16 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:58:16 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:58:16 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:58:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:58:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:58:16 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:58:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:58:57 [INFO] exp_shallowmodel: train time: 40.617s
12/28/2017 05:58:57 [INFO] exp_shallowmodel: test time:  0.020s
12/28/2017 05:58:57 [INFO] exp_shallowmodel: accuracy:   0.870
12/28/2017 05:58:57 [INFO] exp_shallowmodel: f1_score:   0.556
12/28/2017 05:58:57 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:58:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.61      0.59      0.60        59
          C       0.20      0.08      0.12        12
          F       0.95      0.98      0.97       396
          R       0.56      0.51      0.53        55

avg / total       0.85      0.87      0.86       522

12/28/2017 05:58:57 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:58:57 [INFO] exp_shallowmodel: 
[[ 35   0   8  16]
 [  3   1   5   3]
 [  2   1 390   3]
 [ 17   3   7  28]]
12/28/2017 05:59:01 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/28/2017 05:59:01 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:59:01 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:59:01 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:59:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:59:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:59:01 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:59:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 05:59:46 [INFO] exp_shallowmodel: train time: 45.224s
12/28/2017 05:59:46 [INFO] exp_shallowmodel: test time:  0.038s
12/28/2017 05:59:46 [INFO] exp_shallowmodel: accuracy:   0.856
12/28/2017 05:59:46 [INFO] exp_shallowmodel: f1_score:   0.542
12/28/2017 05:59:46 [INFO] exp_shallowmodel: classification report:
12/28/2017 05:59:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.54      0.55        59
          C       1.00      0.08      0.15        12
          F       0.93      0.98      0.95       396
          R       0.55      0.47      0.51        55

avg / total       0.85      0.86      0.84       522

12/28/2017 05:59:46 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 05:59:46 [INFO] exp_shallowmodel: 
[[ 32   0  11  16]
 [  4   1   6   1]
 [  4   0 388   4]
 [ 17   0  12  26]]
12/28/2017 05:59:56 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/28/2017 05:59:56 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 05:59:56 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 05:59:56 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 05:59:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 05:59:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 05:59:56 [INFO] exp_shallowmodel: Training: 
12/28/2017 05:59:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 06:01:15 [INFO] exp_shallowmodel: train time: 79.017s
12/28/2017 06:01:15 [INFO] exp_shallowmodel: test time:  0.029s
12/28/2017 06:01:15 [INFO] exp_shallowmodel: accuracy:   0.862
12/28/2017 06:01:15 [INFO] exp_shallowmodel: f1_score:   0.516
12/28/2017 06:01:15 [INFO] exp_shallowmodel: classification report:
12/28/2017 06:01:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.59      0.61      0.60        59
          C       0.00      0.00      0.00        12
          F       0.95      0.98      0.96       396
          R       0.53      0.47      0.50        55

avg / total       0.84      0.86      0.85       522

12/28/2017 06:01:15 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 06:01:15 [INFO] exp_shallowmodel: 
[[ 36   0   6  17]
 [  5   0   3   4]
 [  3   3 388   2]
 [ 17   0  12  26]]
12/28/2017 06:01:24 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/28/2017 06:01:24 [INFO] exp_shallowmodel: #(data) = 4197
12/28/2017 06:01:24 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 06:01:24 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 06:01:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 06:01:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 06:01:24 [INFO] exp_shallowmodel: Training: 
12/28/2017 06:01:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 06:02:49 [INFO] exp_shallowmodel: train time: 84.983s
12/28/2017 06:02:49 [INFO] exp_shallowmodel: test time:  0.047s
12/28/2017 06:02:49 [INFO] exp_shallowmodel: accuracy:   0.872
12/28/2017 06:02:49 [INFO] exp_shallowmodel: f1_score:   0.639
12/28/2017 06:02:49 [INFO] exp_shallowmodel: classification report:
12/28/2017 06:02:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.61      0.61        59
          C       1.00      0.33      0.50        12
          F       0.94      0.99      0.97       396
          R       0.55      0.44      0.48        55

avg / total       0.86      0.87      0.86       522

12/28/2017 06:02:49 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 06:02:49 [INFO] exp_shallowmodel: 
[[ 36   0   7  16]
 [  2   4   5   1]
 [  2   0 391   3]
 [ 20   0  11  24]]
12/28/2017 06:03:01 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/28/2017 06:03:01 [INFO] exp_shallowmodel: #(data) = 4176
12/28/2017 06:03:01 [INFO] exp_shallowmodel: #(feature) = 30094
12/28/2017 06:03:01 [INFO] exp_shallowmodel: ================================================================================
12/28/2017 06:03:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/28/2017 06:03:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/28/2017 06:03:01 [INFO] exp_shallowmodel: Training: 
12/28/2017 06:03:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/28/2017 06:03:53 [INFO] exp_shallowmodel: train time: 52.138s
12/28/2017 06:03:53 [INFO] exp_shallowmodel: test time:  0.021s
12/28/2017 06:03:53 [INFO] exp_shallowmodel: accuracy:   0.862
12/28/2017 06:03:53 [INFO] exp_shallowmodel: f1_score:   0.555
12/28/2017 06:03:53 [INFO] exp_shallowmodel: classification report:
12/28/2017 06:03:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.61      0.69      0.65        64
          C       1.00      0.07      0.13        14
          F       0.93      0.99      0.96       402
          R       0.61      0.40      0.48        63

avg / total       0.86      0.86      0.84       543

12/28/2017 06:03:53 [INFO] exp_shallowmodel: confusion matrix:
12/28/2017 06:03:53 [INFO] exp_shallowmodel: 
[[ 44   0  11   9]
 [  4   1   4   5]
 [  2   0 398   2]
 [ 22   0  16  25]]
