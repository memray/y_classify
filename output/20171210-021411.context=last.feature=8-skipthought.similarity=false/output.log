12/10/2017 02:14:11 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:11 [INFO] configuration: selected_context_id  :   2
12/10/2017 02:14:11 [INFO] configuration: selected_feature_set_id  :   8
12/10/2017 02:14:11 [INFO] configuration: similarity_feature  :   False
12/10/2017 02:14:11 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:11 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:11 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:11 [INFO] configuration: timemark  :   20171210-021411
12/10/2017 02:14:11 [INFO] configuration: context_set  :   last
12/10/2017 02:14:11 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:11 [INFO] configuration: utterance_range  :   ['current_user_utterance', 'last_system_utterance', 'current_user_utterance']
12/10/2017 02:14:11 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:11 [INFO] configuration: feature_set  :   8-skipthought
12/10/2017 02:14:11 [INFO] configuration: feature_set_number  :   ['11']
12/10/2017 02:14:11 [INFO] configuration: experiment_name  :   20171210-021411.context=last.feature=8-skipthought.similarity=false
12/10/2017 02:14:11 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021411.context=last.feature=8-skipthought.similarity=false
12/10/2017 02:14:11 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021411.context=last.feature=8-skipthought.similarity=false/output.log
12/10/2017 02:14:11 [INFO] configuration: valid_type  :   {'C', 'F', 'R', 'A'}
12/10/2017 02:14:11 [INFO] configuration: data_name  :   
12/10/2017 02:14:11 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:11 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:11 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:11 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:11 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:11 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:11 [INFO] configuration: #division  :   5
12/10/2017 02:14:11 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:11 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:11 [INFO] configuration: action_words  :   {'moderate', 'video', 'delete', 'music', 'reminders', 'temperatur', 'phone', 'remove', 'discard', 'start', 'share', 'room', 'shuffle', 'north', 'telephon', 'ani', 'items', 'tell', 'stop', 'address', 'part', 'expens', 'findcar', 'remov', 'else', 'snooze', 'price', 'centr', 'member', 'expensive', 'temperature', 'song', 'next', 'light', 'south', 'els', 'list', 'food', 'turn', 'time', 'matter', 'item', 'moder', 'show', 'shuffl', 'skip', 'cheap', 'volum', 'findcare', 'watch', 'help', 'cast', 'reminds', 'clear', 'centre', 'volume', 'remind', 'reminder', 'play', 'timer', 'post', 'weather', 'telephone', 'any', 'number', 'delet', 'alarm', 'add', 'area', 'snooz'}
12/10/2017 02:14:11 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:11 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:11 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:11 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:11 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:11 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:11 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:11 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:11 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:11 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:11 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:11 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:11 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:11 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:11 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:11 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:11 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:11 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:11 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 3, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:11 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:14 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:14 [INFO] task_runner: context=last, feature=8-skipthought
12/10/2017 02:14:14 [INFO] task_runner: retained feature numbers=[11.1]
12/10/2017 02:14:14 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:14 [INFO] task_runner: #(feature)=7200
12/10/2017 02:14:14 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:15 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:15 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:14:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:55 [INFO] exp_shallowmodel: train time: 159.877s
12/10/2017 02:16:55 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:16:55 [INFO] exp_shallowmodel: accuracy:   0.585
12/10/2017 02:16:55 [INFO] exp_shallowmodel: f1_score:   0.439
12/10/2017 02:16:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.07      0.09        14
          C       0.58      0.58      0.58       164
          F       0.68      0.71      0.70       268
          R       0.40      0.38      0.39       125

avg / total       0.58      0.58      0.58       571

12/10/2017 02:16:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:55 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  2  95  40  27]
 [  4  34 190  40]
 [  2  32  43  48]]
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:16:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:56 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:45 [INFO] exp_shallowmodel: train time: 168.587s
12/10/2017 02:19:45 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:19:45 [INFO] exp_shallowmodel: accuracy:   0.557
12/10/2017 02:19:45 [INFO] exp_shallowmodel: f1_score:   0.421
12/10/2017 02:19:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.07      0.07        14
          C       0.53      0.54      0.54       164
          F       0.67      0.66      0.66       268
          R       0.41      0.41      0.41       125

avg / total       0.56      0.56      0.56       571

12/10/2017 02:19:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:45 [INFO] exp_shallowmodel: 
[[  1   2   6   5]
 [  5  89  45  25]
 [  5  42 177  44]
 [  2  34  38  51]]
12/10/2017 02:19:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:19:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:19:46 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:19:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:24 [INFO] exp_shallowmodel: train time: 158.386s
12/10/2017 02:22:24 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:22:24 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 02:22:24 [INFO] exp_shallowmodel: f1_score:   0.445
12/10/2017 02:22:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.14      0.14        14
          C       0.55      0.57      0.56       164
          F       0.71      0.72      0.72       268
          R       0.37      0.35      0.36       125

avg / total       0.58      0.58      0.58       571

12/10/2017 02:22:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:24 [INFO] exp_shallowmodel: 
[[  2   3   2   7]
 [  4  93  31  36]
 [  4  40 193  31]
 [  4  32  45  44]]
12/10/2017 02:22:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:22:26 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:22:26 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:22:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:05 [INFO] exp_shallowmodel: train time: 159.703s
12/10/2017 02:25:05 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 02:25:05 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 02:25:05 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 02:25:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.62      0.59       164
          F       0.70      0.69      0.69       268
          R       0.45      0.42      0.43       125

avg / total       0.59      0.59      0.59       571

12/10/2017 02:25:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:05 [INFO] exp_shallowmodel: 
[[  0   1   6   7]
 [  2 101  35  26]
 [  3  50 184  31]
 [  5  29  39  52]]
12/10/2017 02:25:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:25:07 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:25:07 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:25:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:27:43 [INFO] exp_shallowmodel: train time: 156.030s
12/10/2017 02:27:43 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:27:43 [INFO] exp_shallowmodel: accuracy:   0.555
12/10/2017 02:27:43 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 02:27:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:27:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.62      0.59       164
          F       0.66      0.63      0.65       268
          R       0.38      0.38      0.38       125

avg / total       0.55      0.56      0.55       571

12/10/2017 02:27:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:27:43 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  3 101  33  27]
 [  4  50 169  45]
 [  5  27  46  47]]
12/10/2017 02:27:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:27:44 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:27:44 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:27:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:27:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:27:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:27:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:27:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:30:30 [INFO] exp_shallowmodel: train time: 166.271s
12/10/2017 02:30:30 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 02:30:30 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 02:30:30 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 02:30:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:30:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.07      0.08        14
          C       0.53      0.48      0.50       164
          F       0.66      0.72      0.68       268
          R       0.40      0.38      0.39       125

avg / total       0.55      0.56      0.55       571

12/10/2017 02:30:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:30:30 [INFO] exp_shallowmodel: 
[[  1   4   7   2]
 [  2  79  51  32]
 [  3  37 192  36]
 [  6  29  43  47]]
12/10/2017 02:30:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:30:31 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:30:31 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:30:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:30:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:30:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:30:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:30:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:10 [INFO] exp_shallowmodel: train time: 158.390s
12/10/2017 02:33:10 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:33:10 [INFO] exp_shallowmodel: accuracy:   0.604
12/10/2017 02:33:10 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 02:33:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.56      0.58       164
          F       0.71      0.74      0.72       268
          R       0.41      0.45      0.43       125

avg / total       0.60      0.60      0.60       571

12/10/2017 02:33:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:10 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  2  92  38  32]
 [  3  26 197  42]
 [  3  29  37  56]]
12/10/2017 02:33:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:33:11 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:33:11 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:33:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:35:56 [INFO] exp_shallowmodel: train time: 165.266s
12/10/2017 02:35:56 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 02:35:56 [INFO] exp_shallowmodel: accuracy:   0.541
12/10/2017 02:35:56 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:35:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:35:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.54      0.52       164
          F       0.68      0.65      0.67       268
          R       0.35      0.37      0.36       125

avg / total       0.54      0.54      0.54       571

12/10/2017 02:35:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:35:56 [INFO] exp_shallowmodel: 
[[  0   5   5   4]
 [  1  88  39  36]
 [  3  43 175  47]
 [  4  37  38  46]]
12/10/2017 02:35:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:35:58 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:35:58 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:35:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:35:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:35:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:35:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:35:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:38:37 [INFO] exp_shallowmodel: train time: 159.767s
12/10/2017 02:38:37 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:38:37 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 02:38:37 [INFO] exp_shallowmodel: f1_score:   0.448
12/10/2017 02:38:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:38:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.07      0.08        14
          C       0.59      0.68      0.63       164
          F       0.67      0.66      0.67       268
          R       0.46      0.38      0.42       125

avg / total       0.59      0.59      0.59       571

12/10/2017 02:38:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:38:37 [INFO] exp_shallowmodel: 
[[  1   2   6   5]
 [  2 111  39  12]
 [  4  46 178  40]
 [  5  29  43  48]]
12/10/2017 02:38:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:38:39 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:38:39 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:38:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:38:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:38:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:38:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:38:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:41:11 [INFO] exp_shallowmodel: train time: 152.841s
12/10/2017 02:41:11 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:41:11 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 02:41:11 [INFO] exp_shallowmodel: f1_score:   0.390
12/10/2017 02:41:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:41:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.52      0.50      0.51       169
          F       0.67      0.71      0.69       271
          R       0.37      0.35      0.36       130

avg / total       0.54      0.55      0.55       586

12/10/2017 02:41:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:41:11 [INFO] exp_shallowmodel: 
[[  0   2   7   7]
 [  3  85  48  33]
 [  5  36 192  38]
 [  3  41  40  46]]
12/10/2017 02:41:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:41:13 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:41:13 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:41:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:41:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:41:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:41:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:41:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:43:47 [INFO] exp_shallowmodel: train time: 154.378s
12/10/2017 02:43:47 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:43:47 [INFO] exp_shallowmodel: accuracy:   0.545
12/10/2017 02:43:47 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 02:43:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:43:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.51      0.51       164
          F       0.68      0.66      0.67       268
          R       0.37      0.40      0.39       125

avg / total       0.55      0.54      0.54       571

12/10/2017 02:43:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:43:47 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  2  84  43  35]
 [  4  41 177  46]
 [  4  37  34  50]]
12/10/2017 02:43:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:43:48 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:43:48 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:43:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:43:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:43:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:43:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:43:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:46:19 [INFO] exp_shallowmodel: train time: 150.494s
12/10/2017 02:46:19 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 02:46:19 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 02:46:19 [INFO] exp_shallowmodel: f1_score:   0.431
12/10/2017 02:46:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:46:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.07      0.08        14
          C       0.53      0.57      0.55       164
          F       0.69      0.67      0.68       268
          R       0.40      0.42      0.41       125

avg / total       0.57      0.57      0.57       571

12/10/2017 02:46:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:46:19 [INFO] exp_shallowmodel: 
[[  1   4   6   3]
 [  0  93  34  37]
 [  6  46 179  37]
 [  3  31  39  52]]
12/10/2017 02:46:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:46:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:46:20 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:46:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:46:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:46:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:46:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:46:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:49:01 [INFO] exp_shallowmodel: train time: 161.052s
12/10/2017 02:49:01 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:49:01 [INFO] exp_shallowmodel: accuracy:   0.545
12/10/2017 02:49:01 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 02:49:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:49:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.14      0.15        14
          C       0.52      0.48      0.50       164
          F       0.65      0.70      0.67       268
          R       0.36      0.34      0.35       125

avg / total       0.54      0.54      0.54       571

12/10/2017 02:49:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:49:01 [INFO] exp_shallowmodel: 
[[  2   4   7   1]
 [  2  78  49  35]
 [  4  36 188  40]
 [  4  32  46  43]]
12/10/2017 02:49:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:49:02 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:49:02 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:49:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:49:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:49:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:49:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:49:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:51:50 [INFO] exp_shallowmodel: train time: 167.963s
12/10/2017 02:51:50 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:51:50 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 02:51:50 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 02:51:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:51:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.55      0.54       164
          F       0.67      0.67      0.67       268
          R       0.43      0.42      0.42       125

avg / total       0.56      0.56      0.56       571

12/10/2017 02:51:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:51:50 [INFO] exp_shallowmodel: 
[[  0   1   5   8]
 [  2  90  44  28]
 [  4  53 179  32]
 [  7  27  39  52]]
12/10/2017 02:51:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:51:52 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:51:52 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:51:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:51:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:51:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:51:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:51:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:54:27 [INFO] exp_shallowmodel: train time: 155.960s
12/10/2017 02:54:27 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:54:27 [INFO] exp_shallowmodel: accuracy:   0.560
12/10/2017 02:54:27 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:54:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:54:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.07      0.07        14
          C       0.54      0.57      0.56       164
          F       0.65      0.66      0.65       268
          R       0.43      0.40      0.41       125

avg / total       0.56      0.56      0.56       571

12/10/2017 02:54:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:54:27 [INFO] exp_shallowmodel: 
[[  1   4   5   4]
 [  3  93  48  20]
 [  5  44 176  43]
 [  4  30  41  50]]
12/10/2017 02:54:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:54:29 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:54:29 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:54:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:54:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:54:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:54:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:54:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:57:10 [INFO] exp_shallowmodel: train time: 161.016s
12/10/2017 02:57:10 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 02:57:10 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:57:10 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 02:57:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:57:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.07      0.07        14
          C       0.57      0.59      0.58       164
          F       0.68      0.68      0.68       268
          R       0.39      0.37      0.38       125

avg / total       0.57      0.57      0.57       571

12/10/2017 02:57:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:57:10 [INFO] exp_shallowmodel: 
[[  1   2   3   8]
 [  2  97  43  22]
 [  7  36 182  43]
 [  5  35  39  46]]
12/10/2017 02:57:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:57:11 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:57:11 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:57:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:57:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:57:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:57:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:57:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:59:55 [INFO] exp_shallowmodel: train time: 163.674s
12/10/2017 02:59:55 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 02:59:55 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 02:59:55 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 02:59:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:59:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.55      0.62      0.58       164
          F       0.69      0.67      0.68       268
          R       0.37      0.34      0.36       125

avg / total       0.56      0.57      0.57       571

12/10/2017 02:59:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:59:55 [INFO] exp_shallowmodel: 
[[  1   1   7   5]
 [  1 102  29  32]
 [  6  46 179  37]
 [  0  36  46  43]]
12/10/2017 02:59:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:59:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:59:56 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 02:59:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:59:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:59:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:59:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:59:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:02:33 [INFO] exp_shallowmodel: train time: 157.194s
12/10/2017 03:02:33 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 03:02:33 [INFO] exp_shallowmodel: accuracy:   0.604
12/10/2017 03:02:33 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 03:02:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:02:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.63      0.63       164
          F       0.68      0.72      0.70       268
          R       0.42      0.38      0.40       125

avg / total       0.59      0.60      0.60       571

12/10/2017 03:02:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:02:33 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  3 104  30  27]
 [  2  36 193  37]
 [  0  25  52  48]]
12/10/2017 03:02:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 03:02:34 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:02:34 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:02:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:02:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:02:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:02:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:02:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:05:08 [INFO] exp_shallowmodel: train time: 153.586s
12/10/2017 03:05:08 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:05:08 [INFO] exp_shallowmodel: accuracy:   0.567
12/10/2017 03:05:08 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 03:05:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:05:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.07      0.08        14
          C       0.54      0.64      0.59       164
          F       0.69      0.66      0.67       268
          R       0.37      0.33      0.35       125

avg / total       0.56      0.57      0.56       571

12/10/2017 03:05:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:05:08 [INFO] exp_shallowmodel: 
[[  1   2   6   5]
 [  1 105  34  24]
 [  5  45 177  41]
 [  3  41  40  41]]
12/10/2017 03:05:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 03:05:09 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:05:09 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:05:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:05:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:05:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:05:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:05:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:07:53 [INFO] exp_shallowmodel: train time: 164.036s
12/10/2017 03:07:53 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:07:53 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 03:07:53 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 03:07:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:07:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.56      0.60      0.58       169
          F       0.65      0.66      0.65       271
          R       0.40      0.35      0.37       130

avg / total       0.55      0.56      0.55       586

12/10/2017 03:07:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:07:53 [INFO] exp_shallowmodel: 
[[  0   3   5   8]
 [  3 102  43  21]
 [  7  45 178  41]
 [  3  32  49  46]]
12/10/2017 03:07:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 03:07:54 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:07:54 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:07:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:07:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:07:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:07:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:07:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:10:38 [INFO] exp_shallowmodel: train time: 163.023s
12/10/2017 03:10:38 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:10:38 [INFO] exp_shallowmodel: accuracy:   0.550
12/10/2017 03:10:38 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 03:10:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:10:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.57      0.55       164
          F       0.65      0.67      0.66       268
          R       0.38      0.32      0.35       125

avg / total       0.54      0.55      0.55       571

12/10/2017 03:10:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:10:38 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  4  94  42  24]
 [  4  47 180  37]
 [  7  31  47  40]]
12/10/2017 03:10:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 03:10:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:10:39 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:10:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:10:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:10:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:10:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:10:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:13:12 [INFO] exp_shallowmodel: train time: 152.858s
12/10/2017 03:13:12 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:13:12 [INFO] exp_shallowmodel: accuracy:   0.538
12/10/2017 03:13:12 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 03:13:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:13:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.07      0.08        14
          C       0.51      0.58      0.54       164
          F       0.64      0.64      0.64       268
          R       0.37      0.32      0.34       125

avg / total       0.53      0.54      0.53       571

12/10/2017 03:13:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:13:12 [INFO] exp_shallowmodel: 
[[  1   4   7   2]
 [  1  95  48  20]
 [  7  45 171  45]
 [  2  43  40  40]]
12/10/2017 03:13:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 03:13:13 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:13:13 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:13:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:13:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:13:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:13:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:13:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:15:57 [INFO] exp_shallowmodel: train time: 164.147s
12/10/2017 03:15:57 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:15:57 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 03:15:57 [INFO] exp_shallowmodel: f1_score:   0.464
12/10/2017 03:15:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:15:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.21      0.21        14
          C       0.56      0.57      0.56       164
          F       0.67      0.68      0.67       268
          R       0.42      0.40      0.41       125

avg / total       0.57      0.57      0.57       571

12/10/2017 03:15:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:15:57 [INFO] exp_shallowmodel: 
[[  3   2   5   4]
 [  3  94  40  27]
 [  5  45 181  37]
 [  4  28  43  50]]
12/10/2017 03:15:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 03:15:58 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:15:58 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:15:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:15:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:15:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:15:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:15:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:18:34 [INFO] exp_shallowmodel: train time: 155.776s
12/10/2017 03:18:34 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 03:18:34 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 03:18:34 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 03:18:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:18:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.59      0.58       164
          F       0.67      0.69      0.68       268
          R       0.39      0.37      0.38       125

avg / total       0.57      0.57      0.57       571

12/10/2017 03:18:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:18:34 [INFO] exp_shallowmodel: 
[[  0   1   8   5]
 [  2  96  35  31]
 [  4  41 186  37]
 [  4  28  47  46]]
12/10/2017 03:18:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 03:18:35 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:18:35 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:18:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:18:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:18:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:18:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:18:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:21:16 [INFO] exp_shallowmodel: train time: 161.156s
12/10/2017 03:21:16 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:21:16 [INFO] exp_shallowmodel: accuracy:   0.560
12/10/2017 03:21:16 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 03:21:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:21:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.62      0.57       164
          F       0.70      0.66      0.68       268
          R       0.35      0.33      0.34       125

avg / total       0.55      0.56      0.56       571

12/10/2017 03:21:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:21:16 [INFO] exp_shallowmodel: 
[[  0   5   5   4]
 [  1 101  31  31]
 [  2  48 178  40]
 [  4  38  42  41]]
12/10/2017 03:21:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 03:21:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:21:18 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:21:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:21:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:21:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:21:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:21:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:23:54 [INFO] exp_shallowmodel: train time: 156.532s
12/10/2017 03:23:54 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 03:23:54 [INFO] exp_shallowmodel: accuracy:   0.545
12/10/2017 03:23:54 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 03:23:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:23:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.54      0.54       164
          F       0.67      0.65      0.66       268
          R       0.36      0.38      0.37       125

avg / total       0.55      0.54      0.55       571

12/10/2017 03:23:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:23:54 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  2  89  38  35]
 [  7  40 174  47]
 [  2  35  40  48]]
12/10/2017 03:23:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 03:23:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:23:56 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:23:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:23:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:23:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:23:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:23:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:26:37 [INFO] exp_shallowmodel: train time: 161.452s
12/10/2017 03:26:37 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:26:37 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 03:26:37 [INFO] exp_shallowmodel: f1_score:   0.430
12/10/2017 03:26:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:26:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.57      0.52      0.54       164
          F       0.66      0.72      0.69       268
          R       0.39      0.38      0.39       125

avg / total       0.56      0.57      0.57       571

12/10/2017 03:26:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:26:37 [INFO] exp_shallowmodel: 
[[  1   3   8   2]
 [  1  85  48  30]
 [  3  30 193  42]
 [  1  32  44  48]]
12/10/2017 03:26:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 03:26:38 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:26:38 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:26:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:26:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:26:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:26:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:26:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:29:15 [INFO] exp_shallowmodel: train time: 156.541s
12/10/2017 03:29:15 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 03:29:15 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 03:29:15 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 03:29:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:29:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.57      0.56       164
          F       0.72      0.69      0.70       268
          R       0.40      0.43      0.42       125

avg / total       0.59      0.58      0.58       571

12/10/2017 03:29:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:29:15 [INFO] exp_shallowmodel: 
[[  0   3   3   8]
 [  0  94  34  36]
 [  6  41 184  37]
 [  5  32  34  54]]
12/10/2017 03:29:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 03:29:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:29:16 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:29:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:29:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:29:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:29:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:29:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:31:49 [INFO] exp_shallowmodel: train time: 153.389s
12/10/2017 03:31:49 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 03:31:49 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 03:31:49 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 03:31:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:31:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.54      0.53       164
          F       0.69      0.73      0.71       268
          R       0.43      0.39      0.41       125

avg / total       0.57      0.58      0.58       571

12/10/2017 03:31:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:31:49 [INFO] exp_shallowmodel: 
[[  0   2   6   6]
 [  4  88  44  28]
 [  3  40 195  30]
 [  3  35  38  49]]
12/10/2017 03:31:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 03:31:51 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:31:51 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:31:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:31:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:31:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:31:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:31:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:34:29 [INFO] exp_shallowmodel: train time: 158.277s
12/10/2017 03:34:29 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:34:29 [INFO] exp_shallowmodel: accuracy:   0.565
12/10/2017 03:34:29 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 03:34:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:34:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.06      0.08        16
          C       0.57      0.61      0.59       169
          F       0.64      0.66      0.65       271
          R       0.42      0.38      0.40       130

avg / total       0.56      0.56      0.56       586

12/10/2017 03:34:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:34:29 [INFO] exp_shallowmodel: 
[[  1   3   9   3]
 [  2 103  40  24]
 [  5  46 178  42]
 [  2  30  49  49]]
12/10/2017 03:34:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 03:34:30 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:34:30 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:34:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:34:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:34:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:34:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:34:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:37:12 [INFO] exp_shallowmodel: train time: 161.693s
12/10/2017 03:37:12 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:37:12 [INFO] exp_shallowmodel: accuracy:   0.529
12/10/2017 03:37:12 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 03:37:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:37:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.07      0.06        14
          C       0.51      0.53      0.52       164
          F       0.66      0.67      0.67       268
          R       0.31      0.27      0.29       125

avg / total       0.53      0.53      0.53       571

12/10/2017 03:37:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:37:12 [INFO] exp_shallowmodel: 
[[  1   2   7   4]
 [  7  87  35  35]
 [  5  46 180  37]
 [  5  37  49  34]]
12/10/2017 03:37:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 03:37:13 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:37:13 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:37:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:37:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:37:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:37:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:37:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:39:56 [INFO] exp_shallowmodel: train time: 162.335s
12/10/2017 03:39:56 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:39:56 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 03:39:56 [INFO] exp_shallowmodel: f1_score:   0.442
12/10/2017 03:39:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:39:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.07      0.07        14
          C       0.60      0.63      0.62       164
          F       0.68      0.68      0.68       268
          R       0.41      0.39      0.40       125

avg / total       0.59      0.59      0.59       571

12/10/2017 03:39:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:39:56 [INFO] exp_shallowmodel: 
[[  1   0   8   5]
 [  4 104  31  25]
 [  6  41 181  40]
 [  4  27  45  49]]
12/10/2017 03:39:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 03:39:57 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:39:57 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:39:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:39:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:39:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:39:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:39:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:42:34 [INFO] exp_shallowmodel: train time: 157.627s
12/10/2017 03:42:34 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:42:34 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 03:42:34 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 03:42:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:42:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.07      0.08        14
          C       0.52      0.49      0.51       164
          F       0.70      0.70      0.70       268
          R       0.38      0.42      0.40       125

avg / total       0.56      0.56      0.56       571

12/10/2017 03:42:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:42:34 [INFO] exp_shallowmodel: 
[[  1   2   5   6]
 [  3  81  37  43]
 [  2  43 188  35]
 [  5  29  39  52]]
12/10/2017 03:42:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 03:42:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:42:36 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:42:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:42:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:42:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:42:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:42:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:45:20 [INFO] exp_shallowmodel: train time: 164.546s
12/10/2017 03:45:20 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:45:20 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 03:45:20 [INFO] exp_shallowmodel: f1_score:   0.464
12/10/2017 03:45:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:45:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.14      0.17        14
          C       0.58      0.57      0.57       164
          F       0.65      0.71      0.68       268
          R       0.47      0.41      0.44       125

avg / total       0.58      0.59      0.58       571

12/10/2017 03:45:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:45:20 [INFO] exp_shallowmodel: 
[[  2   4   7   1]
 [  0  94  51  19]
 [  4  38 189  37]
 [  4  27  43  51]]
12/10/2017 03:45:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 03:45:21 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:45:21 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:45:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:45:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:45:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:45:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:45:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:48:09 [INFO] exp_shallowmodel: train time: 167.557s
12/10/2017 03:48:09 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:48:09 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 03:48:09 [INFO] exp_shallowmodel: f1_score:   0.431
12/10/2017 03:48:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:48:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.53      0.55      0.54       164
          F       0.69      0.72      0.70       268
          R       0.41      0.38      0.39       125

avg / total       0.57      0.58      0.57       571

12/10/2017 03:48:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:48:09 [INFO] exp_shallowmodel: 
[[  1   6   5   2]
 [  3  90  45  26]
 [  1  36 192  39]
 [  3  38  37  47]]
12/10/2017 03:48:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 03:48:10 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:48:10 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:48:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:48:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:48:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:48:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:48:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:50:47 [INFO] exp_shallowmodel: train time: 157.137s
12/10/2017 03:50:47 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 03:50:47 [INFO] exp_shallowmodel: accuracy:   0.585
12/10/2017 03:50:47 [INFO] exp_shallowmodel: f1_score:   0.455
12/10/2017 03:50:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:50:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.14      0.17        14
          C       0.59      0.59      0.59       164
          F       0.69      0.71      0.70       268
          R       0.37      0.36      0.36       125

avg / total       0.58      0.58      0.58       571

12/10/2017 03:50:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:50:47 [INFO] exp_shallowmodel: 
[[  2   2   7   3]
 [  1  96  37  30]
 [  4  29 191  44]
 [  3  36  41  45]]
12/10/2017 03:50:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 03:50:49 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:50:49 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:50:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:50:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:50:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:50:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:50:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:53:28 [INFO] exp_shallowmodel: train time: 159.286s
12/10/2017 03:53:28 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:53:28 [INFO] exp_shallowmodel: accuracy:   0.545
12/10/2017 03:53:28 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 03:53:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:53:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.59      0.56       164
          F       0.65      0.66      0.66       268
          R       0.35      0.30      0.32       125

avg / total       0.54      0.54      0.54       571

12/10/2017 03:53:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:53:28 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  4  97  38  25]
 [  5  48 177  38]
 [  4  32  52  37]]
12/10/2017 03:53:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 03:53:29 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:53:29 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:53:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:53:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:53:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:53:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:53:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:56:06 [INFO] exp_shallowmodel: train time: 156.678s
12/10/2017 03:56:06 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:56:06 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 03:56:06 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 03:56:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:56:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.53      0.53       164
          F       0.64      0.66      0.65       268
          R       0.39      0.38      0.39       125

avg / total       0.54      0.55      0.54       571

12/10/2017 03:56:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:56:06 [INFO] exp_shallowmodel: 
[[  0   1  11   2]
 [  2  87  48  27]
 [  2  44 177  45]
 [  4  32  41  48]]
12/10/2017 03:56:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 03:56:07 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:56:07 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:56:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:56:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:56:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:56:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:56:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:58:36 [INFO] exp_shallowmodel: train time: 149.229s
12/10/2017 03:58:36 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 03:58:36 [INFO] exp_shallowmodel: accuracy:   0.520
12/10/2017 03:58:36 [INFO] exp_shallowmodel: f1_score:   0.371
12/10/2017 03:58:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:58:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.57      0.53       164
          F       0.63      0.62      0.62       268
          R       0.34      0.31      0.33       125

avg / total       0.52      0.52      0.52       571

12/10/2017 03:58:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:58:36 [INFO] exp_shallowmodel: 
[[  0   1   8   5]
 [  2  93  39  30]
 [  9  54 165  40]
 [  2  36  48  39]]
12/10/2017 03:58:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 03:58:38 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:58:38 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 03:58:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:58:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:58:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:58:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:58:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:01:11 [INFO] exp_shallowmodel: train time: 153.278s
12/10/2017 04:01:11 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:01:11 [INFO] exp_shallowmodel: accuracy:   0.584
12/10/2017 04:01:11 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 04:01:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:01:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.58      0.57      0.58       169
          F       0.67      0.72      0.70       271
          R       0.42      0.38      0.40       130

avg / total       0.57      0.58      0.58       586

12/10/2017 04:01:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:01:11 [INFO] exp_shallowmodel: 
[[  0   1   8   7]
 [  0  97  43  29]
 [  6  37 195  33]
 [  5  32  43  50]]
12/10/2017 04:01:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 04:01:12 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:01:12 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:01:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:01:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:01:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:01:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:01:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:03:43 [INFO] exp_shallowmodel: train time: 151.156s
12/10/2017 04:03:43 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:03:43 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 04:03:43 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 04:03:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:03:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.07      0.09        14
          C       0.53      0.57      0.55       164
          F       0.68      0.66      0.67       268
          R       0.40      0.40      0.40       125

avg / total       0.56      0.56      0.56       571

12/10/2017 04:03:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:03:43 [INFO] exp_shallowmodel: 
[[  1   3   7   3]
 [  5  94  36  29]
 [  2  47 176  43]
 [  1  33  41  50]]
12/10/2017 04:03:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 04:03:45 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:03:45 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:03:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:03:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:03:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:03:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:03:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:06:17 [INFO] exp_shallowmodel: train time: 152.109s
12/10/2017 04:06:17 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:06:17 [INFO] exp_shallowmodel: accuracy:   0.545
12/10/2017 04:06:17 [INFO] exp_shallowmodel: f1_score:   0.390
12/10/2017 04:06:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:06:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.56      0.54       164
          F       0.65      0.65      0.65       268
          R       0.38      0.36      0.37       125

avg / total       0.54      0.54      0.54       571

12/10/2017 04:06:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:06:17 [INFO] exp_shallowmodel: 
[[  0   5   7   2]
 [  1  92  47  24]
 [  6  42 174  46]
 [  1  40  39  45]]
12/10/2017 04:06:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 04:06:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:06:18 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:06:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:06:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:06:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:06:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:06:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:08:55 [INFO] exp_shallowmodel: train time: 156.819s
12/10/2017 04:08:55 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:08:55 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 04:08:55 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 04:08:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:08:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.51      0.54       164
          F       0.68      0.71      0.69       268
          R       0.37      0.39      0.38       125

avg / total       0.57      0.56      0.56       571

12/10/2017 04:08:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:08:55 [INFO] exp_shallowmodel: 
[[  0   1   8   5]
 [  2  83  45  34]
 [  8  26 190  44]
 [  5  35  36  49]]
12/10/2017 04:08:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 04:08:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:08:56 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:08:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:08:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:08:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:08:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:08:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:11:36 [INFO] exp_shallowmodel: train time: 159.923s
12/10/2017 04:11:36 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:11:36 [INFO] exp_shallowmodel: accuracy:   0.553
12/10/2017 04:11:36 [INFO] exp_shallowmodel: f1_score:   0.390
12/10/2017 04:11:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:11:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.56      0.55       164
          F       0.65      0.69      0.67       268
          R       0.39      0.31      0.35       125

avg / total       0.54      0.55      0.55       571

12/10/2017 04:11:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:11:36 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  3  92  47  22]
 [  3  43 185  37]
 [  6  35  45  39]]
12/10/2017 04:11:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 04:11:37 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:11:37 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:11:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:11:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:11:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:11:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:11:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:14:16 [INFO] exp_shallowmodel: train time: 159.224s
12/10/2017 04:14:16 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:14:16 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 04:14:16 [INFO] exp_shallowmodel: f1_score:   0.452
12/10/2017 04:14:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:14:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.59      0.59      0.59       164
          F       0.67      0.71      0.69       268
          R       0.44      0.42      0.43       125

avg / total       0.58      0.59      0.59       571

12/10/2017 04:14:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:14:16 [INFO] exp_shallowmodel: 
[[  1   3   6   4]
 [  0  96  44  24]
 [  3  37 189  39]
 [  2  28  42  53]]
12/10/2017 04:14:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 04:14:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:14:18 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:14:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:14:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:14:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:14:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:14:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:16:47 [INFO] exp_shallowmodel: train time: 149.431s
12/10/2017 04:16:47 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:16:47 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 04:16:47 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 04:16:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:16:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.57      0.55       164
          F       0.69      0.69      0.69       268
          R       0.42      0.42      0.42       125

avg / total       0.57      0.58      0.57       571

12/10/2017 04:16:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:16:47 [INFO] exp_shallowmodel: 
[[  0   6   3   5]
 [  1  93  38  32]
 [  3  45 184  36]
 [  3  30  40  52]]
12/10/2017 04:16:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 04:16:48 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:16:48 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:16:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:16:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:16:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:16:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:16:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:19:21 [INFO] exp_shallowmodel: train time: 153.204s
12/10/2017 04:19:21 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:19:21 [INFO] exp_shallowmodel: accuracy:   0.552
12/10/2017 04:19:21 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 04:19:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:19:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.49      0.54      0.51       164
          F       0.67      0.69      0.68       268
          R       0.38      0.34      0.35       125

avg / total       0.54      0.55      0.55       571

12/10/2017 04:19:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:19:22 [INFO] exp_shallowmodel: 
[[  1   2   6   5]
 [  3  88  43  30]
 [  2  47 184  35]
 [  2  41  40  42]]
12/10/2017 04:19:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 04:19:23 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:19:23 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:19:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:19:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:19:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:19:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:19:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:22:02 [INFO] exp_shallowmodel: train time: 159.397s
12/10/2017 04:22:02 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:22:02 [INFO] exp_shallowmodel: accuracy:   0.560
12/10/2017 04:22:02 [INFO] exp_shallowmodel: f1_score:   0.441
12/10/2017 04:22:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:22:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.14      0.17        14
          C       0.52      0.49      0.51       164
          F       0.64      0.69      0.67       268
          R       0.44      0.41      0.42       125

avg / total       0.55      0.56      0.56       571

12/10/2017 04:22:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:22:02 [INFO] exp_shallowmodel: 
[[  2   3   6   3]
 [  3  81  51  29]
 [  2  46 186  34]
 [  3  25  46  51]]
12/10/2017 04:22:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 04:22:03 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:22:03 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:22:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:22:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:22:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:22:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:22:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:24:48 [INFO] exp_shallowmodel: train time: 164.248s
12/10/2017 04:24:48 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:24:48 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 04:24:48 [INFO] exp_shallowmodel: f1_score:   0.469
12/10/2017 04:24:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:24:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.07      0.08        14
          C       0.64      0.64      0.64       164
          F       0.70      0.72      0.71       268
          R       0.46      0.43      0.44       125

avg / total       0.61      0.62      0.62       571

12/10/2017 04:24:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:24:48 [INFO] exp_shallowmodel: 
[[  1   3   3   7]
 [  1 105  38  20]
 [  6  31 194  37]
 [  3  25  43  54]]
12/10/2017 04:24:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 04:24:49 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 04:24:49 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:24:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:24:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:24:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:24:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:24:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:27:24 [INFO] exp_shallowmodel: train time: 154.947s
12/10/2017 04:27:24 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:27:24 [INFO] exp_shallowmodel: accuracy:   0.565
12/10/2017 04:27:24 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 04:27:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:27:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.56      0.58      0.57       169
          F       0.67      0.65      0.66       271
          R       0.42      0.44      0.43       130

avg / total       0.57      0.56      0.57       586

12/10/2017 04:27:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:27:24 [INFO] exp_shallowmodel: 
[[  0   4   6   6]
 [  5  98  39  27]
 [  5  45 176  45]
 [  4  28  41  57]]
12/10/2017 04:27:27 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 04:27:27 [INFO] task_runner: context=last, feature=8-skipthought
12/10/2017 04:27:27 [INFO] task_runner: retained feature numbers=[11.1]
12/10/2017 04:27:27 [INFO] task_runner: #(data)=5934
12/10/2017 04:27:27 [INFO] task_runner: #(feature)=7200
12/10/2017 04:27:27 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 04:27:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 04:27:29 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:27:29 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:27:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:27:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:27:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:27:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:27:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:30:19 [INFO] exp_shallowmodel: train time: 170.412s
12/10/2017 04:30:19 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:30:19 [INFO] exp_shallowmodel: accuracy:   0.530
12/10/2017 04:30:19 [INFO] exp_shallowmodel: f1_score:   0.378
12/10/2017 04:30:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:30:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.48      0.50      0.49       169
          F       0.67      0.70      0.68       281
          R       0.29      0.26      0.28       122

avg / total       0.52      0.53      0.52       592

12/10/2017 04:30:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:30:19 [INFO] exp_shallowmodel: 
[[  1   7   6   6]
 [  4  85  45  35]
 [  5  44 196  36]
 [  5  40  45  32]]
12/10/2017 04:30:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 04:30:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:30:20 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:30:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:30:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:30:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:30:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:30:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:33:19 [INFO] exp_shallowmodel: train time: 178.483s
12/10/2017 04:33:19 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:33:19 [INFO] exp_shallowmodel: accuracy:   0.535
12/10/2017 04:33:19 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 04:33:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:33:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.05        20
          C       0.49      0.53      0.51       169
          F       0.70      0.69      0.70       281
          R       0.28      0.26      0.27       122

avg / total       0.53      0.54      0.53       592

12/10/2017 04:33:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:33:19 [INFO] exp_shallowmodel: 
[[  1   3   9   7]
 [ 10  89  40  30]
 [  1  41 195  44]
 [  6  49  35  32]]
12/10/2017 04:33:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 04:33:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:33:20 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:33:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:33:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:33:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:33:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:33:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:36:27 [INFO] exp_shallowmodel: train time: 187.117s
12/10/2017 04:36:27 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:36:27 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 04:36:27 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 04:36:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:36:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.15      0.18        20
          C       0.49      0.52      0.51       169
          F       0.73      0.69      0.71       281
          R       0.32      0.35      0.34       122

avg / total       0.56      0.55      0.56       592

12/10/2017 04:36:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:36:27 [INFO] exp_shallowmodel: 
[[  3   4   6   7]
 [  3  88  35  43]
 [  3  44 194  40]
 [  5  42  32  43]]
12/10/2017 04:36:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 04:36:29 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:36:29 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:36:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:36:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:36:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:36:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:36:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:39:26 [INFO] exp_shallowmodel: train time: 177.019s
12/10/2017 04:39:26 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:39:26 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 04:39:26 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 04:39:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:39:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.10      0.14        20
          C       0.54      0.60      0.57       169
          F       0.68      0.67      0.68       281
          R       0.36      0.34      0.35       122

avg / total       0.56      0.56      0.56       592

12/10/2017 04:39:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:39:26 [INFO] exp_shallowmodel: 
[[  2   3  10   5]
 [  1 102  32  34]
 [  5  52 189  35]
 [  1  33  47  41]]
12/10/2017 04:39:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 04:39:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:39:27 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:39:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:39:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:39:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:39:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:39:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:42:18 [INFO] exp_shallowmodel: train time: 171.002s
12/10/2017 04:42:18 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:42:18 [INFO] exp_shallowmodel: accuracy:   0.537
12/10/2017 04:42:18 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 04:42:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:42:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.05        20
          C       0.52      0.57      0.54       169
          F       0.69      0.66      0.67       281
          R       0.30      0.30      0.30       122

avg / total       0.54      0.54      0.54       592

12/10/2017 04:42:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:42:18 [INFO] exp_shallowmodel: 
[[  1   6   6   7]
 [  4  96  37  32]
 [  7  42 185  47]
 [  5  41  40  36]]
12/10/2017 04:42:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 04:42:19 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:42:19 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:42:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:42:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:42:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:42:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:42:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:45:07 [INFO] exp_shallowmodel: train time: 167.594s
12/10/2017 04:45:07 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:45:07 [INFO] exp_shallowmodel: accuracy:   0.520
12/10/2017 04:45:07 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 04:45:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:45:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        20
          C       0.49      0.49      0.49       169
          F       0.64      0.65      0.65       281
          R       0.33      0.34      0.34       122

avg / total       0.52      0.52      0.52       592

12/10/2017 04:45:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:45:07 [INFO] exp_shallowmodel: 
[[  2   3  10   5]
 [  1  82  58  28]
 [  6  42 182  51]
 [  7  40  33  42]]
12/10/2017 04:45:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 04:45:08 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:45:08 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:45:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:45:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:45:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:45:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:45:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:47:55 [INFO] exp_shallowmodel: train time: 166.650s
12/10/2017 04:47:55 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:47:55 [INFO] exp_shallowmodel: accuracy:   0.537
12/10/2017 04:47:55 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 04:47:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:47:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.05      0.05        20
          C       0.48      0.51      0.50       169
          F       0.68      0.68      0.68       281
          R       0.35      0.32      0.33       122

avg / total       0.53      0.54      0.54       592

12/10/2017 04:47:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:47:55 [INFO] exp_shallowmodel: 
[[  1   8   8   3]
 [  5  87  42  35]
 [ 10  45 191  35]
 [  3  41  39  39]]
12/10/2017 04:47:56 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 04:47:56 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:47:56 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:47:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:47:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:47:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:47:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:47:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:50:36 [INFO] exp_shallowmodel: train time: 160.561s
12/10/2017 04:50:36 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:50:36 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 04:50:36 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 04:50:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:50:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.49      0.51      0.50       169
          F       0.67      0.72      0.69       281
          R       0.36      0.33      0.34       122

avg / total       0.54      0.55      0.54       592

12/10/2017 04:50:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:50:36 [INFO] exp_shallowmodel: 
[[  1   5   9   5]
 [  2  86  47  34]
 [  0  47 201  33]
 [  2  39  41  40]]
12/10/2017 04:50:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 04:50:38 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:50:38 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:50:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:50:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:50:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:50:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:50:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:53:20 [INFO] exp_shallowmodel: train time: 161.850s
12/10/2017 04:53:20 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:53:20 [INFO] exp_shallowmodel: accuracy:   0.547
12/10/2017 04:53:20 [INFO] exp_shallowmodel: f1_score:   0.443
12/10/2017 04:53:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:53:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.20      0.22        20
          C       0.52      0.57      0.54       169
          F       0.68      0.65      0.67       281
          R       0.33      0.34      0.34       122

avg / total       0.55      0.55      0.55       592

12/10/2017 04:53:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:53:20 [INFO] exp_shallowmodel: 
[[  4   2   6   8]
 [  0  96  40  33]
 [  7  49 182  43]
 [  5  37  38  42]]
12/10/2017 04:53:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 04:53:21 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:53:21 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:53:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:53:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:53:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:53:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:53:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:56:08 [INFO] exp_shallowmodel: train time: 167.578s
12/10/2017 04:56:08 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:56:08 [INFO] exp_shallowmodel: accuracy:   0.520
12/10/2017 04:56:08 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 04:56:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:56:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.11      0.14        28
          C       0.46      0.51      0.48       172
          F       0.65      0.68      0.67       283
          R       0.30      0.27      0.28       123

avg / total       0.51      0.52      0.51       606

12/10/2017 04:56:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:56:08 [INFO] exp_shallowmodel: 
[[  3   9  10   6]
 [  1  87  50  34]
 [  6  49 192  36]
 [  5  43  42  33]]
12/10/2017 04:56:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 04:56:10 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:56:10 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:56:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:56:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:56:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:56:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:56:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:59:01 [INFO] exp_shallowmodel: train time: 171.585s
12/10/2017 04:59:01 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:59:01 [INFO] exp_shallowmodel: accuracy:   0.537
12/10/2017 04:59:01 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 04:59:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:59:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.47      0.50      0.49       169
          F       0.72      0.68      0.70       281
          R       0.31      0.34      0.33       122

avg / total       0.54      0.54      0.54       592

12/10/2017 04:59:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:59:01 [INFO] exp_shallowmodel: 
[[  1   3   5  11]
 [  4  85  35  45]
 [  4  50 190  37]
 [  6  41  33  42]]
12/10/2017 04:59:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 04:59:03 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:59:03 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 04:59:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:59:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:59:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:59:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:59:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:01:52 [INFO] exp_shallowmodel: train time: 169.402s
12/10/2017 05:01:52 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:01:52 [INFO] exp_shallowmodel: accuracy:   0.510
12/10/2017 05:01:52 [INFO] exp_shallowmodel: f1_score:   0.356
12/10/2017 05:01:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:01:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.47      0.48       169
          F       0.63      0.67      0.65       281
          R       0.32      0.29      0.30       122

avg / total       0.50      0.51      0.51       592

12/10/2017 05:01:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:01:52 [INFO] exp_shallowmodel: 
[[  0   6   7   7]
 [  3  80  59  27]
 [  5  47 187  42]
 [ 10  32  45  35]]
12/10/2017 05:01:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 05:01:53 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:01:53 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:01:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:01:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:01:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:01:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:01:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:04:39 [INFO] exp_shallowmodel: train time: 165.970s
12/10/2017 05:04:39 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:04:39 [INFO] exp_shallowmodel: accuracy:   0.544
12/10/2017 05:04:39 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 05:04:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:04:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.10      0.10        20
          C       0.51      0.49      0.50       169
          F       0.69      0.69      0.69       281
          R       0.34      0.37      0.36       122

avg / total       0.55      0.54      0.54       592

12/10/2017 05:04:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:04:39 [INFO] exp_shallowmodel: 
[[  2   4   7   7]
 [  6  82  43  38]
 [  4  43 193  41]
 [  7  33  37  45]]
12/10/2017 05:04:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 05:04:41 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:04:41 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:04:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:04:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:04:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:04:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:04:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:07:28 [INFO] exp_shallowmodel: train time: 167.743s
12/10/2017 05:07:28 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:07:28 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 05:07:28 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 05:07:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:07:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.05      0.05        20
          C       0.54      0.55      0.55       169
          F       0.71      0.70      0.71       281
          R       0.34      0.34      0.34       122

avg / total       0.57      0.56      0.56       592

12/10/2017 05:07:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:07:28 [INFO] exp_shallowmodel: 
[[  1   2   9   8]
 [  8  93  32  36]
 [  5  39 198  39]
 [  5  37  38  42]]
12/10/2017 05:07:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 05:07:30 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:07:30 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:07:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:07:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:07:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:07:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:07:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:10:15 [INFO] exp_shallowmodel: train time: 165.266s
12/10/2017 05:10:15 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:10:15 [INFO] exp_shallowmodel: accuracy:   0.537
12/10/2017 05:10:15 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 05:10:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:10:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.15      0.16        20
          C       0.49      0.55      0.52       169
          F       0.68      0.64      0.66       281
          R       0.35      0.34      0.35       122

avg / total       0.54      0.54      0.54       592

12/10/2017 05:10:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:10:15 [INFO] exp_shallowmodel: 
[[  3   3  11   3]
 [  3  93  44  29]
 [  4  51 180  46]
 [  7  42  31  42]]
12/10/2017 05:10:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 05:10:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:10:16 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:10:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:10:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:10:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:10:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:10:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:13:08 [INFO] exp_shallowmodel: train time: 172.202s
12/10/2017 05:13:08 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:13:08 [INFO] exp_shallowmodel: accuracy:   0.535
12/10/2017 05:13:08 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 05:13:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:13:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.51      0.50      0.50       169
          F       0.68      0.69      0.69       281
          R       0.29      0.30      0.30       122

avg / total       0.53      0.54      0.53       592

12/10/2017 05:13:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:13:08 [INFO] exp_shallowmodel: 
[[  1   6   6   7]
 [  4  85  37  43]
 [  4  44 194  39]
 [  4  33  48  37]]
12/10/2017 05:13:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 05:13:10 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:13:10 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:13:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:13:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:13:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:13:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:13:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:16:00 [INFO] exp_shallowmodel: train time: 170.861s
12/10/2017 05:16:00 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:16:00 [INFO] exp_shallowmodel: accuracy:   0.534
12/10/2017 05:16:00 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 05:16:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:16:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.10      0.12        20
          C       0.49      0.56      0.52       169
          F       0.68      0.66      0.67       281
          R       0.30      0.27      0.28       122

avg / total       0.53      0.53      0.53       592

12/10/2017 05:16:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:16:00 [INFO] exp_shallowmodel: 
[[  2   4   9   5]
 [  3  95  42  29]
 [  7  44 186  44]
 [  1  52  36  33]]
12/10/2017 05:16:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 05:16:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:16:02 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:16:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:16:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:16:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:16:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:16:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:18:47 [INFO] exp_shallowmodel: train time: 164.865s
12/10/2017 05:18:47 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:18:47 [INFO] exp_shallowmodel: accuracy:   0.557
12/10/2017 05:18:47 [INFO] exp_shallowmodel: f1_score:   0.429
12/10/2017 05:18:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:18:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.15      0.18        20
          C       0.53      0.53      0.53       169
          F       0.70      0.72      0.71       281
          R       0.29      0.30      0.29       122

avg / total       0.55      0.56      0.55       592

12/10/2017 05:18:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:18:47 [INFO] exp_shallowmodel: 
[[  3   4   5   8]
 [  3  89  40  37]
 [  5  32 202  42]
 [  2  42  42  36]]
12/10/2017 05:18:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 05:18:48 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:18:48 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:18:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:18:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:18:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:18:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:18:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:21:35 [INFO] exp_shallowmodel: train time: 167.591s
12/10/2017 05:21:35 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:21:35 [INFO] exp_shallowmodel: accuracy:   0.525
12/10/2017 05:21:35 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 05:21:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:21:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.05        20
          C       0.45      0.46      0.45       169
          F       0.66      0.68      0.67       281
          R       0.37      0.34      0.35       122

avg / total       0.52      0.53      0.52       592

12/10/2017 05:21:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:21:35 [INFO] exp_shallowmodel: 
[[  1   9   6   4]
 [  3  77  54  35]
 [  6  51 192  32]
 [  7  33  41  41]]
12/10/2017 05:21:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 05:21:37 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 05:21:37 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:21:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:21:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:21:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:21:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:21:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:24:27 [INFO] exp_shallowmodel: train time: 170.528s
12/10/2017 05:24:27 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:24:27 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 05:24:27 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 05:24:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:24:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.53      0.65      0.58       172
          F       0.71      0.67      0.69       283
          R       0.37      0.34      0.36       123

avg / total       0.56      0.57      0.56       606

12/10/2017 05:24:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:24:27 [INFO] exp_shallowmodel: 
[[  0  10  14   4]
 [  3 112  27  30]
 [  5  50 191  37]
 [  2  41  38  42]]
12/10/2017 05:24:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 05:24:28 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:24:28 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:24:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:24:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:24:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:24:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:24:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:27:19 [INFO] exp_shallowmodel: train time: 170.697s
12/10/2017 05:27:19 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:27:19 [INFO] exp_shallowmodel: accuracy:   0.541
12/10/2017 05:27:19 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 05:27:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:27:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.20      0.20        20
          C       0.49      0.47      0.48       169
          F       0.69      0.70      0.70       281
          R       0.31      0.31      0.31       122

avg / total       0.54      0.54      0.54       592

12/10/2017 05:27:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:27:19 [INFO] exp_shallowmodel: 
[[  4   3   7   6]
 [  7  80  45  37]
 [  4  38 198  41]
 [  6  42  36  38]]
12/10/2017 05:27:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 05:27:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:27:20 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:27:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:27:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:27:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:27:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:27:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:30:12 [INFO] exp_shallowmodel: train time: 171.591s
12/10/2017 05:30:12 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:30:12 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 05:30:12 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 05:30:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:30:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.06        20
          C       0.49      0.58      0.53       169
          F       0.70      0.69      0.69       281
          R       0.35      0.30      0.32       122

avg / total       0.55      0.55      0.55       592

12/10/2017 05:30:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:30:12 [INFO] exp_shallowmodel: 
[[  1   4  11   4]
 [  3  98  44  24]
 [  6  44 193  38]
 [  6  53  27  36]]
12/10/2017 05:30:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 05:30:13 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:30:13 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:30:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:30:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:30:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:30:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:30:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:33:06 [INFO] exp_shallowmodel: train time: 172.496s
12/10/2017 05:33:06 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:33:06 [INFO] exp_shallowmodel: accuracy:   0.524
12/10/2017 05:33:06 [INFO] exp_shallowmodel: f1_score:   0.366
12/10/2017 05:33:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:33:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.49      0.49       169
          F       0.67      0.68      0.67       281
          R       0.31      0.30      0.30       122

avg / total       0.52      0.52      0.52       592

12/10/2017 05:33:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:33:06 [INFO] exp_shallowmodel: 
[[  0   5   8   7]
 [  3  83  46  37]
 [  4  47 190  40]
 [  7  38  40  37]]
12/10/2017 05:33:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 05:33:07 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:33:07 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:33:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:33:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:33:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:33:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:33:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:36:01 [INFO] exp_shallowmodel: train time: 174.020s
12/10/2017 05:36:01 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:36:01 [INFO] exp_shallowmodel: accuracy:   0.524
12/10/2017 05:36:01 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 05:36:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:36:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.06        20
          C       0.51      0.44      0.47       169
          F       0.66      0.67      0.67       281
          R       0.32      0.39      0.35       122

avg / total       0.53      0.52      0.52       592

12/10/2017 05:36:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:36:01 [INFO] exp_shallowmodel: 
[[  1   3   7   9]
 [  5  74  45  45]
 [  7  40 188  46]
 [  3  28  44  47]]
12/10/2017 05:36:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 05:36:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:36:02 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:36:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:36:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:36:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:36:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:36:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:38:46 [INFO] exp_shallowmodel: train time: 163.797s
12/10/2017 05:38:46 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:38:46 [INFO] exp_shallowmodel: accuracy:   0.514
12/10/2017 05:38:46 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 05:38:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:38:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.10      0.12        20
          C       0.46      0.44      0.45       169
          F       0.66      0.67      0.67       281
          R       0.30      0.32      0.31       122

avg / total       0.51      0.51      0.51       592

12/10/2017 05:38:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:38:46 [INFO] exp_shallowmodel: 
[[  2   4   4  10]
 [  4  74  50  41]
 [  4  46 189  42]
 [  4  37  42  39]]
12/10/2017 05:38:47 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 05:38:47 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:38:47 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:38:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:38:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:38:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:38:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:38:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:41:35 [INFO] exp_shallowmodel: train time: 167.082s
12/10/2017 05:41:35 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:41:35 [INFO] exp_shallowmodel: accuracy:   0.530
12/10/2017 05:41:35 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 05:41:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:41:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.48      0.51      0.50       169
          F       0.68      0.68      0.68       281
          R       0.30      0.30      0.30       122

avg / total       0.52      0.53      0.53       592

12/10/2017 05:41:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:41:35 [INFO] exp_shallowmodel: 
[[  1   6   7   6]
 [  3  87  44  35]
 [  2  47 190  42]
 [  6  42  38  36]]
12/10/2017 05:41:36 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 05:41:36 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:41:36 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:41:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:41:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:41:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:41:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:41:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:44:24 [INFO] exp_shallowmodel: train time: 168.146s
12/10/2017 05:44:24 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:44:24 [INFO] exp_shallowmodel: accuracy:   0.593
12/10/2017 05:44:24 [INFO] exp_shallowmodel: f1_score:   0.460
12/10/2017 05:44:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:44:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.15      0.18        20
          C       0.57      0.54      0.56       169
          F       0.73      0.75      0.74       281
          R       0.35      0.37      0.36       122

avg / total       0.59      0.59      0.59       592

12/10/2017 05:44:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:44:24 [INFO] exp_shallowmodel: 
[[  3   5   6   6]
 [  2  92  34  41]
 [  2  31 211  37]
 [  6  33  38  45]]
12/10/2017 05:44:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 05:44:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:44:25 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:44:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:44:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:44:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:44:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:44:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:47:16 [INFO] exp_shallowmodel: train time: 171.089s
12/10/2017 05:47:16 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:47:16 [INFO] exp_shallowmodel: accuracy:   0.527
12/10/2017 05:47:16 [INFO] exp_shallowmodel: f1_score:   0.378
12/10/2017 05:47:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:47:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.05        20
          C       0.50      0.47      0.49       169
          F       0.65      0.70      0.67       281
          R       0.30      0.29      0.30       122

avg / total       0.52      0.53      0.52       592

12/10/2017 05:47:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:47:16 [INFO] exp_shallowmodel: 
[[  1   5   8   6]
 [  7  80  43  39]
 [  4  46 196  35]
 [  5  29  53  35]]
12/10/2017 05:47:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 05:47:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:47:18 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:47:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:47:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:47:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:47:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:47:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:50:07 [INFO] exp_shallowmodel: train time: 169.833s
12/10/2017 05:50:07 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:50:07 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 05:50:07 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 05:50:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:50:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.47      0.47      0.47       169
          F       0.70      0.73      0.72       281
          R       0.34      0.33      0.33       122

avg / total       0.54      0.55      0.54       592

12/10/2017 05:50:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:50:07 [INFO] exp_shallowmodel: 
[[  0   3   9   8]
 [  3  80  52  34]
 [  2  38 206  35]
 [  4  50  28  40]]
12/10/2017 05:50:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 05:50:09 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 05:50:09 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:50:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:50:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:50:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:50:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:50:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:52:52 [INFO] exp_shallowmodel: train time: 163.776s
12/10/2017 05:52:52 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:52:52 [INFO] exp_shallowmodel: accuracy:   0.563
12/10/2017 05:52:52 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 05:52:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:52:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.04      0.05        28
          C       0.51      0.56      0.54       172
          F       0.70      0.71      0.71       283
          R       0.37      0.33      0.35       123

avg / total       0.55      0.56      0.55       606

12/10/2017 05:52:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:52:52 [INFO] exp_shallowmodel: 
[[  1  10   7  10]
 [  5  97  40  30]
 [  5  45 202  31]
 [  4  37  41  41]]
12/10/2017 05:52:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 05:52:54 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:52:54 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:52:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:52:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:52:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:52:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:52:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:55:43 [INFO] exp_shallowmodel: train time: 169.110s
12/10/2017 05:55:43 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:55:43 [INFO] exp_shallowmodel: accuracy:   0.549
12/10/2017 05:55:43 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 05:55:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:55:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.20      0.19        20
          C       0.50      0.50      0.50       169
          F       0.67      0.69      0.68       281
          R       0.38      0.34      0.36       122

avg / total       0.55      0.55      0.55       592

12/10/2017 05:55:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:55:43 [INFO] exp_shallowmodel: 
[[  4   6   7   3]
 [  3  85  48  33]
 [ 10  43 194  34]
 [  6  35  39  42]]
12/10/2017 05:55:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 05:55:44 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:55:44 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:55:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:55:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:55:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:55:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:55:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:58:38 [INFO] exp_shallowmodel: train time: 174.072s
12/10/2017 05:58:38 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:58:38 [INFO] exp_shallowmodel: accuracy:   0.530
12/10/2017 05:58:38 [INFO] exp_shallowmodel: f1_score:   0.413
12/10/2017 05:58:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:58:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.16      0.15      0.15        20
          C       0.54      0.54      0.54       169
          F       0.68      0.64      0.66       281
          R       0.28      0.31      0.29       122

avg / total       0.54      0.53      0.53       592

12/10/2017 05:58:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:58:38 [INFO] exp_shallowmodel: 
[[  3   4   4   9]
 [  3  92  38  36]
 [  5  41 181  54]
 [  8  34  42  38]]
12/10/2017 05:58:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 05:58:39 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:58:39 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 05:58:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:58:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:58:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:58:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:58:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:01:34 [INFO] exp_shallowmodel: train time: 174.684s
12/10/2017 06:01:34 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:01:34 [INFO] exp_shallowmodel: accuracy:   0.549
12/10/2017 06:01:34 [INFO] exp_shallowmodel: f1_score:   0.442
12/10/2017 06:01:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:01:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.20      0.19        20
          C       0.48      0.54      0.51       169
          F       0.70      0.64      0.67       281
          R       0.40      0.40      0.40       122

avg / total       0.56      0.55      0.55       592

12/10/2017 06:01:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:01:34 [INFO] exp_shallowmodel: 
[[  4   6   7   3]
 [  4  91  43  31]
 [  6  56 181  38]
 [  9  38  26  49]]
12/10/2017 06:01:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 06:01:35 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:01:35 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:01:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:01:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:01:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:01:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:01:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:04:15 [INFO] exp_shallowmodel: train time: 159.978s
12/10/2017 06:04:15 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 06:04:15 [INFO] exp_shallowmodel: accuracy:   0.534
12/10/2017 06:04:15 [INFO] exp_shallowmodel: f1_score:   0.390
12/10/2017 06:04:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:04:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.06        20
          C       0.48      0.52      0.50       169
          F       0.68      0.67      0.67       281
          R       0.33      0.33      0.33       122

avg / total       0.53      0.53      0.53       592

12/10/2017 06:04:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:04:15 [INFO] exp_shallowmodel: 
[[  1   5   6   8]
 [  8  88  42  31]
 [  4  49 187  41]
 [  3  40  39  40]]
12/10/2017 06:04:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 06:04:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:04:17 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:04:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:04:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:04:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:04:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:04:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:07:04 [INFO] exp_shallowmodel: train time: 167.846s
12/10/2017 06:07:04 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 06:07:04 [INFO] exp_shallowmodel: accuracy:   0.535
12/10/2017 06:07:04 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 06:07:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:07:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.49      0.52      0.51       169
          F       0.69      0.67      0.68       281
          R       0.32      0.33      0.32       122

avg / total       0.53      0.54      0.53       592

12/10/2017 06:07:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:07:04 [INFO] exp_shallowmodel: 
[[  1   5   7   7]
 [  3  88  43  35]
 [  7  42 188  44]
 [  2  44  36  40]]
12/10/2017 06:07:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 06:07:06 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:07:06 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:07:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:07:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:07:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:07:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:07:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:09:49 [INFO] exp_shallowmodel: train time: 163.847s
12/10/2017 06:09:49 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 06:09:49 [INFO] exp_shallowmodel: accuracy:   0.525
12/10/2017 06:09:49 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 06:09:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:09:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.49      0.49       169
          F       0.66      0.70      0.68       281
          R       0.27      0.26      0.27       122

avg / total       0.51      0.53      0.52       592

12/10/2017 06:09:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:09:49 [INFO] exp_shallowmodel: 
[[  0   4   6  10]
 [  4  83  49  33]
 [  2  41 196  42]
 [  4  42  44  32]]
12/10/2017 06:09:51 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 06:09:51 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:09:51 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:09:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:09:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:09:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:09:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:09:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:12:42 [INFO] exp_shallowmodel: train time: 171.242s
12/10/2017 06:12:42 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:12:42 [INFO] exp_shallowmodel: accuracy:   0.505
12/10/2017 06:12:42 [INFO] exp_shallowmodel: f1_score:   0.374
12/10/2017 06:12:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:12:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.10      0.11        20
          C       0.45      0.50      0.48       169
          F       0.68      0.65      0.67       281
          R       0.24      0.24      0.24       122

avg / total       0.51      0.51      0.51       592

12/10/2017 06:12:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:12:42 [INFO] exp_shallowmodel: 
[[  2   5   7   6]
 [  4  85  36  44]
 [  3  53 183  42]
 [  6  44  43  29]]
12/10/2017 06:12:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 06:12:43 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:12:43 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:12:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:12:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:12:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:12:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:12:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:15:26 [INFO] exp_shallowmodel: train time: 162.341s
12/10/2017 06:15:26 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 06:15:26 [INFO] exp_shallowmodel: accuracy:   0.549
12/10/2017 06:15:26 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 06:15:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:15:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.10      0.12        20
          C       0.52      0.46      0.49       169
          F       0.66      0.69      0.68       281
          R       0.38      0.42      0.40       122

avg / total       0.54      0.55      0.55       592

12/10/2017 06:15:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:15:26 [INFO] exp_shallowmodel: 
[[  2   5   6   7]
 [  5  78  52  34]
 [  4  40 194  43]
 [  2  28  41  51]]
12/10/2017 06:15:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 06:15:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:15:27 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:15:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:15:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:15:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:15:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:15:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:18:17 [INFO] exp_shallowmodel: train time: 169.889s
12/10/2017 06:18:17 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:18:17 [INFO] exp_shallowmodel: accuracy:   0.507
12/10/2017 06:18:17 [INFO] exp_shallowmodel: f1_score:   0.373
12/10/2017 06:18:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:18:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.10      0.11        20
          C       0.46      0.49      0.47       169
          F       0.65      0.66      0.65       281
          R       0.28      0.25      0.26       122

avg / total       0.50      0.51      0.50       592

12/10/2017 06:18:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:18:17 [INFO] exp_shallowmodel: 
[[  2   4   9   5]
 [  5  82  47  35]
 [  8  51 186  36]
 [  3  43  46  30]]
12/10/2017 06:18:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 06:18:18 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 06:18:18 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:18:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:18:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:18:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:18:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:18:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:21:11 [INFO] exp_shallowmodel: train time: 172.835s
12/10/2017 06:21:11 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:21:11 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 06:21:11 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 06:21:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:21:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.04      0.04        28
          C       0.48      0.47      0.47       172
          F       0.70      0.72      0.71       283
          R       0.37      0.38      0.38       123

avg / total       0.54      0.55      0.54       606

12/10/2017 06:21:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:21:11 [INFO] exp_shallowmodel: 
[[  1   7  10  10]
 [  6  80  48  38]
 [  7  42 203  31]
 [  6  39  31  47]]
12/10/2017 06:21:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 06:21:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:21:12 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:21:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:21:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:21:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:21:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:21:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:24:00 [INFO] exp_shallowmodel: train time: 168.387s
12/10/2017 06:24:00 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:24:00 [INFO] exp_shallowmodel: accuracy:   0.522
12/10/2017 06:24:00 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 06:24:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:24:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.10      0.10        20
          C       0.46      0.47      0.47       169
          F       0.69      0.69      0.69       281
          R       0.28      0.27      0.28       122

avg / total       0.52      0.52      0.52       592

12/10/2017 06:24:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:24:00 [INFO] exp_shallowmodel: 
[[  2   3   4  11]
 [  5  80  45  39]
 [  4  49 194  34]
 [  9  42  38  33]]
12/10/2017 06:24:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 06:24:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:24:02 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:24:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:24:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:24:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:24:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:24:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:26:48 [INFO] exp_shallowmodel: train time: 166.823s
12/10/2017 06:26:49 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:26:49 [INFO] exp_shallowmodel: accuracy:   0.527
12/10/2017 06:26:49 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 06:26:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:26:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        20
          C       0.47      0.49      0.48       169
          F       0.66      0.69      0.68       281
          R       0.31      0.27      0.29       122

avg / total       0.52      0.53      0.52       592

12/10/2017 06:26:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:26:49 [INFO] exp_shallowmodel: 
[[  2   4   6   8]
 [  3  82  51  33]
 [  4  48 195  34]
 [  7  39  43  33]]
12/10/2017 06:26:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 06:26:50 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:26:50 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:26:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:26:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:26:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:26:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:26:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:29:38 [INFO] exp_shallowmodel: train time: 167.816s
12/10/2017 06:29:38 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:29:38 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 06:29:38 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 06:29:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:29:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        20
          C       0.53      0.59      0.56       169
          F       0.69      0.68      0.68       281
          R       0.28      0.25      0.26       122

avg / total       0.54      0.55      0.54       592

12/10/2017 06:29:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:29:38 [INFO] exp_shallowmodel: 
[[  2   4   6   8]
 [  3 100  38  28]
 [  8  38 190  45]
 [  4  47  40  31]]
12/10/2017 06:29:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 06:29:39 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:29:39 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:29:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:29:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:29:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:29:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:29:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:32:24 [INFO] exp_shallowmodel: train time: 165.319s
12/10/2017 06:32:24 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 06:32:24 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 06:32:24 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 06:32:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:32:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.05      0.06        20
          C       0.52      0.56      0.54       169
          F       0.71      0.72      0.71       281
          R       0.40      0.38      0.39       122

avg / total       0.57      0.58      0.58       592

12/10/2017 06:32:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:32:24 [INFO] exp_shallowmodel: 
[[  1   7   8   4]
 [  3  95  42  29]
 [  2  42 202  35]
 [  5  38  33  46]]
12/10/2017 06:32:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 06:32:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:32:25 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:32:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:32:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:32:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:32:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:32:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:35:13 [INFO] exp_shallowmodel: train time: 167.534s
12/10/2017 06:35:13 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:35:13 [INFO] exp_shallowmodel: accuracy:   0.525
12/10/2017 06:35:13 [INFO] exp_shallowmodel: f1_score:   0.379
12/10/2017 06:35:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:35:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.46      0.47      0.46       169
          F       0.69      0.69      0.69       281
          R       0.30      0.31      0.31       122

avg / total       0.52      0.53      0.52       592

12/10/2017 06:35:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:35:13 [INFO] exp_shallowmodel: 
[[  1   5   4  10]
 [  4  79  42  44]
 [  6  49 193  33]
 [  3  39  42  38]]
12/10/2017 06:35:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 06:35:14 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:35:14 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:35:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:35:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:35:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:35:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:35:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:38:00 [INFO] exp_shallowmodel: train time: 166.192s
12/10/2017 06:38:00 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 06:38:00 [INFO] exp_shallowmodel: accuracy:   0.532
12/10/2017 06:38:00 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 06:38:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:38:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.55      0.51       169
          F       0.67      0.63      0.65       281
          R       0.37      0.36      0.37       122

avg / total       0.53      0.53      0.53       592

12/10/2017 06:38:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:38:00 [INFO] exp_shallowmodel: 
[[  0   6   8   6]
 [  3  93  39  34]
 [  6  63 178  34]
 [  7  31  40  44]]
12/10/2017 06:38:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 06:38:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:38:02 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:38:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:38:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:38:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:38:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:38:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:40:46 [INFO] exp_shallowmodel: train time: 164.453s
12/10/2017 06:40:46 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:40:46 [INFO] exp_shallowmodel: accuracy:   0.532
12/10/2017 06:40:46 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 06:40:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:40:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.05      0.05        20
          C       0.51      0.54      0.52       169
          F       0.68      0.67      0.67       281
          R       0.30      0.28      0.29       122

avg / total       0.53      0.53      0.53       592

12/10/2017 06:40:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:40:46 [INFO] exp_shallowmodel: 
[[  1   0   9  10]
 [  8  91  43  27]
 [  5  44 189  43]
 [  5  44  39  34]]
12/10/2017 06:40:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 06:40:48 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:40:48 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:40:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:40:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:40:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:40:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:40:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:43:44 [INFO] exp_shallowmodel: train time: 176.267s
12/10/2017 06:43:44 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 06:43:44 [INFO] exp_shallowmodel: accuracy:   0.508
12/10/2017 06:43:44 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 06:43:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:43:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.15      0.17        20
          C       0.49      0.36      0.42       169
          F       0.66      0.69      0.67       281
          R       0.27      0.35      0.31       122

avg / total       0.52      0.51      0.51       592

12/10/2017 06:43:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:43:44 [INFO] exp_shallowmodel: 
[[  3   3   5   9]
 [  2  61  50  56]
 [  6  31 194  50]
 [  4  29  46  43]]
12/10/2017 06:43:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 06:43:45 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 06:43:45 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:43:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:43:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:43:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:43:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:43:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:46:39 [INFO] exp_shallowmodel: train time: 173.738s
12/10/2017 06:46:39 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:46:39 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 06:46:39 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 06:46:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:46:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        20
          C       0.52      0.53      0.52       169
          F       0.70      0.69      0.69       281
          R       0.35      0.37      0.36       122

avg / total       0.56      0.56      0.56       592

12/10/2017 06:46:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:46:39 [INFO] exp_shallowmodel: 
[[  2   4   7   7]
 [  3  89  40  37]
 [  4  46 193  38]
 [  7  33  37  45]]
12/10/2017 06:46:40 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 06:46:40 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 06:46:40 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:46:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:46:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:46:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:46:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:46:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:49:38 [INFO] exp_shallowmodel: train time: 178.091s
12/10/2017 06:49:38 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:49:38 [INFO] exp_shallowmodel: accuracy:   0.515
12/10/2017 06:49:38 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 06:49:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:49:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.05        28
          C       0.46      0.48      0.47       172
          F       0.66      0.66      0.66       283
          R       0.31      0.34      0.33       123

avg / total       0.51      0.51      0.51       606

12/10/2017 06:49:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:49:38 [INFO] exp_shallowmodel: 
[[  1   7   9  11]
 [  1  82  44  45]
 [  5  55 187  36]
 [  5  34  42  42]]
12/10/2017 06:49:43 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 06:49:43 [INFO] task_runner: context=last, feature=8-skipthought
12/10/2017 06:49:43 [INFO] task_runner: retained feature numbers=[11.1]
12/10/2017 06:49:43 [INFO] task_runner: #(data)=3530
12/10/2017 06:49:43 [INFO] task_runner: #(feature)=7200
12/10/2017 06:49:43 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 06:49:44 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 06:49:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:49:44 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:49:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:49:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:49:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:49:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:49:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:50:37 [INFO] exp_shallowmodel: train time: 53.040s
12/10/2017 06:50:37 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:50:37 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 06:50:37 [INFO] exp_shallowmodel: f1_score:   0.339
12/10/2017 06:50:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:50:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.17      0.20        23
          C       0.17      0.11      0.13        27
          F       0.75      0.83      0.79       250
          R       0.28      0.21      0.24        52

avg / total       0.60      0.64      0.62       352

12/10/2017 06:50:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:50:37 [INFO] exp_shallowmodel: 
[[  4   1  16   2]
 [  3   3  19   2]
 [  8  11 207  24]
 [  3   3  35  11]]
12/10/2017 06:50:38 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 06:50:38 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:50:38 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:50:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:50:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:50:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:50:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:50:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:51:32 [INFO] exp_shallowmodel: train time: 54.168s
12/10/2017 06:51:32 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:51:32 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 06:51:32 [INFO] exp_shallowmodel: f1_score:   0.301
12/10/2017 06:51:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:51:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.19      0.21        27
          F       0.73      0.81      0.77       250
          R       0.26      0.19      0.22        52

avg / total       0.58      0.62      0.60       352

12/10/2017 06:51:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:51:32 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  1   5  17   4]
 [ 11  14 203  22]
 [  4   1  37  10]]
12/10/2017 06:51:33 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 06:51:33 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:51:33 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:51:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:51:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:51:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:51:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:51:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:52:29 [INFO] exp_shallowmodel: train time: 56.104s
12/10/2017 06:52:29 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:52:29 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 06:52:29 [INFO] exp_shallowmodel: f1_score:   0.335
12/10/2017 06:52:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:52:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.17      0.15        23
          C       0.30      0.11      0.16        27
          F       0.75      0.79      0.77       250
          R       0.27      0.25      0.26        52

avg / total       0.60      0.62      0.61       352

12/10/2017 06:52:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:52:29 [INFO] exp_shallowmodel: 
[[  4   0  19   0]
 [  1   3  18   5]
 [ 17   6 197  30]
 [  9   1  29  13]]
12/10/2017 06:52:29 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 06:52:29 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:52:29 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:52:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:52:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:52:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:52:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:52:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:53:23 [INFO] exp_shallowmodel: train time: 53.926s
12/10/2017 06:53:23 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:53:23 [INFO] exp_shallowmodel: accuracy:   0.642
12/10/2017 06:53:23 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 06:53:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:53:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.04      0.05        23
          C       0.18      0.07      0.11        27
          F       0.74      0.85      0.79       250
          R       0.31      0.21      0.25        52

avg / total       0.59      0.64      0.61       352

12/10/2017 06:53:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:53:23 [INFO] exp_shallowmodel: 
[[  1   0  18   4]
 [  1   2  19   5]
 [ 15   8 212  15]
 [  3   1  37  11]]
12/10/2017 06:53:24 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 06:53:24 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:53:24 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:53:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:53:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:53:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:53:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:53:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:54:18 [INFO] exp_shallowmodel: train time: 53.470s
12/10/2017 06:54:18 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:54:18 [INFO] exp_shallowmodel: accuracy:   0.628
12/10/2017 06:54:18 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 06:54:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:54:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.13      0.17        23
          C       0.12      0.07      0.09        27
          F       0.74      0.82      0.78       250
          R       0.26      0.23      0.24        52

avg / total       0.59      0.63      0.61       352

12/10/2017 06:54:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:54:18 [INFO] exp_shallowmodel: 
[[  3   2  16   2]
 [  1   2  18   6]
 [  6  13 204  27]
 [  3   0  37  12]]
12/10/2017 06:54:18 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 06:54:18 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:54:18 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:54:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:54:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:54:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:54:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:54:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:55:13 [INFO] exp_shallowmodel: train time: 54.396s
12/10/2017 06:55:13 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:55:13 [INFO] exp_shallowmodel: accuracy:   0.625
12/10/2017 06:55:13 [INFO] exp_shallowmodel: f1_score:   0.325
12/10/2017 06:55:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:55:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.09      0.10        23
          C       0.16      0.11      0.13        27
          F       0.75      0.80      0.77       250
          R       0.30      0.29      0.29        52

avg / total       0.60      0.62      0.61       352

12/10/2017 06:55:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:55:13 [INFO] exp_shallowmodel: 
[[  2   0  21   0]
 [  1   3  17   6]
 [ 11  10 200  29]
 [  2   6  29  15]]
12/10/2017 06:55:13 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 06:55:13 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:55:13 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:55:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:55:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:55:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:55:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:55:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:56:06 [INFO] exp_shallowmodel: train time: 52.583s
12/10/2017 06:56:06 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:56:06 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 06:56:06 [INFO] exp_shallowmodel: f1_score:   0.242
12/10/2017 06:56:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:56:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.15      0.07      0.10        27
          F       0.71      0.83      0.77       250
          R       0.14      0.08      0.10        52

avg / total       0.54      0.61      0.57       352

12/10/2017 06:56:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:56:06 [INFO] exp_shallowmodel: 
[[  0   2  21   0]
 [  4   2  19   2]
 [ 11   8 208  23]
 [  4   1  43   4]]
12/10/2017 06:56:07 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 06:56:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:56:07 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:56:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:56:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:56:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:56:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:56:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:56:58 [INFO] exp_shallowmodel: train time: 51.533s
12/10/2017 06:56:58 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:56:58 [INFO] exp_shallowmodel: accuracy:   0.625
12/10/2017 06:56:58 [INFO] exp_shallowmodel: f1_score:   0.294
12/10/2017 06:56:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:56:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.17      0.22        23
          C       0.00      0.00      0.00        27
          F       0.73      0.83      0.78       250
          R       0.22      0.15      0.18        52

avg / total       0.57      0.62      0.59       352

12/10/2017 06:56:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:56:58 [INFO] exp_shallowmodel: 
[[  4   2  15   2]
 [  0   0  21   6]
 [  9  12 208  21]
 [  1   3  40   8]]
12/10/2017 06:56:59 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 06:56:59 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:56:59 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:56:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:56:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:56:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:56:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:56:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:57:55 [INFO] exp_shallowmodel: train time: 55.949s
12/10/2017 06:57:55 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:57:55 [INFO] exp_shallowmodel: accuracy:   0.656
12/10/2017 06:57:55 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 06:57:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:57:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.47      0.30      0.36        27
          F       0.74      0.86      0.79       250
          R       0.35      0.17      0.23        52

avg / total       0.61      0.66      0.63       352

12/10/2017 06:57:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:57:55 [INFO] exp_shallowmodel: 
[[  0   1  20   2]
 [  1   8  18   0]
 [ 15   6 214  15]
 [  4   2  37   9]]
12/10/2017 06:57:56 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 06:57:56 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:57:56 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:57:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:57:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:57:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:57:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:57:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:58:49 [INFO] exp_shallowmodel: train time: 53.166s
12/10/2017 06:58:49 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:58:49 [INFO] exp_shallowmodel: accuracy:   0.624
12/10/2017 06:58:49 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 06:58:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:58:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.04      0.06        25
          C       0.29      0.22      0.25        27
          F       0.72      0.84      0.77       251
          R       0.24      0.15      0.19        59

avg / total       0.56      0.62      0.59       362

12/10/2017 06:58:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:58:49 [INFO] exp_shallowmodel: 
[[  1   2  21   1]
 [  0   6  16   5]
 [  9   9 210  23]
 [  1   4  45   9]]
12/10/2017 06:58:50 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 06:58:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:58:50 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:58:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:58:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:58:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:58:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:58:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:59:49 [INFO] exp_shallowmodel: train time: 59.249s
12/10/2017 06:59:49 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 06:59:49 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 06:59:49 [INFO] exp_shallowmodel: f1_score:   0.343
12/10/2017 06:59:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:59:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.09      0.10        23
          C       0.41      0.26      0.32        27
          F       0.74      0.82      0.78       250
          R       0.21      0.15      0.18        52

avg / total       0.59      0.63      0.61       352

12/10/2017 06:59:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:59:49 [INFO] exp_shallowmodel: 
[[  2   0  19   2]
 [  2   7  15   3]
 [ 11   8 206  25]
 [  3   2  39   8]]
12/10/2017 06:59:50 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 06:59:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:59:50 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 06:59:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:59:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:59:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:59:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:59:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:00:44 [INFO] exp_shallowmodel: train time: 54.662s
12/10/2017 07:00:44 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:00:44 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 07:00:44 [INFO] exp_shallowmodel: f1_score:   0.300
12/10/2017 07:00:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:00:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.09      0.11        23
          C       0.24      0.15      0.18        27
          F       0.73      0.83      0.78       250
          R       0.16      0.12      0.13        52

avg / total       0.57      0.62      0.59       352

12/10/2017 07:00:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:00:44 [INFO] exp_shallowmodel: 
[[  2   0  18   3]
 [  1   4  20   2]
 [  8   9 207  26]
 [  4   4  38   6]]
12/10/2017 07:00:45 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 07:00:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:00:45 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:00:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:00:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:00:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:00:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:00:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:01:36 [INFO] exp_shallowmodel: train time: 50.979s
12/10/2017 07:01:36 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:01:36 [INFO] exp_shallowmodel: accuracy:   0.625
12/10/2017 07:01:36 [INFO] exp_shallowmodel: f1_score:   0.303
12/10/2017 07:01:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:01:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.13      0.16        23
          C       0.17      0.11      0.13        27
          F       0.73      0.83      0.78       250
          R       0.17      0.12      0.14        52

avg / total       0.57      0.62      0.59       352

12/10/2017 07:01:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:01:36 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  0   3  21   3]
 [  7  12 208  23]
 [  4   2  40   6]]
12/10/2017 07:01:37 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 07:01:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:01:37 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:01:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:01:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:01:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:01:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:01:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:02:31 [INFO] exp_shallowmodel: train time: 54.365s
12/10/2017 07:02:31 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:02:31 [INFO] exp_shallowmodel: accuracy:   0.625
12/10/2017 07:02:31 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 07:02:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:02:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.13      0.14        23
          C       0.38      0.19      0.25        27
          F       0.72      0.81      0.77       250
          R       0.24      0.17      0.20        52

avg / total       0.59      0.62      0.60       352

12/10/2017 07:02:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:02:31 [INFO] exp_shallowmodel: 
[[  3   0  18   2]
 [  1   5  20   1]
 [ 15   6 203  26]
 [  2   2  39   9]]
12/10/2017 07:02:32 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 07:02:32 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:02:32 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:02:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:02:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:02:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:02:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:02:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:03:29 [INFO] exp_shallowmodel: train time: 57.162s
12/10/2017 07:03:29 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:03:29 [INFO] exp_shallowmodel: accuracy:   0.628
12/10/2017 07:03:29 [INFO] exp_shallowmodel: f1_score:   0.279
12/10/2017 07:03:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:03:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.10      0.07      0.09        27
          F       0.74      0.83      0.78       250
          R       0.30      0.21      0.25        52

avg / total       0.58      0.63      0.60       352

12/10/2017 07:03:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:03:29 [INFO] exp_shallowmodel: 
[[  0   2  19   2]
 [  2   2  19   4]
 [ 11  11 208  20]
 [  2   5  34  11]]
12/10/2017 07:03:30 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 07:03:30 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:03:30 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:03:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:03:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:03:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:03:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:03:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:04:27 [INFO] exp_shallowmodel: train time: 56.890s
12/10/2017 07:04:27 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:04:27 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 07:04:27 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 07:04:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:04:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.09      0.09        23
          C       0.20      0.11      0.14        27
          F       0.74      0.85      0.79       250
          R       0.19      0.12      0.14        52

avg / total       0.58      0.63      0.60       352

12/10/2017 07:04:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:04:27 [INFO] exp_shallowmodel: 
[[  2   2  18   1]
 [  0   3  19   5]
 [  9  10 212  19]
 [ 10   0  36   6]]
12/10/2017 07:04:27 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 07:04:27 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:04:27 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:04:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:04:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:04:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:04:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:04:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:05:24 [INFO] exp_shallowmodel: train time: 56.680s
12/10/2017 07:05:24 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:05:24 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 07:05:24 [INFO] exp_shallowmodel: f1_score:   0.325
12/10/2017 07:05:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:05:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.04      0.05        23
          C       0.31      0.19      0.23        27
          F       0.74      0.82      0.78       250
          R       0.28      0.21      0.24        52

avg / total       0.59      0.63      0.61       352

12/10/2017 07:05:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:05:24 [INFO] exp_shallowmodel: 
[[  1   0  17   5]
 [  4   5  17   1]
 [ 11  10 206  23]
 [  2   1  38  11]]
12/10/2017 07:05:25 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 07:05:25 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:05:25 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:05:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:05:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:05:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:05:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:05:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:06:21 [INFO] exp_shallowmodel: train time: 56.095s
12/10/2017 07:06:21 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:06:21 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 07:06:21 [INFO] exp_shallowmodel: f1_score:   0.355
12/10/2017 07:06:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:06:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.06        23
          C       0.39      0.33      0.36        27
          F       0.74      0.81      0.77       250
          R       0.25      0.21      0.23        52

avg / total       0.60      0.63      0.61       352

12/10/2017 07:06:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:06:21 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  1   9  13   4]
 [  7  13 202  28]
 [  4   1  36  11]]
12/10/2017 07:06:22 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 07:06:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:06:22 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:06:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:06:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:06:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:06:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:06:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:07:13 [INFO] exp_shallowmodel: train time: 51.075s
12/10/2017 07:07:13 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:07:13 [INFO] exp_shallowmodel: accuracy:   0.628
12/10/2017 07:07:13 [INFO] exp_shallowmodel: f1_score:   0.285
12/10/2017 07:07:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:07:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.11      0.15        27
          F       0.73      0.83      0.78       250
          R       0.23      0.19      0.21        52

avg / total       0.57      0.63      0.60       352

12/10/2017 07:07:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:07:13 [INFO] exp_shallowmodel: 
[[  0   3  17   3]
 [  1   3  18   5]
 [ 11   5 208  26]
 [  0   1  41  10]]
12/10/2017 07:07:14 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 07:07:14 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 07:07:14 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:07:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:07:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:07:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:07:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:07:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:08:06 [INFO] exp_shallowmodel: train time: 52.145s
12/10/2017 07:08:06 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:08:06 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 07:08:06 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 07:08:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:08:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.08      0.09        25
          C       0.16      0.11      0.13        27
          F       0.74      0.71      0.72       251
          R       0.26      0.37      0.31        59

avg / total       0.57      0.56      0.57       362

12/10/2017 07:08:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:08:06 [INFO] exp_shallowmodel: 
[[  2   2  15   6]
 [  1   3  15   8]
 [ 14  12 177  48]
 [  3   2  32  22]]
12/10/2017 07:08:06 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 07:08:06 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:08:06 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:08:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:08:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:08:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:08:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:08:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:09:03 [INFO] exp_shallowmodel: train time: 56.412s
12/10/2017 07:09:03 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:09:03 [INFO] exp_shallowmodel: accuracy:   0.648
12/10/2017 07:09:03 [INFO] exp_shallowmodel: f1_score:   0.346
12/10/2017 07:09:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:09:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.17      0.20        23
          C       0.31      0.19      0.23        27
          F       0.75      0.85      0.79       250
          R       0.21      0.13      0.16        52

avg / total       0.60      0.65      0.62       352

12/10/2017 07:09:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:09:03 [INFO] exp_shallowmodel: 
[[  4   2  16   1]
 [  1   5  17   4]
 [ 12   4 212  22]
 [  1   5  39   7]]
12/10/2017 07:09:04 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 07:09:04 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:09:04 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:09:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:09:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:09:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:09:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:09:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:09:55 [INFO] exp_shallowmodel: train time: 51.304s
12/10/2017 07:09:55 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:09:55 [INFO] exp_shallowmodel: accuracy:   0.645
12/10/2017 07:09:55 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 07:09:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:09:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.26      0.19      0.22        27
          F       0.73      0.86      0.79       250
          R       0.31      0.15      0.21        52

avg / total       0.58      0.64      0.61       352

12/10/2017 07:09:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:09:55 [INFO] exp_shallowmodel: 
[[  0   2  18   3]
 [  2   5  19   1]
 [ 11  11 214  14]
 [  0   1  43   8]]
12/10/2017 07:09:56 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 07:09:56 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:09:56 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:09:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:09:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:09:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:09:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:09:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:10:49 [INFO] exp_shallowmodel: train time: 53.579s
12/10/2017 07:10:49 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:10:49 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 07:10:49 [INFO] exp_shallowmodel: f1_score:   0.267
12/10/2017 07:10:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:10:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        23
          C       0.10      0.07      0.08        27
          F       0.72      0.78      0.75       250
          R       0.17      0.17      0.17        52

avg / total       0.55      0.59      0.57       352

12/10/2017 07:10:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:10:49 [INFO] exp_shallowmodel: 
[[  1   4  13   5]
 [  1   2  20   4]
 [  7  13 195  35]
 [  0   2  41   9]]
12/10/2017 07:10:50 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 07:10:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:10:50 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:10:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:10:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:10:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:10:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:10:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:11:42 [INFO] exp_shallowmodel: train time: 52.545s
12/10/2017 07:11:42 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:11:42 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 07:11:42 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 07:11:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:11:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.04      0.04        23
          C       0.27      0.15      0.19        27
          F       0.74      0.79      0.76       250
          R       0.26      0.23      0.24        52

avg / total       0.58      0.61      0.59       352

12/10/2017 07:11:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:11:42 [INFO] exp_shallowmodel: 
[[  1   2  15   5]
 [  1   4  20   2]
 [ 17   8 197  28]
 [  3   1  36  12]]
12/10/2017 07:11:43 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 07:11:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:11:43 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:11:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:11:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:11:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:11:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:11:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:12:39 [INFO] exp_shallowmodel: train time: 56.260s
12/10/2017 07:12:39 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:12:39 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 07:12:39 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 07:12:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:12:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.09      0.11        23
          C       0.13      0.07      0.10        27
          F       0.74      0.83      0.78       250
          R       0.19      0.15      0.17        52

avg / total       0.57      0.62      0.59       352

12/10/2017 07:12:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:12:39 [INFO] exp_shallowmodel: 
[[  2   2  14   5]
 [  0   2  22   3]
 [  8   9 207  26]
 [  5   2  37   8]]
12/10/2017 07:12:40 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 07:12:40 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:12:40 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:12:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:12:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:12:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:12:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:12:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:13:33 [INFO] exp_shallowmodel: train time: 52.348s
12/10/2017 07:13:33 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:13:33 [INFO] exp_shallowmodel: accuracy:   0.642
12/10/2017 07:13:33 [INFO] exp_shallowmodel: f1_score:   0.297
12/10/2017 07:13:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:13:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.09      0.11        23
          C       0.25      0.15      0.19        27
          F       0.72      0.86      0.79       250
          R       0.16      0.08      0.10        52

avg / total       0.57      0.64      0.60       352

12/10/2017 07:13:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:13:33 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  1   4  20   2]
 [  8   8 216  18]
 [  2   4  42   4]]
12/10/2017 07:13:33 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 07:13:33 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:13:33 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:13:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:13:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:13:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:13:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:13:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:14:25 [INFO] exp_shallowmodel: train time: 52.152s
12/10/2017 07:14:25 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:14:25 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 07:14:25 [INFO] exp_shallowmodel: f1_score:   0.300
12/10/2017 07:14:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:14:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.09      0.09        23
          C       0.20      0.15      0.17        27
          F       0.74      0.82      0.78       250
          R       0.20      0.13      0.16        52

avg / total       0.58      0.62      0.60       352

12/10/2017 07:14:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:14:25 [INFO] exp_shallowmodel: 
[[  2   1  16   4]
 [  1   4  20   2]
 [ 11  12 205  22]
 [  7   3  35   7]]
12/10/2017 07:14:26 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 07:14:26 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:14:26 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:14:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:14:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:14:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:14:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:14:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:15:20 [INFO] exp_shallowmodel: train time: 54.006s
12/10/2017 07:15:20 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:15:20 [INFO] exp_shallowmodel: accuracy:   0.636
12/10/2017 07:15:20 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 07:15:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:15:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.06        23
          C       0.28      0.19      0.22        27
          F       0.74      0.84      0.79       250
          R       0.22      0.15      0.18        52

avg / total       0.58      0.64      0.61       352

12/10/2017 07:15:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:15:20 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  1   5  14   7]
 [ 10  11 210  19]
 [  1   2  41   8]]
12/10/2017 07:15:21 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 07:15:21 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:15:21 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:15:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:15:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:15:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:15:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:15:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:16:17 [INFO] exp_shallowmodel: train time: 56.398s
12/10/2017 07:16:17 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:16:17 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 07:16:17 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 07:16:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:16:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.09      0.11        23
          C       0.18      0.15      0.16        27
          F       0.74      0.81      0.77       250
          R       0.21      0.17      0.19        52

avg / total       0.58      0.62      0.60       352

12/10/2017 07:16:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:16:17 [INFO] exp_shallowmodel: 
[[  2   1  15   5]
 [  1   4  19   3]
 [  9  13 203  25]
 [  2   4  37   9]]
12/10/2017 07:16:18 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 07:16:18 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 07:16:18 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:16:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:16:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:16:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:16:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:16:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:17:13 [INFO] exp_shallowmodel: train time: 54.841s
12/10/2017 07:17:13 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:17:13 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 07:17:13 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 07:17:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:17:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.12      0.16        25
          C       0.36      0.19      0.24        27
          F       0.71      0.83      0.76       251
          R       0.20      0.14      0.16        59

avg / total       0.56      0.62      0.58       362

12/10/2017 07:17:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:17:13 [INFO] exp_shallowmodel: 
[[  3   3  17   2]
 [  0   5  21   1]
 [  8   5 208  30]
 [  1   1  49   8]]
12/10/2017 07:17:14 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 07:17:14 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:17:14 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:17:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:17:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:17:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:17:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:17:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:18:08 [INFO] exp_shallowmodel: train time: 53.910s
12/10/2017 07:18:08 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:18:08 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 07:18:08 [INFO] exp_shallowmodel: f1_score:   0.260
12/10/2017 07:18:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:18:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.04      0.05        23
          C       0.06      0.04      0.05        27
          F       0.72      0.79      0.76       250
          R       0.20      0.17      0.19        52

avg / total       0.55      0.59      0.57       352

12/10/2017 07:18:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:18:08 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  1   1  21   4]
 [ 11  11 198  30]
 [  5   4  34   9]]
12/10/2017 07:18:08 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 07:18:08 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:18:08 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:18:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:18:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:18:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:18:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:18:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:19:03 [INFO] exp_shallowmodel: train time: 54.251s
12/10/2017 07:19:03 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:19:03 [INFO] exp_shallowmodel: accuracy:   0.614
12/10/2017 07:19:03 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 07:19:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:19:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.04      0.06        23
          C       0.22      0.19      0.20        27
          F       0.74      0.81      0.77       250
          R       0.18      0.15      0.16        52

avg / total       0.57      0.61      0.59       352

12/10/2017 07:19:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:19:03 [INFO] exp_shallowmodel: 
[[  1   3  15   4]
 [  0   5  17   5]
 [  9  11 202  28]
 [  1   4  39   8]]
12/10/2017 07:19:03 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 07:19:03 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:19:03 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:19:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:19:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:19:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:19:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:19:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:20:04 [INFO] exp_shallowmodel: train time: 60.263s
12/10/2017 07:20:04 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:20:04 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 07:20:04 [INFO] exp_shallowmodel: f1_score:   0.305
12/10/2017 07:20:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:20:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.04      0.05        23
          C       0.21      0.15      0.17        27
          F       0.72      0.80      0.76       250
          R       0.27      0.21      0.24        52

avg / total       0.57      0.61      0.59       352

12/10/2017 07:20:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:20:04 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  0   4  18   5]
 [ 13  14 199  24]
 [  2   0  39  11]]
12/10/2017 07:20:04 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 07:20:04 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:20:04 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:20:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:20:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:20:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:20:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:20:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:21:05 [INFO] exp_shallowmodel: train time: 60.360s
12/10/2017 07:21:05 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:21:05 [INFO] exp_shallowmodel: accuracy:   0.659
12/10/2017 07:21:05 [INFO] exp_shallowmodel: f1_score:   0.375
12/10/2017 07:21:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:21:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.13      0.18        23
          C       0.30      0.26      0.28        27
          F       0.75      0.84      0.79       250
          R       0.30      0.21      0.25        52

avg / total       0.62      0.66      0.63       352

12/10/2017 07:21:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:21:05 [INFO] exp_shallowmodel: 
[[  3   1  17   2]
 [  0   7  17   3]
 [  6  12 211  21]
 [  2   3  36  11]]
12/10/2017 07:21:05 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 07:21:05 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:21:05 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:21:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:21:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:21:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:21:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:21:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:21:58 [INFO] exp_shallowmodel: train time: 52.559s
12/10/2017 07:21:58 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:21:58 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 07:21:58 [INFO] exp_shallowmodel: f1_score:   0.271
12/10/2017 07:21:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:21:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.07      0.11        27
          F       0.74      0.74      0.74       250
          R       0.19      0.31      0.23        52

avg / total       0.57      0.57      0.57       352

12/10/2017 07:21:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:21:58 [INFO] exp_shallowmodel: 
[[  0   0  18   5]
 [  1   2  15   9]
 [  6   5 184  55]
 [  2   1  33  16]]
12/10/2017 07:21:59 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 07:21:59 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:21:59 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:21:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:21:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:21:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:21:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:21:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:22:53 [INFO] exp_shallowmodel: train time: 54.371s
12/10/2017 07:22:53 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:22:53 [INFO] exp_shallowmodel: accuracy:   0.582
12/10/2017 07:22:53 [INFO] exp_shallowmodel: f1_score:   0.272
12/10/2017 07:22:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:22:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.22      0.21        23
          C       0.06      0.04      0.05        27
          F       0.71      0.78      0.75       250
          R       0.11      0.08      0.09        52

avg / total       0.54      0.58      0.56       352

12/10/2017 07:22:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:22:53 [INFO] exp_shallowmodel: 
[[  5   2  14   2]
 [  2   1  21   3]
 [ 17  10 195  28]
 [  1   4  43   4]]
12/10/2017 07:22:54 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 07:22:54 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:22:54 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:22:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:22:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:22:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:22:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:22:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:23:49 [INFO] exp_shallowmodel: train time: 55.641s
12/10/2017 07:23:49 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:23:49 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 07:23:49 [INFO] exp_shallowmodel: f1_score:   0.301
12/10/2017 07:23:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:23:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.09      0.10        23
          C       0.19      0.15      0.17        27
          F       0.73      0.82      0.77       250
          R       0.21      0.13      0.16        52

avg / total       0.57      0.62      0.59       352

12/10/2017 07:23:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:23:49 [INFO] exp_shallowmodel: 
[[  2   3  17   1]
 [  0   4  18   5]
 [ 12  12 205  21]
 [  3   2  40   7]]
12/10/2017 07:23:50 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 07:23:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:23:50 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:23:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:23:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:23:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:23:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:23:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:24:46 [INFO] exp_shallowmodel: train time: 55.466s
12/10/2017 07:24:46 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:24:46 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 07:24:46 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 07:24:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:24:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.06        23
          C       0.24      0.15      0.18        27
          F       0.73      0.84      0.78       250
          R       0.29      0.19      0.23        52

avg / total       0.58      0.64      0.61       352

12/10/2017 07:24:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:24:46 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  1   4  20   2]
 [  9  11 210  20]
 [  2   2  38  10]]
12/10/2017 07:24:46 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 07:24:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:24:46 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:24:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:24:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:24:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:24:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:24:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:25:41 [INFO] exp_shallowmodel: train time: 54.347s
12/10/2017 07:25:41 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:25:41 [INFO] exp_shallowmodel: accuracy:   0.659
12/10/2017 07:25:41 [INFO] exp_shallowmodel: f1_score:   0.368
12/10/2017 07:25:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:25:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.09      0.09        23
          C       0.39      0.26      0.31        27
          F       0.77      0.84      0.80       250
          R       0.32      0.23      0.27        52

avg / total       0.63      0.66      0.64       352

12/10/2017 07:25:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:25:41 [INFO] exp_shallowmodel: 
[[  2   2  18   1]
 [  3   7  14   3]
 [ 11   7 211  21]
 [  6   2  32  12]]
12/10/2017 07:25:42 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 07:25:42 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 07:25:42 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:25:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:25:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:25:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:25:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:25:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:26:32 [INFO] exp_shallowmodel: train time: 50.113s
12/10/2017 07:26:32 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:26:32 [INFO] exp_shallowmodel: accuracy:   0.572
12/10/2017 07:26:32 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 07:26:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:26:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.12      0.15        25
          C       0.08      0.04      0.05        27
          F       0.75      0.72      0.73       251
          R       0.24      0.39      0.30        59

avg / total       0.58      0.57      0.57       362

12/10/2017 07:26:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:26:32 [INFO] exp_shallowmodel: 
[[  3   2  17   3]
 [  2   1  12  12]
 [  6   8 180  57]
 [  3   2  31  23]]
12/10/2017 07:26:32 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 07:26:32 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:26:32 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:26:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:26:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:26:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:26:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:26:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:27:31 [INFO] exp_shallowmodel: train time: 58.959s
12/10/2017 07:27:31 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:27:31 [INFO] exp_shallowmodel: accuracy:   0.648
12/10/2017 07:27:31 [INFO] exp_shallowmodel: f1_score:   0.344
12/10/2017 07:27:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:27:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.13      0.15        23
          C       0.28      0.19      0.22        27
          F       0.74      0.84      0.79       250
          R       0.28      0.17      0.21        52

avg / total       0.60      0.65      0.62       352

12/10/2017 07:27:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:27:31 [INFO] exp_shallowmodel: 
[[  3   0  18   2]
 [  1   5  19   2]
 [  9  11 211  19]
 [  3   2  38   9]]
12/10/2017 07:27:32 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 07:27:32 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:27:32 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:27:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:27:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:27:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:27:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:27:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:28:25 [INFO] exp_shallowmodel: train time: 52.845s
12/10/2017 07:28:25 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:28:25 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 07:28:25 [INFO] exp_shallowmodel: f1_score:   0.310
12/10/2017 07:28:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:28:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.13      0.15        23
          C       0.13      0.11      0.12        27
          F       0.73      0.81      0.77       250
          R       0.26      0.17      0.21        52

avg / total       0.58      0.62      0.59       352

12/10/2017 07:28:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:28:25 [INFO] exp_shallowmodel: 
[[  3   3  15   2]
 [  0   3  21   3]
 [ 13  14 202  21]
 [  2   3  38   9]]
12/10/2017 07:28:26 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 07:28:26 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:28:26 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:28:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:28:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:28:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:28:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:28:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:29:23 [INFO] exp_shallowmodel: train time: 57.140s
12/10/2017 07:29:23 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:29:23 [INFO] exp_shallowmodel: accuracy:   0.631
12/10/2017 07:29:23 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 07:29:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:29:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.09      0.11        23
          C       0.27      0.22      0.24        27
          F       0.75      0.82      0.78       250
          R       0.22      0.19      0.20        52

avg / total       0.60      0.63      0.61       352

12/10/2017 07:29:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:29:23 [INFO] exp_shallowmodel: 
[[  2   1  18   2]
 [  0   6  14   7]
 [  7  12 204  27]
 [  3   3  36  10]]
12/10/2017 07:29:24 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 07:29:24 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:29:24 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:29:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:29:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:29:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:29:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:29:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:30:17 [INFO] exp_shallowmodel: train time: 53.176s
12/10/2017 07:30:17 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:30:17 [INFO] exp_shallowmodel: accuracy:   0.605
12/10/2017 07:30:17 [INFO] exp_shallowmodel: f1_score:   0.279
12/10/2017 07:30:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:30:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.16      0.11      0.13        27
          F       0.74      0.80      0.77       250
          R       0.24      0.19      0.22        52

avg / total       0.57      0.61      0.59       352

12/10/2017 07:30:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:30:17 [INFO] exp_shallowmodel: 
[[  0   3  17   3]
 [  0   3  18   6]
 [ 17  11 200  22]
 [  5   2  35  10]]
12/10/2017 07:30:17 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 07:30:17 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:30:17 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:30:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:30:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:30:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:30:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:30:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:31:14 [INFO] exp_shallowmodel: train time: 56.186s
12/10/2017 07:31:14 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:31:14 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 07:31:14 [INFO] exp_shallowmodel: f1_score:   0.362
12/10/2017 07:31:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:31:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.13      0.15        23
          C       0.32      0.26      0.29        27
          F       0.74      0.81      0.77       250
          R       0.28      0.21      0.24        52

avg / total       0.60      0.63      0.62       352

12/10/2017 07:31:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:31:14 [INFO] exp_shallowmodel: 
[[  3   0  18   2]
 [  1   7  18   1]
 [ 10  12 202  26]
 [  3   3  35  11]]
12/10/2017 07:31:14 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 07:31:14 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:31:14 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:31:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:31:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:31:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:31:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:31:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:32:14 [INFO] exp_shallowmodel: train time: 59.411s
12/10/2017 07:32:14 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:32:14 [INFO] exp_shallowmodel: accuracy:   0.665
12/10/2017 07:32:14 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 07:32:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:32:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.17      0.21        23
          C       0.12      0.07      0.09        27
          F       0.76      0.87      0.81       250
          R       0.29      0.19      0.23        52

avg / total       0.61      0.66      0.63       352

12/10/2017 07:32:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:32:14 [INFO] exp_shallowmodel: 
[[  4   0  16   3]
 [  2   2  18   5]
 [  6  10 218  16]
 [  4   4  34  10]]
12/10/2017 07:32:15 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 07:32:15 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:32:15 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:32:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:32:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:32:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:32:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:32:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:33:07 [INFO] exp_shallowmodel: train time: 52.644s
12/10/2017 07:33:07 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:33:07 [INFO] exp_shallowmodel: accuracy:   0.653
12/10/2017 07:33:07 [INFO] exp_shallowmodel: f1_score:   0.337
12/10/2017 07:33:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:33:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        23
          C       0.36      0.19      0.24        27
          F       0.74      0.85      0.79       250
          R       0.27      0.23      0.25        52

avg / total       0.60      0.65      0.62       352

12/10/2017 07:33:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:33:07 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  1   5  18   3]
 [  4   7 212  27]
 [  3   1  36  12]]
12/10/2017 07:33:08 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 07:33:08 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:33:08 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:33:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:33:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:33:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:33:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:33:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:34:01 [INFO] exp_shallowmodel: train time: 53.121s
12/10/2017 07:34:01 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:34:01 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 07:34:01 [INFO] exp_shallowmodel: f1_score:   0.313
12/10/2017 07:34:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:34:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.17      0.19        23
          C       0.16      0.11      0.13        27
          F       0.75      0.84      0.79       250
          R       0.18      0.12      0.14        52

avg / total       0.58      0.63      0.61       352

12/10/2017 07:34:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:34:01 [INFO] exp_shallowmodel: 
[[  4   2  15   2]
 [  4   3  17   3]
 [  7  11 210  22]
 [  4   3  39   6]]
12/10/2017 07:34:02 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 07:34:02 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 07:34:02 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:34:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:34:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:34:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:34:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:34:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:34:56 [INFO] exp_shallowmodel: train time: 54.632s
12/10/2017 07:34:56 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:34:56 [INFO] exp_shallowmodel: accuracy:   0.625
12/10/2017 07:34:56 [INFO] exp_shallowmodel: f1_score:   0.292
12/10/2017 07:34:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:34:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.04      0.06        23
          C       0.21      0.11      0.15        27
          F       0.73      0.83      0.78       250
          R       0.20      0.17      0.19        52

avg / total       0.57      0.62      0.59       352

12/10/2017 07:34:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:34:56 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  1   3  20   3]
 [  7   8 207  28]
 [  1   2  40   9]]
12/10/2017 07:34:57 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 07:34:57 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 07:34:57 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:34:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:34:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:34:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:34:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:34:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:35:54 [INFO] exp_shallowmodel: train time: 56.631s
12/10/2017 07:35:54 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 07:35:54 [INFO] exp_shallowmodel: accuracy:   0.624
12/10/2017 07:35:54 [INFO] exp_shallowmodel: f1_score:   0.279
12/10/2017 07:35:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:35:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.27      0.11      0.16        27
          F       0.71      0.85      0.78       251
          R       0.23      0.15      0.18        59

avg / total       0.55      0.62      0.58       362

12/10/2017 07:35:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:35:54 [INFO] exp_shallowmodel: 
[[  0   0  21   4]
 [  0   3  19   5]
 [  9   6 214  22]
 [  2   2  46   9]]
12/10/2017 07:35:59 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 07:35:59 [INFO] task_runner: context=last, feature=8-skipthought
12/10/2017 07:35:59 [INFO] task_runner: retained feature numbers=[11.1]
12/10/2017 07:35:59 [INFO] task_runner: #(data)=5241
12/10/2017 07:35:59 [INFO] task_runner: #(feature)=7200
12/10/2017 07:35:59 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 07:36:01 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 07:36:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:36:01 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:36:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:36:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:36:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:36:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:36:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:37:07 [INFO] exp_shallowmodel: train time: 66.077s
12/10/2017 07:37:07 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:37:07 [INFO] exp_shallowmodel: accuracy:   0.672
12/10/2017 07:37:07 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 07:37:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:37:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.19      0.20        59
          C       0.00      0.00      0.00        12
          F       0.80      0.83      0.81       396
          R       0.22      0.24      0.23        55

avg / total       0.65      0.67      0.66       522

12/10/2017 07:37:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:37:07 [INFO] exp_shallowmodel: 
[[ 11   0  37  11]
 [  3   0   9   0]
 [ 32   1 327  36]
 [  5   0  37  13]]
12/10/2017 07:37:08 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 07:37:08 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:37:08 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:37:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:37:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:37:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:37:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:37:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:38:15 [INFO] exp_shallowmodel: train time: 66.856s
12/10/2017 07:38:15 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:38:15 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 07:38:15 [INFO] exp_shallowmodel: f1_score:   0.333
12/10/2017 07:38:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:38:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.27      0.26        59
          C       0.00      0.00      0.00        12
          F       0.82      0.84      0.83       396
          R       0.26      0.22      0.24        55

avg / total       0.68      0.69      0.69       522

12/10/2017 07:38:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:38:15 [INFO] exp_shallowmodel: 
[[ 16   3  36   4]
 [  4   0   8   0]
 [ 30   1 334  31]
 [ 12   2  29  12]]
12/10/2017 07:38:16 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 07:38:16 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:38:16 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:38:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:38:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:38:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:38:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:38:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:39:23 [INFO] exp_shallowmodel: train time: 66.810s
12/10/2017 07:39:23 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:39:23 [INFO] exp_shallowmodel: accuracy:   0.661
12/10/2017 07:39:23 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 07:39:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:39:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.16      0.15      0.16        59
          C       0.00      0.00      0.00        12
          F       0.78      0.82      0.80       396
          R       0.27      0.24      0.25        55

avg / total       0.64      0.66      0.65       522

12/10/2017 07:39:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:39:23 [INFO] exp_shallowmodel: 
[[  9   0  42   8]
 [  1   0   9   2]
 [ 42   5 323  26]
 [  3   1  38  13]]
12/10/2017 07:39:24 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 07:39:24 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:39:24 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:39:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:39:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:39:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:39:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:39:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:40:32 [INFO] exp_shallowmodel: train time: 68.426s
12/10/2017 07:40:32 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:40:32 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 07:40:32 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 07:40:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:40:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.36      0.33        59
          C       0.00      0.00      0.00        12
          F       0.81      0.83      0.82       396
          R       0.18      0.15      0.16        55

avg / total       0.67      0.69      0.68       522

12/10/2017 07:40:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:40:32 [INFO] exp_shallowmodel: 
[[ 21   0  33   5]
 [  2   0   5   5]
 [ 35   5 329  27]
 [  9   0  38   8]]
12/10/2017 07:40:33 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 07:40:33 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:40:33 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:40:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:40:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:40:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:40:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:40:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:41:37 [INFO] exp_shallowmodel: train time: 63.957s
12/10/2017 07:41:37 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:41:37 [INFO] exp_shallowmodel: accuracy:   0.672
12/10/2017 07:41:37 [INFO] exp_shallowmodel: f1_score:   0.365
12/10/2017 07:41:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:41:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.19      0.21        59
          C       0.40      0.17      0.24        12
          F       0.80      0.82      0.81       396
          R       0.19      0.22      0.20        55

avg / total       0.66      0.67      0.67       522

12/10/2017 07:41:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:41:37 [INFO] exp_shallowmodel: 
[[ 11   1  37  10]
 [  1   2   6   3]
 [ 29   2 326  39]
 [  4   0  39  12]]
12/10/2017 07:41:38 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 07:41:38 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:41:38 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:41:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:41:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:41:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:41:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:41:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:42:46 [INFO] exp_shallowmodel: train time: 67.778s
12/10/2017 07:42:46 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:42:46 [INFO] exp_shallowmodel: accuracy:   0.648
12/10/2017 07:42:46 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 07:42:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:42:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.20      0.20        59
          C       0.00      0.00      0.00        12
          F       0.80      0.79      0.79       396
          R       0.23      0.27      0.25        55

avg / total       0.65      0.65      0.65       522

12/10/2017 07:42:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:42:46 [INFO] exp_shallowmodel: 
[[ 12   3  36   8]
 [  1   0   8   3]
 [ 44   3 311  38]
 [  5   2  33  15]]
12/10/2017 07:42:47 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 07:42:47 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:42:47 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:42:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:42:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:42:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:42:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:42:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:43:57 [INFO] exp_shallowmodel: train time: 69.836s
12/10/2017 07:43:57 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:43:57 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 07:43:57 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 07:43:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:43:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        59
          C       0.00      0.00      0.00        12
          F       0.82      0.87      0.84       396
          R       0.33      0.31      0.32        55

avg / total       0.67      0.70      0.69       522

12/10/2017 07:43:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:43:57 [INFO] exp_shallowmodel: 
[[  6   1  39  13]
 [  0   0   7   5]
 [ 35   2 343  16]
 [  8   1  29  17]]
12/10/2017 07:43:58 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 07:43:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:43:58 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:43:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:43:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:43:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:43:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:43:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:45:07 [INFO] exp_shallowmodel: train time: 68.772s
12/10/2017 07:45:07 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:45:07 [INFO] exp_shallowmodel: accuracy:   0.680
12/10/2017 07:45:07 [INFO] exp_shallowmodel: f1_score:   0.363
12/10/2017 07:45:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:45:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.20      0.21        59
          C       0.25      0.17      0.20        12
          F       0.81      0.83      0.82       396
          R       0.21      0.22      0.21        55

avg / total       0.67      0.68      0.68       522

12/10/2017 07:45:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:45:07 [INFO] exp_shallowmodel: 
[[ 12   2  36   9]
 [  1   2   8   1]
 [ 30   2 329  35]
 [ 10   2  31  12]]
12/10/2017 07:45:08 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 07:45:08 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:45:08 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:45:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:45:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:45:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:45:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:45:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:46:16 [INFO] exp_shallowmodel: train time: 67.914s
12/10/2017 07:46:16 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:46:16 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 07:46:16 [INFO] exp_shallowmodel: f1_score:   0.349
12/10/2017 07:46:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:46:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.24      0.25        59
          C       0.20      0.08      0.12        12
          F       0.81      0.84      0.82       396
          R       0.21      0.20      0.20        55

avg / total       0.67      0.69      0.68       522

12/10/2017 07:46:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:46:16 [INFO] exp_shallowmodel: 
[[ 14   0  38   7]
 [  0   1   8   3]
 [ 28   4 332  32]
 [ 10   0  34  11]]
12/10/2017 07:46:17 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 07:46:17 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 07:46:17 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:46:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:46:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:46:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:46:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:46:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:47:20 [INFO] exp_shallowmodel: train time: 62.825s
12/10/2017 07:47:20 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:47:20 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 07:47:20 [INFO] exp_shallowmodel: f1_score:   0.343
12/10/2017 07:47:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:47:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.27      0.28        64
          C       0.17      0.07      0.10        14
          F       0.79      0.83      0.81       402
          R       0.20      0.17      0.19        63

avg / total       0.65      0.67      0.66       543

12/10/2017 07:47:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:47:20 [INFO] exp_shallowmodel: 
[[ 17   1  37   9]
 [  1   1  10   2]
 [ 33   3 334  32]
 [  8   1  43  11]]
12/10/2017 07:47:21 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 07:47:21 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:47:21 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:47:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:47:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:47:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:47:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:47:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:48:28 [INFO] exp_shallowmodel: train time: 66.703s
12/10/2017 07:48:28 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:48:28 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 07:48:28 [INFO] exp_shallowmodel: f1_score:   0.325
12/10/2017 07:48:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:48:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.17      0.18        59
          C       0.00      0.00      0.00        12
          F       0.80      0.83      0.81       396
          R       0.30      0.31      0.31        55

avg / total       0.66      0.68      0.67       522

12/10/2017 07:48:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:48:28 [INFO] exp_shallowmodel: 
[[ 10   0  40   9]
 [  1   0  11   0]
 [ 36   1 329  30]
 [  5   0  33  17]]
12/10/2017 07:48:29 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 07:48:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:48:29 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:48:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:48:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:48:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:48:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:48:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:49:39 [INFO] exp_shallowmodel: train time: 69.938s
12/10/2017 07:49:39 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:49:39 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 07:49:39 [INFO] exp_shallowmodel: f1_score:   0.370
12/10/2017 07:49:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:49:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.24      0.26        59
          C       0.20      0.08      0.12        12
          F       0.82      0.87      0.85       396
          R       0.27      0.24      0.25        55

avg / total       0.69      0.72      0.70       522

12/10/2017 07:49:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:49:39 [INFO] exp_shallowmodel: 
[[ 14   2  36   7]
 [  1   1   8   2]
 [ 24   0 346  26]
 [  8   2  32  13]]
12/10/2017 07:49:40 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 07:49:40 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:49:40 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:49:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:49:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:49:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:49:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:49:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:50:48 [INFO] exp_shallowmodel: train time: 68.241s
12/10/2017 07:50:48 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:50:48 [INFO] exp_shallowmodel: accuracy:   0.661
12/10/2017 07:50:48 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 07:50:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:50:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.22      0.22        59
          C       0.00      0.00      0.00        12
          F       0.80      0.82      0.81       396
          R       0.17      0.16      0.17        55

avg / total       0.65      0.66      0.65       522

12/10/2017 07:50:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:50:48 [INFO] exp_shallowmodel: 
[[ 13   0  41   5]
 [  3   0   8   1]
 [ 32   2 323  39]
 [ 11   1  34   9]]
12/10/2017 07:50:49 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 07:50:49 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:50:49 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:50:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:50:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:50:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:50:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:50:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:51:57 [INFO] exp_shallowmodel: train time: 67.407s
12/10/2017 07:51:57 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:51:57 [INFO] exp_shallowmodel: accuracy:   0.695
12/10/2017 07:51:57 [INFO] exp_shallowmodel: f1_score:   0.341
12/10/2017 07:51:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:51:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.22      0.25        59
          C       0.00      0.00      0.00        12
          F       0.80      0.84      0.82       396
          R       0.30      0.29      0.30        55

avg / total       0.67      0.70      0.68       522

12/10/2017 07:51:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:51:57 [INFO] exp_shallowmodel: 
[[ 13   0  41   5]
 [  0   0   9   3]
 [ 28   5 334  29]
 [  6   0  33  16]]
12/10/2017 07:51:58 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 07:51:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:51:58 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:51:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:51:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:51:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:51:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:51:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:53:06 [INFO] exp_shallowmodel: train time: 68.191s
12/10/2017 07:53:06 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:53:06 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 07:53:06 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 07:53:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:53:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.24      0.24        59
          C       0.00      0.00      0.00        12
          F       0.82      0.86      0.84       396
          R       0.26      0.22      0.24        55

avg / total       0.67      0.70      0.69       522

12/10/2017 07:53:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:53:06 [INFO] exp_shallowmodel: 
[[ 14   0  34  11]
 [  1   0   7   4]
 [ 35   3 339  19]
 [  7   1  35  12]]
12/10/2017 07:53:07 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 07:53:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:53:07 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:53:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:53:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:53:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:53:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:53:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:54:17 [INFO] exp_shallowmodel: train time: 70.182s
12/10/2017 07:54:17 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:54:17 [INFO] exp_shallowmodel: accuracy:   0.663
12/10/2017 07:54:17 [INFO] exp_shallowmodel: f1_score:   0.321
12/10/2017 07:54:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:54:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.15      0.16        59
          C       0.12      0.08      0.10        12
          F       0.81      0.82      0.81       396
          R       0.20      0.22      0.21        55

avg / total       0.66      0.66      0.66       522

12/10/2017 07:54:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:54:17 [INFO] exp_shallowmodel: 
[[  9   0  39  11]
 [  4   1   5   2]
 [ 31   5 324  36]
 [  8   2  33  12]]
12/10/2017 07:54:18 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 07:54:18 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:54:18 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:54:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:54:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:54:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:54:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:54:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:55:45 [INFO] exp_shallowmodel: train time: 86.821s
12/10/2017 07:55:45 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:55:45 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 07:55:45 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 07:55:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:55:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.31      0.31        59
          C       0.00      0.00      0.00        12
          F       0.81      0.83      0.82       396
          R       0.20      0.18      0.19        55

avg / total       0.67      0.69      0.68       522

12/10/2017 07:55:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:55:45 [INFO] exp_shallowmodel: 
[[ 18   1  31   9]
 [  0   0  10   2]
 [ 34   2 330  30]
 [  7   1  37  10]]
12/10/2017 07:55:46 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 07:55:46 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:55:46 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:55:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:55:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:55:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:55:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:55:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:56:53 [INFO] exp_shallowmodel: train time: 67.085s
12/10/2017 07:56:53 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:56:53 [INFO] exp_shallowmodel: accuracy:   0.659
12/10/2017 07:56:53 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 07:56:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:56:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.19      0.19        59
          C       0.00      0.00      0.00        12
          F       0.81      0.81      0.81       396
          R       0.18      0.20      0.19        55

avg / total       0.65      0.66      0.66       522

12/10/2017 07:56:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:56:53 [INFO] exp_shallowmodel: 
[[ 11   1  39   8]
 [  3   0   6   3]
 [ 31   4 322  39]
 [ 12   1  31  11]]
12/10/2017 07:56:55 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 07:56:55 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:56:55 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:56:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:56:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:56:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:56:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:56:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:58:05 [INFO] exp_shallowmodel: train time: 70.520s
12/10/2017 07:58:05 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:58:05 [INFO] exp_shallowmodel: accuracy:   0.684
12/10/2017 07:58:05 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 07:58:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:58:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.24      0.25        59
          C       0.00      0.00      0.00        12
          F       0.80      0.84      0.82       396
          R       0.19      0.16      0.17        55

avg / total       0.66      0.68      0.67       522

12/10/2017 07:58:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:58:05 [INFO] exp_shallowmodel: 
[[ 14   1  36   8]
 [  2   0   8   2]
 [ 31   2 334  29]
 [  7   1  38   9]]
12/10/2017 07:58:06 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 07:58:06 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 07:58:06 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:58:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:58:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:58:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:58:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:58:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:59:11 [INFO] exp_shallowmodel: train time: 64.830s
12/10/2017 07:59:11 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 07:59:11 [INFO] exp_shallowmodel: accuracy:   0.687
12/10/2017 07:59:11 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 07:59:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:59:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.23      0.26        64
          C       0.20      0.14      0.17        14
          F       0.80      0.85      0.82       402
          R       0.30      0.25      0.28        63

avg / total       0.66      0.69      0.67       543

12/10/2017 07:59:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:59:11 [INFO] exp_shallowmodel: 
[[ 15   2  40   7]
 [  2   2   9   1]
 [ 27   6 340  29]
 [  9   0  38  16]]
12/10/2017 07:59:12 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 07:59:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:59:12 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 07:59:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:59:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:59:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:59:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:59:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:00:46 [INFO] exp_shallowmodel: train time: 94.023s
12/10/2017 08:00:46 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:00:46 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 08:00:46 [INFO] exp_shallowmodel: f1_score:   0.308
12/10/2017 08:00:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:00:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.16      0.14      0.15        59
          C       0.12      0.08      0.10        12
          F       0.82      0.84      0.83       396
          R       0.15      0.16      0.16        55

avg / total       0.66      0.67      0.66       522

12/10/2017 08:00:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:00:46 [INFO] exp_shallowmodel: 
[[  8   0  35  16]
 [  2   1   7   2]
 [ 28   5 331  32]
 [ 11   2  33   9]]
12/10/2017 08:00:47 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 08:00:47 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:00:47 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:00:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:00:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:00:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:00:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:00:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:01:48 [INFO] exp_shallowmodel: train time: 60.501s
12/10/2017 08:01:48 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:01:48 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 08:01:48 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 08:01:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:01:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.32      0.33        59
          C       0.25      0.08      0.12        12
          F       0.82      0.83      0.83       396
          R       0.30      0.33      0.31        55

avg / total       0.70      0.70      0.70       522

12/10/2017 08:01:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:01:48 [INFO] exp_shallowmodel: 
[[ 19   0  36   4]
 [  2   1   4   5]
 [ 29   3 330  34]
 [  6   0  31  18]]
12/10/2017 08:01:49 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 08:01:49 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:01:49 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:01:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:01:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:01:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:01:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:01:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:02:56 [INFO] exp_shallowmodel: train time: 67.010s
12/10/2017 08:02:56 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:02:56 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 08:02:56 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 08:02:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:02:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.19      0.18        59
          C       0.00      0.00      0.00        12
          F       0.80      0.83      0.82       396
          R       0.17      0.15      0.16        55

avg / total       0.65      0.67      0.66       522

12/10/2017 08:02:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:02:56 [INFO] exp_shallowmodel: 
[[ 11   1  36  11]
 [  2   0   8   2]
 [ 39   2 330  25]
 [ 10   0  37   8]]
12/10/2017 08:02:57 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 08:02:57 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:02:57 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:02:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:02:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:02:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:02:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:02:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:04:09 [INFO] exp_shallowmodel: train time: 72.144s
12/10/2017 08:04:09 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:04:09 [INFO] exp_shallowmodel: accuracy:   0.684
12/10/2017 08:04:09 [INFO] exp_shallowmodel: f1_score:   0.303
12/10/2017 08:04:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:04:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.12      0.14        59
          C       0.00      0.00      0.00        12
          F       0.80      0.85      0.82       396
          R       0.25      0.25      0.25        55

avg / total       0.65      0.68      0.67       522

12/10/2017 08:04:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:04:09 [INFO] exp_shallowmodel: 
[[  7   1  43   8]
 [  3   0   9   0]
 [ 25   1 336  34]
 [  7   1  33  14]]
12/10/2017 08:04:10 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 08:04:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:04:10 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:04:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:04:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:04:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:04:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:04:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:05:21 [INFO] exp_shallowmodel: train time: 71.155s
12/10/2017 08:05:21 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:05:21 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 08:05:21 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 08:05:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:05:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.17      0.18        59
          C       0.33      0.08      0.13        12
          F       0.81      0.85      0.83       396
          R       0.19      0.18      0.19        55

avg / total       0.66      0.68      0.67       522

12/10/2017 08:05:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:05:21 [INFO] exp_shallowmodel: 
[[ 10   0  38  11]
 [  3   1   8   0]
 [ 28   1 335  32]
 [ 12   1  32  10]]
12/10/2017 08:05:23 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 08:05:23 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:05:23 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:05:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:05:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:05:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:05:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:05:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:06:30 [INFO] exp_shallowmodel: train time: 66.914s
12/10/2017 08:06:30 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:06:30 [INFO] exp_shallowmodel: accuracy:   0.663
12/10/2017 08:06:30 [INFO] exp_shallowmodel: f1_score:   0.335
12/10/2017 08:06:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:06:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.15      0.15        59
          C       0.09      0.08      0.09        12
          F       0.81      0.81      0.81       396
          R       0.30      0.29      0.30        55

avg / total       0.67      0.66      0.66       522

12/10/2017 08:06:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:06:30 [INFO] exp_shallowmodel: 
[[  9   4  39   7]
 [  2   1   8   1]
 [ 41   6 320  29]
 [ 12   0  27  16]]
12/10/2017 08:06:31 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 08:06:31 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:06:31 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:06:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:06:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:06:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:06:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:06:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:07:36 [INFO] exp_shallowmodel: train time: 65.571s
12/10/2017 08:07:36 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:07:36 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 08:07:36 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 08:07:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:07:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.19      0.21        59
          C       0.00      0.00      0.00        12
          F       0.79      0.85      0.82       396
          R       0.26      0.20      0.22        55

avg / total       0.66      0.69      0.67       522

12/10/2017 08:07:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:07:36 [INFO] exp_shallowmodel: 
[[ 11   2  42   4]
 [  0   0  11   1]
 [ 29   2 338  27]
 [  7   2  35  11]]
12/10/2017 08:07:37 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 08:07:37 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:07:37 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:07:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:07:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:07:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:07:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:07:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:08:51 [INFO] exp_shallowmodel: train time: 73.396s
12/10/2017 08:08:51 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:08:51 [INFO] exp_shallowmodel: accuracy:   0.674
12/10/2017 08:08:51 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 08:08:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:08:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.19      0.19        59
          C       0.00      0.00      0.00        12
          F       0.81      0.83      0.82       396
          R       0.26      0.25      0.26        55

avg / total       0.66      0.67      0.67       522

12/10/2017 08:08:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:08:51 [INFO] exp_shallowmodel: 
[[ 11   1  40   7]
 [  1   0   9   2]
 [ 37   1 327  31]
 [ 10   1  30  14]]
12/10/2017 08:08:52 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 08:08:52 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:08:52 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:08:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:08:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:08:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:08:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:08:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:10:01 [INFO] exp_shallowmodel: train time: 69.401s
12/10/2017 08:10:01 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:10:01 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 08:10:01 [INFO] exp_shallowmodel: f1_score:   0.367
12/10/2017 08:10:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:10:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.29      0.31        59
          C       0.17      0.08      0.11        12
          F       0.83      0.86      0.84       396
          R       0.21      0.20      0.20        55

avg / total       0.69      0.71      0.70       522

12/10/2017 08:10:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:10:01 [INFO] exp_shallowmodel: 
[[ 17   0  30  12]
 [  2   1   6   3]
 [ 25   3 341  27]
 [  6   2  36  11]]
12/10/2017 08:10:02 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 08:10:02 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 08:10:02 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:10:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:10:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:10:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:10:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:10:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:11:06 [INFO] exp_shallowmodel: train time: 63.267s
12/10/2017 08:11:06 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:11:06 [INFO] exp_shallowmodel: accuracy:   0.685
12/10/2017 08:11:06 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 08:11:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:11:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.22      0.23        64
          C       0.00      0.00      0.00        14
          F       0.81      0.85      0.83       402
          R       0.25      0.24      0.25        63

avg / total       0.66      0.69      0.67       543

12/10/2017 08:11:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:11:06 [INFO] exp_shallowmodel: 
[[ 14   2  40   8]
 [  5   0   6   3]
 [ 23   3 343  33]
 [ 15   0  33  15]]
12/10/2017 08:11:07 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 08:11:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:11:07 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:11:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:11:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:11:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:11:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:11:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:12:14 [INFO] exp_shallowmodel: train time: 66.827s
12/10/2017 08:12:14 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:12:14 [INFO] exp_shallowmodel: accuracy:   0.692
12/10/2017 08:12:14 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 08:12:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:12:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.17      0.19        59
          C       0.00      0.00      0.00        12
          F       0.82      0.85      0.83       396
          R       0.29      0.29      0.29        55

avg / total       0.67      0.69      0.68       522

12/10/2017 08:12:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:12:14 [INFO] exp_shallowmodel: 
[[ 10   0  38  11]
 [  2   0   9   1]
 [ 28   6 335  27]
 [  9   1  29  16]]
12/10/2017 08:12:15 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 08:12:15 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:12:15 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:12:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:12:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:12:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:12:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:12:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:13:19 [INFO] exp_shallowmodel: train time: 64.316s
12/10/2017 08:13:19 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:13:19 [INFO] exp_shallowmodel: accuracy:   0.665
12/10/2017 08:13:19 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 08:13:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:13:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.22      0.23        59
          C       0.00      0.00      0.00        12
          F       0.79      0.83      0.81       396
          R       0.15      0.13      0.14        55

avg / total       0.64      0.66      0.65       522

12/10/2017 08:13:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:13:19 [INFO] exp_shallowmodel: 
[[ 13   2  34  10]
 [  3   0   9   0]
 [ 34   4 327  31]
 [  5   0  43   7]]
12/10/2017 08:13:20 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 08:13:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:13:20 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:13:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:13:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:13:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:13:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:13:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:14:30 [INFO] exp_shallowmodel: train time: 69.732s
12/10/2017 08:14:30 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:14:30 [INFO] exp_shallowmodel: accuracy:   0.684
12/10/2017 08:14:30 [INFO] exp_shallowmodel: f1_score:   0.304
12/10/2017 08:14:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:14:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.24      0.24        59
          C       0.00      0.00      0.00        12
          F       0.79      0.85      0.82       396
          R       0.19      0.13      0.15        55

avg / total       0.65      0.68      0.67       522

12/10/2017 08:14:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:14:30 [INFO] exp_shallowmodel: 
[[ 14   2  38   5]
 [  1   0  11   0]
 [ 34   2 336  24]
 [  7   3  38   7]]
12/10/2017 08:14:31 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 08:14:31 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:14:31 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:14:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:14:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:14:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:14:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:14:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:15:39 [INFO] exp_shallowmodel: train time: 67.507s
12/10/2017 08:15:39 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:15:39 [INFO] exp_shallowmodel: accuracy:   0.670
12/10/2017 08:15:39 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 08:15:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:15:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.15      0.15        59
          C       0.00      0.00      0.00        12
          F       0.83      0.84      0.83       396
          R       0.19      0.18      0.18        55

avg / total       0.66      0.67      0.67       522

12/10/2017 08:15:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:15:39 [INFO] exp_shallowmodel: 
[[  9   3  36  11]
 [  7   0   4   1]
 [ 32   1 331  32]
 [ 15   1  29  10]]
12/10/2017 08:15:40 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 08:15:40 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:15:40 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:15:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:15:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:15:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:15:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:15:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:16:48 [INFO] exp_shallowmodel: train time: 67.984s
12/10/2017 08:16:48 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:16:48 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 08:16:48 [INFO] exp_shallowmodel: f1_score:   0.355
12/10/2017 08:16:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:16:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.20      0.22        59
          C       0.20      0.08      0.12        12
          F       0.81      0.85      0.83       396
          R       0.25      0.25      0.25        55

avg / total       0.68      0.69      0.68       522

12/10/2017 08:16:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:16:48 [INFO] exp_shallowmodel: 
[[ 12   0  38   9]
 [  3   1   4   4]
 [ 27   4 335  30]
 [  6   0  35  14]]
12/10/2017 08:16:49 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 08:16:49 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:16:49 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:16:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:16:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:16:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:16:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:16:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:17:55 [INFO] exp_shallowmodel: train time: 66.405s
12/10/2017 08:17:55 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:17:55 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 08:17:55 [INFO] exp_shallowmodel: f1_score:   0.295
12/10/2017 08:17:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:17:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.20      0.20        59
          C       0.00      0.00      0.00        12
          F       0.81      0.85      0.83       396
          R       0.17      0.13      0.15        55

avg / total       0.66      0.68      0.67       522

12/10/2017 08:17:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:17:55 [INFO] exp_shallowmodel: 
[[ 12   2  38   7]
 [  2   0   7   3]
 [ 33   2 337  24]
 [ 12   2  34   7]]
12/10/2017 08:17:56 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 08:17:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:17:56 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:17:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:17:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:17:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:17:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:17:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:19:01 [INFO] exp_shallowmodel: train time: 65.000s
12/10/2017 08:19:01 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:19:01 [INFO] exp_shallowmodel: accuracy:   0.680
12/10/2017 08:19:01 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 08:19:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:19:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.17      0.19        59
          C       0.38      0.25      0.30        12
          F       0.81      0.82      0.81       396
          R       0.29      0.33      0.31        55

avg / total       0.67      0.68      0.68       522

12/10/2017 08:19:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:19:01 [INFO] exp_shallowmodel: 
[[ 10   0  38  11]
 [  1   3   7   1]
 [ 35   4 324  33]
 [  3   1  33  18]]
12/10/2017 08:19:02 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 08:19:02 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:19:02 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:19:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:19:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:19:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:19:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:19:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:20:09 [INFO] exp_shallowmodel: train time: 66.648s
12/10/2017 08:20:09 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:20:09 [INFO] exp_shallowmodel: accuracy:   0.697
12/10/2017 08:20:09 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 08:20:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:20:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.24      0.25        59
          C       0.00      0.00      0.00        12
          F       0.82      0.85      0.83       396
          R       0.25      0.24      0.24        55

avg / total       0.67      0.70      0.69       522

12/10/2017 08:20:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:20:09 [INFO] exp_shallowmodel: 
[[ 14   0  35  10]
 [  0   0  10   2]
 [ 28   3 337  28]
 [ 11   0  31  13]]
12/10/2017 08:20:10 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 08:20:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:20:10 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:20:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:20:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:20:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:20:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:20:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:21:18 [INFO] exp_shallowmodel: train time: 67.868s
12/10/2017 08:21:18 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:21:18 [INFO] exp_shallowmodel: accuracy:   0.692
12/10/2017 08:21:18 [INFO] exp_shallowmodel: f1_score:   0.348
12/10/2017 08:21:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:21:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.17      0.19        59
          C       0.20      0.08      0.12        12
          F       0.80      0.85      0.83       396
          R       0.27      0.25      0.26        55

avg / total       0.67      0.69      0.68       522

12/10/2017 08:21:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:21:18 [INFO] exp_shallowmodel: 
[[ 10   0  40   9]
 [  3   1   8   0]
 [ 27   4 336  29]
 [  7   0  34  14]]
12/10/2017 08:21:19 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 08:21:19 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 08:21:19 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:21:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:21:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:21:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:21:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:21:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:22:25 [INFO] exp_shallowmodel: train time: 65.966s
12/10/2017 08:22:25 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:22:25 [INFO] exp_shallowmodel: accuracy:   0.692
12/10/2017 08:22:25 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 08:22:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:22:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.28      0.30        64
          C       0.40      0.14      0.21        14
          F       0.81      0.85      0.83       402
          R       0.24      0.22      0.23        63

avg / total       0.67      0.69      0.68       543

12/10/2017 08:22:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:22:25 [INFO] exp_shallowmodel: 
[[ 18   0  36  10]
 [  1   2   7   4]
 [ 28   2 342  30]
 [ 11   1  37  14]]
12/10/2017 08:22:26 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 08:22:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:22:26 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:22:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:22:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:22:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:22:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:22:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:23:38 [INFO] exp_shallowmodel: train time: 71.202s
12/10/2017 08:23:38 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:23:38 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 08:23:38 [INFO] exp_shallowmodel: f1_score:   0.366
12/10/2017 08:23:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:23:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.27      0.27        59
          C       0.50      0.08      0.14        12
          F       0.81      0.84      0.82       396
          R       0.24      0.22      0.23        55

avg / total       0.68      0.69      0.68       522

12/10/2017 08:23:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:23:38 [INFO] exp_shallowmodel: 
[[ 16   0  34   9]
 [  3   1   7   1]
 [ 35   1 331  29]
 [  4   0  39  12]]
12/10/2017 08:23:39 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 08:23:39 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:23:39 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:23:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:23:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:23:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:23:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:23:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:24:42 [INFO] exp_shallowmodel: train time: 63.001s
12/10/2017 08:24:42 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:24:42 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 08:24:42 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 08:24:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:24:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.10      0.12        59
          C       0.20      0.08      0.12        12
          F       0.82      0.86      0.84       396
          R       0.30      0.31      0.31        55

avg / total       0.67      0.70      0.69       522

12/10/2017 08:24:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:24:42 [INFO] exp_shallowmodel: 
[[  6   2  43   8]
 [  2   1   7   2]
 [ 25   1 341  29]
 [ 12   1  25  17]]
12/10/2017 08:24:43 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 08:24:43 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:24:43 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:24:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:24:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:24:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:24:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:24:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:25:48 [INFO] exp_shallowmodel: train time: 64.723s
12/10/2017 08:25:48 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:25:48 [INFO] exp_shallowmodel: accuracy:   0.692
12/10/2017 08:25:48 [INFO] exp_shallowmodel: f1_score:   0.340
12/10/2017 08:25:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:25:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.31      0.29        59
          C       0.00      0.00      0.00        12
          F       0.83      0.83      0.83       396
          R       0.23      0.24      0.23        55

avg / total       0.69      0.69      0.69       522

12/10/2017 08:25:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:25:48 [INFO] exp_shallowmodel: 
[[ 18   3  26  12]
 [  0   0  11   1]
 [ 34   2 330  30]
 [ 12   0  30  13]]
12/10/2017 08:25:49 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 08:25:49 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:25:49 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:25:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:25:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:25:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:25:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:25:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:26:56 [INFO] exp_shallowmodel: train time: 67.793s
12/10/2017 08:26:56 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:26:56 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 08:26:56 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 08:26:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:26:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.22      0.23        59
          C       0.00      0.00      0.00        12
          F       0.80      0.84      0.82       396
          R       0.24      0.22      0.23        55

avg / total       0.66      0.68      0.67       522

12/10/2017 08:26:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:26:56 [INFO] exp_shallowmodel: 
[[ 13   1  38   7]
 [  2   0   9   1]
 [ 31   5 331  29]
 [  8   0  35  12]]
12/10/2017 08:26:58 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 08:26:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:26:58 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:26:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:26:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:26:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:26:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:26:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:28:05 [INFO] exp_shallowmodel: train time: 67.488s
12/10/2017 08:28:05 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:28:05 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 08:28:05 [INFO] exp_shallowmodel: f1_score:   0.352
12/10/2017 08:28:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:28:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.22      0.25        59
          C       0.00      0.00      0.00        12
          F       0.81      0.85      0.83       396
          R       0.32      0.33      0.32        55

avg / total       0.68      0.71      0.69       522

12/10/2017 08:28:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:28:05 [INFO] exp_shallowmodel: 
[[ 13   1  39   6]
 [  1   0   9   2]
 [ 23   4 338  31]
 [  6   0  31  18]]
12/10/2017 08:28:06 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 08:28:06 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:28:06 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:28:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:28:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:28:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:28:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:28:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:29:10 [INFO] exp_shallowmodel: train time: 63.611s
12/10/2017 08:29:10 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:29:10 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 08:29:10 [INFO] exp_shallowmodel: f1_score:   0.283
12/10/2017 08:29:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:29:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.19      0.20        59
          C       0.00      0.00      0.00        12
          F       0.79      0.84      0.81       396
          R       0.12      0.11      0.12        55

avg / total       0.64      0.67      0.65       522

12/10/2017 08:29:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:29:10 [INFO] exp_shallowmodel: 
[[ 11   2  36  10]
 [  1   0   8   3]
 [ 31   3 332  30]
 [  6   0  43   6]]
12/10/2017 08:29:11 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 08:29:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:29:11 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:29:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:29:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:29:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:29:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:29:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:30:19 [INFO] exp_shallowmodel: train time: 67.857s
12/10/2017 08:30:19 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:30:19 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 08:30:19 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 08:30:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:30:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.16      0.15      0.16        59
          C       0.00      0.00      0.00        12
          F       0.82      0.86      0.84       396
          R       0.27      0.25      0.26        55

avg / total       0.67      0.69      0.68       522

12/10/2017 08:30:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:30:19 [INFO] exp_shallowmodel: 
[[  9   1  37  12]
 [  2   0   6   4]
 [ 34   1 339  22]
 [ 10   0  31  14]]
12/10/2017 08:30:20 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 08:30:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:30:20 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:30:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:30:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:30:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:30:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:30:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:31:25 [INFO] exp_shallowmodel: train time: 65.482s
12/10/2017 08:31:25 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:31:25 [INFO] exp_shallowmodel: accuracy:   0.680
12/10/2017 08:31:25 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 08:31:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:31:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.22      0.23        59
          C       0.00      0.00      0.00        12
          F       0.79      0.85      0.82       396
          R       0.12      0.09      0.10        55

avg / total       0.64      0.68      0.66       522

12/10/2017 08:31:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:31:25 [INFO] exp_shallowmodel: 
[[ 13   2  40   4]
 [  0   0  11   1]
 [ 25   3 337  31]
 [ 14   0  36   5]]
12/10/2017 08:31:26 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 08:31:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:31:26 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:31:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:31:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:31:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:31:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:31:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:32:33 [INFO] exp_shallowmodel: train time: 66.895s
12/10/2017 08:32:33 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:32:33 [INFO] exp_shallowmodel: accuracy:   0.672
12/10/2017 08:32:33 [INFO] exp_shallowmodel: f1_score:   0.297
12/10/2017 08:32:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:32:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.24      0.24        59
          C       0.00      0.00      0.00        12
          F       0.80      0.83      0.82       396
          R       0.15      0.13      0.14        55

avg / total       0.65      0.67      0.66       522

12/10/2017 08:32:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:32:33 [INFO] exp_shallowmodel: 
[[ 14   1  33  11]
 [  1   0  10   1]
 [ 37   1 330  28]
 [  8   1  39   7]]
12/10/2017 08:32:34 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 08:32:34 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 08:32:34 [INFO] exp_shallowmodel: #(feature) = 7200
12/10/2017 08:32:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:32:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:32:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:32:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:32:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:33:44 [INFO] exp_shallowmodel: train time: 69.138s
12/10/2017 08:33:44 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 08:33:44 [INFO] exp_shallowmodel: accuracy:   0.672
12/10/2017 08:33:44 [INFO] exp_shallowmodel: f1_score:   0.342
12/10/2017 08:33:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:33:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.27      0.29        64
          C       0.11      0.07      0.09        14
          F       0.81      0.84      0.82       402
          R       0.17      0.17      0.17        63

avg / total       0.66      0.67      0.66       543

12/10/2017 08:33:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:33:44 [INFO] exp_shallowmodel: 
[[ 17   0  37  10]
 [  1   1   7   5]
 [ 22   6 336  38]
 [ 14   2  36  11]]
