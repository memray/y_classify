/ihome/pbrusilosky/rum20/packages/anaconda3/bin/python -m dialogue.classify.task_runner -selected_feature_set_id 10 -selected_context_id 1
No. of param settings = 1
[('deep_model', False), ('selected_context_id', 1), ('selected_feature_set_id', 10), ('similarity_feature', False)]
12/17/2017 20:11:50 [INFO] configuration: deep_model  :   False
12/17/2017 20:11:50 [INFO] configuration: selected_context_id  :   1
12/17/2017 20:11:50 [INFO] configuration: selected_feature_set_id  :   10
12/17/2017 20:11:50 [INFO] configuration: similarity_feature  :   False
12/17/2017 20:11:50 [INFO] configuration: seed  :   154316847
12/17/2017 20:11:50 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/17/2017 20:11:50 [INFO] configuration: task_name  :   utterance_type
12/17/2017 20:11:50 [INFO] configuration: timemark  :   20171217-201150
12/17/2017 20:11:50 [INFO] configuration: context_set  :   current
12/17/2017 20:11:50 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/17/2017 20:11:50 [INFO] configuration: utterance_range  :   ['current_user_utterance']
12/17/2017 20:11:50 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/17/2017 20:11:50 [INFO] configuration: feature_set  :   10-[5+1.3.4]
12/17/2017 20:11:50 [INFO] configuration: feature_set_number  :   ['1', '2', '3', '5', '6', '7', '8']
12/17/2017 20:11:50 [INFO] configuration: experiment_name  :   20171217-201150.context=current.feature=10-[5+1.3.4].similarity=false
12/17/2017 20:11:50 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171217-201150.context=current.feature=10-[5+1.3.4].similarity=false
12/17/2017 20:11:50 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171217-201150.context=current.feature=10-[5+1.3.4].similarity=false/output.log
12/17/2017 20:11:50 [INFO] configuration: valid_type  :   {'R', 'A', 'C', 'F'}
12/17/2017 20:11:50 [INFO] configuration: data_name  :   
12/17/2017 20:11:50 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/17/2017 20:11:50 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/17/2017 20:11:50 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/17/2017 20:11:50 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/17/2017 20:11:50 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/17/2017 20:11:50 [INFO] configuration: do_cross_validation  :   True
12/17/2017 20:11:50 [INFO] configuration: #division  :   5
12/17/2017 20:11:50 [INFO] configuration: #cross_validation  :   10
12/17/2017 20:11:50 [INFO] configuration: cv_index_cache_path  :   
12/17/2017 20:11:50 [INFO] configuration: action_words  :   {'remov', 'time', 'skip', 'cheap', 'remind', 'part', 'moder', 'telephone', 'timer', 'clear', 'reminds', 'ani', 'watch', 'shuffle', 'moderate', 'volum', 'next', 'centre', 'tell', 'video', 'start', 'expens', 'turn', 'alarm', 'telephon', 'item', 'temperatur', 'show', 'help', 'findcare', 'matter', 'area', 'play', 'remove', 'south', 'snooze', 'reminders', 'discard', 'member', 'els', 'north', 'song', 'reminder', 'centr', 'phone', 'add', 'weather', 'address', 'delet', 'food', 'shuffl', 'items', 'else', 'post', 'snooz', 'findcar', 'room', 'cast', 'price', 'temperature', 'any', 'delete', 'list', 'music', 'expensive', 'number', 'share', 'stop', 'light', 'volume'}
12/17/2017 20:11:50 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/17/2017 20:11:50 [INFO] configuration: lda_topic_number  :   50
12/17/2017 20:11:50 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/17/2017 20:11:50 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/17/2017 20:11:50 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/17/2017 20:11:50 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/17/2017 20:11:50 [INFO] configuration: w2v_vector_length  :   300
12/17/2017 20:11:50 [INFO] configuration: d2v_vector_length  :   300
12/17/2017 20:11:50 [INFO] configuration: d2v_window_size  :   5
12/17/2017 20:11:50 [INFO] configuration: d2v_min_count  :   2
12/17/2017 20:11:50 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/17/2017 20:11:50 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/17/2017 20:11:50 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/17/2017 20:11:50 [INFO] configuration: batch_size  :   128
12/17/2017 20:11:50 [INFO] configuration: max_epoch  :   50
12/17/2017 20:11:50 [INFO] configuration: early_stop_tolerance  :   2
12/17/2017 20:11:50 [INFO] configuration: concat_sents  :   True
12/17/2017 20:11:50 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/17/2017 20:11:50 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 1, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/17/2017 20:11:50 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/17/2017 20:11:55 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 20:11:55 [INFO] task_runner: context=current, feature=10-[5+1.3.4]
12/17/2017 20:11:55 [INFO] task_runner: retained feature numbers=[8.1, 6, 3, 2.2, 1, 7, 5, 2.1]
12/17/2017 20:11:55 [INFO] task_runner: #(data)=5725
12/17/2017 20:11:55 [INFO] task_runner: #(feature)=1090
12/17/2017 20:11:55 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 20:11:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/17/2017 20:11:56 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:11:56 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:11:56 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:11:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:11:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:11:56 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:11:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:13:33 [INFO] exp_shallowmodel: train time: 97.550s
12/17/2017 20:13:33 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:13:33 [INFO] exp_shallowmodel: accuracy:   0.664
12/17/2017 20:13:33 [INFO] exp_shallowmodel: f1_score:   0.465
12/17/2017 20:13:33 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:13:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.68      0.66       164
          F       0.73      0.82      0.78       268
          R       0.49      0.37      0.42       125

avg / total       0.64      0.66      0.65       571

12/17/2017 20:13:33 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:13:33 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 112  27  25]
 [  0  26 221  21]
 [  3  34  42  46]]
12/17/2017 20:13:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/17/2017 20:13:34 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:13:34 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:13:34 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:13:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:13:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:13:34 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:13:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:15:07 [INFO] exp_shallowmodel: train time: 93.723s
12/17/2017 20:15:07 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:15:07 [INFO] exp_shallowmodel: accuracy:   0.641
12/17/2017 20:15:07 [INFO] exp_shallowmodel: f1_score:   0.476
12/17/2017 20:15:07 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:15:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.60      0.66      0.63       164
          F       0.72      0.78      0.75       268
          R       0.51      0.38      0.43       125

avg / total       0.63      0.64      0.63       571

12/17/2017 20:15:07 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:15:07 [INFO] exp_shallowmodel: 
[[  1   3   9   1]
 [  2 108  25  29]
 [  3  40 210  15]
 [  1  30  47  47]]
12/17/2017 20:15:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/17/2017 20:15:08 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:15:08 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:15:08 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:15:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:15:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:15:08 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:15:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:16:49 [INFO] exp_shallowmodel: train time: 101.312s
12/17/2017 20:16:49 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:16:49 [INFO] exp_shallowmodel: accuracy:   0.662
12/17/2017 20:16:49 [INFO] exp_shallowmodel: f1_score:   0.487
12/17/2017 20:16:49 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:16:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.60      0.68      0.64       164
          F       0.75      0.83      0.79       268
          R       0.51      0.35      0.42       125

avg / total       0.64      0.66      0.65       571

12/17/2017 20:16:49 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:16:49 [INFO] exp_shallowmodel: 
[[  1   4   6   3]
 [  2 111  31  20]
 [  1  26 222  19]
 [  1  43  37  44]]
12/17/2017 20:16:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/17/2017 20:16:49 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:16:49 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:16:49 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:16:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:16:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:16:49 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:16:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:18:45 [INFO] exp_shallowmodel: train time: 115.798s
12/17/2017 20:18:45 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:18:45 [INFO] exp_shallowmodel: accuracy:   0.637
12/17/2017 20:18:45 [INFO] exp_shallowmodel: f1_score:   0.497
12/17/2017 20:18:45 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:18:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.14      0.21        14
          C       0.59      0.62      0.60       164
          F       0.72      0.80      0.76       268
          R       0.47      0.37      0.41       125

avg / total       0.62      0.64      0.63       571

12/17/2017 20:18:45 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:18:45 [INFO] exp_shallowmodel: 
[[  2   1   8   3]
 [  0 101  36  27]
 [  1  31 215  21]
 [  2  38  39  46]]
12/17/2017 20:18:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/17/2017 20:18:46 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:18:46 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:18:46 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:18:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:18:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:18:46 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:18:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:20:52 [INFO] exp_shallowmodel: train time: 126.462s
12/17/2017 20:20:52 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:20:52 [INFO] exp_shallowmodel: accuracy:   0.622
12/17/2017 20:20:52 [INFO] exp_shallowmodel: f1_score:   0.440
12/17/2017 20:20:52 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:20:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.65      0.61       164
          F       0.72      0.75      0.73       268
          R       0.47      0.38      0.42       125

avg / total       0.60      0.62      0.61       571

12/17/2017 20:20:52 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:20:52 [INFO] exp_shallowmodel: 
[[  0   5   8   1]
 [  0 107  31  26]
 [  2  40 201  25]
 [  2  36  40  47]]
12/17/2017 20:20:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/17/2017 20:20:52 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:20:52 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:20:52 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:20:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:20:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:20:52 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:20:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:22:06 [INFO] exp_shallowmodel: train time: 73.637s
12/17/2017 20:22:06 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:22:06 [INFO] exp_shallowmodel: accuracy:   0.609
12/17/2017 20:22:06 [INFO] exp_shallowmodel: f1_score:   0.435
12/17/2017 20:22:06 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:22:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.62      0.59       164
          F       0.70      0.75      0.72       268
          R       0.51      0.36      0.42       125

avg / total       0.60      0.61      0.60       571

12/17/2017 20:22:06 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:22:06 [INFO] exp_shallowmodel: 
[[  0   3   9   2]
 [  5 102  36  21]
 [  5  42 201  20]
 [  5  32  43  45]]
12/17/2017 20:22:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/17/2017 20:22:06 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:22:06 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:22:06 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:22:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:22:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:22:06 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:22:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:22:59 [INFO] exp_shallowmodel: train time: 52.840s
12/17/2017 20:22:59 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:22:59 [INFO] exp_shallowmodel: accuracy:   0.678
12/17/2017 20:22:59 [INFO] exp_shallowmodel: f1_score:   0.478
12/17/2017 20:22:59 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:22:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.74      0.69       164
          F       0.76      0.81      0.78       268
          R       0.50      0.38      0.43       125

avg / total       0.65      0.68      0.66       571

12/17/2017 20:22:59 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:22:59 [INFO] exp_shallowmodel: 
[[  0   1   7   6]
 [  0 121  25  18]
 [  2  24 218  24]
 [  0  39  38  48]]
12/17/2017 20:22:59 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/17/2017 20:22:59 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:22:59 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:22:59 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:22:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:22:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:22:59 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:22:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:23:40 [INFO] exp_shallowmodel: train time: 40.987s
12/17/2017 20:23:40 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:23:40 [INFO] exp_shallowmodel: accuracy:   0.641
12/17/2017 20:23:40 [INFO] exp_shallowmodel: f1_score:   0.499
12/17/2017 20:23:40 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:23:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.14      0.22        14
          C       0.62      0.63      0.62       164
          F       0.72      0.81      0.76       268
          R       0.44      0.34      0.39       125

avg / total       0.62      0.64      0.63       571

12/17/2017 20:23:40 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:23:40 [INFO] exp_shallowmodel: 
[[  2   3   6   3]
 [  0 104  30  30]
 [  2  27 217  22]
 [  0  35  47  43]]
12/17/2017 20:23:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/17/2017 20:23:40 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:23:40 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:23:40 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:23:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:23:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:23:40 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:23:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:24:13 [INFO] exp_shallowmodel: train time: 32.565s
12/17/2017 20:24:13 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:24:13 [INFO] exp_shallowmodel: accuracy:   0.662
12/17/2017 20:24:13 [INFO] exp_shallowmodel: f1_score:   0.496
12/17/2017 20:24:13 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:24:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.64      0.71      0.67       164
          F       0.71      0.80      0.75       268
          R       0.54      0.37      0.44       125

avg / total       0.64      0.66      0.65       571

12/17/2017 20:24:13 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:24:13 [INFO] exp_shallowmodel: 
[[  1   1  11   1]
 [  0 116  26  22]
 [  0  37 215  16]
 [  2  26  51  46]]
12/17/2017 20:24:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/17/2017 20:24:13 [INFO] exp_shallowmodel: #(data) = 4568
12/17/2017 20:24:13 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:24:13 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:24:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:24:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:24:13 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:24:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:24:58 [INFO] exp_shallowmodel: train time: 44.850s
12/17/2017 20:24:58 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:24:58 [INFO] exp_shallowmodel: accuracy:   0.638
12/17/2017 20:24:58 [INFO] exp_shallowmodel: f1_score:   0.452
12/17/2017 20:24:58 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:24:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.57      0.64      0.61       169
          F       0.71      0.79      0.75       271
          R       0.54      0.38      0.45       130

avg / total       0.61      0.64      0.62       586

12/17/2017 20:24:58 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:24:58 [INFO] exp_shallowmodel: 
[[  0   1   8   7]
 [  0 109  39  21]
 [  1  41 215  14]
 [  0  40  40  50]]
12/17/2017 20:24:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/17/2017 20:24:58 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:24:58 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:24:58 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:24:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:24:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:24:58 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:24:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:25:45 [INFO] exp_shallowmodel: train time: 47.197s
12/17/2017 20:25:45 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:25:45 [INFO] exp_shallowmodel: accuracy:   0.622
12/17/2017 20:25:45 [INFO] exp_shallowmodel: f1_score:   0.427
12/17/2017 20:25:45 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:25:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.66      0.61       164
          F       0.72      0.79      0.75       268
          R       0.44      0.28      0.34       125

avg / total       0.60      0.62      0.60       571

12/17/2017 20:25:45 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:25:45 [INFO] exp_shallowmodel: 
[[  0   0  12   2]
 [  4 109  28  23]
 [  2  35 211  20]
 [  1  47  42  35]]
12/17/2017 20:25:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/17/2017 20:25:46 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:25:46 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:25:46 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:25:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:25:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:25:46 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:25:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:26:30 [INFO] exp_shallowmodel: train time: 44.036s
12/17/2017 20:26:30 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 20:26:30 [INFO] exp_shallowmodel: accuracy:   0.629
12/17/2017 20:26:30 [INFO] exp_shallowmodel: f1_score:   0.447
12/17/2017 20:26:30 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:26:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.65      0.61       164
          F       0.71      0.76      0.74       268
          R       0.52      0.39      0.45       125

avg / total       0.61      0.63      0.62       571

12/17/2017 20:26:30 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:26:30 [INFO] exp_shallowmodel: 
[[  0   0  11   3]
 [  0 106  37  21]
 [  1  41 204  22]
 [  2  39  35  49]]
12/17/2017 20:26:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/17/2017 20:26:30 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:26:30 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:26:30 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:26:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:26:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:26:30 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:26:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:27:24 [INFO] exp_shallowmodel: train time: 54.038s
12/17/2017 20:27:24 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:27:24 [INFO] exp_shallowmodel: accuracy:   0.606
12/17/2017 20:27:24 [INFO] exp_shallowmodel: f1_score:   0.425
12/17/2017 20:27:24 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:27:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.63      0.60       164
          F       0.68      0.75      0.71       268
          R       0.46      0.33      0.38       125

avg / total       0.59      0.61      0.59       571

12/17/2017 20:27:24 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:27:24 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  1 104  37  22]
 [  1  43 201  23]
 [  4  30  50  41]]
12/17/2017 20:27:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/17/2017 20:27:24 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:27:24 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:27:24 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:27:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:27:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:27:24 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:27:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:28:15 [INFO] exp_shallowmodel: train time: 50.547s
12/17/2017 20:28:15 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:28:15 [INFO] exp_shallowmodel: accuracy:   0.676
12/17/2017 20:28:15 [INFO] exp_shallowmodel: f1_score:   0.480
12/17/2017 20:28:15 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:28:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.65      0.63       164
          F       0.76      0.84      0.80       268
          R       0.57      0.43      0.49       125

avg / total       0.66      0.68      0.66       571

12/17/2017 20:28:15 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:28:15 [INFO] exp_shallowmodel: 
[[  0   4   8   2]
 [  1 106  30  27]
 [  2  28 226  12]
 [  3  33  35  54]]
12/17/2017 20:28:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/17/2017 20:28:15 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:28:15 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:28:15 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:28:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:28:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:28:15 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:28:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:29:07 [INFO] exp_shallowmodel: train time: 52.636s
12/17/2017 20:29:07 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:29:07 [INFO] exp_shallowmodel: accuracy:   0.653
12/17/2017 20:29:07 [INFO] exp_shallowmodel: f1_score:   0.459
12/17/2017 20:29:07 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:29:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.65      0.63       164
          F       0.74      0.81      0.78       268
          R       0.48      0.39      0.43       125

avg / total       0.63      0.65      0.64       571

12/17/2017 20:29:07 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:29:07 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 106  29  29]
 [  0  28 218  22]
 [  2  37  37  49]]
12/17/2017 20:29:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/17/2017 20:29:08 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:29:08 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:29:08 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:29:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:29:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:29:08 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:29:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:30:12 [INFO] exp_shallowmodel: train time: 64.862s
12/17/2017 20:30:12 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:30:12 [INFO] exp_shallowmodel: accuracy:   0.641
12/17/2017 20:30:12 [INFO] exp_shallowmodel: f1_score:   0.454
12/17/2017 20:30:12 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:30:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.60      0.60       164
          F       0.73      0.80      0.76       268
          R       0.49      0.43      0.46       125

avg / total       0.62      0.64      0.63       571

12/17/2017 20:30:12 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:30:12 [INFO] exp_shallowmodel: 
[[  0   0   9   5]
 [  0  98  36  30]
 [  1  31 214  22]
 [  1  36  34  54]]
12/17/2017 20:30:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/17/2017 20:30:13 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:30:13 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:30:13 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:30:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:30:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:30:13 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:30:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:31:02 [INFO] exp_shallowmodel: train time: 49.314s
12/17/2017 20:31:02 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:31:02 [INFO] exp_shallowmodel: accuracy:   0.658
12/17/2017 20:31:02 [INFO] exp_shallowmodel: f1_score:   0.459
12/17/2017 20:31:02 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:31:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.69      0.65       164
          F       0.74      0.82      0.78       268
          R       0.48      0.35      0.41       125

avg / total       0.63      0.66      0.64       571

12/17/2017 20:31:02 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:31:02 [INFO] exp_shallowmodel: 
[[  0   3   5   6]
 [  0 113  24  27]
 [  0  34 219  15]
 [  2  33  46  44]]
12/17/2017 20:31:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/17/2017 20:31:02 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:31:02 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:31:02 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:31:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:31:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:31:02 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:31:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:32:02 [INFO] exp_shallowmodel: train time: 60.357s
12/17/2017 20:32:02 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:32:02 [INFO] exp_shallowmodel: accuracy:   0.678
12/17/2017 20:32:02 [INFO] exp_shallowmodel: f1_score:   0.487
12/17/2017 20:32:02 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:32:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.65      0.73      0.69       164
          F       0.73      0.80      0.76       268
          R       0.60      0.42      0.50       125

avg / total       0.66      0.68      0.66       571

12/17/2017 20:32:02 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:32:02 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  1 119  28  16]
 [  3  35 215  15]
 [  1  26  45  53]]
12/17/2017 20:32:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/17/2017 20:32:03 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:32:03 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:32:03 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:32:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:32:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:32:03 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:32:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:32:47 [INFO] exp_shallowmodel: train time: 43.915s
12/17/2017 20:32:47 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:32:47 [INFO] exp_shallowmodel: accuracy:   0.665
12/17/2017 20:32:47 [INFO] exp_shallowmodel: f1_score:   0.507
12/17/2017 20:32:47 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:32:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.14      0.18        14
          C       0.61      0.73      0.67       164
          F       0.74      0.81      0.77       268
          R       0.56      0.32      0.41       125

avg / total       0.65      0.67      0.65       571

12/17/2017 20:32:47 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:32:47 [INFO] exp_shallowmodel: 
[[  2   0   9   3]
 [  1 120  29  14]
 [  2  33 218  15]
 [  3  43  39  40]]
12/17/2017 20:32:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/17/2017 20:32:47 [INFO] exp_shallowmodel: #(data) = 4568
12/17/2017 20:32:47 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:32:47 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:32:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:32:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:32:47 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:32:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:33:23 [INFO] exp_shallowmodel: train time: 36.139s
12/17/2017 20:33:23 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:33:23 [INFO] exp_shallowmodel: accuracy:   0.643
12/17/2017 20:33:23 [INFO] exp_shallowmodel: f1_score:   0.458
12/17/2017 20:33:23 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:33:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.64      0.66      0.65       169
          F       0.72      0.79      0.75       271
          R       0.48      0.39      0.43       130

avg / total       0.62      0.64      0.63       586

12/17/2017 20:33:23 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:33:23 [INFO] exp_shallowmodel: 
[[  0   2  10   4]
 [  1 112  31  25]
 [  0  30 214  27]
 [  3  32  44  51]]
12/17/2017 20:33:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/17/2017 20:33:23 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:33:23 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:33:23 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:33:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:33:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:33:23 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:33:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:34:18 [INFO] exp_shallowmodel: train time: 55.285s
12/17/2017 20:34:18 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:34:18 [INFO] exp_shallowmodel: accuracy:   0.664
12/17/2017 20:34:18 [INFO] exp_shallowmodel: f1_score:   0.531
12/17/2017 20:34:18 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:34:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.14      0.24        14
          C       0.62      0.66      0.64       164
          F       0.74      0.79      0.76       268
          R       0.53      0.45      0.48       125

avg / total       0.66      0.66      0.65       571

12/17/2017 20:34:18 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:34:18 [INFO] exp_shallowmodel: 
[[  2   3   8   1]
 [  0 108  30  26]
 [  1  31 213  23]
 [  0  31  38  56]]
12/17/2017 20:34:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/17/2017 20:34:19 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:34:19 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:34:19 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:34:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:34:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:34:19 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:34:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:34:53 [INFO] exp_shallowmodel: train time: 34.041s
12/17/2017 20:34:53 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:34:53 [INFO] exp_shallowmodel: accuracy:   0.636
12/17/2017 20:34:53 [INFO] exp_shallowmodel: f1_score:   0.467
12/17/2017 20:34:53 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:34:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.58      0.62      0.60       164
          F       0.72      0.82      0.77       268
          R       0.47      0.33      0.38       125

avg / total       0.61      0.64      0.62       571

12/17/2017 20:34:53 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:34:53 [INFO] exp_shallowmodel: 
[[  1   3  10   0]
 [  0 101  35  28]
 [  1  28 220  19]
 [  1  43  40  41]]
12/17/2017 20:34:53 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/17/2017 20:34:53 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:34:53 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:34:53 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:34:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:34:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:34:53 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:34:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:35:29 [INFO] exp_shallowmodel: train time: 36.599s
12/17/2017 20:35:29 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:35:29 [INFO] exp_shallowmodel: accuracy:   0.639
12/17/2017 20:35:29 [INFO] exp_shallowmodel: f1_score:   0.438
12/17/2017 20:35:29 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:35:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.68      0.64       164
          F       0.73      0.81      0.77       268
          R       0.42      0.30      0.35       125

avg / total       0.61      0.64      0.62       571

12/17/2017 20:35:29 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:35:29 [INFO] exp_shallowmodel: 
[[  0   1   4   9]
 [  0 111  25  28]
 [  1  35 217  15]
 [  0  38  50  37]]
12/17/2017 20:35:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/17/2017 20:35:30 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:35:30 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:35:30 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:35:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:35:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:35:30 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:35:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:36:17 [INFO] exp_shallowmodel: train time: 47.491s
12/17/2017 20:36:17 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:36:17 [INFO] exp_shallowmodel: accuracy:   0.643
12/17/2017 20:36:17 [INFO] exp_shallowmodel: f1_score:   0.485
12/17/2017 20:36:17 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:36:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.59      0.63      0.61       164
          F       0.73      0.77      0.75       268
          R       0.52      0.45      0.48       125

avg / total       0.63      0.64      0.64       571

12/17/2017 20:36:17 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:36:17 [INFO] exp_shallowmodel: 
[[  1   1   9   3]
 [  1 103  32  28]
 [  1  39 207  21]
 [  3  31  35  56]]
12/17/2017 20:36:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/17/2017 20:36:17 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:36:17 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:36:17 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:36:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:36:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:36:17 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:36:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:37:19 [INFO] exp_shallowmodel: train time: 61.305s
12/17/2017 20:37:19 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:37:19 [INFO] exp_shallowmodel: accuracy:   0.632
12/17/2017 20:37:19 [INFO] exp_shallowmodel: f1_score:   0.439
12/17/2017 20:37:19 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:37:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.65      0.62       164
          F       0.73      0.79      0.76       268
          R       0.43      0.34      0.38       125

avg / total       0.61      0.63      0.62       571

12/17/2017 20:37:19 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:37:19 [INFO] exp_shallowmodel: 
[[  0   3   5   6]
 [  0 107  31  26]
 [  0  33 212  23]
 [  1  39  43  42]]
12/17/2017 20:37:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/17/2017 20:37:19 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:37:19 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:37:19 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:37:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:37:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:37:19 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:37:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:38:04 [INFO] exp_shallowmodel: train time: 45.722s
12/17/2017 20:38:04 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:38:04 [INFO] exp_shallowmodel: accuracy:   0.680
12/17/2017 20:38:04 [INFO] exp_shallowmodel: f1_score:   0.479
12/17/2017 20:38:04 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:38:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.66      0.76      0.70       164
          F       0.75      0.81      0.78       268
          R       0.53      0.37      0.43       125

avg / total       0.66      0.68      0.66       571

12/17/2017 20:38:04 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:38:04 [INFO] exp_shallowmodel: 
[[  0   3   9   2]
 [  0 124  18  22]
 [  3  30 218  17]
 [  2  32  45  46]]
12/17/2017 20:38:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/17/2017 20:38:05 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:38:05 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:38:05 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:38:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:38:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:38:05 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:38:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:38:48 [INFO] exp_shallowmodel: train time: 43.068s
12/17/2017 20:38:48 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:38:48 [INFO] exp_shallowmodel: accuracy:   0.658
12/17/2017 20:38:48 [INFO] exp_shallowmodel: f1_score:   0.500
12/17/2017 20:38:48 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:38:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.14      0.18        14
          C       0.62      0.62      0.62       164
          F       0.75      0.85      0.80       268
          R       0.46      0.35      0.40       125

avg / total       0.64      0.66      0.64       571

12/17/2017 20:38:48 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:38:48 [INFO] exp_shallowmodel: 
[[  2   0   7   5]
 [  2 102  29  31]
 [  1  24 228  15]
 [  3  39  39  44]]
12/17/2017 20:38:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/17/2017 20:38:48 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:38:48 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:38:48 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:38:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:38:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:38:48 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:38:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:39:44 [INFO] exp_shallowmodel: train time: 55.693s
12/17/2017 20:39:44 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:39:44 [INFO] exp_shallowmodel: accuracy:   0.665
12/17/2017 20:39:44 [INFO] exp_shallowmodel: f1_score:   0.511
12/17/2017 20:39:44 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:39:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.14      0.16        14
          C       0.63      0.65      0.64       164
          F       0.74      0.82      0.78       268
          R       0.55      0.41      0.47       125

avg / total       0.65      0.67      0.66       571

12/17/2017 20:39:44 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:39:44 [INFO] exp_shallowmodel: 
[[  2   0   9   3]
 [  5 106  29  24]
 [  1  31 221  15]
 [  3  32  39  51]]
12/17/2017 20:39:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/17/2017 20:39:44 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:39:44 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:39:44 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:39:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:39:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:39:44 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:39:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:40:29 [INFO] exp_shallowmodel: train time: 44.911s
12/17/2017 20:40:29 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:40:29 [INFO] exp_shallowmodel: accuracy:   0.632
12/17/2017 20:40:29 [INFO] exp_shallowmodel: f1_score:   0.441
12/17/2017 20:40:29 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:40:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.60      0.59       164
          F       0.71      0.81      0.76       268
          R       0.48      0.36      0.41       125

avg / total       0.61      0.63      0.62       571

12/17/2017 20:40:29 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:40:29 [INFO] exp_shallowmodel: 
[[  0   1   8   5]
 [  2  99  40  23]
 [  2  28 217  21]
 [  0  41  39  45]]
12/17/2017 20:40:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/17/2017 20:40:29 [INFO] exp_shallowmodel: #(data) = 4568
12/17/2017 20:40:29 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:40:29 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:40:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:40:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:40:29 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:40:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:41:37 [INFO] exp_shallowmodel: train time: 68.489s
12/17/2017 20:41:37 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:41:37 [INFO] exp_shallowmodel: accuracy:   0.606
12/17/2017 20:41:37 [INFO] exp_shallowmodel: f1_score:   0.444
12/17/2017 20:41:37 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:41:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.06      0.06        16
          C       0.57      0.66      0.61       169
          F       0.70      0.74      0.72       271
          R       0.48      0.32      0.38       130

avg / total       0.60      0.61      0.60       586

12/17/2017 20:41:37 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:41:37 [INFO] exp_shallowmodel: 
[[  1   3  10   2]
 [  7 112  30  20]
 [  2  45 201  23]
 [  6  38  45  41]]
12/17/2017 20:41:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/17/2017 20:41:37 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:41:37 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:41:37 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:41:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:41:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:41:37 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:41:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:42:29 [INFO] exp_shallowmodel: train time: 51.905s
12/17/2017 20:42:29 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:42:29 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 20:42:29 [INFO] exp_shallowmodel: f1_score:   0.507
12/17/2017 20:42:29 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:42:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.21      0.30        14
          C       0.58      0.67      0.62       164
          F       0.74      0.76      0.75       268
          R       0.41      0.32      0.36       125

avg / total       0.61      0.63      0.62       571

12/17/2017 20:42:29 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:42:29 [INFO] exp_shallowmodel: 
[[  3   1   6   4]
 [  1 110  26  27]
 [  0  37 204  27]
 [  2  42  41  40]]
12/17/2017 20:42:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/17/2017 20:42:30 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:42:30 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:42:30 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:42:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:42:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:42:30 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:42:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:43:06 [INFO] exp_shallowmodel: train time: 36.789s
12/17/2017 20:43:06 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:43:06 [INFO] exp_shallowmodel: accuracy:   0.655
12/17/2017 20:43:06 [INFO] exp_shallowmodel: f1_score:   0.465
12/17/2017 20:43:06 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:43:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.65      0.64       164
          F       0.72      0.80      0.76       268
          R       0.53      0.42      0.47       125

avg / total       0.63      0.65      0.64       571

12/17/2017 20:43:06 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:43:06 [INFO] exp_shallowmodel: 
[[  0   0   7   7]
 [  1 107  29  27]
 [  1  40 215  12]
 [  0  25  48  52]]
12/17/2017 20:43:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/17/2017 20:43:07 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:43:07 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:43:07 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:43:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:43:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:43:07 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:43:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:43:59 [INFO] exp_shallowmodel: train time: 52.932s
12/17/2017 20:43:59 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:43:59 [INFO] exp_shallowmodel: accuracy:   0.651
12/17/2017 20:43:59 [INFO] exp_shallowmodel: f1_score:   0.460
12/17/2017 20:43:59 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:43:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.70      0.65       164
          F       0.74      0.79      0.76       268
          R       0.49      0.38      0.43       125

avg / total       0.63      0.65      0.64       571

12/17/2017 20:43:59 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:43:59 [INFO] exp_shallowmodel: 
[[  0   2   7   5]
 [  1 114  26  23]
 [  1  36 211  20]
 [  1  35  42  47]]
12/17/2017 20:44:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/17/2017 20:44:00 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:44:00 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:44:00 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:44:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:44:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:44:00 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:44:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:45:00 [INFO] exp_shallowmodel: train time: 60.177s
12/17/2017 20:45:00 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:45:00 [INFO] exp_shallowmodel: accuracy:   0.644
12/17/2017 20:45:00 [INFO] exp_shallowmodel: f1_score:   0.449
12/17/2017 20:45:00 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:45:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.61      0.60       164
          F       0.75      0.82      0.79       268
          R       0.45      0.38      0.41       125

avg / total       0.62      0.64      0.63       571

12/17/2017 20:45:00 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:45:00 [INFO] exp_shallowmodel: 
[[  0   4   9   1]
 [  1 100  23  40]
 [  1  30 221  16]
 [  1  37  40  47]]
12/17/2017 20:45:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/17/2017 20:45:00 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:45:00 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:45:00 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:45:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:45:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:45:00 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:45:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:45:53 [INFO] exp_shallowmodel: train time: 53.467s
12/17/2017 20:45:53 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:45:53 [INFO] exp_shallowmodel: accuracy:   0.673
12/17/2017 20:45:53 [INFO] exp_shallowmodel: f1_score:   0.514
12/17/2017 20:45:53 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:45:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.14      0.19        14
          C       0.62      0.70      0.65       164
          F       0.75      0.84      0.79       268
          R       0.54      0.34      0.42       125

avg / total       0.65      0.67      0.66       571

12/17/2017 20:45:53 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:45:53 [INFO] exp_shallowmodel: 
[[  2   1  11   0]
 [  0 114  30  20]
 [  3  23 225  17]
 [  2  47  33  43]]
12/17/2017 20:45:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/17/2017 20:45:54 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:45:54 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:45:54 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:45:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:45:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:45:54 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:45:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:46:34 [INFO] exp_shallowmodel: train time: 40.635s
12/17/2017 20:46:34 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:46:34 [INFO] exp_shallowmodel: accuracy:   0.653
12/17/2017 20:46:34 [INFO] exp_shallowmodel: f1_score:   0.453
12/17/2017 20:46:34 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:46:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.74      0.69       164
          F       0.72      0.80      0.76       268
          R       0.46      0.30      0.37       125

avg / total       0.63      0.65      0.63       571

12/17/2017 20:46:34 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:46:34 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  0 121  26  17]
 [  2  29 214  23]
 [  3  36  48  38]]
12/17/2017 20:46:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/17/2017 20:46:34 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:46:34 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:46:34 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:46:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:46:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:46:34 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:46:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:47:27 [INFO] exp_shallowmodel: train time: 52.479s
12/17/2017 20:47:27 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:47:27 [INFO] exp_shallowmodel: accuracy:   0.618
12/17/2017 20:47:27 [INFO] exp_shallowmodel: f1_score:   0.434
12/17/2017 20:47:27 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:47:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.62      0.58       164
          F       0.71      0.78      0.74       268
          R       0.51      0.34      0.41       125

avg / total       0.60      0.62      0.60       571

12/17/2017 20:47:27 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:47:27 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  3 102  36  23]
 [  0  44 208  16]
 [  4  37  41  43]]
12/17/2017 20:47:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/17/2017 20:47:27 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:47:27 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:47:27 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:47:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:47:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:47:27 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:47:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:48:26 [INFO] exp_shallowmodel: train time: 59.340s
12/17/2017 20:48:26 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:48:26 [INFO] exp_shallowmodel: accuracy:   0.643
12/17/2017 20:48:26 [INFO] exp_shallowmodel: f1_score:   0.500
12/17/2017 20:48:26 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:48:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.14      0.21        14
          C       0.60      0.62      0.61       164
          F       0.72      0.81      0.76       268
          R       0.48      0.37      0.42       125

avg / total       0.63      0.64      0.63       571

12/17/2017 20:48:26 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:48:26 [INFO] exp_shallowmodel: 
[[  2   0   8   4]
 [  0 101  32  31]
 [  1  34 218  15]
 [  2  32  45  46]]
12/17/2017 20:48:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/17/2017 20:48:27 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:48:27 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:48:27 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:48:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:48:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:48:27 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:48:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:49:19 [INFO] exp_shallowmodel: train time: 52.527s
12/17/2017 20:49:19 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:49:19 [INFO] exp_shallowmodel: accuracy:   0.664
12/17/2017 20:49:19 [INFO] exp_shallowmodel: f1_score:   0.525
12/17/2017 20:49:19 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:49:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.14      0.24        14
          C       0.64      0.70      0.67       164
          F       0.71      0.81      0.76       268
          R       0.54      0.37      0.44       125

avg / total       0.65      0.66      0.65       571

12/17/2017 20:49:19 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:49:19 [INFO] exp_shallowmodel: 
[[  2   0   8   4]
 [  0 115  36  13]
 [  1  29 216  22]
 [  0  36  43  46]]
12/17/2017 20:49:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/17/2017 20:49:19 [INFO] exp_shallowmodel: #(data) = 4568
12/17/2017 20:49:19 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:49:19 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:49:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:49:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:49:19 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:49:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:50:11 [INFO] exp_shallowmodel: train time: 51.928s
12/17/2017 20:50:11 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:50:11 [INFO] exp_shallowmodel: accuracy:   0.642
12/17/2017 20:50:11 [INFO] exp_shallowmodel: f1_score:   0.476
12/17/2017 20:50:11 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:50:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.06      0.10        16
          C       0.59      0.68      0.63       169
          F       0.76      0.78      0.77       271
          R       0.45      0.37      0.41       130

avg / total       0.63      0.64      0.63       586

12/17/2017 20:50:11 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:50:11 [INFO] exp_shallowmodel: 
[[  1   2  10   3]
 [  2 115  25  27]
 [  0  31 212  28]
 [  2  47  33  48]]
12/17/2017 20:50:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/17/2017 20:50:12 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:50:12 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:50:12 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:50:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:50:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:50:12 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:50:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:51:39 [INFO] exp_shallowmodel: train time: 87.794s
12/17/2017 20:51:39 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:51:40 [INFO] exp_shallowmodel: accuracy:   0.681
12/17/2017 20:51:40 [INFO] exp_shallowmodel: f1_score:   0.485
12/17/2017 20:51:40 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:51:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.70      0.66       164
          F       0.75      0.82      0.78       268
          R       0.59      0.43      0.50       125

avg / total       0.66      0.68      0.67       571

12/17/2017 20:51:40 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:51:40 [INFO] exp_shallowmodel: 
[[  0   6   8   0]
 [  0 115  25  24]
 [  0  34 220  14]
 [  0  30  41  54]]
12/17/2017 20:51:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/17/2017 20:51:40 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:51:40 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:51:40 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:51:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:51:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:51:40 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:51:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:53:13 [INFO] exp_shallowmodel: train time: 93.046s
12/17/2017 20:53:13 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:53:13 [INFO] exp_shallowmodel: accuracy:   0.657
12/17/2017 20:53:13 [INFO] exp_shallowmodel: f1_score:   0.469
12/17/2017 20:53:13 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:53:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.67      0.65       164
          F       0.73      0.80      0.76       268
          R       0.55      0.41      0.47       125

avg / total       0.64      0.66      0.65       571

12/17/2017 20:53:13 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:53:13 [INFO] exp_shallowmodel: 
[[  0   4   8   2]
 [  3 110  31  20]
 [  3  32 214  19]
 [  2  31  41  51]]
12/17/2017 20:53:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/17/2017 20:53:13 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:53:13 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:53:13 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:53:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:53:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:53:13 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:53:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:54:52 [INFO] exp_shallowmodel: train time: 98.576s
12/17/2017 20:54:52 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:54:52 [INFO] exp_shallowmodel: accuracy:   0.629
12/17/2017 20:54:52 [INFO] exp_shallowmodel: f1_score:   0.435
12/17/2017 20:54:52 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:54:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.63      0.60       164
          F       0.73      0.80      0.76       268
          R       0.44      0.33      0.37       125

avg / total       0.60      0.63      0.61       571

12/17/2017 20:54:52 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:54:52 [INFO] exp_shallowmodel: 
[[  0   1   9   4]
 [  1 104  30  29]
 [  1  33 214  20]
 [  2  43  39  41]]
12/17/2017 20:54:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/17/2017 20:54:52 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:54:52 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:54:52 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:54:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:54:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:54:52 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:54:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:57:00 [INFO] exp_shallowmodel: train time: 127.838s
12/17/2017 20:57:00 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:57:00 [INFO] exp_shallowmodel: accuracy:   0.648
12/17/2017 20:57:00 [INFO] exp_shallowmodel: f1_score:   0.484
12/17/2017 20:57:00 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:57:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.57      0.64      0.60       164
          F       0.76      0.79      0.77       268
          R       0.52      0.42      0.46       125

avg / total       0.64      0.65      0.64       571

12/17/2017 20:57:00 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:57:00 [INFO] exp_shallowmodel: 
[[  1   2  10   1]
 [  3 105  27  29]
 [  0  38 212  18]
 [  3  39  31  52]]
12/17/2017 20:57:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/17/2017 20:57:01 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:57:01 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:57:01 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:57:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:57:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:57:01 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:57:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 20:58:51 [INFO] exp_shallowmodel: train time: 110.270s
12/17/2017 20:58:51 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 20:58:51 [INFO] exp_shallowmodel: accuracy:   0.655
12/17/2017 20:58:51 [INFO] exp_shallowmodel: f1_score:   0.489
12/17/2017 20:58:51 [INFO] exp_shallowmodel: classification report:
12/17/2017 20:58:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.62      0.66      0.64       164
          F       0.75      0.80      0.77       268
          R       0.49      0.41      0.44       125

avg / total       0.64      0.65      0.65       571

12/17/2017 20:58:51 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 20:58:51 [INFO] exp_shallowmodel: 
[[  1   4   5   4]
 [  2 108  27  27]
 [  1  30 214  23]
 [  2  31  41  51]]
12/17/2017 20:58:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/17/2017 20:58:51 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 20:58:51 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 20:58:51 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 20:58:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 20:58:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 20:58:51 [INFO] exp_shallowmodel: Training: 
12/17/2017 20:58:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:00:22 [INFO] exp_shallowmodel: train time: 90.413s
12/17/2017 21:00:22 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:00:22 [INFO] exp_shallowmodel: accuracy:   0.650
12/17/2017 21:00:22 [INFO] exp_shallowmodel: f1_score:   0.485
12/17/2017 21:00:22 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:00:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.58      0.62      0.60       164
          F       0.73      0.83      0.77       268
          R       0.52      0.38      0.44       125

avg / total       0.65      0.65      0.63       571

12/17/2017 21:00:22 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:00:22 [INFO] exp_shallowmodel: 
[[  1   3   7   3]
 [  0 101  40  23]
 [  0  29 222  17]
 [  0  41  37  47]]
12/17/2017 21:00:22 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/17/2017 21:00:22 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:00:22 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 21:00:22 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:00:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:00:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:00:22 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:00:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:02:06 [INFO] exp_shallowmodel: train time: 104.084s
12/17/2017 21:02:06 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:02:06 [INFO] exp_shallowmodel: accuracy:   0.655
12/17/2017 21:02:06 [INFO] exp_shallowmodel: f1_score:   0.456
12/17/2017 21:02:06 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:02:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.68      0.66       164
          F       0.73      0.82      0.77       268
          R       0.46      0.34      0.39       125

avg / total       0.63      0.65      0.64       571

12/17/2017 21:02:06 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:02:06 [INFO] exp_shallowmodel: 
[[  0   1  10   3]
 [  0 111  23  30]
 [  2  29 220  17]
 [  0  32  50  43]]
12/17/2017 21:02:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/17/2017 21:02:06 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:02:06 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 21:02:06 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:02:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:02:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:02:06 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:02:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:03:43 [INFO] exp_shallowmodel: train time: 96.720s
12/17/2017 21:03:43 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:03:43 [INFO] exp_shallowmodel: accuracy:   0.641
12/17/2017 21:03:43 [INFO] exp_shallowmodel: f1_score:   0.509
12/17/2017 21:03:43 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:03:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.14      0.24        14
          C       0.61      0.68      0.64       164
          F       0.72      0.77      0.74       268
          R       0.47      0.37      0.41       125

avg / total       0.63      0.64      0.63       571

12/17/2017 21:03:43 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:03:43 [INFO] exp_shallowmodel: 
[[  2   1   7   4]
 [  0 111  30  23]
 [  1  35 207  25]
 [  0  35  44  46]]
12/17/2017 21:03:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/17/2017 21:03:43 [INFO] exp_shallowmodel: #(data) = 4583
12/17/2017 21:03:43 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 21:03:43 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:03:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:03:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:03:43 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:03:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:05:17 [INFO] exp_shallowmodel: train time: 93.848s
12/17/2017 21:05:17 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:05:17 [INFO] exp_shallowmodel: accuracy:   0.660
12/17/2017 21:05:17 [INFO] exp_shallowmodel: f1_score:   0.488
12/17/2017 21:05:17 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:05:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.63      0.75      0.69       164
          F       0.74      0.79      0.76       268
          R       0.49      0.34      0.40       125

avg / total       0.64      0.66      0.64       571

12/17/2017 21:05:17 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:05:17 [INFO] exp_shallowmodel: 
[[  1   0  10   3]
 [  1 123  20  20]
 [  2  35 211  20]
 [  1  36  46  42]]
12/17/2017 21:05:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/17/2017 21:05:18 [INFO] exp_shallowmodel: #(data) = 4568
12/17/2017 21:05:18 [INFO] exp_shallowmodel: #(feature) = 1090
12/17/2017 21:05:18 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:05:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:05:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:05:18 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:05:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:07:05 [INFO] exp_shallowmodel: train time: 106.983s
12/17/2017 21:07:05 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:07:05 [INFO] exp_shallowmodel: accuracy:   0.643
12/17/2017 21:07:05 [INFO] exp_shallowmodel: f1_score:   0.482
12/17/2017 21:07:05 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:07:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.06      0.11        16
          C       0.61      0.64      0.63       169
          F       0.72      0.80      0.76       271
          R       0.49      0.40      0.44       130

avg / total       0.63      0.64      0.63       586

12/17/2017 21:07:05 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:07:05 [INFO] exp_shallowmodel: 
[[  1   1  11   3]
 [  0 108  31  30]
 [  2  31 216  22]
 [  0  36  42  52]]
12/17/2017 21:07:12 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 21:07:12 [INFO] task_runner: context=current, feature=10-[5+1.3.4]
12/17/2017 21:07:12 [INFO] task_runner: retained feature numbers=[8.1, 6, 3, 2.2, 1, 7, 5, 2.1]
12/17/2017 21:07:12 [INFO] task_runner: #(data)=5934
12/17/2017 21:07:12 [INFO] task_runner: #(feature)=1409
12/17/2017 21:07:12 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 21:07:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/17/2017 21:07:12 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:07:12 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:07:12 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:07:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:07:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:07:12 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:07:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:09:19 [INFO] exp_shallowmodel: train time: 126.881s
12/17/2017 21:09:19 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:09:19 [INFO] exp_shallowmodel: accuracy:   0.615
12/17/2017 21:09:19 [INFO] exp_shallowmodel: f1_score:   0.470
12/17/2017 21:09:19 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:09:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.15      0.21        20
          C       0.58      0.63      0.60       169
          F       0.71      0.79      0.75       281
          R       0.38      0.28      0.32       122

avg / total       0.59      0.61      0.60       592

12/17/2017 21:09:19 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:09:19 [INFO] exp_shallowmodel: 
[[  3   0  13   4]
 [  2 106  33  28]
 [  3  34 221  23]
 [  1  43  44  34]]
12/17/2017 21:09:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/17/2017 21:09:20 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:09:20 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:09:20 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:09:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:09:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:09:20 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:09:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:11:14 [INFO] exp_shallowmodel: train time: 114.133s
12/17/2017 21:11:14 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:11:14 [INFO] exp_shallowmodel: accuracy:   0.650
12/17/2017 21:11:14 [INFO] exp_shallowmodel: f1_score:   0.532
12/17/2017 21:11:14 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:11:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.25      0.32        20
          C       0.57      0.64      0.60       169
          F       0.75      0.81      0.78       281
          R       0.51      0.36      0.42       122

avg / total       0.64      0.65      0.64       592

12/17/2017 21:11:14 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:11:14 [INFO] exp_shallowmodel: 
[[  5   2   9   4]
 [  2 109  36  22]
 [  1  37 227  16]
 [  3  44  31  44]]
12/17/2017 21:11:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/17/2017 21:11:14 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:11:14 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:11:14 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:11:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:11:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:11:14 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:11:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:12:59 [INFO] exp_shallowmodel: train time: 104.344s
12/17/2017 21:12:59 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:12:59 [INFO] exp_shallowmodel: accuracy:   0.613
12/17/2017 21:12:59 [INFO] exp_shallowmodel: f1_score:   0.456
12/17/2017 21:12:59 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:12:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.10      0.13        20
          C       0.55      0.61      0.58       169
          F       0.71      0.78      0.74       281
          R       0.46      0.31      0.37       122

avg / total       0.59      0.61      0.60       592

12/17/2017 21:12:59 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:12:59 [INFO] exp_shallowmodel: 
[[  2   3  13   2]
 [  2 103  37  27]
 [  3  42 220  16]
 [  3  40  41  38]]
12/17/2017 21:12:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/17/2017 21:12:59 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:12:59 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:12:59 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:12:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:12:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:12:59 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:12:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:15:18 [INFO] exp_shallowmodel: train time: 139.058s
12/17/2017 21:15:18 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:15:18 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 21:15:18 [INFO] exp_shallowmodel: f1_score:   0.466
12/17/2017 21:15:18 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:15:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.10      0.14        20
          C       0.56      0.62      0.59       169
          F       0.72      0.80      0.76       281
          R       0.45      0.32      0.37       122

avg / total       0.60      0.62      0.61       592

12/17/2017 21:15:18 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:15:18 [INFO] exp_shallowmodel: 
[[  2   9   7   2]
 [  1 105  37  26]
 [  3  34 224  20]
 [  2  39  42  39]]
12/17/2017 21:15:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/17/2017 21:15:19 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:15:19 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:15:19 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:15:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:15:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:15:19 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:15:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:17:43 [INFO] exp_shallowmodel: train time: 144.814s
12/17/2017 21:17:43 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:17:43 [INFO] exp_shallowmodel: accuracy:   0.628
12/17/2017 21:17:43 [INFO] exp_shallowmodel: f1_score:   0.468
12/17/2017 21:17:43 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:17:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.10      0.12        20
          C       0.55      0.66      0.60       169
          F       0.73      0.78      0.76       281
          R       0.49      0.32      0.39       122

avg / total       0.61      0.63      0.62       592

12/17/2017 21:17:43 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:17:43 [INFO] exp_shallowmodel: 
[[  2   4   7   7]
 [  3 112  38  16]
 [  4  41 219  17]
 [  3  46  34  39]]
12/17/2017 21:17:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/17/2017 21:17:44 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:17:44 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:17:44 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:17:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:17:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:17:44 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:17:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:19:23 [INFO] exp_shallowmodel: train time: 99.519s
12/17/2017 21:19:23 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:19:23 [INFO] exp_shallowmodel: accuracy:   0.630
12/17/2017 21:19:23 [INFO] exp_shallowmodel: f1_score:   0.470
12/17/2017 21:19:23 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:19:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.10      0.14        20
          C       0.58      0.63      0.61       169
          F       0.72      0.80      0.76       281
          R       0.45      0.32      0.38       122

avg / total       0.61      0.63      0.61       592

12/17/2017 21:19:23 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:19:23 [INFO] exp_shallowmodel: 
[[  2   3  11   4]
 [  1 107  33  28]
 [  3  38 225  15]
 [  2  36  45  39]]
12/17/2017 21:19:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/17/2017 21:19:24 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:19:24 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:19:24 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:19:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:19:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:19:24 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:19:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:21:41 [INFO] exp_shallowmodel: train time: 137.218s
12/17/2017 21:21:41 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:21:41 [INFO] exp_shallowmodel: accuracy:   0.644
12/17/2017 21:21:41 [INFO] exp_shallowmodel: f1_score:   0.474
12/17/2017 21:21:41 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:21:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.56      0.64      0.60       169
          F       0.76      0.79      0.78       281
          R       0.47      0.39      0.43       122

avg / total       0.63      0.64      0.63       592

12/17/2017 21:21:41 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:21:41 [INFO] exp_shallowmodel: 
[[  1   6   7   6]
 [  0 109  30  30]
 [  1  38 223  19]
 [  0  40  34  48]]
12/17/2017 21:21:42 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/17/2017 21:21:42 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:21:42 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:21:42 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:21:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:21:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:21:42 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:21:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:24:20 [INFO] exp_shallowmodel: train time: 158.266s
12/17/2017 21:24:20 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:24:20 [INFO] exp_shallowmodel: accuracy:   0.642
12/17/2017 21:24:20 [INFO] exp_shallowmodel: f1_score:   0.525
12/17/2017 21:24:20 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:24:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.20      0.31        20
          C       0.56      0.65      0.60       169
          F       0.74      0.78      0.76       281
          R       0.52      0.38      0.44       122

avg / total       0.64      0.64      0.63       592

12/17/2017 21:24:20 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:24:20 [INFO] exp_shallowmodel: 
[[  4   4   5   7]
 [  0 110  39  20]
 [  1  44 220  16]
 [  1  40  35  46]]
12/17/2017 21:24:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/17/2017 21:24:21 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:24:21 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:24:21 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:24:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:24:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:24:21 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:24:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:26:20 [INFO] exp_shallowmodel: train time: 119.670s
12/17/2017 21:26:20 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:26:20 [INFO] exp_shallowmodel: accuracy:   0.600
12/17/2017 21:26:20 [INFO] exp_shallowmodel: f1_score:   0.453
12/17/2017 21:26:20 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:26:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.15      0.19        20
          C       0.52      0.60      0.56       169
          F       0.70      0.78      0.74       281
          R       0.42      0.26      0.32       122

avg / total       0.58      0.60      0.58       592

12/17/2017 21:26:20 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:26:20 [INFO] exp_shallowmodel: 
[[  3   0  13   4]
 [  2 101  45  21]
 [  3  40 219  19]
 [  3  53  34  32]]
12/17/2017 21:26:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/17/2017 21:26:21 [INFO] exp_shallowmodel: #(data) = 4736
12/17/2017 21:26:21 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:26:21 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:26:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:26:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:26:21 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:26:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:28:14 [INFO] exp_shallowmodel: train time: 113.110s
12/17/2017 21:28:14 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:28:14 [INFO] exp_shallowmodel: accuracy:   0.622
12/17/2017 21:28:14 [INFO] exp_shallowmodel: f1_score:   0.457
12/17/2017 21:28:14 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:28:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        28
          C       0.56      0.60      0.58       172
          F       0.73      0.82      0.77       283
          R       0.41      0.32      0.36       123

avg / total       0.60      0.62      0.60       606

12/17/2017 21:28:14 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:28:14 [INFO] exp_shallowmodel: 
[[  2   6   9  11]
 [  2 104  39  27]
 [  1  31 232  19]
 [  1  44  39  39]]
12/17/2017 21:28:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/17/2017 21:28:14 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:28:14 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:28:14 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:28:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:28:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:28:14 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:28:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:30:37 [INFO] exp_shallowmodel: train time: 143.042s
12/17/2017 21:30:37 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:30:37 [INFO] exp_shallowmodel: accuracy:   0.635
12/17/2017 21:30:37 [INFO] exp_shallowmodel: f1_score:   0.464
12/17/2017 21:30:37 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:30:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.55      0.61      0.58       169
          F       0.73      0.81      0.77       281
          R       0.48      0.37      0.42       122

avg / total       0.62      0.64      0.62       592

12/17/2017 21:30:37 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:30:37 [INFO] exp_shallowmodel: 
[[  1   3  13   3]
 [  1 103  39  26]
 [  0  35 227  19]
 [  0  45  32  45]]
12/17/2017 21:30:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/17/2017 21:30:38 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:30:38 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:30:38 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:30:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:30:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:30:38 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:30:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:33:36 [INFO] exp_shallowmodel: train time: 178.230s
12/17/2017 21:33:36 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:33:36 [INFO] exp_shallowmodel: accuracy:   0.618
12/17/2017 21:33:36 [INFO] exp_shallowmodel: f1_score:   0.493
12/17/2017 21:33:36 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:33:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.20      0.28        20
          C       0.55      0.60      0.57       169
          F       0.73      0.79      0.76       281
          R       0.42      0.33      0.37       122

avg / total       0.60      0.62      0.61       592

12/17/2017 21:33:36 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:33:36 [INFO] exp_shallowmodel: 
[[  4   3  10   3]
 [  1 101  35  32]
 [  3  36 221  21]
 [  1  43  38  40]]
12/17/2017 21:33:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/17/2017 21:33:37 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:33:37 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:33:37 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:33:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:33:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:33:37 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:33:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:36:14 [INFO] exp_shallowmodel: train time: 156.901s
12/17/2017 21:36:14 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:36:14 [INFO] exp_shallowmodel: accuracy:   0.627
12/17/2017 21:36:14 [INFO] exp_shallowmodel: f1_score:   0.453
12/17/2017 21:36:14 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:36:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.05      0.06        20
          C       0.55      0.64      0.59       169
          F       0.75      0.79      0.77       281
          R       0.47      0.34      0.39       122

avg / total       0.61      0.63      0.61       592

12/17/2017 21:36:14 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:36:14 [INFO] exp_shallowmodel: 
[[  1   4   8   7]
 [  1 108  36  24]
 [  5  39 221  16]
 [  4  47  30  41]]
12/17/2017 21:36:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/17/2017 21:36:14 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:36:14 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:36:14 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:36:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:36:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:36:14 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:36:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:37:33 [INFO] exp_shallowmodel: train time: 78.461s
12/17/2017 21:37:33 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:37:33 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 21:37:33 [INFO] exp_shallowmodel: f1_score:   0.510
12/17/2017 21:37:33 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:37:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.25      0.34        20
          C       0.56      0.62      0.59       169
          F       0.71      0.80      0.76       281
          R       0.43      0.30      0.35       122

avg / total       0.61      0.62      0.61       592

12/17/2017 21:37:33 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:37:33 [INFO] exp_shallowmodel: 
[[  5   2   9   4]
 [  0 104  44  21]
 [  2  32 225  22]
 [  2  47  37  36]]
12/17/2017 21:37:33 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/17/2017 21:37:33 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:37:33 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:37:33 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:37:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:37:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:37:33 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:37:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:38:26 [INFO] exp_shallowmodel: train time: 52.926s
12/17/2017 21:38:26 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:38:26 [INFO] exp_shallowmodel: accuracy:   0.660
12/17/2017 21:38:26 [INFO] exp_shallowmodel: f1_score:   0.472
12/17/2017 21:38:26 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:38:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.05      0.07        20
          C       0.60      0.67      0.63       169
          F       0.76      0.85      0.80       281
          R       0.46      0.32      0.38       122

avg / total       0.63      0.66      0.64       592

12/17/2017 21:38:26 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:38:26 [INFO] exp_shallowmodel: 
[[  1   0  14   5]
 [  1 113  29  26]
 [  2  27 238  14]
 [  3  48  32  39]]
12/17/2017 21:38:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/17/2017 21:38:26 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:38:26 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:38:26 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:38:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:38:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:38:26 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:38:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:39:23 [INFO] exp_shallowmodel: train time: 56.626s
12/17/2017 21:39:23 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:39:23 [INFO] exp_shallowmodel: accuracy:   0.600
12/17/2017 21:39:23 [INFO] exp_shallowmodel: f1_score:   0.467
12/17/2017 21:39:23 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:39:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.15      0.22        20
          C       0.53      0.59      0.56       169
          F       0.72      0.76      0.74       281
          R       0.38      0.32      0.35       122

avg / total       0.59      0.60      0.59       592

12/17/2017 21:39:23 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:39:23 [INFO] exp_shallowmodel: 
[[  3   3   6   8]
 [  2 100  36  31]
 [  2  41 213  25]
 [  0  44  39  39]]
12/17/2017 21:39:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/17/2017 21:39:23 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:39:23 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:39:23 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:39:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:39:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:39:23 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:39:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:40:38 [INFO] exp_shallowmodel: train time: 75.083s
12/17/2017 21:40:38 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:40:38 [INFO] exp_shallowmodel: accuracy:   0.627
12/17/2017 21:40:38 [INFO] exp_shallowmodel: f1_score:   0.485
12/17/2017 21:40:38 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:40:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.15      0.22        20
          C       0.54      0.62      0.58       169
          F       0.74      0.80      0.77       281
          R       0.45      0.32      0.37       122

avg / total       0.61      0.63      0.61       592

12/17/2017 21:40:38 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:40:38 [INFO] exp_shallowmodel: 
[[  3   1  10   6]
 [  2 105  36  26]
 [  2  39 224  16]
 [  0  51  32  39]]
12/17/2017 21:40:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/17/2017 21:40:38 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:40:38 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:40:38 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:40:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:40:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:40:38 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:40:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:41:38 [INFO] exp_shallowmodel: train time: 59.601s
12/17/2017 21:41:38 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:41:38 [INFO] exp_shallowmodel: accuracy:   0.632
12/17/2017 21:41:38 [INFO] exp_shallowmodel: f1_score:   0.473
12/17/2017 21:41:38 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:41:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.10      0.12        20
          C       0.61      0.62      0.62       169
          F       0.72      0.79      0.75       281
          R       0.46      0.36      0.41       122

avg / total       0.61      0.63      0.62       592

12/17/2017 21:41:38 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:41:38 [INFO] exp_shallowmodel: 
[[  2   1  11   6]
 [  1 105  35  28]
 [  8  33 223  17]
 [  3  33  42  44]]
12/17/2017 21:41:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/17/2017 21:41:38 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:41:38 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:41:38 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:41:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:41:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:41:38 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:41:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:42:51 [INFO] exp_shallowmodel: train time: 72.305s
12/17/2017 21:42:51 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:42:51 [INFO] exp_shallowmodel: accuracy:   0.620
12/17/2017 21:42:51 [INFO] exp_shallowmodel: f1_score:   0.484
12/17/2017 21:42:51 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:42:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.20      0.29        20
          C       0.57      0.65      0.61       169
          F       0.72      0.80      0.76       281
          R       0.35      0.24      0.28       122

avg / total       0.60      0.62      0.60       592

12/17/2017 21:42:51 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:42:51 [INFO] exp_shallowmodel: 
[[  4   6   7   3]
 [  0 110  30  29]
 [  1  35 224  21]
 [  3  41  49  29]]
12/17/2017 21:42:51 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/17/2017 21:42:51 [INFO] exp_shallowmodel: #(data) = 4736
12/17/2017 21:42:51 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:42:51 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:42:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:42:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:42:51 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:42:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:46:02 [INFO] exp_shallowmodel: train time: 190.988s
12/17/2017 21:46:02 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:46:02 [INFO] exp_shallowmodel: accuracy:   0.627
12/17/2017 21:46:02 [INFO] exp_shallowmodel: f1_score:   0.477
12/17/2017 21:46:02 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:46:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.11      0.16        28
          C       0.57      0.65      0.61       172
          F       0.72      0.80      0.76       283
          R       0.45      0.33      0.38       123

avg / total       0.61      0.63      0.61       606

12/17/2017 21:46:02 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:46:02 [INFO] exp_shallowmodel: 
[[  3   5  11   9]
 [  0 111  41  20]
 [  3  33 225  22]
 [  3  45  34  41]]
12/17/2017 21:46:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/17/2017 21:46:03 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:46:03 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:46:03 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:46:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:46:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:46:03 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:46:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:48:21 [INFO] exp_shallowmodel: train time: 138.785s
12/17/2017 21:48:21 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:48:21 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 21:48:21 [INFO] exp_shallowmodel: f1_score:   0.481
12/17/2017 21:48:21 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:48:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.20      0.24        20
          C       0.55      0.57      0.56       169
          F       0.75      0.83      0.79       281
          R       0.39      0.29      0.33       122

avg / total       0.60      0.62      0.61       592

12/17/2017 21:48:21 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:48:21 [INFO] exp_shallowmodel: 
[[  4   2   9   5]
 [  2  97  34  36]
 [  5  28 234  14]
 [  2  49  36  35]]
12/17/2017 21:48:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/17/2017 21:48:22 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:48:22 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:48:22 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:48:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:48:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:48:22 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:48:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:50:46 [INFO] exp_shallowmodel: train time: 144.026s
12/17/2017 21:50:46 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:50:46 [INFO] exp_shallowmodel: accuracy:   0.632
12/17/2017 21:50:46 [INFO] exp_shallowmodel: f1_score:   0.468
12/17/2017 21:50:46 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:50:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.10      0.12        20
          C       0.57      0.67      0.62       169
          F       0.73      0.79      0.76       281
          R       0.47      0.31      0.38       122

avg / total       0.61      0.63      0.62       592

12/17/2017 21:50:46 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:50:46 [INFO] exp_shallowmodel: 
[[  2   3  12   3]
 [  2 113  32  22]
 [  4  39 221  17]
 [  5  43  36  38]]
12/17/2017 21:50:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/17/2017 21:50:46 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:50:46 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:50:46 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:50:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:50:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:50:46 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:50:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:52:34 [INFO] exp_shallowmodel: train time: 107.793s
12/17/2017 21:52:34 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:52:34 [INFO] exp_shallowmodel: accuracy:   0.622
12/17/2017 21:52:34 [INFO] exp_shallowmodel: f1_score:   0.442
12/17/2017 21:52:34 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:52:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.05      0.07        20
          C       0.53      0.60      0.57       169
          F       0.75      0.81      0.78       281
          R       0.44      0.30      0.36       122

avg / total       0.60      0.62      0.61       592

12/17/2017 21:52:34 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:52:34 [INFO] exp_shallowmodel: 
[[  1   6  11   2]
 [  4 102  31  32]
 [  2  37 228  14]
 [  3  46  36  37]]
12/17/2017 21:52:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/17/2017 21:52:35 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:52:35 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:52:35 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:52:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:52:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:52:35 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:52:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:55:01 [INFO] exp_shallowmodel: train time: 146.293s
12/17/2017 21:55:01 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:55:01 [INFO] exp_shallowmodel: accuracy:   0.613
12/17/2017 21:55:01 [INFO] exp_shallowmodel: f1_score:   0.473
12/17/2017 21:55:01 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:55:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.15      0.22        20
          C       0.52      0.63      0.57       169
          F       0.72      0.78      0.75       281
          R       0.47      0.29      0.36       122

avg / total       0.60      0.61      0.60       592

12/17/2017 21:55:01 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:55:01 [INFO] exp_shallowmodel: 
[[  3   3  11   3]
 [  2 107  38  22]
 [  1  47 218  15]
 [  1  49  37  35]]
12/17/2017 21:55:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/17/2017 21:55:01 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:55:01 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:55:01 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:55:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:55:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:55:01 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:55:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:57:13 [INFO] exp_shallowmodel: train time: 131.326s
12/17/2017 21:57:13 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 21:57:13 [INFO] exp_shallowmodel: accuracy:   0.605
12/17/2017 21:57:13 [INFO] exp_shallowmodel: f1_score:   0.474
12/17/2017 21:57:13 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:57:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.20      0.22        20
          C       0.53      0.61      0.57       169
          F       0.73      0.75      0.74       281
          R       0.42      0.32      0.36       122

avg / total       0.59      0.60      0.60       592

12/17/2017 21:57:13 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:57:13 [INFO] exp_shallowmodel: 
[[  4   2   6   8]
 [  2 103  42  22]
 [  7  38 212  24]
 [  3  50  30  39]]
12/17/2017 21:57:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/17/2017 21:57:13 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:57:13 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:57:13 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:57:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:57:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:57:13 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:57:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 21:59:02 [INFO] exp_shallowmodel: train time: 108.556s
12/17/2017 21:59:02 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 21:59:02 [INFO] exp_shallowmodel: accuracy:   0.603
12/17/2017 21:59:02 [INFO] exp_shallowmodel: f1_score:   0.441
12/17/2017 21:59:02 [INFO] exp_shallowmodel: classification report:
12/17/2017 21:59:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.55      0.61      0.58       169
          F       0.70      0.79      0.74       281
          R       0.36      0.25      0.29       122

avg / total       0.58      0.60      0.58       592

12/17/2017 21:59:02 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 21:59:02 [INFO] exp_shallowmodel: 
[[  2   3  10   5]
 [  1 103  42  23]
 [  2  32 222  25]
 [  2  49  41  30]]
12/17/2017 21:59:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/17/2017 21:59:02 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 21:59:02 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 21:59:02 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 21:59:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 21:59:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 21:59:02 [INFO] exp_shallowmodel: Training: 
12/17/2017 21:59:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:00:01 [INFO] exp_shallowmodel: train time: 58.986s
12/17/2017 22:00:01 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:00:01 [INFO] exp_shallowmodel: accuracy:   0.627
12/17/2017 22:00:01 [INFO] exp_shallowmodel: f1_score:   0.469
12/17/2017 22:00:01 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:00:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.59      0.66      0.62       169
          F       0.71      0.78      0.75       281
          R       0.44      0.31      0.36       122

avg / total       0.61      0.63      0.61       592

12/17/2017 22:00:01 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:00:01 [INFO] exp_shallowmodel: 
[[  2   4   9   5]
 [  1 111  35  22]
 [  2  37 220  22]
 [  2  37  45  38]]
12/17/2017 22:00:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/17/2017 22:00:01 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:00:01 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:00:01 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:00:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:00:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:00:01 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:00:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:01:16 [INFO] exp_shallowmodel: train time: 74.872s
12/17/2017 22:01:16 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 22:01:16 [INFO] exp_shallowmodel: accuracy:   0.617
12/17/2017 22:01:16 [INFO] exp_shallowmodel: f1_score:   0.482
12/17/2017 22:01:16 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:01:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.20      0.24        20
          C       0.55      0.63      0.59       169
          F       0.74      0.78      0.76       281
          R       0.40      0.30      0.34       122

avg / total       0.60      0.62      0.61       592

12/17/2017 22:01:16 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:01:16 [INFO] exp_shallowmodel: 
[[  4   4   8   4]
 [  1 106  30  32]
 [  4  40 219  18]
 [  4  43  39  36]]
12/17/2017 22:01:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/17/2017 22:01:16 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:01:16 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:01:16 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:01:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:01:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:01:16 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:01:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:02:29 [INFO] exp_shallowmodel: train time: 73.012s
12/17/2017 22:02:29 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 22:02:29 [INFO] exp_shallowmodel: accuracy:   0.617
12/17/2017 22:02:29 [INFO] exp_shallowmodel: f1_score:   0.480
12/17/2017 22:02:29 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:02:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.15      0.22        20
          C       0.57      0.60      0.59       169
          F       0.70      0.79      0.74       281
          R       0.43      0.33      0.37       122

avg / total       0.60      0.62      0.60       592

12/17/2017 22:02:29 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:02:29 [INFO] exp_shallowmodel: 
[[  3   0  11   6]
 [  2 101  40  26]
 [  1  37 221  22]
 [  1  38  43  40]]
12/17/2017 22:02:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/17/2017 22:02:30 [INFO] exp_shallowmodel: #(data) = 4736
12/17/2017 22:02:30 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:02:30 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:02:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:02:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:02:30 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:02:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:03:27 [INFO] exp_shallowmodel: train time: 57.388s
12/17/2017 22:03:27 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:03:27 [INFO] exp_shallowmodel: accuracy:   0.624
12/17/2017 22:03:27 [INFO] exp_shallowmodel: f1_score:   0.470
12/17/2017 22:03:27 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:03:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.11      0.17        28
          C       0.56      0.68      0.61       172
          F       0.73      0.79      0.76       283
          R       0.41      0.28      0.34       123

avg / total       0.60      0.62      0.60       606

12/17/2017 22:03:27 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:03:27 [INFO] exp_shallowmodel: 
[[  3   6   9  10]
 [  1 117  35  19]
 [  1  38 223  21]
 [  2  49  37  35]]
12/17/2017 22:03:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/17/2017 22:03:27 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:03:27 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:03:27 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:03:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:03:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:03:27 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:03:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:04:40 [INFO] exp_shallowmodel: train time: 73.121s
12/17/2017 22:04:40 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 22:04:40 [INFO] exp_shallowmodel: accuracy:   0.659
12/17/2017 22:04:40 [INFO] exp_shallowmodel: f1_score:   0.516
12/17/2017 22:04:40 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:04:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.15      0.23        20
          C       0.59      0.70      0.64       169
          F       0.75      0.80      0.77       281
          R       0.52      0.35      0.42       122

avg / total       0.65      0.66      0.64       592

12/17/2017 22:04:40 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:04:40 [INFO] exp_shallowmodel: 
[[  3   4   9   4]
 [  1 119  31  18]
 [  1  38 225  17]
 [  1  42  36  43]]
12/17/2017 22:04:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/17/2017 22:04:41 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:04:41 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:04:41 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:04:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:04:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:04:41 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:04:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:05:44 [INFO] exp_shallowmodel: train time: 63.436s
12/17/2017 22:05:44 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 22:05:44 [INFO] exp_shallowmodel: accuracy:   0.645
12/17/2017 22:05:44 [INFO] exp_shallowmodel: f1_score:   0.479
12/17/2017 22:05:44 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:05:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.10      0.14        20
          C       0.58      0.66      0.62       169
          F       0.75      0.81      0.78       281
          R       0.45      0.32      0.37       122

avg / total       0.62      0.65      0.63       592

12/17/2017 22:05:44 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:05:44 [INFO] exp_shallowmodel: 
[[  2   1  10   7]
 [  3 112  26  28]
 [  1  38 229  13]
 [  2  42  39  39]]
12/17/2017 22:05:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/17/2017 22:05:44 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:05:44 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:05:44 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:05:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:05:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:05:44 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:05:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:06:39 [INFO] exp_shallowmodel: train time: 54.187s
12/17/2017 22:06:39 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 22:06:39 [INFO] exp_shallowmodel: accuracy:   0.654
12/17/2017 22:06:39 [INFO] exp_shallowmodel: f1_score:   0.520
12/17/2017 22:06:39 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:06:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.20      0.28        20
          C       0.58      0.62      0.60       169
          F       0.75      0.83      0.79       281
          R       0.49      0.36      0.42       122

avg / total       0.64      0.65      0.64       592

12/17/2017 22:06:39 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:06:39 [INFO] exp_shallowmodel: 
[[  4   4   6   6]
 [  1 105  39  24]
 [  2  29 234  16]
 [  2  43  33  44]]
12/17/2017 22:06:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/17/2017 22:06:39 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:06:39 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:06:39 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:06:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:06:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:06:39 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:06:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:07:34 [INFO] exp_shallowmodel: train time: 55.625s
12/17/2017 22:07:34 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:07:34 [INFO] exp_shallowmodel: accuracy:   0.613
12/17/2017 22:07:34 [INFO] exp_shallowmodel: f1_score:   0.448
12/17/2017 22:07:34 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:07:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.10      0.12        20
          C       0.57      0.64      0.60       169
          F       0.73      0.78      0.75       281
          R       0.38      0.27      0.32       122

avg / total       0.59      0.61      0.60       592

12/17/2017 22:07:34 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:07:34 [INFO] exp_shallowmodel: 
[[  2   2  10   6]
 [  1 108  34  26]
 [  5  34 220  22]
 [  5  45  39  33]]
12/17/2017 22:07:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/17/2017 22:07:35 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:07:35 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:07:35 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:07:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:07:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:07:35 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:07:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:08:30 [INFO] exp_shallowmodel: train time: 55.490s
12/17/2017 22:08:30 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 22:08:30 [INFO] exp_shallowmodel: accuracy:   0.628
12/17/2017 22:08:30 [INFO] exp_shallowmodel: f1_score:   0.455
12/17/2017 22:08:30 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:08:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.05      0.08        20
          C       0.59      0.63      0.61       169
          F       0.71      0.80      0.75       281
          R       0.45      0.33      0.38       122

avg / total       0.60      0.63      0.61       592

12/17/2017 22:08:30 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:08:30 [INFO] exp_shallowmodel: 
[[  1   6  12   1]
 [  0 107  37  25]
 [  5  30 224  22]
 [  0  38  44  40]]
12/17/2017 22:08:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/17/2017 22:08:30 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:08:30 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:08:30 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:08:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:08:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:08:30 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:08:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:09:28 [INFO] exp_shallowmodel: train time: 57.714s
12/17/2017 22:09:28 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:09:28 [INFO] exp_shallowmodel: accuracy:   0.620
12/17/2017 22:09:28 [INFO] exp_shallowmodel: f1_score:   0.511
12/17/2017 22:09:28 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:09:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.30      0.36        20
          C       0.55      0.56      0.55       169
          F       0.71      0.81      0.76       281
          R       0.45      0.31      0.37       122

avg / total       0.60      0.62      0.61       592

12/17/2017 22:09:28 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:09:28 [INFO] exp_shallowmodel: 
[[  6   1   9   4]
 [  2  94  46  27]
 [  4  33 229  15]
 [  1  44  39  38]]
12/17/2017 22:09:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/17/2017 22:09:28 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:09:28 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:09:28 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:09:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:09:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:09:28 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:09:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:10:45 [INFO] exp_shallowmodel: train time: 76.343s
12/17/2017 22:10:45 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:10:45 [INFO] exp_shallowmodel: accuracy:   0.605
12/17/2017 22:10:45 [INFO] exp_shallowmodel: f1_score:   0.450
12/17/2017 22:10:45 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:10:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.10      0.13        20
          C       0.51      0.59      0.55       169
          F       0.75      0.77      0.76       281
          R       0.41      0.32      0.36       122

avg / total       0.59      0.60      0.60       592

12/17/2017 22:10:45 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:10:45 [INFO] exp_shallowmodel: 
[[  2   7   6   5]
 [  5 100  32  32]
 [  3  42 217  19]
 [  0  47  36  39]]
12/17/2017 22:10:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/17/2017 22:10:45 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:10:45 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:10:45 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:10:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:10:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:10:45 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:10:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:12:31 [INFO] exp_shallowmodel: train time: 105.909s
12/17/2017 22:12:31 [INFO] exp_shallowmodel: test time:  0.001s
12/17/2017 22:12:31 [INFO] exp_shallowmodel: accuracy:   0.596
12/17/2017 22:12:31 [INFO] exp_shallowmodel: f1_score:   0.472
12/17/2017 22:12:31 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:12:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.25      0.28        20
          C       0.53      0.62      0.57       169
          F       0.72      0.75      0.73       281
          R       0.37      0.25      0.30       122

avg / total       0.58      0.60      0.58       592

12/17/2017 22:12:31 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:12:31 [INFO] exp_shallowmodel: 
[[  5   2   9   4]
 [  2 105  37  25]
 [  4  42 212  23]
 [  5  48  38  31]]
12/17/2017 22:12:32 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/17/2017 22:12:32 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:12:32 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:12:32 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:12:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:12:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:12:32 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:12:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:14:47 [INFO] exp_shallowmodel: train time: 135.183s
12/17/2017 22:14:47 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:14:47 [INFO] exp_shallowmodel: accuracy:   0.622
12/17/2017 22:14:47 [INFO] exp_shallowmodel: f1_score:   0.466
12/17/2017 22:14:47 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:14:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.53      0.59      0.55       169
          F       0.71      0.80      0.76       281
          R       0.51      0.34      0.41       122

avg / total       0.60      0.62      0.61       592

12/17/2017 22:14:47 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:14:47 [INFO] exp_shallowmodel: 
[[  2   3  11   4]
 [  1  99  48  21]
 [  2  39 226  14]
 [  2  47  32  41]]
12/17/2017 22:14:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/17/2017 22:14:48 [INFO] exp_shallowmodel: #(data) = 4736
12/17/2017 22:14:48 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:14:48 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:14:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:14:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:14:48 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:14:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:17:51 [INFO] exp_shallowmodel: train time: 183.248s
12/17/2017 22:17:51 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:17:51 [INFO] exp_shallowmodel: accuracy:   0.594
12/17/2017 22:17:51 [INFO] exp_shallowmodel: f1_score:   0.455
12/17/2017 22:17:51 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:17:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.11      0.18        28
          C       0.50      0.60      0.55       172
          F       0.71      0.76      0.73       283
          R       0.42      0.31      0.36       123

avg / total       0.59      0.59      0.58       606

12/17/2017 22:17:51 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:17:51 [INFO] exp_shallowmodel: 
[[  3   4  10  11]
 [  0 104  48  20]
 [  0  47 215  21]
 [  2  52  31  38]]
12/17/2017 22:17:51 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/17/2017 22:17:51 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:17:51 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:17:51 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:17:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:17:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:17:51 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:17:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:20:03 [INFO] exp_shallowmodel: train time: 131.872s
12/17/2017 22:20:03 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:20:03 [INFO] exp_shallowmodel: accuracy:   0.644
12/17/2017 22:20:03 [INFO] exp_shallowmodel: f1_score:   0.457
12/17/2017 22:20:03 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:20:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        20
          C       0.56      0.66      0.61       169
          F       0.74      0.83      0.78       281
          R       0.46      0.28      0.35       122

avg / total       0.62      0.64      0.62       592

12/17/2017 22:20:03 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:20:03 [INFO] exp_shallowmodel: 
[[  1   2  13   4]
 [  1 112  32  24]
 [  0  35 234  12]
 [  1  50  37  34]]
12/17/2017 22:20:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/17/2017 22:20:04 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:20:04 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:20:04 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:20:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:20:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:20:04 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:20:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:22:13 [INFO] exp_shallowmodel: train time: 129.577s
12/17/2017 22:22:13 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:22:13 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 22:22:13 [INFO] exp_shallowmodel: f1_score:   0.487
12/17/2017 22:22:13 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:22:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.15      0.24        20
          C       0.57      0.62      0.60       169
          F       0.74      0.79      0.77       281
          R       0.38      0.32      0.35       122

avg / total       0.61      0.62      0.61       592

12/17/2017 22:22:13 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:22:13 [INFO] exp_shallowmodel: 
[[  3   1   7   9]
 [  1 105  34  29]
 [  1  32 223  25]
 [  0  45  38  39]]
12/17/2017 22:22:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/17/2017 22:22:14 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:22:14 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:22:14 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:22:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:22:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:22:14 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:22:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:24:02 [INFO] exp_shallowmodel: train time: 108.377s
12/17/2017 22:24:02 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:24:02 [INFO] exp_shallowmodel: accuracy:   0.630
12/17/2017 22:24:02 [INFO] exp_shallowmodel: f1_score:   0.498
12/17/2017 22:24:02 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:24:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.20      0.26        20
          C       0.56      0.60      0.58       169
          F       0.74      0.80      0.77       281
          R       0.44      0.34      0.39       122

avg / total       0.61      0.63      0.62       592

12/17/2017 22:24:02 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:24:02 [INFO] exp_shallowmodel: 
[[  4   2   9   5]
 [  0 101  37  31]
 [  5  32 226  18]
 [  2  44  34  42]]
12/17/2017 22:24:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/17/2017 22:24:03 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:24:03 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:24:03 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:24:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:24:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:24:03 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:24:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:26:23 [INFO] exp_shallowmodel: train time: 140.086s
12/17/2017 22:26:23 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:26:23 [INFO] exp_shallowmodel: accuracy:   0.628
12/17/2017 22:26:23 [INFO] exp_shallowmodel: f1_score:   0.488
12/17/2017 22:26:23 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:26:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.15      0.21        20
          C       0.58      0.64      0.61       169
          F       0.74      0.78      0.76       281
          R       0.42      0.34      0.38       122

avg / total       0.61      0.63      0.62       592

12/17/2017 22:26:23 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:26:23 [INFO] exp_shallowmodel: 
[[  3   1  11   5]
 [  0 108  30  31]
 [  5  34 219  23]
 [  1  44  35  42]]
12/17/2017 22:26:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/17/2017 22:26:23 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:26:23 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:26:23 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:26:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:26:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:26:23 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:26:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:28:51 [INFO] exp_shallowmodel: train time: 147.668s
12/17/2017 22:28:51 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:28:51 [INFO] exp_shallowmodel: accuracy:   0.620
12/17/2017 22:28:51 [INFO] exp_shallowmodel: f1_score:   0.495
12/17/2017 22:28:51 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:28:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.20      0.28        20
          C       0.54      0.60      0.57       169
          F       0.73      0.79      0.76       281
          R       0.43      0.34      0.38       122

avg / total       0.61      0.62      0.61       592

12/17/2017 22:28:51 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:28:51 [INFO] exp_shallowmodel: 
[[  4   3   8   5]
 [  2 101  38  28]
 [  1  37 221  22]
 [  2  45  34  41]]
12/17/2017 22:28:51 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/17/2017 22:28:51 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:28:51 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:28:51 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:28:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:28:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:28:51 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:28:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:31:36 [INFO] exp_shallowmodel: train time: 164.428s
12/17/2017 22:31:36 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:31:36 [INFO] exp_shallowmodel: accuracy:   0.595
12/17/2017 22:31:36 [INFO] exp_shallowmodel: f1_score:   0.429
12/17/2017 22:31:36 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:31:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.53      0.62      0.57       169
          F       0.71      0.74      0.73       281
          R       0.41      0.31      0.36       122

avg / total       0.58      0.59      0.58       592

12/17/2017 22:31:36 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:31:36 [INFO] exp_shallowmodel: 
[[  1   4  11   4]
 [  1 104  34  30]
 [  5  47 209  20]
 [  5  40  39  38]]
12/17/2017 22:31:36 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/17/2017 22:31:36 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:31:36 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:31:36 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:31:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:31:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:31:36 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:31:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:34:13 [INFO] exp_shallowmodel: train time: 157.082s
12/17/2017 22:34:13 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:34:13 [INFO] exp_shallowmodel: accuracy:   0.613
12/17/2017 22:34:13 [INFO] exp_shallowmodel: f1_score:   0.452
12/17/2017 22:34:13 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:34:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.10      0.15        20
          C       0.52      0.61      0.56       169
          F       0.73      0.80      0.76       281
          R       0.43      0.27      0.33       122

avg / total       0.59      0.61      0.59       592

12/17/2017 22:34:13 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:34:13 [INFO] exp_shallowmodel: 
[[  2   3  11   4]
 [  1 103  38  27]
 [  1  42 225  13]
 [  2  52  35  33]]
12/17/2017 22:34:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/17/2017 22:34:14 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:34:14 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:34:14 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:34:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:34:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:34:14 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:34:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:36:21 [INFO] exp_shallowmodel: train time: 127.582s
12/17/2017 22:36:21 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:36:21 [INFO] exp_shallowmodel: accuracy:   0.623
12/17/2017 22:36:21 [INFO] exp_shallowmodel: f1_score:   0.514
12/17/2017 22:36:21 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:36:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.41      0.35      0.38        20
          C       0.60      0.66      0.63       169
          F       0.73      0.78      0.75       281
          R       0.36      0.25      0.30       122

avg / total       0.60      0.62      0.61       592

12/17/2017 22:36:21 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:36:21 [INFO] exp_shallowmodel: 
[[  7   0   9   4]
 [  3 112  28  26]
 [  3  34 219  25]
 [  4  42  45  31]]
12/17/2017 22:36:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/17/2017 22:36:22 [INFO] exp_shallowmodel: #(data) = 4750
12/17/2017 22:36:22 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:36:22 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:36:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:36:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:36:22 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:36:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:38:13 [INFO] exp_shallowmodel: train time: 111.063s
12/17/2017 22:38:13 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:38:13 [INFO] exp_shallowmodel: accuracy:   0.625
12/17/2017 22:38:13 [INFO] exp_shallowmodel: f1_score:   0.471
12/17/2017 22:38:13 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:38:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.10      0.14        20
          C       0.55      0.57      0.56       169
          F       0.73      0.80      0.76       281
          R       0.48      0.38      0.42       122

avg / total       0.61      0.62      0.61       592

12/17/2017 22:38:13 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:38:13 [INFO] exp_shallowmodel: 
[[  2   2   8   8]
 [  1  97  44  27]
 [  4  37 225  15]
 [  2  41  33  46]]
12/17/2017 22:38:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/17/2017 22:38:14 [INFO] exp_shallowmodel: #(data) = 4736
12/17/2017 22:38:14 [INFO] exp_shallowmodel: #(feature) = 1409
12/17/2017 22:38:14 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:38:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:38:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:38:14 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:38:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:40:20 [INFO] exp_shallowmodel: train time: 126.206s
12/17/2017 22:40:20 [INFO] exp_shallowmodel: test time:  0.002s
12/17/2017 22:40:20 [INFO] exp_shallowmodel: accuracy:   0.645
12/17/2017 22:40:20 [INFO] exp_shallowmodel: f1_score:   0.502
12/17/2017 22:40:20 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:40:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.14      0.22        28
          C       0.60      0.69      0.64       172
          F       0.73      0.81      0.77       283
          R       0.47      0.33      0.38       123

avg / total       0.63      0.65      0.63       606

12/17/2017 22:40:20 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:40:20 [INFO] exp_shallowmodel: 
[[  4   6  10   8]
 [  1 119  28  24]
 [  3  38 228  14]
 [  1  36  46  40]]
12/17/2017 22:40:34 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 22:40:34 [INFO] task_runner: context=current, feature=10-[5+1.3.4]
12/17/2017 22:40:34 [INFO] task_runner: retained feature numbers=[8.1, 6, 3, 2.2, 1, 7, 5, 2.1]
12/17/2017 22:40:34 [INFO] task_runner: #(data)=3530
12/17/2017 22:40:34 [INFO] task_runner: #(feature)=6613
12/17/2017 22:40:34 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 22:40:36 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/17/2017 22:40:36 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:40:36 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:40:36 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:40:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:40:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:40:36 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:40:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:41:42 [INFO] exp_shallowmodel: train time: 65.706s
12/17/2017 22:41:42 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 22:41:42 [INFO] exp_shallowmodel: accuracy:   0.716
12/17/2017 22:41:42 [INFO] exp_shallowmodel: f1_score:   0.415
12/17/2017 22:41:42 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:41:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.22      0.29        23
          C       0.31      0.19      0.23        27
          F       0.78      0.92      0.84       250
          R       0.41      0.23      0.30        52

avg / total       0.67      0.72      0.68       352

12/17/2017 22:41:42 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:41:42 [INFO] exp_shallowmodel: 
[[  5   3  15   0]
 [  1   5  15   6]
 [  5   4 230  11]
 [  1   4  35  12]]
12/17/2017 22:41:44 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/17/2017 22:41:44 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:41:44 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:41:44 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:41:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:41:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:41:44 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:41:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:42:30 [INFO] exp_shallowmodel: train time: 46.485s
12/17/2017 22:42:30 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:42:30 [INFO] exp_shallowmodel: accuracy:   0.747
12/17/2017 22:42:30 [INFO] exp_shallowmodel: f1_score:   0.408
12/17/2017 22:42:30 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:42:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        23
          C       0.29      0.15      0.20        27
          F       0.81      0.94      0.87       250
          R       0.57      0.44      0.50        52

avg / total       0.69      0.75      0.71       352

12/17/2017 22:42:30 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:42:30 [INFO] exp_shallowmodel: 
[[  1   0  18   4]
 [  3   4  16   4]
 [  1   5 235   9]
 [  3   5  21  23]]
12/17/2017 22:42:31 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/17/2017 22:42:31 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:42:31 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:42:31 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:42:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:42:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:42:31 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:42:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:43:15 [INFO] exp_shallowmodel: train time: 43.683s
12/17/2017 22:43:15 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 22:43:15 [INFO] exp_shallowmodel: accuracy:   0.761
12/17/2017 22:43:15 [INFO] exp_shallowmodel: f1_score:   0.445
12/17/2017 22:43:15 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:43:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.13      0.20        23
          C       0.27      0.15      0.19        27
          F       0.82      0.95      0.88       250
          R       0.61      0.44      0.51        52

avg / total       0.72      0.76      0.73       352

12/17/2017 22:43:15 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:43:15 [INFO] exp_shallowmodel: 
[[  3   3  16   1]
 [  2   4  13   8]
 [  1   5 238   6]
 [  1   3  25  23]]
12/17/2017 22:43:17 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/17/2017 22:43:17 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:43:17 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:43:17 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:43:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:43:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:43:17 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:43:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:44:02 [INFO] exp_shallowmodel: train time: 45.604s
12/17/2017 22:44:02 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 22:44:02 [INFO] exp_shallowmodel: accuracy:   0.730
12/17/2017 22:44:02 [INFO] exp_shallowmodel: f1_score:   0.410
12/17/2017 22:44:02 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:44:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.13      0.20        23
          C       0.27      0.15      0.19        27
          F       0.80      0.93      0.86       250
          R       0.45      0.35      0.39        52

avg / total       0.68      0.73      0.70       352

12/17/2017 22:44:02 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:44:02 [INFO] exp_shallowmodel: 
[[  3   0  15   5]
 [  0   4  17   6]
 [  4   3 232  11]
 [  0   8  26  18]]
12/17/2017 22:44:04 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/17/2017 22:44:04 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:44:04 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:44:04 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:44:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:44:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:44:04 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:44:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:44:50 [INFO] exp_shallowmodel: train time: 46.595s
12/17/2017 22:44:50 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 22:44:50 [INFO] exp_shallowmodel: accuracy:   0.696
12/17/2017 22:44:50 [INFO] exp_shallowmodel: f1_score:   0.385
12/17/2017 22:44:50 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:44:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.32      0.26      0.29        27
          F       0.78      0.88      0.83       250
          R       0.39      0.33      0.35        52

avg / total       0.65      0.70      0.67       352

12/17/2017 22:44:50 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:44:50 [INFO] exp_shallowmodel: 
[[  1   1  15   6]
 [  0   7  17   3]
 [  4   8 220  18]
 [  0   6  29  17]]
12/17/2017 22:44:52 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/17/2017 22:44:52 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:44:52 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:44:52 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:44:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:44:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:44:52 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:44:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:45:38 [INFO] exp_shallowmodel: train time: 46.573s
12/17/2017 22:45:38 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:45:38 [INFO] exp_shallowmodel: accuracy:   0.722
12/17/2017 22:45:38 [INFO] exp_shallowmodel: f1_score:   0.414
12/17/2017 22:45:38 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:45:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.09      0.10        23
          C       0.36      0.19      0.24        27
          F       0.81      0.90      0.85       250
          R       0.50      0.42      0.46        52

avg / total       0.68      0.72      0.70       352

12/17/2017 22:45:38 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:45:38 [INFO] exp_shallowmodel: 
[[  2   0  18   3]
 [  0   5  13   9]
 [ 12   3 225  10]
 [  2   6  22  22]]
12/17/2017 22:45:40 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/17/2017 22:45:40 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:45:40 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:45:40 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:45:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:45:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:45:40 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:45:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:46:26 [INFO] exp_shallowmodel: train time: 46.143s
12/17/2017 22:46:26 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 22:46:26 [INFO] exp_shallowmodel: accuracy:   0.736
12/17/2017 22:46:26 [INFO] exp_shallowmodel: f1_score:   0.437
12/17/2017 22:46:26 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:46:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.13      0.18        23
          C       0.35      0.22      0.27        27
          F       0.81      0.92      0.86       250
          R       0.49      0.38      0.43        52

avg / total       0.69      0.74      0.71       352

12/17/2017 22:46:26 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:46:26 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  0   6  13   8]
 [  3   7 230  10]
 [  4   3  25  20]]
12/17/2017 22:46:27 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/17/2017 22:46:27 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:46:27 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:46:27 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:46:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:46:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:46:27 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:46:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:47:09 [INFO] exp_shallowmodel: train time: 41.991s
12/17/2017 22:47:09 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 22:47:09 [INFO] exp_shallowmodel: accuracy:   0.727
12/17/2017 22:47:09 [INFO] exp_shallowmodel: f1_score:   0.443
12/17/2017 22:47:09 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:47:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.13      0.19        23
          C       0.48      0.41      0.44        27
          F       0.79      0.92      0.85       250
          R       0.40      0.23      0.29        52

avg / total       0.68      0.73      0.69       352

12/17/2017 22:47:09 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:47:09 [INFO] exp_shallowmodel: 
[[  3   4  13   3]
 [  0  11  12   4]
 [  4   5 230  11]
 [  2   3  35  12]]
12/17/2017 22:47:11 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/17/2017 22:47:11 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:47:11 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:47:11 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:47:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:47:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:47:11 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:47:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:47:53 [INFO] exp_shallowmodel: train time: 42.322s
12/17/2017 22:47:53 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:47:53 [INFO] exp_shallowmodel: accuracy:   0.710
12/17/2017 22:47:53 [INFO] exp_shallowmodel: f1_score:   0.416
12/17/2017 22:47:53 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:47:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.32      0.22      0.26        27
          F       0.80      0.88      0.84       250
          R       0.47      0.42      0.44        52

avg / total       0.67      0.71      0.69       352

12/17/2017 22:47:53 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:47:53 [INFO] exp_shallowmodel: 
[[  2   1  18   2]
 [  0   6  16   5]
 [  5   7 220  18]
 [  3   5  22  22]]
12/17/2017 22:47:55 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/17/2017 22:47:55 [INFO] exp_shallowmodel: #(data) = 2816
12/17/2017 22:47:55 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:47:55 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:47:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:47:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:47:55 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:47:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:48:41 [INFO] exp_shallowmodel: train time: 46.028s
12/17/2017 22:48:41 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:48:41 [INFO] exp_shallowmodel: accuracy:   0.718
12/17/2017 22:48:41 [INFO] exp_shallowmodel: f1_score:   0.397
12/17/2017 22:48:41 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:48:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.08      0.12        25
          C       0.38      0.19      0.25        27
          F       0.76      0.94      0.84       251
          R       0.53      0.29      0.37        59

avg / total       0.66      0.72      0.67       362

12/17/2017 22:48:41 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:48:41 [INFO] exp_shallowmodel: 
[[  2   1  20   2]
 [  0   5  17   5]
 [  3   4 236   8]
 [  2   3  37  17]]
12/17/2017 22:48:42 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/17/2017 22:48:42 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:48:42 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:48:42 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:48:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:48:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:48:42 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:48:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:49:24 [INFO] exp_shallowmodel: train time: 41.835s
12/17/2017 22:49:24 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 22:49:24 [INFO] exp_shallowmodel: accuracy:   0.739
12/17/2017 22:49:24 [INFO] exp_shallowmodel: f1_score:   0.392
12/17/2017 22:49:24 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:49:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.36      0.19      0.24        27
          F       0.80      0.94      0.86       250
          R       0.54      0.40      0.46        52

avg / total       0.67      0.74      0.70       352

12/17/2017 22:49:24 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:49:24 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   5  12  10]
 [  5   5 234   6]
 [  1   4  26  21]]
12/17/2017 22:49:25 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/17/2017 22:49:25 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:49:25 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:49:25 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:49:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:49:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:49:25 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:49:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:50:12 [INFO] exp_shallowmodel: train time: 46.539s
12/17/2017 22:50:12 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:50:12 [INFO] exp_shallowmodel: accuracy:   0.679
12/17/2017 22:50:12 [INFO] exp_shallowmodel: f1_score:   0.335
12/17/2017 22:50:12 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:50:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        23
          C       0.19      0.11      0.14        27
          F       0.77      0.88      0.82       250
          R       0.34      0.29      0.31        52

avg / total       0.62      0.68      0.65       352

12/17/2017 22:50:12 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:50:12 [INFO] exp_shallowmodel: 
[[  1   1  14   7]
 [  1   3  18   5]
 [  5   8 220  17]
 [  1   4  32  15]]
12/17/2017 22:50:13 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/17/2017 22:50:13 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:50:13 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:50:13 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:50:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:50:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:50:13 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:50:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:50:58 [INFO] exp_shallowmodel: train time: 44.318s
12/17/2017 22:50:58 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 22:50:58 [INFO] exp_shallowmodel: accuracy:   0.724
12/17/2017 22:50:58 [INFO] exp_shallowmodel: f1_score:   0.417
12/17/2017 22:50:58 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:50:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.09      0.13        23
          C       0.35      0.26      0.30        27
          F       0.79      0.92      0.85       250
          R       0.49      0.33      0.39        52

avg / total       0.68      0.72      0.69       352

12/17/2017 22:50:58 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:50:58 [INFO] exp_shallowmodel: 
[[  2   1  18   2]
 [  1   7  13   6]
 [  5   6 229  10]
 [  0   6  29  17]]
12/17/2017 22:50:59 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/17/2017 22:50:59 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:50:59 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:50:59 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:50:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:50:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:50:59 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:50:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:51:41 [INFO] exp_shallowmodel: train time: 42.232s
12/17/2017 22:51:41 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:51:41 [INFO] exp_shallowmodel: accuracy:   0.713
12/17/2017 22:51:41 [INFO] exp_shallowmodel: f1_score:   0.421
12/17/2017 22:51:41 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:51:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.13      0.18        23
          C       0.35      0.22      0.27        27
          F       0.80      0.89      0.84       250
          R       0.42      0.37      0.39        52

avg / total       0.67      0.71      0.69       352

12/17/2017 22:51:41 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:51:41 [INFO] exp_shallowmodel: 
[[  3   0  14   6]
 [  0   6  14   7]
 [  7   7 223  13]
 [  1   4  28  19]]
12/17/2017 22:51:43 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/17/2017 22:51:43 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:51:43 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:51:43 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:51:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:51:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:51:43 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:51:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:52:31 [INFO] exp_shallowmodel: train time: 48.640s
12/17/2017 22:52:31 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:52:31 [INFO] exp_shallowmodel: accuracy:   0.733
12/17/2017 22:52:31 [INFO] exp_shallowmodel: f1_score:   0.404
12/17/2017 22:52:31 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:52:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.31      0.19      0.23        27
          F       0.80      0.94      0.86       250
          R       0.52      0.33      0.40        52

avg / total       0.68      0.73      0.70       352

12/17/2017 22:52:31 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:52:31 [INFO] exp_shallowmodel: 
[[  2   1  17   3]
 [  1   5  13   8]
 [  5   6 234   5]
 [  2   4  29  17]]
12/17/2017 22:52:33 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/17/2017 22:52:33 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:52:33 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:52:33 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:52:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:52:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:52:33 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:52:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:53:28 [INFO] exp_shallowmodel: train time: 54.470s
12/17/2017 22:53:28 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:53:28 [INFO] exp_shallowmodel: accuracy:   0.736
12/17/2017 22:53:28 [INFO] exp_shallowmodel: f1_score:   0.425
12/17/2017 22:53:28 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:53:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.13      0.18        23
          C       0.46      0.22      0.30        27
          F       0.79      0.94      0.86       250
          R       0.47      0.29      0.36        52

avg / total       0.69      0.74      0.70       352

12/17/2017 22:53:28 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:53:28 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  1   6  15   5]
 [  5   1 235   9]
 [  1   5  31  15]]
12/17/2017 22:53:29 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/17/2017 22:53:29 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:53:29 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:53:29 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:53:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:53:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:53:29 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:53:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:53:56 [INFO] exp_shallowmodel: train time: 26.767s
12/17/2017 22:53:56 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 22:53:56 [INFO] exp_shallowmodel: accuracy:   0.730
12/17/2017 22:53:56 [INFO] exp_shallowmodel: f1_score:   0.415
12/17/2017 22:53:56 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:53:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.38      0.19      0.25        27
          F       0.80      0.92      0.85       250
          R       0.50      0.38      0.43        52

avg / total       0.68      0.73      0.70       352

12/17/2017 22:53:56 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:53:56 [INFO] exp_shallowmodel: 
[[  2   0  16   5]
 [  2   5  17   3]
 [  4   4 230  12]
 [  2   4  26  20]]
12/17/2017 22:53:57 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/17/2017 22:53:57 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:53:57 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:53:57 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:53:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:53:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:53:57 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:53:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:54:21 [INFO] exp_shallowmodel: train time: 24.458s
12/17/2017 22:54:21 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 22:54:21 [INFO] exp_shallowmodel: accuracy:   0.719
12/17/2017 22:54:21 [INFO] exp_shallowmodel: f1_score:   0.428
12/17/2017 22:54:21 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:54:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.47      0.33      0.39        27
          F       0.78      0.90      0.83       250
          R       0.50      0.37      0.42        52

avg / total       0.67      0.72      0.69       352

12/17/2017 22:54:21 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:54:21 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  0   9  14   4]
 [  4   8 224  14]
 [  2   1  30  19]]
12/17/2017 22:54:22 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/17/2017 22:54:22 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:54:22 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:54:22 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:54:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:54:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:54:22 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:54:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:54:46 [INFO] exp_shallowmodel: train time: 23.563s
12/17/2017 22:54:46 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:54:46 [INFO] exp_shallowmodel: accuracy:   0.736
12/17/2017 22:54:46 [INFO] exp_shallowmodel: f1_score:   0.427
12/17/2017 22:54:46 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:54:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.17      0.25        23
          C       0.27      0.15      0.19        27
          F       0.80      0.93      0.86       250
          R       0.49      0.35      0.40        52

avg / total       0.69      0.74      0.70       352

12/17/2017 22:54:46 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:54:46 [INFO] exp_shallowmodel: 
[[  4   0  16   3]
 [  0   4  16   7]
 [  4   4 233   9]
 [  1   7  26  18]]
12/17/2017 22:54:46 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/17/2017 22:54:46 [INFO] exp_shallowmodel: #(data) = 2816
12/17/2017 22:54:46 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:54:46 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:54:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:54:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:54:46 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:54:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:55:18 [INFO] exp_shallowmodel: train time: 31.361s
12/17/2017 22:55:18 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 22:55:18 [INFO] exp_shallowmodel: accuracy:   0.702
12/17/2017 22:55:18 [INFO] exp_shallowmodel: f1_score:   0.369
12/17/2017 22:55:18 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:55:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        25
          C       0.24      0.15      0.18        27
          F       0.77      0.91      0.83       251
          R       0.47      0.34      0.39        59

avg / total       0.64      0.70      0.66       362

12/17/2017 22:55:18 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:55:18 [INFO] exp_shallowmodel: 
[[  1   2  19   3]
 [  0   4  17   6]
 [  2   6 229  14]
 [  1   5  33  20]]
12/17/2017 22:55:19 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/17/2017 22:55:19 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:55:19 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:55:19 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:55:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:55:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:55:19 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:55:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:56:02 [INFO] exp_shallowmodel: train time: 43.412s
12/17/2017 22:56:02 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 22:56:02 [INFO] exp_shallowmodel: accuracy:   0.736
12/17/2017 22:56:02 [INFO] exp_shallowmodel: f1_score:   0.413
12/17/2017 22:56:02 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:56:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.43      0.22      0.29        27
          F       0.80      0.91      0.85       250
          R       0.54      0.48      0.51        52

avg / total       0.68      0.74      0.70       352

12/17/2017 22:56:02 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:56:02 [INFO] exp_shallowmodel: 
[[  0   1  17   5]
 [  1   6  16   4]
 [  4   6 228  12]
 [  1   1  25  25]]
12/17/2017 22:56:04 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/17/2017 22:56:04 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:56:04 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:56:04 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:56:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:56:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:56:04 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:56:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:56:51 [INFO] exp_shallowmodel: train time: 47.060s
12/17/2017 22:56:51 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:56:51 [INFO] exp_shallowmodel: accuracy:   0.710
12/17/2017 22:56:51 [INFO] exp_shallowmodel: f1_score:   0.375
12/17/2017 22:56:51 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:56:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.24      0.19      0.21        27
          F       0.79      0.91      0.85       250
          R       0.45      0.33      0.38        52

avg / total       0.66      0.71      0.68       352

12/17/2017 22:56:51 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:56:51 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  1   5  14   7]
 [  4   8 227  11]
 [  1   7  27  17]]
12/17/2017 22:56:52 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/17/2017 22:56:52 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:56:52 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:56:52 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:56:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:56:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:56:52 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:56:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:57:34 [INFO] exp_shallowmodel: train time: 41.833s
12/17/2017 22:57:34 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 22:57:34 [INFO] exp_shallowmodel: accuracy:   0.753
12/17/2017 22:57:34 [INFO] exp_shallowmodel: f1_score:   0.488
12/17/2017 22:57:34 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:57:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.22      0.29        23
          C       0.42      0.30      0.35        27
          F       0.82      0.93      0.87       250
          R       0.51      0.38      0.44        52

avg / total       0.72      0.75      0.73       352

12/17/2017 22:57:34 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:57:34 [INFO] exp_shallowmodel: 
[[  5   0  15   3]
 [  1   8  12   6]
 [  2   6 232  10]
 [  3   5  24  20]]
12/17/2017 22:57:36 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/17/2017 22:57:36 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:57:36 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:57:36 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:57:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:57:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:57:36 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:57:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:58:15 [INFO] exp_shallowmodel: train time: 39.278s
12/17/2017 22:58:15 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:58:15 [INFO] exp_shallowmodel: accuracy:   0.713
12/17/2017 22:58:15 [INFO] exp_shallowmodel: f1_score:   0.362
12/17/2017 22:58:15 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:58:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        23
          C       0.29      0.15      0.20        27
          F       0.79      0.92      0.85       250
          R       0.41      0.29      0.34        52

avg / total       0.65      0.71      0.67       352

12/17/2017 22:58:15 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:58:15 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  0   4  14   9]
 [  4   6 231   9]
 [  4   3  30  15]]
12/17/2017 22:58:16 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/17/2017 22:58:16 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:58:16 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:58:16 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:58:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:58:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:58:16 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:58:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:59:06 [INFO] exp_shallowmodel: train time: 49.751s
12/17/2017 22:59:06 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:59:06 [INFO] exp_shallowmodel: accuracy:   0.744
12/17/2017 22:59:06 [INFO] exp_shallowmodel: f1_score:   0.437
12/17/2017 22:59:06 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:59:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.47      0.26      0.33        27
          F       0.82      0.92      0.86       250
          R       0.47      0.48      0.48        52

avg / total       0.70      0.74      0.71       352

12/17/2017 22:59:06 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:59:06 [INFO] exp_shallowmodel: 
[[  1   0  17   5]
 [  0   7  12   8]
 [  2   4 229  15]
 [  1   4  22  25]]
12/17/2017 22:59:07 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/17/2017 22:59:07 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:59:07 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:59:07 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:59:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:59:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:59:07 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:59:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 22:59:48 [INFO] exp_shallowmodel: train time: 40.060s
12/17/2017 22:59:48 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 22:59:48 [INFO] exp_shallowmodel: accuracy:   0.699
12/17/2017 22:59:48 [INFO] exp_shallowmodel: f1_score:   0.346
12/17/2017 22:59:48 [INFO] exp_shallowmodel: classification report:
12/17/2017 22:59:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        23
          C       0.18      0.11      0.14        27
          F       0.78      0.91      0.84       250
          R       0.43      0.29      0.34        52

avg / total       0.64      0.70      0.66       352

12/17/2017 22:59:48 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 22:59:48 [INFO] exp_shallowmodel: 
[[  1   0  18   4]
 [  0   3  19   5]
 [  5   7 227  11]
 [  2   7  28  15]]
12/17/2017 22:59:49 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/17/2017 22:59:49 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 22:59:49 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 22:59:49 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 22:59:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 22:59:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 22:59:49 [INFO] exp_shallowmodel: Training: 
12/17/2017 22:59:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:00:30 [INFO] exp_shallowmodel: train time: 41.162s
12/17/2017 23:00:30 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:00:30 [INFO] exp_shallowmodel: accuracy:   0.705
12/17/2017 23:00:30 [INFO] exp_shallowmodel: f1_score:   0.335
12/17/2017 23:00:30 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:00:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.10      0.07      0.09        27
          F       0.78      0.92      0.85       250
          R       0.47      0.27      0.34        52

avg / total       0.64      0.70      0.66       352

12/17/2017 23:00:30 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:00:30 [INFO] exp_shallowmodel: 
[[  1   2  16   4]
 [  1   2  20   4]
 [  3   8 231   8]
 [  2   8  28  14]]
12/17/2017 23:00:32 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/17/2017 23:00:32 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:00:32 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:00:32 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:00:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:00:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:00:32 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:00:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:01:19 [INFO] exp_shallowmodel: train time: 47.429s
12/17/2017 23:01:19 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:01:19 [INFO] exp_shallowmodel: accuracy:   0.727
12/17/2017 23:01:19 [INFO] exp_shallowmodel: f1_score:   0.420
12/17/2017 23:01:19 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:01:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.09      0.13        23
          C       0.41      0.26      0.32        27
          F       0.78      0.92      0.85       250
          R       0.50      0.31      0.38        52

avg / total       0.68      0.73      0.69       352

12/17/2017 23:01:19 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:01:19 [INFO] exp_shallowmodel: 
[[  2   1  17   3]
 [  1   7  15   4]
 [  4   6 231   9]
 [  0   3  33  16]]
12/17/2017 23:01:20 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/17/2017 23:01:20 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:01:20 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:01:20 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:01:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:01:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:01:20 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:01:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:02:03 [INFO] exp_shallowmodel: train time: 42.711s
12/17/2017 23:02:03 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:02:03 [INFO] exp_shallowmodel: accuracy:   0.722
12/17/2017 23:02:03 [INFO] exp_shallowmodel: f1_score:   0.418
12/17/2017 23:02:03 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:02:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.13      0.17        23
          C       0.47      0.26      0.33        27
          F       0.80      0.92      0.86       250
          R       0.38      0.27      0.31        52

avg / total       0.68      0.72      0.69       352

12/17/2017 23:02:03 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:02:03 [INFO] exp_shallowmodel: 
[[  3   0  16   4]
 [  0   7  11   9]
 [  6   4 230  10]
 [  4   4  30  14]]
12/17/2017 23:02:05 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/17/2017 23:02:05 [INFO] exp_shallowmodel: #(data) = 2816
12/17/2017 23:02:05 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:02:05 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:02:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:02:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:02:05 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:02:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:02:52 [INFO] exp_shallowmodel: train time: 47.055s
12/17/2017 23:02:52 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:02:52 [INFO] exp_shallowmodel: accuracy:   0.743
12/17/2017 23:02:52 [INFO] exp_shallowmodel: f1_score:   0.485
12/17/2017 23:02:52 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:02:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.20      0.29        25
          C       0.43      0.22      0.29        27
          F       0.79      0.92      0.85       251
          R       0.60      0.44      0.51        59

avg / total       0.71      0.74      0.71       362

12/17/2017 23:02:52 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:02:52 [INFO] exp_shallowmodel: 
[[  5   0  18   2]
 [  0   6  16   5]
 [  3   6 232  10]
 [  2   2  29  26]]
12/17/2017 23:02:53 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/17/2017 23:02:53 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:02:53 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:02:53 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:02:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:02:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:02:53 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:02:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:03:39 [INFO] exp_shallowmodel: train time: 46.067s
12/17/2017 23:03:39 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:03:39 [INFO] exp_shallowmodel: accuracy:   0.705
12/17/2017 23:03:39 [INFO] exp_shallowmodel: f1_score:   0.398
12/17/2017 23:03:39 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:03:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.09      0.12        23
          C       0.35      0.22      0.27        27
          F       0.79      0.89      0.84       250
          R       0.41      0.33      0.37        52

avg / total       0.66      0.70      0.68       352

12/17/2017 23:03:39 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:03:39 [INFO] exp_shallowmodel: 
[[  2   0  19   2]
 [  0   6  16   5]
 [  5   5 223  17]
 [  4   6  25  17]]
12/17/2017 23:03:41 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/17/2017 23:03:41 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:03:41 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:03:41 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:03:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:03:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:03:41 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:03:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:04:44 [INFO] exp_shallowmodel: train time: 62.519s
12/17/2017 23:04:44 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:04:44 [INFO] exp_shallowmodel: accuracy:   0.719
12/17/2017 23:04:44 [INFO] exp_shallowmodel: f1_score:   0.364
12/17/2017 23:04:44 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:04:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.26      0.19      0.22        27
          F       0.79      0.92      0.85       250
          R       0.47      0.33      0.39        52

avg / total       0.65      0.72      0.68       352

12/17/2017 23:04:44 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:04:44 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  0   5  16   6]
 [  3   6 231  10]
 [  1   7  27  17]]
12/17/2017 23:04:46 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/17/2017 23:04:46 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:04:46 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:04:46 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:04:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:04:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:04:46 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:04:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:05:59 [INFO] exp_shallowmodel: train time: 73.099s
12/17/2017 23:05:59 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:05:59 [INFO] exp_shallowmodel: accuracy:   0.750
12/17/2017 23:05:59 [INFO] exp_shallowmodel: f1_score:   0.443
12/17/2017 23:05:59 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:05:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.09      0.14        23
          C       0.41      0.26      0.32        27
          F       0.80      0.94      0.87       250
          R       0.53      0.38      0.44        52

avg / total       0.71      0.75      0.72       352

12/17/2017 23:05:59 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:05:59 [INFO] exp_shallowmodel: 
[[  2   4  14   3]
 [  0   7  12   8]
 [  3   5 235   7]
 [  0   1  31  20]]
12/17/2017 23:06:01 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/17/2017 23:06:01 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:06:01 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:06:01 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:06:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:06:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:06:01 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:06:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:06:49 [INFO] exp_shallowmodel: train time: 47.424s
12/17/2017 23:06:49 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:06:49 [INFO] exp_shallowmodel: accuracy:   0.702
12/17/2017 23:06:49 [INFO] exp_shallowmodel: f1_score:   0.402
12/17/2017 23:06:49 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:06:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.13      0.19        23
          C       0.23      0.19      0.20        27
          F       0.78      0.89      0.83       250
          R       0.46      0.33      0.38        52

avg / total       0.66      0.70      0.67       352

12/17/2017 23:06:49 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:06:49 [INFO] exp_shallowmodel: 
[[  3   1  17   2]
 [  1   5  17   4]
 [  4  10 222  14]
 [  0   6  29  17]]
12/17/2017 23:06:50 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/17/2017 23:06:50 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:06:50 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:06:50 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:06:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:06:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:06:50 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:06:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:07:35 [INFO] exp_shallowmodel: train time: 45.093s
12/17/2017 23:07:35 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:07:35 [INFO] exp_shallowmodel: accuracy:   0.736
12/17/2017 23:07:35 [INFO] exp_shallowmodel: f1_score:   0.421
12/17/2017 23:07:35 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:07:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.13      0.19        23
          C       0.24      0.15      0.18        27
          F       0.81      0.92      0.87       250
          R       0.49      0.40      0.44        52

avg / total       0.69      0.74      0.71       352

12/17/2017 23:07:35 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:07:35 [INFO] exp_shallowmodel: 
[[  3   1  14   5]
 [  0   4  15   8]
 [  3   7 231   9]
 [  2   5  24  21]]
12/17/2017 23:07:37 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/17/2017 23:07:37 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:07:37 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:07:37 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:07:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:07:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:07:37 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:07:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:08:20 [INFO] exp_shallowmodel: train time: 43.867s
12/17/2017 23:08:21 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:08:21 [INFO] exp_shallowmodel: accuracy:   0.716
12/17/2017 23:08:21 [INFO] exp_shallowmodel: f1_score:   0.411
12/17/2017 23:08:21 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:08:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.17      0.27        23
          C       0.33      0.15      0.21        27
          F       0.78      0.92      0.84       250
          R       0.38      0.29      0.33        52

avg / total       0.67      0.72      0.68       352

12/17/2017 23:08:21 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:08:21 [INFO] exp_shallowmodel: 
[[  4   1  14   4]
 [  0   4  17   6]
 [  2   5 229  14]
 [  1   2  34  15]]
12/17/2017 23:08:22 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/17/2017 23:08:22 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:08:22 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:08:22 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:08:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:08:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:08:22 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:08:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:09:04 [INFO] exp_shallowmodel: train time: 41.767s
12/17/2017 23:09:04 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:09:04 [INFO] exp_shallowmodel: accuracy:   0.699
12/17/2017 23:09:04 [INFO] exp_shallowmodel: f1_score:   0.347
12/17/2017 23:09:04 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:09:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.07        23
          C       0.40      0.15      0.22        27
          F       0.77      0.92      0.84       250
          R       0.31      0.23      0.26        52

avg / total       0.63      0.70      0.65       352

12/17/2017 23:09:04 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:09:04 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   4  15   8]
 [  1   3 229  17]
 [  4   2  34  12]]
12/17/2017 23:09:05 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/17/2017 23:09:05 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:09:05 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:09:05 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:09:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:09:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:09:05 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:09:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:09:51 [INFO] exp_shallowmodel: train time: 46.161s
12/17/2017 23:09:51 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:09:51 [INFO] exp_shallowmodel: accuracy:   0.741
12/17/2017 23:09:51 [INFO] exp_shallowmodel: f1_score:   0.423
12/17/2017 23:09:51 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:09:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.13      0.21        23
          C       0.30      0.11      0.16        27
          F       0.79      0.94      0.85       250
          R       0.54      0.40      0.46        52

avg / total       0.70      0.74      0.70       352

12/17/2017 23:09:51 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:09:51 [INFO] exp_shallowmodel: 
[[  3   0  15   5]
 [  0   3  20   4]
 [  2   5 234   9]
 [  0   2  29  21]]
12/17/2017 23:09:53 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/17/2017 23:09:53 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:09:53 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:09:53 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:09:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:09:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:09:53 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:09:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:10:41 [INFO] exp_shallowmodel: train time: 47.963s
12/17/2017 23:10:41 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:10:41 [INFO] exp_shallowmodel: accuracy:   0.730
12/17/2017 23:10:41 [INFO] exp_shallowmodel: f1_score:   0.436
12/17/2017 23:10:41 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:10:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.13      0.19        23
          C       0.39      0.26      0.31        27
          F       0.79      0.92      0.85       250
          R       0.49      0.33      0.39        52

avg / total       0.69      0.73      0.70       352

12/17/2017 23:10:41 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:10:41 [INFO] exp_shallowmodel: 
[[  3   2  15   3]
 [  0   7  13   7]
 [  5   7 230   8]
 [  0   2  33  17]]
12/17/2017 23:10:42 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/17/2017 23:10:42 [INFO] exp_shallowmodel: #(data) = 2816
12/17/2017 23:10:42 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:10:42 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:10:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:10:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:10:42 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:10:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:11:24 [INFO] exp_shallowmodel: train time: 42.306s
12/17/2017 23:11:24 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:11:24 [INFO] exp_shallowmodel: accuracy:   0.724
12/17/2017 23:11:24 [INFO] exp_shallowmodel: f1_score:   0.403
12/17/2017 23:11:24 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:11:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.08      0.13        25
          C       0.29      0.15      0.20        27
          F       0.78      0.93      0.85       251
          R       0.54      0.37      0.44        59

avg / total       0.67      0.72      0.68       362

12/17/2017 23:11:24 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:11:24 [INFO] exp_shallowmodel: 
[[  2   0  20   3]
 [  0   4  17   6]
 [  4   3 234  10]
 [  0   7  30  22]]
12/17/2017 23:11:26 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/17/2017 23:11:26 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:11:26 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:11:26 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:11:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:11:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:11:26 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:11:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:12:13 [INFO] exp_shallowmodel: train time: 46.746s
12/17/2017 23:12:13 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:12:13 [INFO] exp_shallowmodel: accuracy:   0.716
12/17/2017 23:12:13 [INFO] exp_shallowmodel: f1_score:   0.399
12/17/2017 23:12:13 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:12:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.37      0.26      0.30        27
          F       0.80      0.90      0.85       250
          R       0.41      0.35      0.38        52

avg / total       0.67      0.72      0.69       352

12/17/2017 23:12:13 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:12:13 [INFO] exp_shallowmodel: 
[[  1   0  16   6]
 [  1   7  11   8]
 [  5   7 226  12]
 [  0   5  29  18]]
12/17/2017 23:12:14 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/17/2017 23:12:14 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:12:14 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:12:14 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:12:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:12:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:12:14 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:12:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:12:58 [INFO] exp_shallowmodel: train time: 43.863s
12/17/2017 23:12:58 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:12:58 [INFO] exp_shallowmodel: accuracy:   0.730
12/17/2017 23:12:58 [INFO] exp_shallowmodel: f1_score:   0.402
12/17/2017 23:12:58 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:12:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.09      0.12        23
          C       0.19      0.11      0.14        27
          F       0.80      0.92      0.86       250
          R       0.55      0.44      0.49        52

avg / total       0.68      0.73      0.70       352

12/17/2017 23:12:58 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:12:58 [INFO] exp_shallowmodel: 
[[  2   3  16   2]
 [  1   3  18   5]
 [  4   5 229  12]
 [  2   5  22  23]]
12/17/2017 23:12:59 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/17/2017 23:12:59 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:12:59 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:12:59 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:12:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:12:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:12:59 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:12:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:13:47 [INFO] exp_shallowmodel: train time: 47.725s
12/17/2017 23:13:47 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:13:47 [INFO] exp_shallowmodel: accuracy:   0.753
12/17/2017 23:13:47 [INFO] exp_shallowmodel: f1_score:   0.471
12/17/2017 23:13:47 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:13:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.09      0.12        23
          C       0.41      0.26      0.32        27
          F       0.81      0.91      0.86       250
          R       0.64      0.54      0.58        52

avg / total       0.71      0.75      0.73       352

12/17/2017 23:13:47 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:13:47 [INFO] exp_shallowmodel: 
[[  2   1  17   3]
 [  0   7  15   5]
 [  6   8 228   8]
 [  1   1  22  28]]
12/17/2017 23:13:49 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/17/2017 23:13:49 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:13:49 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:13:49 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:13:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:13:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:13:49 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:13:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:14:30 [INFO] exp_shallowmodel: train time: 41.522s
12/17/2017 23:14:30 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:14:30 [INFO] exp_shallowmodel: accuracy:   0.713
12/17/2017 23:14:30 [INFO] exp_shallowmodel: f1_score:   0.432
12/17/2017 23:14:30 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:14:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.09      0.12        23
          C       0.42      0.37      0.39        27
          F       0.79      0.89      0.84       250
          R       0.44      0.33      0.37        52

avg / total       0.67      0.71      0.69       352

12/17/2017 23:14:30 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:14:30 [INFO] exp_shallowmodel: 
[[  2   0  16   5]
 [  0  10  11   6]
 [  5  12 222  11]
 [  2   2  31  17]]
12/17/2017 23:14:32 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/17/2017 23:14:32 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:14:32 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:14:32 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:14:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:14:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:14:32 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:14:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:15:20 [INFO] exp_shallowmodel: train time: 48.170s
12/17/2017 23:15:20 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:15:20 [INFO] exp_shallowmodel: accuracy:   0.736
12/17/2017 23:15:20 [INFO] exp_shallowmodel: f1_score:   0.452
12/17/2017 23:15:20 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:15:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.26      0.32        23
          C       0.25      0.15      0.19        27
          F       0.81      0.92      0.86       250
          R       0.54      0.38      0.45        52

avg / total       0.70      0.74      0.71       352

12/17/2017 23:15:20 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:15:20 [INFO] exp_shallowmodel: 
[[  6   0  16   1]
 [  0   4  15   8]
 [  6   7 229   8]
 [  3   5  24  20]]
12/17/2017 23:15:21 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/17/2017 23:15:21 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:15:21 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:15:21 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:15:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:15:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:15:21 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:15:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:16:00 [INFO] exp_shallowmodel: train time: 38.655s
12/17/2017 23:16:00 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:16:00 [INFO] exp_shallowmodel: accuracy:   0.702
12/17/2017 23:16:00 [INFO] exp_shallowmodel: f1_score:   0.346
12/17/2017 23:16:00 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:16:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.13      0.16        23
          C       0.21      0.11      0.15        27
          F       0.79      0.93      0.85       250
          R       0.31      0.17      0.22        52

avg / total       0.63      0.70      0.66       352

12/17/2017 23:16:00 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:16:00 [INFO] exp_shallowmodel: 
[[  3   1  15   4]
 [  3   3  13   8]
 [  5   5 232   8]
 [  3   5  35   9]]
12/17/2017 23:16:01 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/17/2017 23:16:01 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:16:01 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:16:01 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:16:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:16:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:16:01 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:16:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:16:47 [INFO] exp_shallowmodel: train time: 46.097s
12/17/2017 23:16:47 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:16:47 [INFO] exp_shallowmodel: accuracy:   0.722
12/17/2017 23:16:47 [INFO] exp_shallowmodel: f1_score:   0.392
12/17/2017 23:16:47 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:16:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.19      0.24        27
          F       0.78      0.90      0.84       250
          R       0.56      0.44      0.49        52

avg / total       0.66      0.72      0.69       352

12/17/2017 23:16:47 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:16:47 [INFO] exp_shallowmodel: 
[[  0   1  18   4]
 [  1   5  19   2]
 [  4   8 226  12]
 [  1   1  27  23]]
12/17/2017 23:16:49 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/17/2017 23:16:49 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:16:49 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:16:49 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:16:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:16:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:16:49 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:16:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:17:34 [INFO] exp_shallowmodel: train time: 45.571s
12/17/2017 23:17:34 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:17:34 [INFO] exp_shallowmodel: accuracy:   0.716
12/17/2017 23:17:34 [INFO] exp_shallowmodel: f1_score:   0.429
12/17/2017 23:17:34 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:17:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.17      0.23        23
          C       0.27      0.15      0.19        27
          F       0.80      0.88      0.84       250
          R       0.48      0.44      0.46        52

avg / total       0.68      0.72      0.69       352

12/17/2017 23:17:34 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:17:34 [INFO] exp_shallowmodel: 
[[  4   2  16   1]
 [  0   4  17   6]
 [  7   4 221  18]
 [  1   5  23  23]]
12/17/2017 23:17:36 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/17/2017 23:17:36 [INFO] exp_shallowmodel: #(data) = 2826
12/17/2017 23:17:36 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:17:36 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:17:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:17:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:17:36 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:17:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:18:27 [INFO] exp_shallowmodel: train time: 51.499s
12/17/2017 23:18:27 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:18:27 [INFO] exp_shallowmodel: accuracy:   0.707
12/17/2017 23:18:27 [INFO] exp_shallowmodel: f1_score:   0.404
12/17/2017 23:18:27 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:18:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.13      0.19        23
          C       0.40      0.22      0.29        27
          F       0.79      0.90      0.84       250
          R       0.34      0.27      0.30        52

avg / total       0.66      0.71      0.68       352

12/17/2017 23:18:27 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:18:27 [INFO] exp_shallowmodel: 
[[  3   1  17   2]
 [  1   6  14   6]
 [  3   2 226  19]
 [  2   6  30  14]]
12/17/2017 23:18:29 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/17/2017 23:18:29 [INFO] exp_shallowmodel: #(data) = 2816
12/17/2017 23:18:29 [INFO] exp_shallowmodel: #(feature) = 6613
12/17/2017 23:18:29 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:18:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:18:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:18:29 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:18:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:19:19 [INFO] exp_shallowmodel: train time: 49.712s
12/17/2017 23:19:19 [INFO] exp_shallowmodel: test time:  0.003s
12/17/2017 23:19:19 [INFO] exp_shallowmodel: accuracy:   0.702
12/17/2017 23:19:19 [INFO] exp_shallowmodel: f1_score:   0.372
12/17/2017 23:19:19 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:19:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.08      0.13        25
          C       0.40      0.15      0.22        27
          F       0.76      0.93      0.84       251
          R       0.38      0.25      0.30        59

avg / total       0.64      0.70      0.65       362

12/17/2017 23:19:19 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:19:19 [INFO] exp_shallowmodel: 
[[  2   0  19   4]
 [  0   4  16   7]
 [  1   3 233  14]
 [  2   3  39  15]]
12/17/2017 23:19:30 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 23:19:30 [INFO] task_runner: context=current, feature=10-[5+1.3.4]
12/17/2017 23:19:30 [INFO] task_runner: retained feature numbers=[8.1, 6, 3, 2.2, 1, 7, 5, 2.1]
12/17/2017 23:19:30 [INFO] task_runner: #(data)=5241
12/17/2017 23:19:30 [INFO] task_runner: #(feature)=6130
12/17/2017 23:19:30 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/17/2017 23:19:32 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/17/2017 23:19:32 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:19:32 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:19:32 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:19:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:19:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:19:32 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:19:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:21:22 [INFO] exp_shallowmodel: train time: 110.065s
12/17/2017 23:21:22 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:21:22 [INFO] exp_shallowmodel: accuracy:   0.751
12/17/2017 23:21:22 [INFO] exp_shallowmodel: f1_score:   0.385
12/17/2017 23:21:22 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:21:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.17      0.21        59
          C       0.33      0.08      0.13        12
          F       0.82      0.92      0.87       396
          R       0.41      0.27      0.33        55

avg / total       0.70      0.75      0.72       522

12/17/2017 23:21:22 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:21:22 [INFO] exp_shallowmodel: 
[[ 10   0  42   7]
 [  3   1   4   4]
 [ 17   2 366  11]
 [  6   0  34  15]]
12/17/2017 23:21:24 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/17/2017 23:21:24 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:21:24 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:21:24 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:21:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:21:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:21:24 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:21:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:23:33 [INFO] exp_shallowmodel: train time: 129.273s
12/17/2017 23:23:33 [INFO] exp_shallowmodel: test time:  0.006s
12/17/2017 23:23:33 [INFO] exp_shallowmodel: accuracy:   0.757
12/17/2017 23:23:33 [INFO] exp_shallowmodel: f1_score:   0.353
12/17/2017 23:23:33 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:23:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.22      0.29        59
          C       0.00      0.00      0.00        12
          F       0.82      0.94      0.88       396
          R       0.31      0.20      0.24        55

avg / total       0.71      0.76      0.72       522

12/17/2017 23:23:33 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:23:33 [INFO] exp_shallowmodel: 
[[ 13   1  37   8]
 [  2   0   8   2]
 [  7   4 371  14]
 [  9   1  34  11]]
12/17/2017 23:23:35 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/17/2017 23:23:35 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:23:35 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:23:35 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:23:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:23:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:23:35 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:23:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:26:20 [INFO] exp_shallowmodel: train time: 165.342s
12/17/2017 23:26:20 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:26:20 [INFO] exp_shallowmodel: accuracy:   0.743
12/17/2017 23:26:20 [INFO] exp_shallowmodel: f1_score:   0.384
12/17/2017 23:26:20 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:26:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.20      0.25        59
          C       0.20      0.08      0.12        12
          F       0.81      0.91      0.86       396
          R       0.38      0.25      0.30        55

avg / total       0.70      0.74      0.72       522

12/17/2017 23:26:20 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:26:20 [INFO] exp_shallowmodel: 
[[ 12   0  39   8]
 [  2   1   8   1]
 [ 17   4 361  14]
 [  5   0  36  14]]
12/17/2017 23:26:22 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/17/2017 23:26:22 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:26:22 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:26:22 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:26:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:26:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:26:22 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:26:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:29:08 [INFO] exp_shallowmodel: train time: 166.061s
12/17/2017 23:29:08 [INFO] exp_shallowmodel: test time:  0.006s
12/17/2017 23:29:08 [INFO] exp_shallowmodel: accuracy:   0.741
12/17/2017 23:29:08 [INFO] exp_shallowmodel: f1_score:   0.368
12/17/2017 23:29:08 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:29:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.19      0.23        59
          C       0.17      0.08      0.11        12
          F       0.83      0.91      0.87       396
          R       0.28      0.24      0.25        55

avg / total       0.70      0.74      0.72       522

12/17/2017 23:29:08 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:29:08 [INFO] exp_shallowmodel: 
[[ 11   0  38  10]
 [  0   1   6   5]
 [ 12   3 362  19]
 [ 12   2  28  13]]
12/17/2017 23:29:10 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/17/2017 23:29:10 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:29:10 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:29:10 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:29:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:29:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:29:10 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:29:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:31:16 [INFO] exp_shallowmodel: train time: 125.221s
12/17/2017 23:31:16 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:31:16 [INFO] exp_shallowmodel: accuracy:   0.738
12/17/2017 23:31:16 [INFO] exp_shallowmodel: f1_score:   0.413
12/17/2017 23:31:16 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:31:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.22      0.28        59
          C       0.50      0.17      0.25        12
          F       0.82      0.90      0.86       396
          R       0.27      0.25      0.26        55

avg / total       0.71      0.74      0.72       522

12/17/2017 23:31:16 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:31:16 [INFO] exp_shallowmodel: 
[[ 13   0  38   8]
 [  1   2   7   2]
 [ 11   1 356  28]
 [  9   1  31  14]]
12/17/2017 23:31:18 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/17/2017 23:31:18 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:31:18 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:31:18 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:31:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:31:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:31:18 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:31:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:34:15 [INFO] exp_shallowmodel: train time: 177.016s
12/17/2017 23:34:15 [INFO] exp_shallowmodel: test time:  0.006s
12/17/2017 23:34:15 [INFO] exp_shallowmodel: accuracy:   0.751
12/17/2017 23:34:15 [INFO] exp_shallowmodel: f1_score:   0.361
12/17/2017 23:34:15 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:34:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.20      0.27        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.33      0.29      0.31        55

avg / total       0.70      0.75      0.72       522

12/17/2017 23:34:15 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:34:15 [INFO] exp_shallowmodel: 
[[ 12   0  35  12]
 [  1   0   8   3]
 [ 14   0 364  18]
 [  4   0  35  16]]
12/17/2017 23:34:16 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/17/2017 23:34:16 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:34:16 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:34:16 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:34:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:34:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:34:16 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:34:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:36:45 [INFO] exp_shallowmodel: train time: 148.610s
12/17/2017 23:36:45 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:36:45 [INFO] exp_shallowmodel: accuracy:   0.762
12/17/2017 23:36:45 [INFO] exp_shallowmodel: f1_score:   0.414
12/17/2017 23:36:45 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:36:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.20      0.26        59
          C       0.40      0.17      0.24        12
          F       0.82      0.94      0.87       396
          R       0.44      0.22      0.29        55

avg / total       0.72      0.76      0.73       522

12/17/2017 23:36:45 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:36:45 [INFO] exp_shallowmodel: 
[[ 12   1  38   8]
 [  0   2   9   1]
 [ 16   2 372   6]
 [  7   0  36  12]]
12/17/2017 23:36:47 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/17/2017 23:36:47 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:36:47 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:36:47 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:36:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:36:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:36:47 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:36:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:38:53 [INFO] exp_shallowmodel: train time: 125.889s
12/17/2017 23:38:53 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:38:53 [INFO] exp_shallowmodel: accuracy:   0.745
12/17/2017 23:38:53 [INFO] exp_shallowmodel: f1_score:   0.406
12/17/2017 23:38:53 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:38:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.22      0.29        59
          C       0.33      0.17      0.22        12
          F       0.81      0.91      0.86       396
          R       0.30      0.22      0.25        55

avg / total       0.70      0.75      0.72       522

12/17/2017 23:38:53 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:38:53 [INFO] exp_shallowmodel: 
[[ 13   0  40   6]
 [  2   2   6   2]
 [ 12   2 362  20]
 [  4   2  37  12]]
12/17/2017 23:38:55 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/17/2017 23:38:55 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:38:55 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:38:55 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:38:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:38:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:38:55 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:38:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:41:16 [INFO] exp_shallowmodel: train time: 141.039s
12/17/2017 23:41:16 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:41:16 [INFO] exp_shallowmodel: accuracy:   0.747
12/17/2017 23:41:16 [INFO] exp_shallowmodel: f1_score:   0.434
12/17/2017 23:41:16 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:41:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.20      0.26        59
          C       0.50      0.25      0.33        12
          F       0.81      0.91      0.86       396
          R       0.36      0.24      0.29        55

avg / total       0.71      0.75      0.72       522

12/17/2017 23:41:16 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:41:16 [INFO] exp_shallowmodel: 
[[ 12   1  42   4]
 [  2   3   7   0]
 [ 14   1 362  19]
 [  7   1  34  13]]
12/17/2017 23:41:18 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/17/2017 23:41:18 [INFO] exp_shallowmodel: #(data) = 4176
12/17/2017 23:41:18 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:41:18 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:41:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:41:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:41:18 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:41:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:43:02 [INFO] exp_shallowmodel: train time: 104.078s
12/17/2017 23:43:02 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:43:02 [INFO] exp_shallowmodel: accuracy:   0.750
12/17/2017 23:43:02 [INFO] exp_shallowmodel: f1_score:   0.335
12/17/2017 23:43:02 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:43:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.19      0.24        64
          C       0.00      0.00      0.00        14
          F       0.80      0.96      0.87       402
          R       0.36      0.16      0.22        63

avg / total       0.68      0.75      0.70       543

12/17/2017 23:43:02 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:43:02 [INFO] exp_shallowmodel: 
[[ 12   0  44   8]
 [  4   0  10   0]
 [  6   1 385  10]
 [ 12   1  40  10]]
12/17/2017 23:43:04 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/17/2017 23:43:04 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:43:04 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:43:04 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:43:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:43:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:43:04 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:43:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:45:40 [INFO] exp_shallowmodel: train time: 155.660s
12/17/2017 23:45:40 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:45:40 [INFO] exp_shallowmodel: accuracy:   0.734
12/17/2017 23:45:40 [INFO] exp_shallowmodel: f1_score:   0.363
12/17/2017 23:45:40 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:45:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.10      0.13        59
          C       0.20      0.08      0.12        12
          F       0.81      0.91      0.86       396
          R       0.39      0.31      0.34        55

avg / total       0.68      0.73      0.70       522

12/17/2017 23:45:40 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:45:40 [INFO] exp_shallowmodel: 
[[  6   1  47   5]
 [  3   1   7   1]
 [ 16   0 359  21]
 [  6   3  29  17]]
12/17/2017 23:45:41 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/17/2017 23:45:41 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:45:41 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:45:41 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:45:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:45:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:45:41 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:45:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:48:18 [INFO] exp_shallowmodel: train time: 156.050s
12/17/2017 23:48:18 [INFO] exp_shallowmodel: test time:  0.004s
12/17/2017 23:48:18 [INFO] exp_shallowmodel: accuracy:   0.745
12/17/2017 23:48:18 [INFO] exp_shallowmodel: f1_score:   0.374
12/17/2017 23:48:18 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:48:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.20      0.26        59
          C       0.25      0.08      0.12        12
          F       0.83      0.92      0.87       396
          R       0.28      0.22      0.24        55

avg / total       0.70      0.75      0.72       522

12/17/2017 23:48:18 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:48:18 [INFO] exp_shallowmodel: 
[[ 12   0  36  11]
 [  3   1   6   2]
 [ 13   1 364  18]
 [  6   2  35  12]]
12/17/2017 23:48:20 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/17/2017 23:48:20 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:48:20 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:48:20 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:48:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:48:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:48:20 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:48:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:50:22 [INFO] exp_shallowmodel: train time: 122.570s
12/17/2017 23:50:22 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:50:22 [INFO] exp_shallowmodel: accuracy:   0.743
12/17/2017 23:50:22 [INFO] exp_shallowmodel: f1_score:   0.375
12/17/2017 23:50:22 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:50:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.24      0.29        59
          C       0.33      0.08      0.13        12
          F       0.82      0.92      0.87       396
          R       0.25      0.18      0.21        55

avg / total       0.70      0.74      0.72       522

12/17/2017 23:50:22 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:50:22 [INFO] exp_shallowmodel: 
[[ 14   0  37   8]
 [  3   1   5   3]
 [ 12   2 363  19]
 [  9   0  36  10]]
12/17/2017 23:50:24 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/17/2017 23:50:24 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:50:24 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:50:24 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:50:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:50:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:50:24 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:50:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:52:49 [INFO] exp_shallowmodel: train time: 144.890s
12/17/2017 23:52:49 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:52:49 [INFO] exp_shallowmodel: accuracy:   0.745
12/17/2017 23:52:49 [INFO] exp_shallowmodel: f1_score:   0.403
12/17/2017 23:52:49 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:52:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.22      0.28        59
          C       0.33      0.08      0.13        12
          F       0.81      0.90      0.86       396
          R       0.38      0.31      0.34        55

avg / total       0.71      0.75      0.72       522

12/17/2017 23:52:49 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:52:49 [INFO] exp_shallowmodel: 
[[ 13   1  41   4]
 [  0   1   7   4]
 [ 17   1 358  20]
 [  3   0  35  17]]
12/17/2017 23:52:51 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/17/2017 23:52:51 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:52:51 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:52:51 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:52:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:52:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:52:51 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:52:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:55:41 [INFO] exp_shallowmodel: train time: 170.093s
12/17/2017 23:55:41 [INFO] exp_shallowmodel: test time:  0.006s
12/17/2017 23:55:41 [INFO] exp_shallowmodel: accuracy:   0.745
12/17/2017 23:55:41 [INFO] exp_shallowmodel: f1_score:   0.405
12/17/2017 23:55:41 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:55:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.17      0.23        59
          C       0.50      0.17      0.25        12
          F       0.82      0.92      0.86       396
          R       0.31      0.25      0.28        55

avg / total       0.70      0.75      0.72       522

12/17/2017 23:55:41 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:55:41 [INFO] exp_shallowmodel: 
[[ 10   0  39  10]
 [  4   2   6   0]
 [ 10   2 363  21]
 [  5   0  36  14]]
12/17/2017 23:55:43 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/17/2017 23:55:43 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:55:43 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:55:43 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:55:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:55:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:55:43 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:55:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/17/2017 23:58:11 [INFO] exp_shallowmodel: train time: 147.558s
12/17/2017 23:58:11 [INFO] exp_shallowmodel: test time:  0.005s
12/17/2017 23:58:11 [INFO] exp_shallowmodel: accuracy:   0.757
12/17/2017 23:58:11 [INFO] exp_shallowmodel: f1_score:   0.360
12/17/2017 23:58:11 [INFO] exp_shallowmodel: classification report:
12/17/2017 23:58:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.48      0.20      0.29        59
          C       0.00      0.00      0.00        12
          F       0.81      0.93      0.87       396
          R       0.36      0.24      0.29        55

avg / total       0.71      0.76      0.72       522

12/17/2017 23:58:11 [INFO] exp_shallowmodel: confusion matrix:
12/17/2017 23:58:11 [INFO] exp_shallowmodel: 
[[ 12   1  38   8]
 [  1   0  10   1]
 [  9   3 370  14]
 [  3   1  38  13]]
12/17/2017 23:58:13 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/17/2017 23:58:13 [INFO] exp_shallowmodel: #(data) = 4197
12/17/2017 23:58:13 [INFO] exp_shallowmodel: #(feature) = 6130
12/17/2017 23:58:13 [INFO] exp_shallowmodel: ================================================================================
12/17/2017 23:58:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/17/2017 23:58:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/17/2017 23:58:13 [INFO] exp_shallowmodel: Training: 
12/17/2017 23:58:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:01:00 [INFO] exp_shallowmodel: train time: 167.407s
12/18/2017 00:01:00 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:01:00 [INFO] exp_shallowmodel: accuracy:   0.739
12/18/2017 00:01:00 [INFO] exp_shallowmodel: f1_score:   0.332
12/18/2017 00:01:00 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:01:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.17      0.20        59
          C       0.00      0.00      0.00        12
          F       0.83      0.92      0.87       396
          R       0.31      0.22      0.26        55

avg / total       0.69      0.74      0.71       522

12/18/2017 00:01:00 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:01:00 [INFO] exp_shallowmodel: 
[[ 10   2  40   7]
 [  2   0   7   3]
 [ 14   1 364  17]
 [ 13   0  30  12]]
12/18/2017 00:01:02 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/18/2017 00:01:02 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:01:02 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:01:02 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:01:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:01:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:01:02 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:01:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:03:44 [INFO] exp_shallowmodel: train time: 161.791s
12/18/2017 00:03:44 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:03:44 [INFO] exp_shallowmodel: accuracy:   0.753
12/18/2017 00:03:44 [INFO] exp_shallowmodel: f1_score:   0.432
12/18/2017 00:03:44 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:03:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.19      0.24        59
          C       0.50      0.25      0.33        12
          F       0.82      0.92      0.87       396
          R       0.35      0.24      0.28        55

avg / total       0.71      0.75      0.72       522

12/18/2017 00:03:44 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:03:44 [INFO] exp_shallowmodel: 
[[ 11   0  41   7]
 [  3   3   4   2]
 [ 12   3 366  15]
 [  5   0  37  13]]
12/18/2017 00:03:46 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/18/2017 00:03:46 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:03:46 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:03:46 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:03:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:03:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:03:46 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:03:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:06:20 [INFO] exp_shallowmodel: train time: 153.851s
12/18/2017 00:06:20 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 00:06:20 [INFO] exp_shallowmodel: accuracy:   0.753
12/18/2017 00:06:20 [INFO] exp_shallowmodel: f1_score:   0.426
12/18/2017 00:06:20 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:06:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.25      0.31        59
          C       0.50      0.17      0.25        12
          F       0.82      0.92      0.87       396
          R       0.35      0.24      0.28        55

avg / total       0.72      0.75      0.73       522

12/18/2017 00:06:20 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:06:20 [INFO] exp_shallowmodel: 
[[ 15   0  38   6]
 [  1   2   6   3]
 [ 16   2 363  15]
 [  7   0  35  13]]
12/18/2017 00:06:22 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/18/2017 00:06:22 [INFO] exp_shallowmodel: #(data) = 4176
12/18/2017 00:06:22 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:06:22 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:06:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:06:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:06:22 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:06:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:08:59 [INFO] exp_shallowmodel: train time: 157.743s
12/18/2017 00:08:59 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 00:08:59 [INFO] exp_shallowmodel: accuracy:   0.746
12/18/2017 00:08:59 [INFO] exp_shallowmodel: f1_score:   0.418
12/18/2017 00:08:59 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:08:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.20      0.25        64
          C       0.43      0.21      0.29        14
          F       0.81      0.94      0.87       402
          R       0.36      0.21      0.26        63

avg / total       0.70      0.75      0.71       543

12/18/2017 00:08:59 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:08:59 [INFO] exp_shallowmodel: 
[[ 13   0  38  13]
 [  0   3  10   1]
 [ 13   4 376   9]
 [ 12   0  38  13]]
12/18/2017 00:09:01 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/18/2017 00:09:01 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:09:01 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:09:01 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:09:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:09:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:09:01 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:09:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:10:41 [INFO] exp_shallowmodel: train time: 99.896s
12/18/2017 00:10:41 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:10:41 [INFO] exp_shallowmodel: accuracy:   0.747
12/18/2017 00:10:41 [INFO] exp_shallowmodel: f1_score:   0.390
12/18/2017 00:10:41 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:10:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.20      0.26        59
          C       0.33      0.08      0.13        12
          F       0.82      0.91      0.86       396
          R       0.33      0.27      0.30        55

avg / total       0.71      0.75      0.72       522

12/18/2017 00:10:41 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:10:41 [INFO] exp_shallowmodel: 
[[ 12   0  41   6]
 [  1   1   6   4]
 [ 13   1 362  20]
 [  6   1  33  15]]
12/18/2017 00:10:43 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/18/2017 00:10:43 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:10:43 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:10:43 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:10:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:10:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:10:43 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:10:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:12:59 [INFO] exp_shallowmodel: train time: 135.605s
12/18/2017 00:12:59 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:12:59 [INFO] exp_shallowmodel: accuracy:   0.736
12/18/2017 00:12:59 [INFO] exp_shallowmodel: f1_score:   0.351
12/18/2017 00:12:59 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:12:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.24      0.29        59
          C       0.00      0.00      0.00        12
          F       0.81      0.90      0.85       396
          R       0.31      0.22      0.26        55

avg / total       0.69      0.74      0.71       522

12/18/2017 00:12:59 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:12:59 [INFO] exp_shallowmodel: 
[[ 14   0  41   4]
 [  2   0   6   4]
 [ 17   2 358  19]
 [  3   1  39  12]]
12/18/2017 00:13:01 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/18/2017 00:13:01 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:13:01 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:13:01 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:13:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:13:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:13:01 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:13:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:15:16 [INFO] exp_shallowmodel: train time: 134.929s
12/18/2017 00:15:16 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 00:15:16 [INFO] exp_shallowmodel: accuracy:   0.745
12/18/2017 00:15:16 [INFO] exp_shallowmodel: f1_score:   0.414
12/18/2017 00:15:16 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:15:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.14      0.19        59
          C       0.40      0.33      0.36        12
          F       0.82      0.92      0.87       396
          R       0.28      0.20      0.23        55

avg / total       0.69      0.75      0.71       522

12/18/2017 00:15:16 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:15:16 [INFO] exp_shallowmodel: 
[[  8   0  43   8]
 [  1   4   5   2]
 [  8   4 366  18]
 [  7   2  35  11]]
12/18/2017 00:15:18 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/18/2017 00:15:18 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:15:18 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:15:18 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:15:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:15:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:15:18 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:15:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:18:02 [INFO] exp_shallowmodel: train time: 164.020s
12/18/2017 00:18:02 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:18:02 [INFO] exp_shallowmodel: accuracy:   0.764
12/18/2017 00:18:02 [INFO] exp_shallowmodel: f1_score:   0.355
12/18/2017 00:18:02 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:18:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.15      0.20        59
          C       0.00      0.00      0.00        12
          F       0.83      0.95      0.88       396
          R       0.45      0.27      0.34        55

avg / total       0.71      0.76      0.73       522

12/18/2017 00:18:02 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:18:02 [INFO] exp_shallowmodel: 
[[  9   2  41   7]
 [  4   0   6   2]
 [ 11   1 375   9]
 [  8   0  32  15]]
12/18/2017 00:18:04 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/18/2017 00:18:04 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:18:04 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:18:04 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:18:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:18:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:18:04 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:18:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:20:07 [INFO] exp_shallowmodel: train time: 123.116s
12/18/2017 00:20:07 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 00:20:07 [INFO] exp_shallowmodel: accuracy:   0.757
12/18/2017 00:20:07 [INFO] exp_shallowmodel: f1_score:   0.349
12/18/2017 00:20:07 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:20:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.19      0.23        59
          C       0.00      0.00      0.00        12
          F       0.83      0.94      0.88       396
          R       0.36      0.24      0.29        55

avg / total       0.70      0.76      0.72       522

12/18/2017 00:20:07 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:20:07 [INFO] exp_shallowmodel: 
[[ 11   0  42   6]
 [  1   0   5   6]
 [ 12   2 371  11]
 [ 13   0  29  13]]
12/18/2017 00:20:09 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/18/2017 00:20:09 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:20:09 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:20:09 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:20:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:20:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:20:09 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:20:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:22:24 [INFO] exp_shallowmodel: train time: 135.111s
12/18/2017 00:22:24 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:22:24 [INFO] exp_shallowmodel: accuracy:   0.732
12/18/2017 00:22:24 [INFO] exp_shallowmodel: f1_score:   0.370
12/18/2017 00:22:24 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:22:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.25      0.29        59
          C       0.14      0.08      0.11        12
          F       0.81      0.90      0.85       396
          R       0.32      0.18      0.23        55

avg / total       0.69      0.73      0.71       522

12/18/2017 00:22:24 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:22:24 [INFO] exp_shallowmodel: 
[[ 15   1  40   3]
 [  1   1  10   0]
 [ 18   4 356  18]
 [ 10   1  34  10]]
12/18/2017 00:22:26 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/18/2017 00:22:26 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:22:26 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:22:26 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:22:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:22:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:22:26 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:22:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:24:12 [INFO] exp_shallowmodel: train time: 106.777s
12/18/2017 00:24:12 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 00:24:12 [INFO] exp_shallowmodel: accuracy:   0.762
12/18/2017 00:24:12 [INFO] exp_shallowmodel: f1_score:   0.406
12/18/2017 00:24:12 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:24:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.25      0.34        59
          C       0.50      0.08      0.14        12
          F       0.82      0.93      0.87       396
          R       0.32      0.24      0.27        55

avg / total       0.72      0.76      0.73       522

12/18/2017 00:24:12 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:24:12 [INFO] exp_shallowmodel: 
[[ 15   0  36   8]
 [  0   1   9   2]
 [  8   1 369  18]
 [  7   0  35  13]]
12/18/2017 00:24:14 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/18/2017 00:24:14 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:24:14 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:24:14 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:24:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:24:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:24:14 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:24:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:26:35 [INFO] exp_shallowmodel: train time: 140.821s
12/18/2017 00:26:35 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:26:35 [INFO] exp_shallowmodel: accuracy:   0.747
12/18/2017 00:26:35 [INFO] exp_shallowmodel: f1_score:   0.379
12/18/2017 00:26:35 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:26:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.17      0.22        59
          C       0.33      0.08      0.13        12
          F       0.82      0.92      0.87       396
          R       0.36      0.25      0.30        55

avg / total       0.70      0.75      0.72       522

12/18/2017 00:26:35 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:26:35 [INFO] exp_shallowmodel: 
[[ 10   1  41   7]
 [  2   1   6   3]
 [ 15   1 365  15]
 [  6   0  35  14]]
12/18/2017 00:26:37 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/18/2017 00:26:37 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:26:37 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:26:37 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:26:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:26:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:26:37 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:26:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:29:17 [INFO] exp_shallowmodel: train time: 159.741s
12/18/2017 00:29:17 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 00:29:17 [INFO] exp_shallowmodel: accuracy:   0.736
12/18/2017 00:29:17 [INFO] exp_shallowmodel: f1_score:   0.329
12/18/2017 00:29:17 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:29:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.15      0.20        59
          C       0.00      0.00      0.00        12
          F       0.81      0.92      0.86       396
          R       0.29      0.22      0.25        55

avg / total       0.68      0.74      0.70       522

12/18/2017 00:29:17 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:29:17 [INFO] exp_shallowmodel: 
[[  9   1  43   6]
 [  1   0   7   4]
 [ 12   2 363  19]
 [  7   3  33  12]]
12/18/2017 00:29:19 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/18/2017 00:29:19 [INFO] exp_shallowmodel: #(data) = 4176
12/18/2017 00:29:19 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:29:19 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:29:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:29:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:29:19 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:29:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:31:52 [INFO] exp_shallowmodel: train time: 153.393s
12/18/2017 00:31:52 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:31:52 [INFO] exp_shallowmodel: accuracy:   0.740
12/18/2017 00:31:52 [INFO] exp_shallowmodel: f1_score:   0.420
12/18/2017 00:31:52 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:31:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.25      0.29        64
          C       0.40      0.14      0.21        14
          F       0.82      0.91      0.86       402
          R       0.37      0.27      0.31        63

avg / total       0.70      0.74      0.72       543

12/18/2017 00:31:52 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:31:52 [INFO] exp_shallowmodel: 
[[ 16   1  39   8]
 [  1   2   9   2]
 [ 16   0 367  19]
 [ 12   2  32  17]]
12/18/2017 00:31:54 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/18/2017 00:31:54 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:31:54 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:31:54 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:31:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:31:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:31:54 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:31:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:33:50 [INFO] exp_shallowmodel: train time: 115.230s
12/18/2017 00:33:50 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 00:33:50 [INFO] exp_shallowmodel: accuracy:   0.745
12/18/2017 00:33:50 [INFO] exp_shallowmodel: f1_score:   0.395
12/18/2017 00:33:50 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:33:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.19      0.23        59
          C       0.67      0.17      0.27        12
          F       0.83      0.92      0.87       396
          R       0.24      0.18      0.21        55

avg / total       0.70      0.75      0.72       522

12/18/2017 00:33:50 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:33:50 [INFO] exp_shallowmodel: 
[[ 11   0  38  10]
 [  1   2   7   2]
 [ 10   1 366  19]
 [ 13   0  32  10]]
12/18/2017 00:33:52 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/18/2017 00:33:52 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:33:52 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:33:52 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:33:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:33:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:33:52 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:33:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:36:15 [INFO] exp_shallowmodel: train time: 143.239s
12/18/2017 00:36:15 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:36:15 [INFO] exp_shallowmodel: accuracy:   0.738
12/18/2017 00:36:15 [INFO] exp_shallowmodel: f1_score:   0.334
12/18/2017 00:36:15 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:36:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.20      0.22        59
          C       0.00      0.00      0.00        12
          F       0.81      0.92      0.86       396
          R       0.40      0.18      0.25        55

avg / total       0.69      0.74      0.71       522

12/18/2017 00:36:15 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:36:15 [INFO] exp_shallowmodel: 
[[ 12   1  38   8]
 [  2   0  10   0]
 [ 25   1 363   7]
 [  9   0  36  10]]
12/18/2017 00:36:17 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/18/2017 00:36:17 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:36:17 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:36:17 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:36:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:36:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:36:17 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:36:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:38:25 [INFO] exp_shallowmodel: train time: 128.688s
12/18/2017 00:38:25 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:38:25 [INFO] exp_shallowmodel: accuracy:   0.741
12/18/2017 00:38:25 [INFO] exp_shallowmodel: f1_score:   0.396
12/18/2017 00:38:25 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:38:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.22      0.28        59
          C       0.25      0.08      0.12        12
          F       0.81      0.90      0.85       396
          R       0.37      0.29      0.33        55

avg / total       0.70      0.74      0.72       522

12/18/2017 00:38:25 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:38:25 [INFO] exp_shallowmodel: 
[[ 13   1  41   4]
 [  2   1   5   4]
 [ 18   2 357  19]
 [  1   0  38  16]]
12/18/2017 00:38:27 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/18/2017 00:38:27 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:38:27 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:38:27 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:38:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:38:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:38:27 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:38:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:40:41 [INFO] exp_shallowmodel: train time: 133.162s
12/18/2017 00:40:41 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:40:41 [INFO] exp_shallowmodel: accuracy:   0.762
12/18/2017 00:40:41 [INFO] exp_shallowmodel: f1_score:   0.370
12/18/2017 00:40:41 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:40:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.19      0.25        59
          C       0.00      0.00      0.00        12
          F       0.83      0.93      0.88       396
          R       0.39      0.33      0.36        55

avg / total       0.71      0.76      0.73       522

12/18/2017 00:40:41 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:40:41 [INFO] exp_shallowmodel: 
[[ 11   0  39   9]
 [  2   0   8   2]
 [  9   1 369  17]
 [  8   0  29  18]]
12/18/2017 00:40:43 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/18/2017 00:40:43 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:40:43 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:40:43 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:40:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:40:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:40:43 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:40:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:43:05 [INFO] exp_shallowmodel: train time: 142.252s
12/18/2017 00:43:05 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 00:43:05 [INFO] exp_shallowmodel: accuracy:   0.751
12/18/2017 00:43:05 [INFO] exp_shallowmodel: f1_score:   0.433
12/18/2017 00:43:05 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:43:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.25      0.31        59
          C       0.33      0.17      0.22        12
          F       0.83      0.90      0.86       396
          R       0.37      0.31      0.34        55

avg / total       0.72      0.75      0.73       522

12/18/2017 00:43:05 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:43:05 [INFO] exp_shallowmodel: 
[[ 15   0  40   4]
 [  0   2   7   3]
 [ 13   3 358  22]
 [ 10   1  27  17]]
12/18/2017 00:43:07 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/18/2017 00:43:07 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:43:07 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:43:07 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:43:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:43:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:43:07 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:43:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:45:34 [INFO] exp_shallowmodel: train time: 146.899s
12/18/2017 00:45:34 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:45:34 [INFO] exp_shallowmodel: accuracy:   0.739
12/18/2017 00:45:34 [INFO] exp_shallowmodel: f1_score:   0.359
12/18/2017 00:45:34 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:45:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.15      0.20        59
          C       0.25      0.08      0.12        12
          F       0.82      0.92      0.87       396
          R       0.29      0.22      0.25        55

avg / total       0.69      0.74      0.71       522

12/18/2017 00:45:34 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:45:34 [INFO] exp_shallowmodel: 
[[  9   1  40   9]
 [  2   1   6   3]
 [ 13   1 364  18]
 [  9   1  33  12]]
12/18/2017 00:45:36 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/18/2017 00:45:36 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:45:36 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:45:36 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:45:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:45:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:45:36 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:45:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:47:43 [INFO] exp_shallowmodel: train time: 127.349s
12/18/2017 00:47:43 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 00:47:43 [INFO] exp_shallowmodel: accuracy:   0.762
12/18/2017 00:47:43 [INFO] exp_shallowmodel: f1_score:   0.478
12/18/2017 00:47:43 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:47:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.19      0.25        59
          C       0.62      0.42      0.50        12
          F       0.84      0.93      0.88       396
          R       0.32      0.25      0.28        55

avg / total       0.72      0.76      0.74       522

12/18/2017 00:47:43 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:47:43 [INFO] exp_shallowmodel: 
[[ 11   0  38  10]
 [  0   5   4   3]
 [ 10   1 368  17]
 [  9   2  30  14]]
12/18/2017 00:47:45 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/18/2017 00:47:45 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:47:45 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:47:45 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:47:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:47:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:47:45 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:47:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:50:28 [INFO] exp_shallowmodel: train time: 162.740s
12/18/2017 00:50:28 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:50:28 [INFO] exp_shallowmodel: accuracy:   0.736
12/18/2017 00:50:28 [INFO] exp_shallowmodel: f1_score:   0.366
12/18/2017 00:50:28 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:50:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.19      0.24        59
          C       0.11      0.08      0.10        12
          F       0.82      0.91      0.86       396
          R       0.32      0.24      0.27        55

avg / total       0.69      0.74      0.71       522

12/18/2017 00:50:28 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:50:28 [INFO] exp_shallowmodel: 
[[ 11   2  40   6]
 [  1   1   8   2]
 [ 12   5 359  20]
 [  9   1  32  13]]
12/18/2017 00:50:30 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/18/2017 00:50:30 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:50:30 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:50:30 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:50:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:50:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:50:30 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:50:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:52:38 [INFO] exp_shallowmodel: train time: 128.824s
12/18/2017 00:52:38 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:52:38 [INFO] exp_shallowmodel: accuracy:   0.739
12/18/2017 00:52:38 [INFO] exp_shallowmodel: f1_score:   0.329
12/18/2017 00:52:38 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:52:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.14      0.18        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.32      0.24      0.27        55

avg / total       0.68      0.74      0.71       522

12/18/2017 00:52:38 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:52:38 [INFO] exp_shallowmodel: 
[[  8   1  42   8]
 [  5   0   4   3]
 [ 11   3 365  17]
 [  8   0  34  13]]
12/18/2017 00:52:40 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/18/2017 00:52:40 [INFO] exp_shallowmodel: #(data) = 4176
12/18/2017 00:52:40 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:52:40 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:52:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:52:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:52:40 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:52:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:55:20 [INFO] exp_shallowmodel: train time: 159.117s
12/18/2017 00:55:20 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:55:20 [INFO] exp_shallowmodel: accuracy:   0.748
12/18/2017 00:55:20 [INFO] exp_shallowmodel: f1_score:   0.412
12/18/2017 00:55:20 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:55:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.49      0.33      0.39        64
          C       0.33      0.07      0.12        14
          F       0.80      0.92      0.86       402
          R       0.38      0.22      0.28        63

avg / total       0.71      0.75      0.72       543

12/18/2017 00:55:20 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:55:20 [INFO] exp_shallowmodel: 
[[ 21   0  39   4]
 [  2   1   8   3]
 [ 15   1 370  16]
 [  5   1  43  14]]
12/18/2017 00:55:22 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/18/2017 00:55:22 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:55:22 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:55:22 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:55:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:55:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:55:22 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:55:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:57:18 [INFO] exp_shallowmodel: train time: 116.112s
12/18/2017 00:57:18 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 00:57:18 [INFO] exp_shallowmodel: accuracy:   0.751
12/18/2017 00:57:18 [INFO] exp_shallowmodel: f1_score:   0.437
12/18/2017 00:57:18 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:57:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.22      0.26        59
          C       0.50      0.25      0.33        12
          F       0.83      0.92      0.87       396
          R       0.37      0.24      0.29        55

avg / total       0.71      0.75      0.73       522

12/18/2017 00:57:18 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:57:18 [INFO] exp_shallowmodel: 
[[ 13   1  41   4]
 [  2   3   5   2]
 [ 15   2 363  16]
 [ 12   0  30  13]]
12/18/2017 00:57:20 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/18/2017 00:57:20 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:57:20 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:57:20 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:57:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:57:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:57:20 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:57:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 00:59:29 [INFO] exp_shallowmodel: train time: 129.454s
12/18/2017 00:59:29 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 00:59:29 [INFO] exp_shallowmodel: accuracy:   0.755
12/18/2017 00:59:29 [INFO] exp_shallowmodel: f1_score:   0.388
12/18/2017 00:59:29 [INFO] exp_shallowmodel: classification report:
12/18/2017 00:59:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.17      0.22        59
          C       0.25      0.08      0.12        12
          F       0.83      0.92      0.88       396
          R       0.35      0.31      0.33        55

avg / total       0.71      0.75      0.73       522

12/18/2017 00:59:29 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 00:59:29 [INFO] exp_shallowmodel: 
[[ 10   2  37  10]
 [  1   1   6   4]
 [ 11   1 366  18]
 [  8   0  30  17]]
12/18/2017 00:59:31 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/18/2017 00:59:31 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 00:59:31 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 00:59:31 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 00:59:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 00:59:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 00:59:31 [INFO] exp_shallowmodel: Training: 
12/18/2017 00:59:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:01:23 [INFO] exp_shallowmodel: train time: 112.301s
12/18/2017 01:01:23 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 01:01:23 [INFO] exp_shallowmodel: accuracy:   0.749
12/18/2017 01:01:23 [INFO] exp_shallowmodel: f1_score:   0.384
12/18/2017 01:01:23 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:01:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.22      0.27        59
          C       0.25      0.08      0.12        12
          F       0.83      0.92      0.87       396
          R       0.31      0.24      0.27        55

avg / total       0.71      0.75      0.72       522

12/18/2017 01:01:23 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:01:23 [INFO] exp_shallowmodel: 
[[ 13   0  36  10]
 [  2   1   6   3]
 [ 14   2 364  16]
 [  7   1  34  13]]
12/18/2017 01:01:25 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/18/2017 01:01:25 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 01:01:25 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 01:01:25 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:01:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:01:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:01:25 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:01:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:03:31 [INFO] exp_shallowmodel: train time: 126.001s
12/18/2017 01:03:31 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 01:03:31 [INFO] exp_shallowmodel: accuracy:   0.757
12/18/2017 01:03:31 [INFO] exp_shallowmodel: f1_score:   0.411
12/18/2017 01:03:31 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:03:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.48      0.27      0.35        59
          C       0.20      0.08      0.12        12
          F       0.83      0.91      0.87       396
          R       0.32      0.29      0.30        55

avg / total       0.73      0.76      0.74       522

12/18/2017 01:03:31 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:03:31 [INFO] exp_shallowmodel: 
[[ 16   1  37   5]
 [  5   1   4   2]
 [  5   2 362  27]
 [  7   1  31  16]]
12/18/2017 01:03:33 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/18/2017 01:03:33 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 01:03:33 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 01:03:33 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:03:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:03:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:03:33 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:03:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:05:40 [INFO] exp_shallowmodel: train time: 126.807s
12/18/2017 01:05:40 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 01:05:40 [INFO] exp_shallowmodel: accuracy:   0.764
12/18/2017 01:05:40 [INFO] exp_shallowmodel: f1_score:   0.371
12/18/2017 01:05:40 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:05:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.27      0.34        59
          C       0.00      0.00      0.00        12
          F       0.83      0.94      0.88       396
          R       0.34      0.22      0.27        55

avg / total       0.72      0.76      0.73       522

12/18/2017 01:05:40 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:05:40 [INFO] exp_shallowmodel: 
[[ 16   0  34   9]
 [  1   0   7   4]
 [ 12   3 371  10]
 [  7   1  35  12]]
12/18/2017 01:05:42 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/18/2017 01:05:42 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 01:05:42 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 01:05:42 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:05:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:05:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:05:42 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:05:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:08:04 [INFO] exp_shallowmodel: train time: 141.793s
12/18/2017 01:08:04 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 01:08:04 [INFO] exp_shallowmodel: accuracy:   0.759
12/18/2017 01:08:04 [INFO] exp_shallowmodel: f1_score:   0.400
12/18/2017 01:08:04 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:08:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.24      0.29        59
          C       0.33      0.17      0.22        12
          F       0.83      0.94      0.88       396
          R       0.26      0.16      0.20        55

avg / total       0.71      0.76      0.73       522

12/18/2017 01:08:04 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:08:04 [INFO] exp_shallowmodel: 
[[ 14   1  34  10]
 [  0   2   6   4]
 [ 11   2 371  12]
 [ 11   1  34   9]]
12/18/2017 01:08:06 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/18/2017 01:08:06 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 01:08:06 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 01:08:06 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:08:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:08:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:08:06 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:08:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:10:45 [INFO] exp_shallowmodel: train time: 159.440s
12/18/2017 01:10:45 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 01:10:45 [INFO] exp_shallowmodel: accuracy:   0.747
12/18/2017 01:10:45 [INFO] exp_shallowmodel: f1_score:   0.375
12/18/2017 01:10:45 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:10:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.19      0.24        59
          C       0.33      0.08      0.13        12
          F       0.82      0.92      0.87       396
          R       0.32      0.22      0.26        55

avg / total       0.70      0.75      0.72       522

12/18/2017 01:10:45 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:10:45 [INFO] exp_shallowmodel: 
[[ 11   0  39   9]
 [  1   1   9   1]
 [ 14   1 366  15]
 [  8   1  34  12]]
12/18/2017 01:10:47 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/18/2017 01:10:47 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 01:10:47 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 01:10:47 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:10:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:10:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:10:47 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:10:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:13:24 [INFO] exp_shallowmodel: train time: 156.792s
12/18/2017 01:13:24 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 01:13:24 [INFO] exp_shallowmodel: accuracy:   0.747
12/18/2017 01:13:24 [INFO] exp_shallowmodel: f1_score:   0.345
12/18/2017 01:13:24 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:13:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.22      0.27        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.31      0.20      0.24        55

avg / total       0.69      0.75      0.71       522

12/18/2017 01:13:24 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:13:24 [INFO] exp_shallowmodel: 
[[ 13   0  40   6]
 [  0   0   9   3]
 [ 14   0 366  16]
 [  9   1  34  11]]
12/18/2017 01:13:26 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/18/2017 01:13:26 [INFO] exp_shallowmodel: #(data) = 4197
12/18/2017 01:13:26 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 01:13:26 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:13:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:13:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:13:26 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:13:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:16:24 [INFO] exp_shallowmodel: train time: 177.830s
12/18/2017 01:16:24 [INFO] exp_shallowmodel: test time:  0.006s
12/18/2017 01:16:24 [INFO] exp_shallowmodel: accuracy:   0.749
12/18/2017 01:16:24 [INFO] exp_shallowmodel: f1_score:   0.420
12/18/2017 01:16:24 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:16:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.24      0.29        59
          C       0.50      0.17      0.25        12
          F       0.82      0.91      0.87       396
          R       0.33      0.24      0.28        55

avg / total       0.71      0.75      0.72       522

12/18/2017 01:16:24 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:16:24 [INFO] exp_shallowmodel: 
[[ 14   0  39   6]
 [  2   2   7   1]
 [ 13   2 362  19]
 [ 10   0  32  13]]
12/18/2017 01:16:26 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/18/2017 01:16:26 [INFO] exp_shallowmodel: #(data) = 4176
12/18/2017 01:16:26 [INFO] exp_shallowmodel: #(feature) = 6130
12/18/2017 01:16:26 [INFO] exp_shallowmodel: ================================================================================
12/18/2017 01:16:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/18/2017 01:16:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/18/2017 01:16:26 [INFO] exp_shallowmodel: Training: 
12/18/2017 01:16:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/18/2017 01:18:49 [INFO] exp_shallowmodel: train time: 143.112s
12/18/2017 01:18:49 [INFO] exp_shallowmodel: test time:  0.005s
12/18/2017 01:18:49 [INFO] exp_shallowmodel: accuracy:   0.746
12/18/2017 01:18:49 [INFO] exp_shallowmodel: f1_score:   0.370
12/18/2017 01:18:49 [INFO] exp_shallowmodel: classification report:
12/18/2017 01:18:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.23      0.31        64
          C       0.00      0.00      0.00        14
          F       0.81      0.93      0.87       402
          R       0.39      0.25      0.31        63

avg / total       0.70      0.75      0.71       543

12/18/2017 01:18:49 [INFO] exp_shallowmodel: confusion matrix:
12/18/2017 01:18:49 [INFO] exp_shallowmodel: 
[[ 15   0  43   6]
 [  5   0   8   1]
 [  8   2 374  18]
 [  6   4  37  16]]
Done: 20171218-011852
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
