/ihome/pbrusilosky/rum20/.conda/envs/py36/bin/python -m dialogue.classify.task_runner -selected_feature_set_id 4 -selected_context_id 1
No. of param settings = 1
[('deep_model', False), ('selected_context_id', 1), ('selected_feature_set_id', 4), ('similarity_feature', False)]
12/10/2017 02:14:11 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:11 [INFO] configuration: selected_context_id  :   1
12/10/2017 02:14:11 [INFO] configuration: selected_feature_set_id  :   4
12/10/2017 02:14:11 [INFO] configuration: similarity_feature  :   False
12/10/2017 02:14:11 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:11 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:11 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:11 [INFO] configuration: timemark  :   20171210-021411
12/10/2017 02:14:11 [INFO] configuration: context_set  :   current
12/10/2017 02:14:11 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:11 [INFO] configuration: utterance_range  :   ['current_user_utterance']
12/10/2017 02:14:11 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:11 [INFO] configuration: feature_set  :   4-syntactic
12/10/2017 02:14:11 [INFO] configuration: feature_set_number  :   ['7']
12/10/2017 02:14:11 [INFO] configuration: experiment_name  :   20171210-021411.context=current.feature=4-syntactic.similarity=false
12/10/2017 02:14:11 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021411.context=current.feature=4-syntactic.similarity=false
12/10/2017 02:14:11 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021411.context=current.feature=4-syntactic.similarity=false/output.log
12/10/2017 02:14:11 [INFO] configuration: valid_type  :   {'C', 'A', 'R', 'F'}
12/10/2017 02:14:11 [INFO] configuration: data_name  :   
12/10/2017 02:14:11 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:11 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:11 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:11 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:11 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:11 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:11 [INFO] configuration: #division  :   5
12/10/2017 02:14:11 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:11 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:11 [INFO] configuration: action_words  :   {'discard', 'start', 'clear', 'price', 'time', 'next', 'delete', 'member', 'remove', 'phone', 'telephone', 'snooz', 'light', 'reminders', 'els', 'north', 'moderate', 'cast', 'number', 'ani', 'delet', 'remind', 'volum', 'any', 'item', 'snooze', 'address', 'centre', 'centr', 'shuffl', 'food', 'music', 'findcare', 'song', 'tell', 'items', 'part', 'matter', 'temperatur', 'else', 'reminds', 'alarm', 'list', 'help', 'timer', 'findcar', 'stop', 'post', 'add', 'volume', 'watch', 'expens', 'video', 'temperature', 'share', 'play', 'reminder', 'skip', 'shuffle', 'weather', 'cheap', 'show', 'expensive', 'south', 'moder', 'turn', 'room', 'telephon', 'area', 'remov'}
12/10/2017 02:14:11 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:11 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:11 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:11 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:11 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:11 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:11 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:11 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:11 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:11 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:11 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:11 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:11 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:11 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:11 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:11 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:11 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:11 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:11 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 1, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:11 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:14 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:14 [INFO] task_runner: context=current, feature=4-syntactic
12/10/2017 02:14:14 [INFO] task_runner: retained feature numbers=[7]
12/10/2017 02:14:14 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:14 [INFO] task_runner: #(feature)=306
12/10/2017 02:14:14 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:14 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:14 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:14:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:22 [INFO] exp_shallowmodel: train time: 7.290s
12/10/2017 02:14:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:14:22 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 02:14:22 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 02:14:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.74      0.61       164
          F       0.69      0.72      0.70       268
          R       0.48      0.22      0.30       125

avg / total       0.58      0.60      0.57       571

12/10/2017 02:14:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:22 [INFO] exp_shallowmodel: 
[[  0   9   2   3]
 [  0 122  32  10]
 [  0  60 192  16]
 [  0  46  52  27]]
12/10/2017 02:14:22 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:14:22 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:22 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:14:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:27 [INFO] exp_shallowmodel: train time: 5.644s
12/10/2017 02:14:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:27 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 02:14:27 [INFO] exp_shallowmodel: f1_score:   0.442
12/10/2017 02:14:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.54      0.75      0.63       164
          F       0.68      0.69      0.68       268
          R       0.46      0.26      0.34       125

avg / total       0.59      0.60      0.58       571

12/10/2017 02:14:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:27 [INFO] exp_shallowmodel: 
[[  1   7   5   1]
 [  0 123  26  15]
 [  2  60 184  22]
 [  0  37  55  33]]
12/10/2017 02:14:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:14:27 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:27 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:14:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:34 [INFO] exp_shallowmodel: train time: 6.558s
12/10/2017 02:14:34 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:34 [INFO] exp_shallowmodel: accuracy:   0.585
12/10/2017 02:14:34 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:14:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.77      0.59       164
          F       0.74      0.68      0.71       268
          R       0.44      0.22      0.29       125

avg / total       0.58      0.58      0.56       571

12/10/2017 02:14:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:34 [INFO] exp_shallowmodel: 
[[  0   7   4   3]
 [  0 126  23  15]
 [  1  69 181  17]
 [  1  62  35  27]]
12/10/2017 02:14:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:14:34 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:34 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:14:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:39 [INFO] exp_shallowmodel: train time: 4.627s
12/10/2017 02:14:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:39 [INFO] exp_shallowmodel: accuracy:   0.567
12/10/2017 02:14:39 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 02:14:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.69      0.57       164
          F       0.69      0.66      0.68       268
          R       0.42      0.26      0.33       125

avg / total       0.55      0.57      0.55       571

12/10/2017 02:14:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:39 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 113  32  19]
 [  0  67 178  23]
 [  0  51  41  33]]
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:14:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:39 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:46 [INFO] exp_shallowmodel: train time: 7.229s
12/10/2017 02:14:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:46 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 02:14:46 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:14:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.73      0.59       164
          F       0.70      0.66      0.68       268
          R       0.45      0.26      0.33       125

avg / total       0.57      0.58      0.56       571

12/10/2017 02:14:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:46 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  1 120  26  17]
 [  0  69 176  23]
 [  0  52  40  33]]
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:14:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:46 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:51 [INFO] exp_shallowmodel: train time: 5.130s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 02:14:51 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 02:14:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.75      0.60       164
          F       0.67      0.66      0.67       268
          R       0.48      0.22      0.31       125

avg / total       0.56      0.58      0.55       571

12/10/2017 02:14:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:51 [INFO] exp_shallowmodel: 
[[  0   8   3   3]
 [  0 123  33   8]
 [  1  70 178  19]
 [  0  46  51  28]]
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:56 [INFO] exp_shallowmodel: train time: 4.828s
12/10/2017 02:14:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:56 [INFO] exp_shallowmodel: accuracy:   0.630
12/10/2017 02:14:56 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 02:14:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.83      0.67       164
          F       0.72      0.71      0.72       268
          R       0.53      0.26      0.35       125

avg / total       0.61      0.63      0.60       571

12/10/2017 02:14:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:56 [INFO] exp_shallowmodel: 
[[  0   5   6   3]
 [  0 136  19   9]
 [  0  60 191  17]
 [  0  42  50  33]]
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:14:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:56 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:01 [INFO] exp_shallowmodel: train time: 4.955s
12/10/2017 02:15:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:01 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 02:15:01 [INFO] exp_shallowmodel: f1_score:   0.370
12/10/2017 02:15:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.64      0.55       164
          F       0.67      0.72      0.69       268
          R       0.35      0.18      0.24       125

avg / total       0.53      0.56      0.54       571

12/10/2017 02:15:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:01 [INFO] exp_shallowmodel: 
[[  0   8   5   1]
 [  0 105  41  18]
 [  0  53 194  21]
 [  0  52  51  22]]
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:15:01 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:01 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:06 [INFO] exp_shallowmodel: train time: 4.738s
12/10/2017 02:15:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:06 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 02:15:06 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:15:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.80      0.62       164
          F       0.69      0.63      0.66       268
          R       0.44      0.24      0.31       125

avg / total       0.57      0.58      0.56       571

12/10/2017 02:15:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:06 [INFO] exp_shallowmodel: 
[[  0   4   4   6]
 [  0 131  20  13]
 [  0  79 170  19]
 [  0  43  52  30]]
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:15:06 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:15:06 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:15 [INFO] exp_shallowmodel: train time: 8.800s
12/10/2017 02:15:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:15:15 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 02:15:15 [INFO] exp_shallowmodel: f1_score:   0.371
12/10/2017 02:15:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.46      0.66      0.54       169
          F       0.66      0.70      0.68       271
          R       0.45      0.18      0.26       130

avg / total       0.54      0.56      0.53       586

12/10/2017 02:15:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:15 [INFO] exp_shallowmodel: 
[[  0   5   8   3]
 [  0 112  44  13]
 [  0  68 190  13]
 [  0  58  48  24]]
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:15:15 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:15 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:19 [INFO] exp_shallowmodel: train time: 4.945s
12/10/2017 02:15:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:15:19 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 02:15:19 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 02:15:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.69      0.58       164
          F       0.67      0.71      0.69       268
          R       0.44      0.22      0.29       125

avg / total       0.56      0.58      0.56       571

12/10/2017 02:15:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:20 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  1 113  34  16]
 [  0  63 191  14]
 [  0  47  51  27]]
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:25 [INFO] exp_shallowmodel: train time: 5.744s
12/10/2017 02:15:25 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:15:25 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 02:15:25 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 02:15:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.65      0.55       164
          F       0.68      0.70      0.69       268
          R       0.46      0.25      0.32       125

avg / total       0.55      0.57      0.55       571

12/10/2017 02:15:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:25 [INFO] exp_shallowmodel: 
[[  0   8   4   2]
 [  0 107  39  18]
 [  1  63 187  17]
 [  0  47  47  31]]
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:15:25 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:25 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:32 [INFO] exp_shallowmodel: train time: 6.218s
12/10/2017 02:15:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:32 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:15:32 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 02:15:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.47      0.74      0.58       164
          F       0.70      0.68      0.69       268
          R       0.43      0.19      0.27       125

avg / total       0.56      0.57      0.55       571

12/10/2017 02:15:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:32 [INFO] exp_shallowmodel: 
[[  0   8   3   3]
 [  0 121  31  12]
 [  0  69 182  17]
 [  0  58  43  24]]
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:15:32 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:32 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:37 [INFO] exp_shallowmodel: train time: 5.893s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: accuracy:   0.604
12/10/2017 02:15:37 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:15:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.82      0.63       164
          F       0.72      0.65      0.68       268
          R       0.57      0.29      0.38       125

avg / total       0.61      0.60      0.59       571

12/10/2017 02:15:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:37 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 134  19  11]
 [  1  79 175  13]
 [  1  46  42  36]]
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:15:38 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:38 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:45 [INFO] exp_shallowmodel: train time: 7.220s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:15:45 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:15:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.68      0.57       164
          F       0.69      0.70      0.69       268
          R       0.38      0.22      0.28       125

avg / total       0.55      0.57      0.55       571

12/10/2017 02:15:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:45 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 111  32  21]
 [  0  59 187  22]
 [  0  51  46  28]]
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:51 [INFO] exp_shallowmodel: train time: 5.813s
12/10/2017 02:15:51 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:15:51 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 02:15:51 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 02:15:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.77      0.59       164
          F       0.71      0.66      0.68       268
          R       0.46      0.22      0.30       125

avg / total       0.57      0.58      0.56       571

12/10/2017 02:15:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:51 [INFO] exp_shallowmodel: 
[[  0   7   5   2]
 [  1 126  23  14]
 [  0  75 176  17]
 [  0  52  45  28]]
12/10/2017 02:15:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:15:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:51 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:15:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:58 [INFO] exp_shallowmodel: train time: 7.280s
12/10/2017 02:15:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:58 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:15:58 [INFO] exp_shallowmodel: f1_score:   0.418
12/10/2017 02:15:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.78      0.64       164
          F       0.70      0.70      0.70       268
          R       0.50      0.26      0.34       125

avg / total       0.59      0.61      0.58       571

12/10/2017 02:15:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:58 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  0 128  28   8]
 [  0  62 187  19]
 [  0  45  48  32]]
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:15:58 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:58 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:04 [INFO] exp_shallowmodel: train time: 5.837s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:16:04 [INFO] exp_shallowmodel: f1_score:   0.379
12/10/2017 02:16:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.70      0.58       164
          F       0.66      0.71      0.68       268
          R       0.42      0.18      0.25       125

avg / total       0.54      0.57      0.54       571

12/10/2017 02:16:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:04 [INFO] exp_shallowmodel: 
[[  0   7   5   2]
 [  0 115  36  13]
 [  0  62 190  16]
 [  0  47  56  22]]
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:12 [INFO] exp_shallowmodel: train time: 7.940s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:16:12 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 02:16:12 [INFO] exp_shallowmodel: f1_score:   0.425
12/10/2017 02:16:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.74      0.61       164
          F       0.72      0.69      0.70       268
          R       0.50      0.31      0.38       125

avg / total       0.60      0.61      0.59       571

12/10/2017 02:16:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:12 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  0 122  31  11]
 [  0  59 185  24]
 [  0  50  36  39]]
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 02:16:12 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:16:12 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:18 [INFO] exp_shallowmodel: train time: 6.121s
12/10/2017 02:16:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:18 [INFO] exp_shallowmodel: accuracy:   0.575
12/10/2017 02:16:18 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 02:16:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.51      0.74      0.61       169
          F       0.66      0.66      0.66       271
          R       0.47      0.26      0.34       130

avg / total       0.56      0.58      0.55       586

12/10/2017 02:16:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:18 [INFO] exp_shallowmodel: 
[[  0   4   8   4]
 [  1 125  34   9]
 [  0  68 178  25]
 [  0  47  49  34]]
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 02:16:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:18 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:22 [INFO] exp_shallowmodel: train time: 4.146s
12/10/2017 02:16:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:16:22 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:16:22 [INFO] exp_shallowmodel: f1_score:   0.421
12/10/2017 02:16:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.76      0.62       164
          F       0.71      0.70      0.71       268
          R       0.52      0.27      0.36       125

avg / total       0.60      0.61      0.59       571

12/10/2017 02:16:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:22 [INFO] exp_shallowmodel: 
[[  0   8   4   2]
 [  1 125  26  12]
 [  0  63 188  17]
 [  2  44  45  34]]
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 02:16:22 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:22 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:26 [INFO] exp_shallowmodel: train time: 4.018s
12/10/2017 02:16:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:26 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 02:16:26 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 02:16:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.70      0.57       164
          F       0.69      0.68      0.68       268
          R       0.38      0.21      0.27       125

avg / total       0.54      0.56      0.54       571

12/10/2017 02:16:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:26 [INFO] exp_shallowmodel: 
[[  0   6   7   1]
 [  0 114  36  14]
 [  0  59 182  27]
 [  0  60  39  26]]
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 02:16:26 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:26 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:30 [INFO] exp_shallowmodel: train time: 4.183s
12/10/2017 02:16:30 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:30 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 02:16:30 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 02:16:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.73      0.61       164
          F       0.65      0.71      0.68       268
          R       0.48      0.18      0.26       125

avg / total       0.56      0.58      0.55       571

12/10/2017 02:16:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:30 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 120  36   8]
 [  0  65 190  13]
 [  0  42  61  22]]
12/10/2017 02:16:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 02:16:30 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:30 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:16:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:39 [INFO] exp_shallowmodel: train time: 8.664s
12/10/2017 02:16:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:39 [INFO] exp_shallowmodel: accuracy:   0.567
12/10/2017 02:16:39 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 02:16:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.66      0.56       164
          F       0.65      0.70      0.68       268
          R       0.51      0.22      0.30       125

avg / total       0.56      0.57      0.54       571

12/10/2017 02:16:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:39 [INFO] exp_shallowmodel: 
[[  0   5   5   4]
 [  1 109  43  11]
 [  1  68 188  11]
 [  0  46  52  27]]
12/10/2017 02:16:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 02:16:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:39 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:16:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:46 [INFO] exp_shallowmodel: train time: 6.904s
12/10/2017 02:16:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:46 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 02:16:46 [INFO] exp_shallowmodel: f1_score:   0.421
12/10/2017 02:16:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.74      0.62       164
          F       0.69      0.71      0.70       268
          R       0.51      0.28      0.36       125

avg / total       0.59      0.61      0.59       571

12/10/2017 02:16:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:46 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  1 121  29  13]
 [  1  59 190  18]
 [  0  41  49  35]]
12/10/2017 02:16:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 02:16:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:46 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:16:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:50 [INFO] exp_shallowmodel: train time: 4.190s
12/10/2017 02:16:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:50 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 02:16:50 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 02:16:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.82      0.64       164
          F       0.71      0.66      0.68       268
          R       0.48      0.23      0.31       125

avg / total       0.59      0.60      0.57       571

12/10/2017 02:16:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:50 [INFO] exp_shallowmodel: 
[[  0   7   4   3]
 [  0 135  21   8]
 [  0  71 177  20]
 [  1  46  49  29]]
12/10/2017 02:16:50 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 02:16:50 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:50 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:16:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:56 [INFO] exp_shallowmodel: train time: 5.949s
12/10/2017 02:16:56 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:16:56 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 02:16:56 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 02:16:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.74      0.59       164
          F       0.70      0.67      0.69       268
          R       0.45      0.24      0.31       125

avg / total       0.57      0.58      0.56       571

12/10/2017 02:16:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:56 [INFO] exp_shallowmodel: 
[[  0   5   4   5]
 [  0 121  30  13]
 [  1  69 180  18]
 [  0  53  42  30]]
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 02:16:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:56 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:02 [INFO] exp_shallowmodel: train time: 5.499s
12/10/2017 02:17:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:02 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:17:02 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:17:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.67      0.56       164
          F       0.70      0.71      0.71       268
          R       0.45      0.26      0.33       125

avg / total       0.57      0.58      0.56       571

12/10/2017 02:17:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:02 [INFO] exp_shallowmodel: 
[[  0   7   5   2]
 [  0 110  35  19]
 [  0  59 191  18]
 [  0  51  42  32]]
12/10/2017 02:17:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 02:17:02 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:02 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:09 [INFO] exp_shallowmodel: train time: 7.200s
12/10/2017 02:17:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:09 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:17:09 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:17:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.77      0.62       164
          F       0.72      0.72      0.72       268
          R       0.39      0.19      0.26       125

avg / total       0.57      0.60      0.57       571

12/10/2017 02:17:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:09 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 126  24  14]
 [  0  56 192  20]
 [  0  57  44  24]]
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 02:17:09 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:17:09 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:15 [INFO] exp_shallowmodel: train time: 6.212s
12/10/2017 02:17:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:15 [INFO] exp_shallowmodel: accuracy:   0.558
12/10/2017 02:17:15 [INFO] exp_shallowmodel: f1_score:   0.376
12/10/2017 02:17:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.49      0.72      0.58       169
          F       0.65      0.66      0.66       271
          R       0.42      0.19      0.26       130

avg / total       0.54      0.56      0.53       586

12/10/2017 02:17:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:15 [INFO] exp_shallowmodel: 
[[  0   6   7   3]
 [  0 122  33  14]
 [  0  74 180  17]
 [  0  48  57  25]]
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 02:17:15 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:15 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:21 [INFO] exp_shallowmodel: train time: 5.533s
12/10/2017 02:17:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:21 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 02:17:21 [INFO] exp_shallowmodel: f1_score:   0.366
12/10/2017 02:17:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.47      0.73      0.57       164
          F       0.68      0.68      0.68       268
          R       0.40      0.15      0.22       125

avg / total       0.54      0.56      0.53       571

12/10/2017 02:17:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:21 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  0 119  33  12]
 [  0  73 181  14]
 [  1  57  48  19]]
12/10/2017 02:17:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 02:17:21 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:21 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:26 [INFO] exp_shallowmodel: train time: 5.112s
12/10/2017 02:17:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:17:26 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:17:26 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 02:17:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.79      0.63       164
          F       0.68      0.69      0.69       268
          R       0.50      0.22      0.31       125

avg / total       0.58      0.60      0.57       571

12/10/2017 02:17:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:26 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 130  25   9]
 [  0  68 184  16]
 [  0  46  51  28]]
12/10/2017 02:17:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 02:17:26 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:26 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:31 [INFO] exp_shallowmodel: train time: 4.396s
12/10/2017 02:17:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:31 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:17:31 [INFO] exp_shallowmodel: f1_score:   0.388
12/10/2017 02:17:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.47      0.70      0.56       164
          F       0.68      0.66      0.67       268
          R       0.45      0.24      0.31       125

avg / total       0.56      0.57      0.55       571

12/10/2017 02:17:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:31 [INFO] exp_shallowmodel: 
[[  0   6   4   4]
 [  1 115  33  15]
 [  0  73 178  17]
 [  0  50  45  30]]
12/10/2017 02:17:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 02:17:31 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:31 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:36 [INFO] exp_shallowmodel: train time: 5.570s
12/10/2017 02:17:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:36 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 02:17:36 [INFO] exp_shallowmodel: f1_score:   0.413
12/10/2017 02:17:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.76      0.61       164
          F       0.74      0.74      0.74       268
          R       0.47      0.22      0.30       125

avg / total       0.60      0.61      0.59       571

12/10/2017 02:17:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:36 [INFO] exp_shallowmodel: 
[[  0  11   3   0]
 [  0 125  23  16]
 [  0  56 197  15]
 [  0  52  45  28]]
12/10/2017 02:17:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 02:17:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:36 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:41 [INFO] exp_shallowmodel: train time: 5.302s
12/10/2017 02:17:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:42 [INFO] exp_shallowmodel: accuracy:   0.609
12/10/2017 02:17:42 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 02:17:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.76      0.61       164
          F       0.72      0.75      0.73       268
          R       0.50      0.18      0.27       125

avg / total       0.59      0.61      0.58       571

12/10/2017 02:17:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:42 [INFO] exp_shallowmodel: 
[[  0   7   6   1]
 [  0 125  28  11]
 [  0  57 200  11]
 [  0  57  45  23]]
12/10/2017 02:17:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 02:17:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:42 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:47 [INFO] exp_shallowmodel: train time: 5.228s
12/10/2017 02:17:47 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:17:47 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:17:47 [INFO] exp_shallowmodel: f1_score:   0.395
12/10/2017 02:17:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.76      0.60       164
          F       0.71      0.68      0.69       268
          R       0.42      0.22      0.28       125

avg / total       0.57      0.58      0.56       571

12/10/2017 02:17:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:47 [INFO] exp_shallowmodel: 
[[  0   6   5   3]
 [  0 124  30  10]
 [  1  60 182  25]
 [  0  57  41  27]]
12/10/2017 02:17:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 02:17:47 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:47 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:52 [INFO] exp_shallowmodel: train time: 5.087s
12/10/2017 02:17:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:52 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:17:52 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 02:17:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.74      0.58       164
          F       0.68      0.65      0.66       268
          R       0.46      0.21      0.29       125

avg / total       0.56      0.57      0.54       571

12/10/2017 02:17:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:52 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  1 122  27  14]
 [  1  78 175  14]
 [  0  48  51  26]]
12/10/2017 02:17:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 02:17:52 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:52 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:56 [INFO] exp_shallowmodel: train time: 3.905s
12/10/2017 02:17:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:56 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 02:17:56 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 02:17:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.44      0.76      0.56       164
          F       0.72      0.60      0.65       268
          R       0.55      0.30      0.39       125

avg / total       0.59      0.56      0.55       571

12/10/2017 02:17:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:56 [INFO] exp_shallowmodel: 
[[  0   7   5   2]
 [  0 124  23  17]
 [  0  96 161  11]
 [  0  53  35  37]]
12/10/2017 02:17:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 02:17:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:56 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:17:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:01 [INFO] exp_shallowmodel: train time: 4.826s
12/10/2017 02:18:01 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:18:01 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:18:01 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 02:18:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.79      0.61       164
          F       0.73      0.64      0.68       268
          R       0.42      0.25      0.31       125

avg / total       0.58      0.58      0.56       571

12/10/2017 02:18:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:01 [INFO] exp_shallowmodel: 
[[  0   3   4   7]
 [  0 130  20  14]
 [  0  75 172  21]
 [  1  52  41  31]]
12/10/2017 02:18:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 02:18:01 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:18:01 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:18:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:07 [INFO] exp_shallowmodel: train time: 6.269s
12/10/2017 02:18:07 [INFO] exp_shallowmodel: test time:  0.001s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:18:07 [INFO] exp_shallowmodel: accuracy:   0.565
12/10/2017 02:18:07 [INFO] exp_shallowmodel: f1_score:   0.388
12/10/2017 02:18:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.50      0.75      0.60       169
          F       0.67      0.64      0.66       271
          R       0.41      0.23      0.29       130

avg / total       0.55      0.56      0.54       586

12/10/2017 02:18:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:07 [INFO] exp_shallowmodel: 
[[  0   5   7   4]
 [  0 127  29  13]
 [  0  70 174  27]
 [  0  51  49  30]]
12/10/2017 02:18:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 02:18:07 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:07 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:18:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:15 [INFO] exp_shallowmodel: train time: 8.379s
12/10/2017 02:18:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:15 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 02:18:15 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 02:18:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.84      0.66       164
          F       0.71      0.68      0.69       268
          R       0.53      0.24      0.33       125

avg / total       0.60      0.61      0.59       571

12/10/2017 02:18:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:15 [INFO] exp_shallowmodel: 
[[  0   8   5   1]
 [  0 138  13  13]
 [  0  73 182  13]
 [  1  37  57  30]]
12/10/2017 02:18:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 02:18:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:16 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:18:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:21 [INFO] exp_shallowmodel: train time: 5.101s
12/10/2017 02:18:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:21 [INFO] exp_shallowmodel: accuracy:   0.560
12/10/2017 02:18:21 [INFO] exp_shallowmodel: f1_score:   0.381
12/10/2017 02:18:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.47      0.70      0.56       164
          F       0.66      0.67      0.67       268
          R       0.48      0.22      0.30       125

avg / total       0.55      0.56      0.54       571

12/10/2017 02:18:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:21 [INFO] exp_shallowmodel: 
[[  0   5   9   0]
 [  0 114  38  12]
 [  1  71 179  17]
 [  0  54  44  27]]
12/10/2017 02:18:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 02:18:21 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:21 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:18:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:25 [INFO] exp_shallowmodel: train time: 3.966s
12/10/2017 02:18:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:25 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:18:25 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 02:18:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.77      0.61       164
          F       0.71      0.71      0.71       268
          R       0.58      0.24      0.34       125

avg / total       0.61      0.61      0.58       571

12/10/2017 02:18:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:25 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  0 126  32   6]
 [  0  65 191  12]
 [  1  56  38  30]]
12/10/2017 02:18:25 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 02:18:25 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:25 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:18:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:30 [INFO] exp_shallowmodel: train time: 5.067s
12/10/2017 02:18:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:18:30 [INFO] exp_shallowmodel: accuracy:   0.553
12/10/2017 02:18:30 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 02:18:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.45      0.65      0.53       164
          F       0.68      0.68      0.68       268
          R       0.40      0.23      0.29       125

avg / total       0.54      0.55      0.54       571

12/10/2017 02:18:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:30 [INFO] exp_shallowmodel: 
[[  0   7   3   4]
 [  1 106  41  16]
 [  0  64 181  23]
 [  0  56  40  29]]
12/10/2017 02:18:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 02:18:30 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:30 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:18:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:36 [INFO] exp_shallowmodel: train time: 6.542s
12/10/2017 02:18:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:36 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 02:18:36 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 02:18:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.79      0.63       164
          F       0.72      0.73      0.72       268
          R       0.45      0.20      0.28       125

avg / total       0.59      0.61      0.58       571

12/10/2017 02:18:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:36 [INFO] exp_shallowmodel: 
[[  0   7   6   1]
 [  1 129  20  14]
 [  0  58 195  15]
 [  0  49  51  25]]
12/10/2017 02:18:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 02:18:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:36 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:18:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:42 [INFO] exp_shallowmodel: train time: 5.784s
12/10/2017 02:18:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:42 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 02:18:42 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:18:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.69      0.58       164
          F       0.70      0.70      0.70       268
          R       0.47      0.29      0.36       125

avg / total       0.58      0.59      0.57       571

12/10/2017 02:18:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:42 [INFO] exp_shallowmodel: 
[[  0   5   4   5]
 [  0 113  35  16]
 [  0  61 188  19]
 [  0  47  42  36]]
12/10/2017 02:18:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 02:18:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:42 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:18:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:48 [INFO] exp_shallowmodel: train time: 6.131s
12/10/2017 02:18:48 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:18:48 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:18:48 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 02:18:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.74      0.60       164
          F       0.69      0.69      0.69       268
          R       0.47      0.22      0.30       125

avg / total       0.57      0.59      0.56       571

12/10/2017 02:18:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:48 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  0 122  26  16]
 [  0  69 185  14]
 [  1  46  50  28]]
12/10/2017 02:18:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 02:18:48 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:48 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:18:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:54 [INFO] exp_shallowmodel: train time: 5.731s
12/10/2017 02:18:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:54 [INFO] exp_shallowmodel: accuracy:   0.555
12/10/2017 02:18:54 [INFO] exp_shallowmodel: f1_score:   0.374
12/10/2017 02:18:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.69      0.59       164
          F       0.64      0.67      0.66       268
          R       0.35      0.20      0.26       125

avg / total       0.53      0.56      0.53       571

12/10/2017 02:18:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:54 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  0 113  37  14]
 [  0  61 179  28]
 [  1  45  54  25]]
12/10/2017 02:18:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 02:18:54 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:54 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:18:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:02 [INFO] exp_shallowmodel: train time: 7.584s
12/10/2017 02:19:02 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:19:02 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:19:02 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 02:19:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.77      0.62       164
          F       0.70      0.68      0.69       268
          R       0.41      0.22      0.28       125

avg / total       0.57      0.59      0.56       571

12/10/2017 02:19:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:02 [INFO] exp_shallowmodel: 
[[  0   7   5   2]
 [  0 127  26  11]
 [  0  61 181  26]
 [  1  50  47  27]]
12/10/2017 02:19:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 02:19:02 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:19:02 [INFO] exp_shallowmodel: #(feature) = 306
12/10/2017 02:19:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:09 [INFO] exp_shallowmodel: train time: 7.316s
12/10/2017 02:19:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:19:09 [INFO] exp_shallowmodel: accuracy:   0.563
12/10/2017 02:19:09 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 02:19:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.49      0.76      0.60       169
          F       0.69      0.65      0.67       271
          R       0.39      0.21      0.27       130

avg / total       0.54      0.56      0.54       586

12/10/2017 02:19:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:09 [INFO] exp_shallowmodel: 
[[  0   7   6   3]
 [  0 128  24  17]
 [  0  73 175  23]
 [  1  52  50  27]]
12/10/2017 02:19:13 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:19:13 [INFO] task_runner: context=current, feature=4-syntactic
12/10/2017 02:19:13 [INFO] task_runner: retained feature numbers=[7]
12/10/2017 02:19:13 [INFO] task_runner: #(data)=5934
12/10/2017 02:19:13 [INFO] task_runner: #(feature)=395
12/10/2017 02:19:13 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:19:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 02:19:13 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:19:13 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:19:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:19 [INFO] exp_shallowmodel: train time: 6.224s
12/10/2017 02:19:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:19:19 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 02:19:19 [INFO] exp_shallowmodel: f1_score:   0.379
12/10/2017 02:19:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.46      0.64      0.54       169
          F       0.67      0.71      0.69       281
          R       0.35      0.15      0.21       122

avg / total       0.53      0.55      0.53       592

12/10/2017 02:19:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:19 [INFO] exp_shallowmodel: 
[[  1   3  10   6]
 [  1 109  43  16]
 [  2  67 200  12]
 [  1  58  45  18]]
12/10/2017 02:19:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 02:19:19 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:19:19 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:19:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:26 [INFO] exp_shallowmodel: train time: 7.329s
12/10/2017 02:19:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:19:26 [INFO] exp_shallowmodel: accuracy:   0.586
12/10/2017 02:19:26 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 02:19:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.72      0.58       169
          F       0.68      0.73      0.71       281
          R       0.58      0.16      0.25       122

avg / total       0.58      0.59      0.55       592

12/10/2017 02:19:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:26 [INFO] exp_shallowmodel: 
[[  0   4  14   2]
 [  0 122  39   8]
 [  0  71 206   4]
 [  2  57  44  19]]
12/10/2017 02:19:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 02:19:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:19:26 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:19:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:37 [INFO] exp_shallowmodel: train time: 10.992s
12/10/2017 02:19:37 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:19:37 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:19:37 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 02:19:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.46      0.66      0.54       169
          F       0.66      0.73      0.69       281
          R       0.59      0.18      0.28       122

avg / total       0.57      0.57      0.54       592

12/10/2017 02:19:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:37 [INFO] exp_shallowmodel: 
[[  1   8  10   1]
 [  1 111  47  10]
 [  1  72 204   4]
 [  2  48  50  22]]
12/10/2017 02:19:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 02:19:37 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:19:37 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:19:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:45 [INFO] exp_shallowmodel: train time: 7.499s
12/10/2017 02:19:45 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:19:45 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:19:45 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 02:19:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.73      0.58       169
          F       0.68      0.70      0.69       281
          R       0.38      0.14      0.20       122

avg / total       0.54      0.57      0.54       592

12/10/2017 02:19:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:45 [INFO] exp_shallowmodel: 
[[  0   8   8   4]
 [  0 123  35  11]
 [  0  70 198  13]
 [  2  54  49  17]]
12/10/2017 02:19:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 02:19:45 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:19:45 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:19:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:02 [INFO] exp_shallowmodel: train time: 16.588s
12/10/2017 02:20:02 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:20:02 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 02:20:02 [INFO] exp_shallowmodel: f1_score:   0.363
12/10/2017 02:20:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.76      0.58       169
          F       0.67      0.67      0.67       281
          R       0.47      0.13      0.21       122

avg / total       0.55      0.56      0.53       592

12/10/2017 02:20:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:02 [INFO] exp_shallowmodel: 
[[  0   6  12   2]
 [  0 129  31   9]
 [  0  86 188   7]
 [  0  57  49  16]]
12/10/2017 02:20:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 02:20:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:02 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:20:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:09 [INFO] exp_shallowmodel: train time: 7.004s
12/10/2017 02:20:09 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:20:09 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 02:20:09 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:20:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.45      0.60      0.52       169
          F       0.66      0.74      0.70       281
          R       0.43      0.17      0.25       122

avg / total       0.54      0.56      0.53       592

12/10/2017 02:20:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:09 [INFO] exp_shallowmodel: 
[[  1   8  10   1]
 [  1 102  48  18]
 [  0  65 207   9]
 [  2  50  49  21]]
12/10/2017 02:20:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 02:20:09 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:09 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:20:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:17 [INFO] exp_shallowmodel: train time: 8.177s
12/10/2017 02:20:17 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:20:17 [INFO] exp_shallowmodel: accuracy:   0.547
12/10/2017 02:20:17 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 02:20:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.66      0.55       169
          F       0.65      0.68      0.67       281
          R       0.36      0.16      0.22       122

avg / total       0.52      0.55      0.52       592

12/10/2017 02:20:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:17 [INFO] exp_shallowmodel: 
[[  0   7   8   5]
 [  0 112  43  14]
 [  1  71 192  17]
 [  0  51  51  20]]
12/10/2017 02:20:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 02:20:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:17 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:20:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:24 [INFO] exp_shallowmodel: train time: 7.491s
12/10/2017 02:20:24 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:20:24 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 02:20:24 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:20:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.45      0.54      0.49       169
          F       0.63      0.77      0.69       281
          R       0.55      0.18      0.27       122

avg / total       0.57      0.56      0.53       592

12/10/2017 02:20:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:24 [INFO] exp_shallowmodel: 
[[  1   9   7   3]
 [  0  91  73   5]
 [  0  54 217  10]
 [  0  50  50  22]]
12/10/2017 02:20:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 02:20:24 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:24 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:20:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:31 [INFO] exp_shallowmodel: train time: 6.428s
12/10/2017 02:20:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:20:31 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 02:20:31 [INFO] exp_shallowmodel: f1_score:   0.357
12/10/2017 02:20:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.67      0.55       169
          F       0.67      0.71      0.69       281
          R       0.35      0.13      0.19       122

avg / total       0.52      0.56      0.52       592

12/10/2017 02:20:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:31 [INFO] exp_shallowmodel: 
[[  0   5  12   3]
 [  2 113  41  13]
 [  0  67 200  14]
 [  0  59  47  16]]
12/10/2017 02:20:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 02:20:31 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:20:31 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:20:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:42 [INFO] exp_shallowmodel: train time: 11.563s
12/10/2017 02:20:43 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:20:43 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:20:43 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 02:20:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        28
          C       0.44      0.70      0.54       172
          F       0.71      0.70      0.70       283
          R       0.53      0.20      0.29       123

avg / total       0.59      0.57      0.55       606

12/10/2017 02:20:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:43 [INFO] exp_shallowmodel: 
[[  2  11   8   7]
 [  0 120  45   7]
 [  0  76 199   8]
 [  2  66  30  25]]
12/10/2017 02:20:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 02:20:43 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:43 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:20:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:52 [INFO] exp_shallowmodel: train time: 9.399s
12/10/2017 02:20:52 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:20:52 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 02:20:52 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 02:20:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.49      0.69      0.57       169
          F       0.69      0.75      0.72       281
          R       0.50      0.17      0.26       122

avg / total       0.58      0.59      0.56       592

12/10/2017 02:20:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:52 [INFO] exp_shallowmodel: 
[[  1   6  10   3]
 [  1 117  41  10]
 [  0  63 210   8]
 [  2  54  45  21]]
12/10/2017 02:20:52 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 02:20:52 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:52 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:20:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:00 [INFO] exp_shallowmodel: train time: 8.363s
12/10/2017 02:21:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:00 [INFO] exp_shallowmodel: accuracy:   0.539
12/10/2017 02:21:00 [INFO] exp_shallowmodel: f1_score:   0.413
12/10/2017 02:21:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.15      0.24        20
          C       0.42      0.58      0.49       169
          F       0.65      0.70      0.67       281
          R       0.45      0.18      0.26       122

avg / total       0.54      0.54      0.52       592

12/10/2017 02:21:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:00 [INFO] exp_shallowmodel: 
[[  3   8   7   2]
 [  1  98  53  17]
 [  1  76 196   8]
 [  0  53  47  22]]
12/10/2017 02:21:00 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 02:21:00 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:00 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:21:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:10 [INFO] exp_shallowmodel: train time: 9.994s
12/10/2017 02:21:10 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:10 [INFO] exp_shallowmodel: accuracy:   0.544
12/10/2017 02:21:10 [INFO] exp_shallowmodel: f1_score:   0.354
12/10/2017 02:21:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.43      0.70      0.54       169
          F       0.69      0.66      0.68       281
          R       0.38      0.14      0.20       122

avg / total       0.53      0.54      0.52       592

12/10/2017 02:21:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:10 [INFO] exp_shallowmodel: 
[[  0   9   5   6]
 [  1 119  37  12]
 [  0  85 186  10]
 [  2  62  41  17]]
12/10/2017 02:21:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 02:21:11 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:11 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:21:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:20 [INFO] exp_shallowmodel: train time: 9.167s
12/10/2017 02:21:20 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:20 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:21:20 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 02:21:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.10      0.17        20
          C       0.44      0.69      0.54       169
          F       0.70      0.71      0.70       281
          R       0.42      0.14      0.21       122

avg / total       0.56      0.57      0.54       592

12/10/2017 02:21:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:20 [INFO] exp_shallowmodel: 
[[  2   7  10   1]
 [  1 117  41  10]
 [  1  69 199  12]
 [  0  70  35  17]]
12/10/2017 02:21:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 02:21:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:20 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:21:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:26 [INFO] exp_shallowmodel: train time: 6.236s
12/10/2017 02:21:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:26 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 02:21:26 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 02:21:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.75      0.58       169
          F       0.69      0.69      0.69       281
          R       0.48      0.18      0.26       122

avg / total       0.56      0.58      0.55       592

12/10/2017 02:21:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:26 [INFO] exp_shallowmodel: 
[[  0   6  11   3]
 [  0 126  35   8]
 [  0  73 195  13]
 [  1  58  41  22]]
12/10/2017 02:21:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 02:21:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:26 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:21:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:34 [INFO] exp_shallowmodel: train time: 7.709s
12/10/2017 02:21:34 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:34 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 02:21:34 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 02:21:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.47      0.74      0.58       169
          F       0.69      0.67      0.68       281
          R       0.33      0.15      0.20       122

avg / total       0.55      0.56      0.53       592

12/10/2017 02:21:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:34 [INFO] exp_shallowmodel: 
[[  1   6   9   4]
 [  0 125  31  13]
 [  1  73 187  20]
 [  0  60  44  18]]
12/10/2017 02:21:34 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 02:21:34 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:34 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:21:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:41 [INFO] exp_shallowmodel: train time: 7.398s
12/10/2017 02:21:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:41 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:21:41 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 02:21:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.66      0.54       169
          F       0.66      0.72      0.69       281
          R       0.54      0.21      0.31       122

avg / total       0.56      0.57      0.55       592

12/10/2017 02:21:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:41 [INFO] exp_shallowmodel: 
[[  0   5  10   5]
 [  1 111  48   9]
 [  0  72 201   8]
 [  1  51  44  26]]
12/10/2017 02:21:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 02:21:41 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:41 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:21:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:49 [INFO] exp_shallowmodel: train time: 8.152s
12/10/2017 02:21:49 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:49 [INFO] exp_shallowmodel: accuracy:   0.584
12/10/2017 02:21:49 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:21:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.69      0.57       169
          F       0.69      0.74      0.71       281
          R       0.43      0.19      0.26       122

avg / total       0.55      0.58      0.55       592

12/10/2017 02:21:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:49 [INFO] exp_shallowmodel: 
[[  0   4  10   6]
 [  0 116  40  13]
 [  0  63 207  11]
 [  0  55  44  23]]
12/10/2017 02:21:49 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 02:21:49 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:49 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:21:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:59 [INFO] exp_shallowmodel: train time: 9.984s
12/10/2017 02:21:59 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:59 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 02:21:59 [INFO] exp_shallowmodel: f1_score:   0.352
12/10/2017 02:21:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.69      0.55       169
          F       0.65      0.69      0.67       281
          R       0.41      0.12      0.19       122

avg / total       0.52      0.55      0.51       592

12/10/2017 02:21:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:59 [INFO] exp_shallowmodel: 
[[  0  10   9   1]
 [  0 116  46   7]
 [  0  72 195  14]
 [  2  54  51  15]]
12/10/2017 02:21:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 02:21:59 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:21:59 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:21:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:10 [INFO] exp_shallowmodel: train time: 10.703s
12/10/2017 02:22:10 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:22:10 [INFO] exp_shallowmodel: accuracy:   0.561
12/10/2017 02:22:10 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 02:22:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.46      0.72      0.56       172
          F       0.67      0.70      0.68       283
          R       0.50      0.15      0.24       123

avg / total       0.54      0.56      0.53       606

12/10/2017 02:22:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:10 [INFO] exp_shallowmodel: 
[[  0  13  10   5]
 [  0 123  41   8]
 [  0  79 198   6]
 [  2  55  47  19]]
12/10/2017 02:22:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 02:22:10 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:10 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:22:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:18 [INFO] exp_shallowmodel: train time: 7.657s
12/10/2017 02:22:18 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:22:18 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:22:18 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 02:22:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.70      0.57       169
          F       0.69      0.72      0.71       281
          R       0.35      0.14      0.20       122

avg / total       0.54      0.57      0.54       592

12/10/2017 02:22:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:18 [INFO] exp_shallowmodel: 
[[  0   2  13   5]
 [  0 119  35  15]
 [  0  67 203  11]
 [  2  61  42  17]]
12/10/2017 02:22:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 02:22:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:18 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:22:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:25 [INFO] exp_shallowmodel: train time: 6.610s
12/10/2017 02:22:25 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:22:25 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:22:25 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 02:22:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.66      0.54       169
          F       0.66      0.70      0.68       281
          R       0.54      0.20      0.30       122

avg / total       0.55      0.57      0.54       592

12/10/2017 02:22:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:25 [INFO] exp_shallowmodel: 
[[  0   6  11   3]
 [  0 112  47  10]
 [  0  75 198   8]
 [  0  51  46  25]]
12/10/2017 02:22:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 02:22:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:25 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:22:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:33 [INFO] exp_shallowmodel: train time: 7.969s
12/10/2017 02:22:33 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:22:33 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 02:22:33 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 02:22:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.47      0.72      0.57       169
          F       0.69      0.72      0.71       281
          R       0.51      0.16      0.25       122

avg / total       0.57      0.58      0.55       592

12/10/2017 02:22:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:33 [INFO] exp_shallowmodel: 
[[  0  10  10   0]
 [  2 121  35  11]
 [  0  70 203   8]
 [  3  54  45  20]]
12/10/2017 02:22:33 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 02:22:33 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:33 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:22:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:38 [INFO] exp_shallowmodel: train time: 5.500s
12/10/2017 02:22:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:22:38 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 02:22:38 [INFO] exp_shallowmodel: f1_score:   0.363
12/10/2017 02:22:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.70      0.55       169
          F       0.66      0.68      0.67       281
          R       0.46      0.16      0.23       122

avg / total       0.54      0.55      0.52       592

12/10/2017 02:22:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:38 [INFO] exp_shallowmodel: 
[[  0   7  11   2]
 [  0 118  40  11]
 [  0  81 191   9]
 [  0  55  48  19]]
12/10/2017 02:22:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 02:22:38 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:38 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:22:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:46 [INFO] exp_shallowmodel: train time: 7.460s
12/10/2017 02:22:46 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:22:46 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 02:22:46 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:22:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.47      0.66      0.55       169
          F       0.65      0.71      0.68       281
          R       0.47      0.18      0.26       122

avg / total       0.57      0.56      0.54       592

12/10/2017 02:22:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:46 [INFO] exp_shallowmodel: 
[[  1   5   9   5]
 [  0 111  49   9]
 [  0  70 200  11]
 [  0  48  52  22]]
12/10/2017 02:22:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 02:22:46 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:46 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:22:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:54 [INFO] exp_shallowmodel: train time: 7.911s
12/10/2017 02:22:54 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:22:54 [INFO] exp_shallowmodel: accuracy:   0.529
12/10/2017 02:22:54 [INFO] exp_shallowmodel: f1_score:   0.355
12/10/2017 02:22:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        20
          C       0.44      0.63      0.52       169
          F       0.63      0.68      0.65       281
          R       0.31      0.11      0.16       122

avg / total       0.50      0.53      0.50       592

12/10/2017 02:22:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:54 [INFO] exp_shallowmodel: 
[[  1   6  11   2]
 [  0 107  50  12]
 [  1  73 192  15]
 [  1  55  53  13]]
12/10/2017 02:22:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 02:22:54 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:54 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:22:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:04 [INFO] exp_shallowmodel: train time: 10.028s
12/10/2017 02:23:04 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:23:04 [INFO] exp_shallowmodel: accuracy:   0.537
12/10/2017 02:23:04 [INFO] exp_shallowmodel: f1_score:   0.376
12/10/2017 02:23:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.45      0.66      0.53       169
          F       0.67      0.66      0.66       281
          R       0.34      0.17      0.23       122

avg / total       0.52      0.54      0.52       592

12/10/2017 02:23:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:04 [INFO] exp_shallowmodel: 
[[  1  10   6   3]
 [  0 111  42  16]
 [  2  73 185  21]
 [  2  54  45  21]]
12/10/2017 02:23:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 02:23:04 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:23:04 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:23:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:11 [INFO] exp_shallowmodel: train time: 7.393s
12/10/2017 02:23:11 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:23:11 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 02:23:11 [INFO] exp_shallowmodel: f1_score:   0.375
12/10/2017 02:23:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.43      0.66      0.52       169
          F       0.68      0.70      0.69       281
          R       0.42      0.14      0.21       122

avg / total       0.54      0.55      0.52       592

12/10/2017 02:23:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:11 [INFO] exp_shallowmodel: 
[[  1   9   6   4]
 [  2 111  46  10]
 [  1  74 197   9]
 [  1  64  40  17]]
12/10/2017 02:23:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 02:23:11 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:23:11 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:23:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:23 [INFO] exp_shallowmodel: train time: 11.451s
12/10/2017 02:23:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:23:23 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 02:23:23 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 02:23:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.75      0.59       169
          F       0.68      0.70      0.69       281
          R       0.50      0.17      0.26       122

avg / total       0.57      0.58      0.55       592

12/10/2017 02:23:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:23 [INFO] exp_shallowmodel: 
[[  0   5   9   6]
 [  1 126  35   7]
 [  0  77 196   8]
 [  2  52  47  21]]
12/10/2017 02:23:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 02:23:23 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:23:23 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:23:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:31 [INFO] exp_shallowmodel: train time: 7.836s
12/10/2017 02:23:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:23:31 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:23:31 [INFO] exp_shallowmodel: f1_score:   0.375
12/10/2017 02:23:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.46      0.70      0.55       172
          F       0.68      0.71      0.70       283
          R       0.45      0.17      0.25       123

avg / total       0.54      0.57      0.53       606

12/10/2017 02:23:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:31 [INFO] exp_shallowmodel: 
[[  0  12  11   5]
 [  2 120  40  10]
 [  0  70 202  11]
 [  0  59  43  21]]
12/10/2017 02:23:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 02:23:31 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:23:31 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:23:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:41 [INFO] exp_shallowmodel: train time: 9.927s
12/10/2017 02:23:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:23:41 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 02:23:41 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 02:23:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.73      0.61       169
          F       0.68      0.74      0.71       281
          R       0.48      0.20      0.28       122

avg / total       0.57      0.60      0.57       592

12/10/2017 02:23:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:41 [INFO] exp_shallowmodel: 
[[  0   9   9   2]
 [  0 124  36   9]
 [  0  58 208  15]
 [  0  47  51  24]]
12/10/2017 02:23:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 02:23:41 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:23:41 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:23:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:50 [INFO] exp_shallowmodel: train time: 9.011s
12/10/2017 02:23:50 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:23:50 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 02:23:50 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 02:23:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.66      0.54       169
          F       0.71      0.74      0.72       281
          R       0.48      0.19      0.27       122

avg / total       0.56      0.58      0.55       592

12/10/2017 02:23:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:50 [INFO] exp_shallowmodel: 
[[  0   8   9   3]
 [  1 112  43  13]
 [  0  64 208   9]
 [  0  64  35  23]]
12/10/2017 02:23:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 02:23:50 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:23:50 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:23:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:56 [INFO] exp_shallowmodel: train time: 6.748s
12/10/2017 02:23:56 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:23:56 [INFO] exp_shallowmodel: accuracy:   0.557
12/10/2017 02:23:56 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:23:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.46      0.67      0.54       169
          F       0.65      0.70      0.68       281
          R       0.44      0.16      0.23       122

avg / total       0.57      0.56      0.53       592

12/10/2017 02:23:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:56 [INFO] exp_shallowmodel: 
[[  1   5   8   6]
 [  0 113  48   8]
 [  0  74 197  10]
 [  0  54  49  19]]
12/10/2017 02:23:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 02:23:57 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:23:57 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:23:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:07 [INFO] exp_shallowmodel: train time: 10.726s
12/10/2017 02:24:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:24:07 [INFO] exp_shallowmodel: accuracy:   0.584
12/10/2017 02:24:07 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 02:24:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.73      0.60       169
          F       0.68      0.73      0.70       281
          R       0.40      0.14      0.21       122

avg / total       0.55      0.58      0.55       592

12/10/2017 02:24:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:07 [INFO] exp_shallowmodel: 
[[  0   7   7   6]
 [  0 124  37   8]
 [  0  64 205  12]
 [  3  49  53  17]]
12/10/2017 02:24:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 02:24:07 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:24:07 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:24:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:19 [INFO] exp_shallowmodel: train time: 11.602s
12/10/2017 02:24:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:24:19 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:24:19 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 02:24:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.63      0.55       169
          F       0.64      0.74      0.69       281
          R       0.51      0.20      0.28       122

avg / total       0.55      0.57      0.54       592

12/10/2017 02:24:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:19 [INFO] exp_shallowmodel: 
[[  0  12   8   0]
 [  0 107  52  10]
 [  1  60 207  13]
 [  1  42  55  24]]
12/10/2017 02:24:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 02:24:19 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:24:19 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:24:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:25 [INFO] exp_shallowmodel: train time: 6.221s
12/10/2017 02:24:25 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:24:25 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 02:24:25 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 02:24:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.47      0.66      0.55       169
          F       0.65      0.68      0.67       281
          R       0.37      0.17      0.23       122

avg / total       0.53      0.55      0.53       592

12/10/2017 02:24:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:25 [INFO] exp_shallowmodel: 
[[  1   3   8   8]
 [  0 112  44  13]
 [  3  71 192  15]
 [  0  51  50  21]]
12/10/2017 02:24:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 02:24:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:24:25 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:24:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:31 [INFO] exp_shallowmodel: train time: 5.903s
12/10/2017 02:24:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:24:31 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 02:24:31 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 02:24:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.10      0.17        20
          C       0.42      0.65      0.51       169
          F       0.69      0.70      0.70       281
          R       0.47      0.16      0.23       122

avg / total       0.56      0.55      0.53       592

12/10/2017 02:24:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:31 [INFO] exp_shallowmodel: 
[[  2  11   4   3]
 [  1 110  49   9]
 [  1  74 197   9]
 [  0  69  34  19]]
12/10/2017 02:24:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 02:24:31 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:24:31 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:24:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:40 [INFO] exp_shallowmodel: train time: 8.709s
12/10/2017 02:24:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:24:40 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 02:24:40 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 02:24:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.10      0.16        20
          C       0.45      0.64      0.53       169
          F       0.67      0.69      0.68       281
          R       0.43      0.19      0.26       122

avg / total       0.55      0.56      0.53       592

12/10/2017 02:24:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:40 [INFO] exp_shallowmodel: 
[[  2   4   9   5]
 [  1 109  45  14]
 [  0  74 195  12]
 [  2  53  44  23]]
12/10/2017 02:24:40 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 02:24:40 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:24:40 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:24:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:48 [INFO] exp_shallowmodel: train time: 7.955s
12/10/2017 02:24:48 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:24:48 [INFO] exp_shallowmodel: accuracy:   0.535
12/10/2017 02:24:48 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 02:24:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.44      0.65      0.52       169
          F       0.64      0.68      0.66       281
          R       0.47      0.13      0.21       122

avg / total       0.52      0.54      0.50       592

12/10/2017 02:24:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:48 [INFO] exp_shallowmodel: 
[[  0   9   9   2]
 [  3 110  48   8]
 [  3  79 191   8]
 [  1  54  51  16]]
12/10/2017 02:24:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 02:24:48 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:24:48 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:24:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:57 [INFO] exp_shallowmodel: train time: 9.148s
12/10/2017 02:24:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:57 [INFO] exp_shallowmodel: accuracy:   0.531
12/10/2017 02:24:57 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 02:24:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.06        28
          C       0.41      0.53      0.47       172
          F       0.61      0.74      0.67       283
          R       0.54      0.15      0.24       123

avg / total       0.53      0.53      0.50       606

12/10/2017 02:24:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:57 [INFO] exp_shallowmodel: 
[[  1   7  15   5]
 [  1  92  75   4]
 [  0  66 210   7]
 [  1  57  46  19]]
12/10/2017 02:24:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 02:24:57 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:24:57 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:24:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:04 [INFO] exp_shallowmodel: train time: 6.768s
12/10/2017 02:25:04 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:25:04 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 02:25:04 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 02:25:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        20
          C       0.46      0.69      0.55       169
          F       0.69      0.69      0.69       281
          R       0.44      0.20      0.28       122

avg / total       0.56      0.57      0.55       592

12/10/2017 02:25:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:04 [INFO] exp_shallowmodel: 
[[  1   4   9   6]
 [  1 116  40  12]
 [  0  72 195  14]
 [  1  58  38  25]]
12/10/2017 02:25:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 02:25:04 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:25:04 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:25:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:12 [INFO] exp_shallowmodel: train time: 7.780s
12/10/2017 02:25:12 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:25:12 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 02:25:12 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 02:25:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.48      0.66      0.56       169
          F       0.66      0.73      0.69       281
          R       0.33      0.14      0.20       122

avg / total       0.55      0.56      0.53       592

12/10/2017 02:25:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:12 [INFO] exp_shallowmodel: 
[[  1   8   4   7]
 [  0 111  48  10]
 [  0  59 204  18]
 [  0  51  54  17]]
12/10/2017 02:25:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 02:25:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:25:12 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:25:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:20 [INFO] exp_shallowmodel: train time: 8.262s
12/10/2017 02:25:20 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:25:20 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 02:25:20 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 02:25:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.45      0.69      0.54       169
          F       0.70      0.74      0.72       281
          R       0.55      0.15      0.23       122

avg / total       0.58      0.58      0.55       592

12/10/2017 02:25:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:20 [INFO] exp_shallowmodel: 
[[  1  11   7   1]
 [  1 116  43   9]
 [  2  66 208   5]
 [  1  64  39  18]]
12/10/2017 02:25:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 02:25:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:25:20 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:25:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:30 [INFO] exp_shallowmodel: train time: 10.194s
12/10/2017 02:25:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:25:30 [INFO] exp_shallowmodel: accuracy:   0.591
12/10/2017 02:25:30 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 02:25:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.75      0.60       169
          F       0.69      0.72      0.70       281
          R       0.55      0.18      0.27       122

avg / total       0.58      0.59      0.56       592

12/10/2017 02:25:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:30 [INFO] exp_shallowmodel: 
[[  0   4  12   4]
 [  2 127  35   5]
 [  1  70 201   9]
 [  1  54  45  22]]
12/10/2017 02:25:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 02:25:30 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:25:30 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:25:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:38 [INFO] exp_shallowmodel: train time: 8.003s
12/10/2017 02:25:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:25:38 [INFO] exp_shallowmodel: accuracy:   0.529
12/10/2017 02:25:38 [INFO] exp_shallowmodel: f1_score:   0.351
12/10/2017 02:25:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.42      0.63      0.50       169
          F       0.65      0.69      0.67       281
          R       0.31      0.09      0.14       122

avg / total       0.51      0.53      0.49       592

12/10/2017 02:25:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:38 [INFO] exp_shallowmodel: 
[[  1   8  10   1]
 [  0 107  49  13]
 [  0  76 194  11]
 [  1  64  46  11]]
12/10/2017 02:25:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 02:25:39 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:25:39 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:25:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:59 [INFO] exp_shallowmodel: train time: 20.161s
12/10/2017 02:25:59 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:25:59 [INFO] exp_shallowmodel: accuracy:   0.544
12/10/2017 02:25:59 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 02:25:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.64      0.53       169
          F       0.63      0.68      0.65       281
          R       0.51      0.17      0.26       122

avg / total       0.53      0.54      0.51       592

12/10/2017 02:25:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:59 [INFO] exp_shallowmodel: 
[[  0   6  13   1]
 [  1 109  51   8]
 [  0  78 192  11]
 [  1  50  50  21]]
12/10/2017 02:25:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 02:25:59 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:25:59 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:25:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:06 [INFO] exp_shallowmodel: train time: 7.567s
12/10/2017 02:26:06 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:26:06 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 02:26:06 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 02:26:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.45      0.70      0.55       169
          F       0.69      0.69      0.69       281
          R       0.53      0.21      0.30       122

avg / total       0.59      0.57      0.55       592

12/10/2017 02:26:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:06 [INFO] exp_shallowmodel: 
[[  1   6  10   3]
 [  0 118  39  12]
 [  1  77 195   8]
 [  0  59  37  26]]
12/10/2017 02:26:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 02:26:06 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:26:06 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:26:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:16 [INFO] exp_shallowmodel: train time: 9.632s
12/10/2017 02:26:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:26:16 [INFO] exp_shallowmodel: accuracy:   0.561
12/10/2017 02:26:16 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 02:26:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.46      0.73      0.56       169
          F       0.68      0.69      0.69       281
          R       0.37      0.11      0.17       122

avg / total       0.56      0.56      0.52       592

12/10/2017 02:26:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:16 [INFO] exp_shallowmodel: 
[[  1   8   9   2]
 [  0 123  36  10]
 [  0  76 195  10]
 [  0  63  46  13]]
12/10/2017 02:26:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 02:26:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:26:16 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:26:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:21 [INFO] exp_shallowmodel: train time: 5.181s
12/10/2017 02:26:21 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:26:21 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 02:26:21 [INFO] exp_shallowmodel: f1_score:   0.366
12/10/2017 02:26:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.43      0.66      0.52       169
          F       0.68      0.68      0.68       281
          R       0.49      0.18      0.26       122

avg / total       0.54      0.55      0.53       592

12/10/2017 02:26:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:21 [INFO] exp_shallowmodel: 
[[  0  10   6   4]
 [  1 112  46  10]
 [  0  80 192   9]
 [  0  60  40  22]]
12/10/2017 02:26:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 02:26:21 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:26:21 [INFO] exp_shallowmodel: #(feature) = 395
12/10/2017 02:26:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:29 [INFO] exp_shallowmodel: train time: 7.619s
12/10/2017 02:26:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:26:29 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:26:29 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:26:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.07        28
          C       0.46      0.75      0.57       172
          F       0.70      0.69      0.70       283
          R       0.48      0.17      0.25       123

avg / total       0.58      0.57      0.54       606

12/10/2017 02:26:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:29 [INFO] exp_shallowmodel: 
[[  1  12  10   5]
 [  1 129  34   8]
 [  0  77 196  10]
 [  0  62  40  21]]
12/10/2017 02:26:34 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:26:34 [INFO] task_runner: context=current, feature=4-syntactic
12/10/2017 02:26:34 [INFO] task_runner: retained feature numbers=[7]
12/10/2017 02:26:34 [INFO] task_runner: #(data)=3530
12/10/2017 02:26:34 [INFO] task_runner: #(feature)=1214
12/10/2017 02:26:34 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:26:34 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 02:26:34 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:26:34 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:26:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:43 [INFO] exp_shallowmodel: train time: 8.594s
12/10/2017 02:26:43 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:26:43 [INFO] exp_shallowmodel: accuracy:   0.736
12/10/2017 02:26:43 [INFO] exp_shallowmodel: f1_score:   0.346
12/10/2017 02:26:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.40      0.07      0.12        27
          F       0.76      0.98      0.85       250
          R       0.57      0.23      0.33        52

avg / total       0.67      0.74      0.67       352

12/10/2017 02:26:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:43 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  1   2  24   0]
 [  1   0 244   5]
 [  0   2  38  12]]
12/10/2017 02:26:43 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 02:26:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:26:43 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:26:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:52 [INFO] exp_shallowmodel: train time: 8.944s
12/10/2017 02:26:52 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:26:52 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:26:52 [INFO] exp_shallowmodel: f1_score:   0.304
12/10/2017 02:26:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.75      0.96      0.84       250
          R       0.61      0.27      0.37        52

avg / total       0.62      0.72      0.65       352

12/10/2017 02:26:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:52 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  1   0  25   1]
 [  0   3 241   6]
 [  0   2  36  14]]
12/10/2017 02:26:52 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 02:26:52 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:26:52 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:26:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:59 [INFO] exp_shallowmodel: train time: 7.169s
12/10/2017 02:26:59 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:26:59 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:26:59 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 02:26:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.00      0.00      0.00        27
          F       0.75      0.95      0.84       250
          R       0.50      0.21      0.30        52

avg / total       0.62      0.71      0.65       352

12/10/2017 02:26:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:59 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  1   0  23   3]
 [  3   2 238   7]
 [  4   0  37  11]]
12/10/2017 02:26:59 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 02:26:59 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:26:59 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:26:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:27:23 [INFO] exp_shallowmodel: train time: 23.388s
12/10/2017 02:27:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:27:23 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:27:23 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:27:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:27:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.50      0.04      0.07        27
          F       0.74      0.96      0.84       250
          R       0.33      0.13      0.19        52

avg / total       0.63      0.71      0.63       352

12/10/2017 02:27:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:27:23 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   1  22   4]
 [  1   0 241   8]
 [  3   1  41   7]]
12/10/2017 02:27:23 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 02:27:23 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:27:23 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:27:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:27:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:27:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:27:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:27:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:27:31 [INFO] exp_shallowmodel: train time: 8.213s
12/10/2017 02:27:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:27:31 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:27:31 [INFO] exp_shallowmodel: f1_score:   0.252
12/10/2017 02:27:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:27:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.74      0.96      0.84       250
          R       0.33      0.12      0.17        52

avg / total       0.57      0.70      0.62       352

12/10/2017 02:27:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:27:31 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   0  22   5]
 [  2   3 241   4]
 [  1   1  44   6]]
12/10/2017 02:27:31 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 02:27:31 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:27:31 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:27:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:27:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:27:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:27:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:27:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:27:39 [INFO] exp_shallowmodel: train time: 7.691s
12/10/2017 02:27:39 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:27:39 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:27:39 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 02:27:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:27:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       1.00      0.07      0.14        27
          F       0.76      0.97      0.85       250
          R       0.50      0.25      0.33        52

avg / total       0.69      0.73      0.66       352

12/10/2017 02:27:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:27:39 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  1   2  20   4]
 [  2   0 242   6]
 [  1   0  38  13]]
12/10/2017 02:27:39 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 02:27:39 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:27:39 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:27:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:27:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:27:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:27:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:27:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:27:49 [INFO] exp_shallowmodel: train time: 10.333s
12/10/2017 02:27:49 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:27:49 [INFO] exp_shallowmodel: accuracy:   0.739
12/10/2017 02:27:49 [INFO] exp_shallowmodel: f1_score:   0.341
12/10/2017 02:27:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:27:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.25      0.04      0.06        27
          F       0.76      0.98      0.86       250
          R       0.58      0.27      0.37        52

avg / total       0.66      0.74      0.67       352

12/10/2017 02:27:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:27:49 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  1   1  20   5]
 [  1   2 244   3]
 [  1   1  36  14]]
12/10/2017 02:27:50 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 02:27:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:27:50 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:27:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:27:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:27:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:27:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:27:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:27:57 [INFO] exp_shallowmodel: train time: 7.516s
12/10/2017 02:27:57 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:27:57 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:27:57 [INFO] exp_shallowmodel: f1_score:   0.359
12/10/2017 02:27:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:27:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.13      0.21        23
          C       0.40      0.07      0.12        27
          F       0.75      0.97      0.84       250
          R       0.47      0.17      0.25        52

avg / total       0.67      0.73      0.66       352

12/10/2017 02:27:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:27:57 [INFO] exp_shallowmodel: 
[[  3   0  19   1]
 [  0   2  20   5]
 [  1   3 242   4]
 [  1   0  42   9]]
12/10/2017 02:27:57 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 02:27:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:27:57 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:27:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:27:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:27:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:27:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:27:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:08 [INFO] exp_shallowmodel: train time: 10.658s
12/10/2017 02:28:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:28:08 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:28:08 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 02:28:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.17      0.04      0.06        27
          F       0.76      0.96      0.85       250
          R       0.43      0.23      0.30        52

avg / total       0.62      0.72      0.65       352

12/10/2017 02:28:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:08 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   1  22   4]
 [  0   1 240   9]
 [  2   4  34  12]]
12/10/2017 02:28:08 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 02:28:08 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:28:08 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:28:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:16 [INFO] exp_shallowmodel: train time: 8.190s
12/10/2017 02:28:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:28:16 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:28:16 [INFO] exp_shallowmodel: f1_score:   0.271
12/10/2017 02:28:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        25
          C       0.00      0.00      0.00        27
          F       0.72      0.98      0.83       251
          R       0.44      0.12      0.19        59

avg / total       0.59      0.70      0.61       362

12/10/2017 02:28:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:16 [INFO] exp_shallowmodel: 
[[  1   0  22   2]
 [  0   0  24   3]
 [  2   0 245   4]
 [  1   1  50   7]]
12/10/2017 02:28:16 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 02:28:16 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:28:16 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:28:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:22 [INFO] exp_shallowmodel: train time: 5.635s
12/10/2017 02:28:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:28:22 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:28:22 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 02:28:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.33      0.04      0.07        27
          F       0.75      0.96      0.84       250
          R       0.52      0.27      0.35        52

avg / total       0.67      0.73      0.66       352

12/10/2017 02:28:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:22 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   1  21   5]
 [  1   1 240   8]
 [  0   1  37  14]]
12/10/2017 02:28:22 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 02:28:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:28:22 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:28:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:30 [INFO] exp_shallowmodel: train time: 8.235s
12/10/2017 02:28:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:28:30 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:28:30 [INFO] exp_shallowmodel: f1_score:   0.281
12/10/2017 02:28:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.73      0.95      0.83       250
          R       0.38      0.15      0.22        52

avg / total       0.60      0.70      0.62       352

12/10/2017 02:28:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:30 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  1   0  22   4]
 [  1   2 238   9]
 [  0   0  44   8]]
12/10/2017 02:28:30 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 02:28:30 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:28:30 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:28:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:41 [INFO] exp_shallowmodel: train time: 10.792s
12/10/2017 02:28:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:28:41 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:28:41 [INFO] exp_shallowmodel: f1_score:   0.297
12/10/2017 02:28:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.22      0.07      0.11        27
          F       0.75      0.97      0.84       250
          R       0.50      0.15      0.24        52

avg / total       0.62      0.72      0.64       352

12/10/2017 02:28:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:41 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  1   2  22   2]
 [  2   2 242   4]
 [  0   5  39   8]]
12/10/2017 02:28:41 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 02:28:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:28:41 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:28:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:49 [INFO] exp_shallowmodel: train time: 7.982s
12/10/2017 02:28:49 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:28:49 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:28:49 [INFO] exp_shallowmodel: f1_score:   0.328
12/10/2017 02:28:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.09      0.16        23
          C       0.14      0.04      0.06        27
          F       0.75      0.97      0.84       250
          R       0.45      0.17      0.25        52

avg / total       0.67      0.72      0.65       352

12/10/2017 02:28:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:49 [INFO] exp_shallowmodel: 
[[  2   1  17   3]
 [  0   1  23   3]
 [  0   3 242   5]
 [  0   2  41   9]]
12/10/2017 02:28:49 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 02:28:49 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:28:49 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:28:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:56 [INFO] exp_shallowmodel: train time: 6.743s
12/10/2017 02:28:56 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:28:56 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:28:56 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 02:28:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.17      0.04      0.06        27
          F       0.75      0.97      0.85       250
          R       0.50      0.17      0.26        52

avg / total       0.62      0.72      0.65       352

12/10/2017 02:28:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:56 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   1  21   5]
 [  2   2 243   3]
 [  3   3  37   9]]
12/10/2017 02:28:56 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 02:28:56 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:28:56 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:28:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:29:05 [INFO] exp_shallowmodel: train time: 9.156s
12/10/2017 02:29:05 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:29:05 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:29:05 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:29:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:29:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.00      0.00      0.00        27
          F       0.75      0.97      0.85       250
          R       0.47      0.17      0.25        52

avg / total       0.62      0.72      0.64       352

12/10/2017 02:29:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:29:05 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   0  25   2]
 [  1   2 242   5]
 [  3   3  37   9]]
12/10/2017 02:29:06 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 02:29:06 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:29:06 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:29:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:29:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:29:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:29:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:29:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:29:15 [INFO] exp_shallowmodel: train time: 9.709s
12/10/2017 02:29:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:29:15 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:29:15 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 02:29:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:29:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       1.00      0.04      0.07        27
          F       0.76      0.95      0.84       250
          R       0.52      0.33      0.40        52

avg / total       0.69      0.72      0.66       352

12/10/2017 02:29:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:29:15 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   1  23   3]
 [  3   0 237  10]
 [  3   0  32  17]]
12/10/2017 02:29:15 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 02:29:15 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:29:15 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:29:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:29:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:29:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:29:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:29:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:29:25 [INFO] exp_shallowmodel: train time: 9.576s
12/10/2017 02:29:25 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:29:25 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:29:25 [INFO] exp_shallowmodel: f1_score:   0.297
12/10/2017 02:29:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:29:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.00      0.00      0.00        27
          F       0.74      0.97      0.84       250
          R       0.48      0.19      0.27        52

avg / total       0.61      0.72      0.64       352

12/10/2017 02:29:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:29:25 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  2   0  23   2]
 [  1   0 242   7]
 [  0   0  42  10]]
12/10/2017 02:29:25 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 02:29:25 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:29:25 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:29:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:29:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:29:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:29:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:29:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:29:31 [INFO] exp_shallowmodel: train time: 6.420s
12/10/2017 02:29:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:29:31 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:29:31 [INFO] exp_shallowmodel: f1_score:   0.283
12/10/2017 02:29:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:29:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.04      0.07        27
          F       0.75      0.98      0.85       250
          R       0.38      0.15      0.22        52

avg / total       0.61      0.72      0.64       352

12/10/2017 02:29:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:29:31 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  0   1  20   6]
 [  0   1 245   4]
 [  0   0  44   8]]
12/10/2017 02:29:32 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 02:29:32 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:29:32 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:29:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:29:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:29:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:29:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:29:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:29:42 [INFO] exp_shallowmodel: train time: 10.579s
12/10/2017 02:29:42 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:29:42 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:29:42 [INFO] exp_shallowmodel: f1_score:   0.286
12/10/2017 02:29:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:29:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        25
          C       0.00      0.00      0.00        27
          F       0.73      0.96      0.83       251
          R       0.45      0.17      0.25        59

avg / total       0.60      0.70      0.62       362

12/10/2017 02:29:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:29:42 [INFO] exp_shallowmodel: 
[[  1   0  21   3]
 [  0   0  24   3]
 [  0   4 241   6]
 [  4   2  43  10]]
12/10/2017 02:29:42 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 02:29:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:29:42 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:29:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:29:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:29:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:29:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:29:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:29:50 [INFO] exp_shallowmodel: train time: 7.784s
12/10/2017 02:29:50 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:29:50 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:29:50 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 02:29:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:29:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.07      0.11        27
          F       0.75      0.96      0.84       250
          R       0.61      0.27      0.37        52

avg / total       0.64      0.72      0.66       352

12/10/2017 02:29:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:29:50 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  1   2  22   2]
 [  1   3 239   7]
 [  1   3  34  14]]
12/10/2017 02:29:50 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 02:29:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:29:50 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:29:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:29:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:29:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:29:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:29:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:29:58 [INFO] exp_shallowmodel: train time: 7.968s
12/10/2017 02:29:58 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:29:58 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:29:58 [INFO] exp_shallowmodel: f1_score:   0.287
12/10/2017 02:29:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:29:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.20      0.04      0.06        27
          F       0.73      0.98      0.84       250
          R       0.62      0.15      0.25        52

avg / total       0.63      0.72      0.64       352

12/10/2017 02:29:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:29:58 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   1  24   2]
 [  0   3 244   3]
 [  2   1  41   8]]
12/10/2017 02:29:58 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 02:29:58 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:29:58 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:29:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:29:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:29:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:29:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:29:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:30:05 [INFO] exp_shallowmodel: train time: 6.706s
12/10/2017 02:30:05 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:30:05 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 02:30:05 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 02:30:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:30:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.25      0.04      0.06        27
          F       0.77      0.98      0.86       250
          R       0.56      0.29      0.38        52

avg / total       0.67      0.74      0.68       352

12/10/2017 02:30:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:30:05 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  1   1  21   4]
 [  0   1 244   5]
 [  1   1  35  15]]
12/10/2017 02:30:05 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 02:30:05 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:30:05 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:30:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:30:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:30:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:30:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:30:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:30:13 [INFO] exp_shallowmodel: train time: 7.496s
12/10/2017 02:30:13 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:30:13 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:30:13 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 02:30:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:30:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.74      0.96      0.84       250
          R       0.40      0.19      0.26        52

avg / total       0.59      0.71      0.63       352

12/10/2017 02:30:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:30:13 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   0  23   4]
 [  1   0 241   8]
 [  1   0  41  10]]
12/10/2017 02:30:13 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 02:30:13 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:30:13 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:30:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:30:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:30:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:30:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:30:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:30:22 [INFO] exp_shallowmodel: train time: 8.825s
12/10/2017 02:30:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:30:22 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:30:22 [INFO] exp_shallowmodel: f1_score:   0.328
12/10/2017 02:30:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:30:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.33      0.04      0.07        27
          F       0.76      0.95      0.84       250
          R       0.40      0.27      0.32        52

avg / total       0.66      0.72      0.66       352

12/10/2017 02:30:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:30:22 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   1  20   6]
 [  0   0 237  13]
 [  1   2  35  14]]
12/10/2017 02:30:22 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 02:30:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:30:22 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:30:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:30:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:30:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:30:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:30:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:30:30 [INFO] exp_shallowmodel: train time: 8.091s
12/10/2017 02:30:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:30:30 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:30:30 [INFO] exp_shallowmodel: f1_score:   0.294
12/10/2017 02:30:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:30:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.74      0.97      0.84       250
          R       0.50      0.17      0.26        52

avg / total       0.63      0.72      0.64       352

12/10/2017 02:30:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:30:30 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   0  25   2]
 [  0   2 242   6]
 [  1   3  39   9]]
12/10/2017 02:30:30 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 02:30:30 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:30:30 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:30:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:30:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:30:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:30:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:30:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:30:44 [INFO] exp_shallowmodel: train time: 14.541s
12/10/2017 02:30:44 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:30:44 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 02:30:44 [INFO] exp_shallowmodel: f1_score:   0.269
12/10/2017 02:30:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:30:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.74      0.94      0.83       250
          R       0.36      0.19      0.25        52

avg / total       0.58      0.69      0.62       352

12/10/2017 02:30:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:30:44 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   0  23   4]
 [  4   1 234  11]
 [  1   2  39  10]]
12/10/2017 02:30:45 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 02:30:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:30:45 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:30:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:30:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:30:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:30:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:30:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:30:53 [INFO] exp_shallowmodel: train time: 8.413s
12/10/2017 02:30:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:30:53 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:30:53 [INFO] exp_shallowmodel: f1_score:   0.282
12/10/2017 02:30:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:30:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.04      0.07        27
          F       0.74      0.97      0.84       250
          R       0.38      0.15      0.22        52

avg / total       0.62      0.71      0.63       352

12/10/2017 02:30:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:30:53 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  0   1  22   4]
 [  2   0 242   6]
 [  0   0  44   8]]
12/10/2017 02:30:53 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 02:30:53 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:30:53 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:30:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:30:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:30:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:30:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:30:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:31:11 [INFO] exp_shallowmodel: train time: 17.574s
12/10/2017 02:31:11 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:31:11 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:31:11 [INFO] exp_shallowmodel: f1_score:   0.250
12/10/2017 02:31:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:31:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.74      0.96      0.84       250
          R       0.27      0.12      0.16        52

avg / total       0.57      0.70      0.62       352

12/10/2017 02:31:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:31:11 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  2   0  19   6]
 [  2   2 240   6]
 [  1   0  45   6]]
12/10/2017 02:31:11 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 02:31:11 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:31:11 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:31:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:31:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:31:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:31:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:31:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:31:21 [INFO] exp_shallowmodel: train time: 10.022s
12/10/2017 02:31:21 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:31:21 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:31:21 [INFO] exp_shallowmodel: f1_score:   0.353
12/10/2017 02:31:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:31:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.12      0.21        25
          C       0.33      0.04      0.07        27
          F       0.74      0.98      0.84       251
          R       0.55      0.20      0.30        59

avg / total       0.68      0.72      0.65       362

12/10/2017 02:31:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:31:21 [INFO] exp_shallowmodel: 
[[  3   0  20   2]
 [  0   1  22   4]
 [  0   1 246   4]
 [  1   1  45  12]]
12/10/2017 02:31:21 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 02:31:21 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:31:21 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:31:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:31:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:31:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:31:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:31:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:31:28 [INFO] exp_shallowmodel: train time: 6.965s
12/10/2017 02:31:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:31:28 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:31:28 [INFO] exp_shallowmodel: f1_score:   0.286
12/10/2017 02:31:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:31:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.17      0.04      0.06        27
          F       0.74      0.96      0.84       250
          R       0.43      0.17      0.25        52

avg / total       0.60      0.71      0.64       352

12/10/2017 02:31:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:31:28 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  1   1  21   4]
 [  1   3 239   7]
 [  2   2  39   9]]
12/10/2017 02:31:28 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 02:31:28 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:31:28 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:31:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:31:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:31:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:31:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:31:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:31:36 [INFO] exp_shallowmodel: train time: 7.951s
12/10/2017 02:31:36 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:31:36 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:31:36 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 02:31:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:31:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.76      0.97      0.85       250
          R       0.54      0.29      0.37        52

avg / total       0.62      0.73      0.66       352

12/10/2017 02:31:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:31:36 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  0   0  23   4]
 [  1   2 242   5]
 [  0   1  36  15]]
12/10/2017 02:31:36 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 02:31:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:31:36 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:31:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:31:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:31:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:31:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:31:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:31:43 [INFO] exp_shallowmodel: train time: 7.067s
12/10/2017 02:31:43 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:31:43 [INFO] exp_shallowmodel: accuracy:   0.739
12/10/2017 02:31:43 [INFO] exp_shallowmodel: f1_score:   0.335
12/10/2017 02:31:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:31:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.77      0.97      0.86       250
          R       0.55      0.33      0.41        52

avg / total       0.65      0.74      0.67       352

12/10/2017 02:31:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:31:43 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   0  22   5]
 [  0   1 242   7]
 [  2   1  32  17]]
12/10/2017 02:31:43 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 02:31:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:31:43 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:31:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:31:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:31:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:31:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:31:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:31:54 [INFO] exp_shallowmodel: train time: 10.325s
12/10/2017 02:31:54 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:31:54 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 02:31:54 [INFO] exp_shallowmodel: f1_score:   0.251
12/10/2017 02:31:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:31:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.17      0.04      0.06        27
          F       0.73      0.95      0.82       250
          R       0.27      0.08      0.12        52

avg / total       0.57      0.69      0.61       352

12/10/2017 02:31:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:31:54 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  0   1  25   1]
 [  2   4 238   6]
 [  1   1  46   4]]
12/10/2017 02:31:54 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 02:31:54 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:31:54 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:31:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:31:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:31:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:31:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:31:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:32:08 [INFO] exp_shallowmodel: train time: 14.529s
12/10/2017 02:32:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:32:08 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:32:08 [INFO] exp_shallowmodel: f1_score:   0.300
12/10/2017 02:32:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:32:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.04      0.07        27
          F       0.74      0.98      0.84       250
          R       0.56      0.19      0.29        52

avg / total       0.65      0.73      0.65       352

12/10/2017 02:32:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:32:08 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   1  23   3]
 [  1   1 245   3]
 [  0   0  42  10]]
12/10/2017 02:32:08 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 02:32:08 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:32:08 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:32:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:32:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:32:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:32:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:32:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:32:18 [INFO] exp_shallowmodel: train time: 9.279s
12/10/2017 02:32:18 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:32:18 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:32:18 [INFO] exp_shallowmodel: f1_score:   0.294
12/10/2017 02:32:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:32:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.09      0.14        23
          C       0.00      0.00      0.00        27
          F       0.73      0.96      0.83       250
          R       0.39      0.13      0.20        52

avg / total       0.61      0.71      0.63       352

12/10/2017 02:32:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:32:18 [INFO] exp_shallowmodel: 
[[  2   0  21   0]
 [  1   0  22   4]
 [  1   1 241   7]
 [  1   0  44   7]]
12/10/2017 02:32:18 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 02:32:18 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:32:18 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:32:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:32:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:32:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:32:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:32:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:32:28 [INFO] exp_shallowmodel: train time: 9.956s
12/10/2017 02:32:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:32:28 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:32:28 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 02:32:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:32:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.74      0.96      0.84       250
          R       0.41      0.17      0.24        52

avg / total       0.65      0.71      0.63       352

12/10/2017 02:32:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:32:28 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   0  23   4]
 [  0   0 241   9]
 [  0   2  41   9]]
12/10/2017 02:32:28 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 02:32:28 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:32:28 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:32:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:32:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:32:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:32:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:32:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:32:36 [INFO] exp_shallowmodel: train time: 8.003s
12/10/2017 02:32:36 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:32:36 [INFO] exp_shallowmodel: accuracy:   0.733
12/10/2017 02:32:36 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 02:32:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:32:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.13      0.23        23
          C       0.33      0.07      0.12        27
          F       0.75      0.97      0.85       250
          R       0.48      0.19      0.27        52

avg / total       0.70      0.73      0.67       352

12/10/2017 02:32:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:32:36 [INFO] exp_shallowmodel: 
[[  3   0  19   1]
 [  0   2  20   5]
 [  0   2 243   5]
 [  0   2  40  10]]
12/10/2017 02:32:36 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 02:32:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:32:36 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:32:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:32:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:32:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:32:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:32:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:32:59 [INFO] exp_shallowmodel: train time: 23.313s
12/10/2017 02:32:59 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:32:59 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:32:59 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 02:32:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:32:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.07        23
          C       0.00      0.00      0.00        27
          F       0.75      0.95      0.84       250
          R       0.40      0.19      0.26        52

avg / total       0.60      0.71      0.64       352

12/10/2017 02:32:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:32:59 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  0   0  25   2]
 [  2   1 238   9]
 [  3   0  39  10]]
12/10/2017 02:32:59 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 02:32:59 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:32:59 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:32:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:32:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:32:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:32:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:32:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:07 [INFO] exp_shallowmodel: train time: 7.879s
12/10/2017 02:33:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:33:07 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:33:07 [INFO] exp_shallowmodel: f1_score:   0.286
12/10/2017 02:33:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.07        25
          C       0.00      0.00      0.00        27
          F       0.73      0.98      0.83       251
          R       0.53      0.15      0.24        59

avg / total       0.61      0.71      0.62       362

12/10/2017 02:33:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:07 [INFO] exp_shallowmodel: 
[[  1   1  21   2]
 [  1   0  23   3]
 [  1   1 246   3]
 [  0   1  49   9]]
12/10/2017 02:33:07 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 02:33:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:33:07 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:33:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:13 [INFO] exp_shallowmodel: train time: 5.972s
12/10/2017 02:33:13 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:33:13 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:33:13 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 02:33:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.75      0.97      0.85       250
          R       0.42      0.21      0.28        52

avg / total       0.62      0.72      0.65       352

12/10/2017 02:33:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:13 [INFO] exp_shallowmodel: 
[[  1   0  18   4]
 [  1   0  22   4]
 [  0   1 242   7]
 [  1   1  39  11]]
12/10/2017 02:33:14 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 02:33:14 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:33:14 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:33:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:23 [INFO] exp_shallowmodel: train time: 9.094s
12/10/2017 02:33:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:33:23 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:33:23 [INFO] exp_shallowmodel: f1_score:   0.265
12/10/2017 02:33:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.74      0.97      0.84       250
          R       0.42      0.15      0.23        52

avg / total       0.58      0.71      0.63       352

12/10/2017 02:33:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:23 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  1   0  23   3]
 [  2   1 242   5]
 [  0   0  44   8]]
12/10/2017 02:33:23 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 02:33:23 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:33:23 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:33:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:30 [INFO] exp_shallowmodel: train time: 7.701s
12/10/2017 02:33:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:33:30 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 02:33:30 [INFO] exp_shallowmodel: f1_score:   0.321
12/10/2017 02:33:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.77      0.99      0.87       250
          R       0.52      0.25      0.34        52

avg / total       0.65      0.74      0.67       352

12/10/2017 02:33:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:30 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   0  21   6]
 [  0   0 247   3]
 [  2   5  32  13]]
12/10/2017 02:33:31 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 02:33:31 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:33:31 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:33:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:38 [INFO] exp_shallowmodel: train time: 7.911s
12/10/2017 02:33:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:33:38 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:33:38 [INFO] exp_shallowmodel: f1_score:   0.324
12/10/2017 02:33:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.23      0.11      0.15        27
          F       0.75      0.96      0.84       250
          R       0.40      0.15      0.22        52

avg / total       0.64      0.71      0.65       352

12/10/2017 02:33:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:38 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   3  22   2]
 [  1   3 239   7]
 [  0   6  38   8]]
12/10/2017 02:33:39 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 02:33:39 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:33:39 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:33:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:47 [INFO] exp_shallowmodel: train time: 8.885s
12/10/2017 02:33:47 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:33:47 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:33:47 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 02:33:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.00      0.00      0.00        27
          F       0.75      0.97      0.85       250
          R       0.59      0.25      0.35        52

avg / total       0.64      0.73      0.66       352

12/10/2017 02:33:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:47 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  0   0  24   3]
 [  2   1 242   5]
 [  2   2  35  13]]
12/10/2017 02:33:48 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 02:33:48 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:33:48 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:33:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:34:07 [INFO] exp_shallowmodel: train time: 19.721s
12/10/2017 02:34:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:34:07 [INFO] exp_shallowmodel: accuracy:   0.733
12/10/2017 02:34:07 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 02:34:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:34:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.09      0.14        23
          C       0.67      0.07      0.13        27
          F       0.76      0.98      0.85       250
          R       0.45      0.17      0.25        52

avg / total       0.68      0.73      0.66       352

12/10/2017 02:34:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:34:07 [INFO] exp_shallowmodel: 
[[  2   0  19   2]
 [  0   2  18   7]
 [  2   1 245   2]
 [  1   0  42   9]]
12/10/2017 02:34:07 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 02:34:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:34:07 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:34:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:34:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:34:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:34:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:34:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:34:22 [INFO] exp_shallowmodel: train time: 14.685s
12/10/2017 02:34:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:34:22 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:34:22 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 02:34:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:34:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.75      0.97      0.84       250
          R       0.52      0.23      0.32        52

avg / total       0.61      0.72      0.65       352

12/10/2017 02:34:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:34:22 [INFO] exp_shallowmodel: 
[[  0   1  18   4]
 [  0   0  25   2]
 [  1   2 242   5]
 [  1   0  39  12]]
12/10/2017 02:34:22 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 02:34:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:34:22 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:34:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:34:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:34:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:34:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:34:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:34:31 [INFO] exp_shallowmodel: train time: 8.786s
12/10/2017 02:34:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:34:31 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:34:31 [INFO] exp_shallowmodel: f1_score:   0.301
12/10/2017 02:34:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:34:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.00      0.00      0.00        27
          F       0.75      0.94      0.84       250
          R       0.40      0.23      0.29        52

avg / total       0.61      0.71      0.64       352

12/10/2017 02:34:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:34:31 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   0  21   6]
 [  1   2 236  11]
 [  2   1  37  12]]
12/10/2017 02:34:31 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 02:34:31 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:34:31 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:34:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:34:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:34:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:34:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:34:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:34:40 [INFO] exp_shallowmodel: train time: 8.672s
12/10/2017 02:34:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:34:40 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:34:40 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 02:34:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:34:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.33      0.07      0.12        27
          F       0.74      0.96      0.84       250
          R       0.40      0.15      0.22        52

avg / total       0.68      0.72      0.64       352

12/10/2017 02:34:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:34:40 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   2  22   3]
 [  0   3 241   6]
 [  0   1  43   8]]
12/10/2017 02:34:40 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 02:34:40 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:34:40 [INFO] exp_shallowmodel: #(feature) = 1214
12/10/2017 02:34:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:34:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:34:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:34:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:34:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:34:45 [INFO] exp_shallowmodel: train time: 4.635s
12/10/2017 02:34:45 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:34:45 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:34:45 [INFO] exp_shallowmodel: f1_score:   0.292
12/10/2017 02:34:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:34:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.00      0.00      0.00        27
          F       0.73      0.97      0.84       251
          R       0.56      0.24      0.33        59

avg / total       0.60      0.71      0.63       362

12/10/2017 02:34:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:34:45 [INFO] exp_shallowmodel: 
[[  0   0  23   2]
 [  2   0  22   3]
 [  1   1 243   6]
 [  1   1  43  14]]
12/10/2017 02:34:50 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:34:50 [INFO] task_runner: context=current, feature=4-syntactic
12/10/2017 02:34:50 [INFO] task_runner: retained feature numbers=[7]
12/10/2017 02:34:50 [INFO] task_runner: #(data)=5241
12/10/2017 02:34:50 [INFO] task_runner: #(feature)=1352
12/10/2017 02:34:50 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:34:51 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 02:34:51 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:34:51 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:34:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:34:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:34:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:34:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:34:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:35:16 [INFO] exp_shallowmodel: train time: 25.092s
12/10/2017 02:35:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:35:16 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:35:16 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 02:35:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:35:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.17      0.26        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.27      0.07      0.11        55

avg / total       0.69      0.76      0.70       522

12/10/2017 02:35:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:35:16 [INFO] exp_shallowmodel: 
[[ 10   0  46   3]
 [  1   0  11   0]
 [  3   0 385   8]
 [  4   0  47   4]]
12/10/2017 02:35:16 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 02:35:16 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:35:16 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:35:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:35:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:35:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:35:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:35:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:35:44 [INFO] exp_shallowmodel: train time: 27.623s
12/10/2017 02:35:44 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:35:44 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:35:44 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:35:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:35:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.15      0.21        59
          C       0.00      0.00      0.00        12
          F       0.80      0.96      0.87       396
          R       0.20      0.05      0.09        55

avg / total       0.67      0.75      0.69       522

12/10/2017 02:35:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:35:44 [INFO] exp_shallowmodel: 
[[  9   0  45   5]
 [  2   0   9   1]
 [  7   2 381   6]
 [  7   1  44   3]]
12/10/2017 02:35:44 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 02:35:44 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:35:44 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:35:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:35:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:35:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:35:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:35:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:36:14 [INFO] exp_shallowmodel: train time: 29.775s
12/10/2017 02:36:14 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:36:14 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:36:14 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 02:36:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:36:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.08      0.13        59
          C       0.50      0.08      0.14        12
          F       0.77      0.96      0.86       396
          R       0.42      0.09      0.15        55

avg / total       0.68      0.75      0.68       522

12/10/2017 02:36:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:36:14 [INFO] exp_shallowmodel: 
[[  5   0  53   1]
 [  0   1  11   0]
 [  9   1 380   6]
 [  2   0  48   5]]
12/10/2017 02:36:14 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 02:36:14 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:36:14 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:36:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:36:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:36:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:36:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:36:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:37:06 [INFO] exp_shallowmodel: train time: 52.235s
12/10/2017 02:37:06 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:37:06 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:37:06 [INFO] exp_shallowmodel: f1_score:   0.305
12/10/2017 02:37:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:37:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.10      0.15        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.50      0.13      0.20        55

avg / total       0.68      0.76      0.70       522

12/10/2017 02:37:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:37:06 [INFO] exp_shallowmodel: 
[[  6   0  49   4]
 [  0   0  12   0]
 [ 10   1 382   3]
 [  6   0  42   7]]
12/10/2017 02:37:06 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 02:37:06 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:37:06 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:37:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:37:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:37:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:37:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:37:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:37:25 [INFO] exp_shallowmodel: train time: 18.514s
12/10/2017 02:37:25 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:37:25 [INFO] exp_shallowmodel: accuracy:   0.745
12/10/2017 02:37:25 [INFO] exp_shallowmodel: f1_score:   0.292
12/10/2017 02:37:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:37:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.12      0.17        59
          C       0.00      0.00      0.00        12
          F       0.79      0.95      0.86       396
          R       0.28      0.09      0.14        55

avg / total       0.66      0.75      0.69       522

12/10/2017 02:37:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:37:25 [INFO] exp_shallowmodel: 
[[  7   2  46   4]
 [  0   0  10   2]
 [ 11   1 377   7]
 [  6   0  44   5]]
12/10/2017 02:37:25 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 02:37:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:37:25 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:37:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:37:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:37:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:37:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:37:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:38:05 [INFO] exp_shallowmodel: train time: 40.312s
12/10/2017 02:38:05 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:38:05 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 02:38:05 [INFO] exp_shallowmodel: f1_score:   0.350
12/10/2017 02:38:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:38:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.12      0.18        59
          C       0.50      0.08      0.14        12
          F       0.79      0.98      0.88       396
          R       0.47      0.13      0.20        55

avg / total       0.71      0.77      0.71       522

12/10/2017 02:38:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:38:05 [INFO] exp_shallowmodel: 
[[  7   1  47   4]
 [  1   1  10   0]
 [  5   0 387   4]
 [  5   0  43   7]]
12/10/2017 02:38:06 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 02:38:06 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:38:06 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:38:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:38:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:38:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:38:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:38:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:38:40 [INFO] exp_shallowmodel: train time: 34.124s
12/10/2017 02:38:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:38:40 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:38:40 [INFO] exp_shallowmodel: f1_score:   0.333
12/10/2017 02:38:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:38:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.22      0.32        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.33      0.09      0.14        55

avg / total       0.70      0.77      0.71       522

12/10/2017 02:38:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:38:40 [INFO] exp_shallowmodel: 
[[ 13   0  41   5]
 [  1   0  11   0]
 [  8   1 382   5]
 [  1   1  48   5]]
12/10/2017 02:38:40 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 02:38:40 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:38:40 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:38:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:38:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:38:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:38:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:38:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:39:11 [INFO] exp_shallowmodel: train time: 31.617s
12/10/2017 02:39:12 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:39:12 [INFO] exp_shallowmodel: accuracy:   0.772
12/10/2017 02:39:12 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 02:39:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:39:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.14      0.20        59
          C       0.25      0.08      0.12        12
          F       0.80      0.97      0.88       396
          R       0.67      0.15      0.24        55

avg / total       0.72      0.77      0.72       522

12/10/2017 02:39:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:39:12 [INFO] exp_shallowmodel: 
[[  8   0  49   2]
 [  0   1  10   1]
 [  6   3 386   1]
 [  7   0  40   8]]
12/10/2017 02:39:12 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 02:39:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:39:12 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:39:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:39:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:39:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:39:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:39:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:39:36 [INFO] exp_shallowmodel: train time: 23.970s
12/10/2017 02:39:36 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:39:36 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:39:36 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 02:39:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:39:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        59
          C       1.00      0.08      0.15        12
          F       0.78      0.97      0.87       396
          R       0.38      0.09      0.15        55

avg / total       0.68      0.75      0.69       522

12/10/2017 02:39:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:39:36 [INFO] exp_shallowmodel: 
[[  3   0  53   3]
 [  0   1  11   0]
 [  6   0 385   5]
 [  6   0  44   5]]
12/10/2017 02:39:36 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 02:39:36 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:39:36 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:39:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:39:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:39:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:39:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:39:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:40:00 [INFO] exp_shallowmodel: train time: 24.613s
12/10/2017 02:40:01 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:40:01 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:40:01 [INFO] exp_shallowmodel: f1_score:   0.346
12/10/2017 02:40:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:40:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.20      0.29        64
          C       0.50      0.07      0.12        14
          F       0.78      0.97      0.87       402
          R       0.25      0.06      0.10        63

avg / total       0.68      0.75      0.69       543

12/10/2017 02:40:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:40:01 [INFO] exp_shallowmodel: 
[[ 13   0  44   7]
 [  0   1  13   0]
 [  5   1 391   5]
 [  8   0  51   4]]
12/10/2017 02:40:01 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 02:40:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:40:01 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:40:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:40:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:40:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:40:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:40:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:40:23 [INFO] exp_shallowmodel: train time: 22.699s
12/10/2017 02:40:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:40:23 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 02:40:23 [INFO] exp_shallowmodel: f1_score:   0.375
12/10/2017 02:40:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:40:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.61      0.19      0.29        59
          C       0.33      0.08      0.13        12
          F       0.80      0.96      0.87       396
          R       0.36      0.15      0.21        55

avg / total       0.72      0.77      0.72       522

12/10/2017 02:40:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:40:23 [INFO] exp_shallowmodel: 
[[ 11   0  43   5]
 [  0   1  11   0]
 [  4   1 382   9]
 [  3   1  43   8]]
12/10/2017 02:40:24 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 02:40:24 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:40:24 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:40:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:40:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:40:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:40:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:40:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:40:50 [INFO] exp_shallowmodel: train time: 25.934s
12/10/2017 02:40:50 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:40:50 [INFO] exp_shallowmodel: accuracy:   0.768
12/10/2017 02:40:50 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 02:40:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:40:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.08      0.14        59
          C       0.33      0.08      0.13        12
          F       0.79      0.98      0.88       396
          R       0.47      0.13      0.20        55

avg / total       0.70      0.77      0.70       522

12/10/2017 02:40:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:40:50 [INFO] exp_shallowmodel: 
[[  5   1  49   4]
 [  1   1   9   1]
 [  5   0 388   3]
 [  4   1  43   7]]
12/10/2017 02:40:50 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 02:40:50 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:40:50 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:40:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:40:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:40:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:40:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:40:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:41:17 [INFO] exp_shallowmodel: train time: 27.312s
12/10/2017 02:41:17 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:41:17 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:41:17 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 02:41:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:41:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.08      0.13        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.50      0.13      0.20        55

avg / total       0.68      0.76      0.69       522

12/10/2017 02:41:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:41:17 [INFO] exp_shallowmodel: 
[[  5   1  51   2]
 [  2   0  10   0]
 [  7   1 383   5]
 [  6   0  42   7]]
12/10/2017 02:41:17 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 02:41:17 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:41:17 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:41:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:41:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:41:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:41:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:41:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:41:45 [INFO] exp_shallowmodel: train time: 28.122s
12/10/2017 02:41:45 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:41:45 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 02:41:45 [INFO] exp_shallowmodel: f1_score:   0.322
12/10/2017 02:41:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:41:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.14      0.21        59
          C       0.00      0.00      0.00        12
          F       0.79      0.98      0.87       396
          R       0.47      0.13      0.20        55

avg / total       0.71      0.77      0.71       522

12/10/2017 02:41:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:41:45 [INFO] exp_shallowmodel: 
[[  8   1  47   3]
 [  1   0  10   1]
 [  4   1 387   4]
 [  3   0  45   7]]
12/10/2017 02:41:46 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 02:41:46 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:41:46 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:41:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:41:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:41:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:41:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:41:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:42:12 [INFO] exp_shallowmodel: train time: 26.619s
12/10/2017 02:42:12 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:42:12 [INFO] exp_shallowmodel: accuracy:   0.780
12/10/2017 02:42:12 [INFO] exp_shallowmodel: f1_score:   0.375
12/10/2017 02:42:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:42:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.56      0.17      0.26        59
          C       0.50      0.08      0.14        12
          F       0.80      0.98      0.88       396
          R       0.40      0.15      0.21        55

avg / total       0.73      0.78      0.73       522

12/10/2017 02:42:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:42:12 [INFO] exp_shallowmodel: 
[[ 10   0  42   7]
 [  2   1   9   0]
 [  2   1 388   5]
 [  4   0  43   8]]
12/10/2017 02:42:12 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 02:42:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:42:12 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:42:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:42:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:42:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:42:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:42:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:43:03 [INFO] exp_shallowmodel: train time: 50.223s
12/10/2017 02:43:03 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:43:03 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:43:03 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 02:43:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:43:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.22      0.31        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.86       396
          R       0.17      0.04      0.06        55

avg / total       0.67      0.76      0.70       522

12/10/2017 02:43:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:43:03 [INFO] exp_shallowmodel: 
[[ 13   0  42   4]
 [  0   0  11   1]
 [ 10   1 380   5]
 [  1   1  51   2]]
12/10/2017 02:43:03 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 02:43:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:43:03 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:43:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:43:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:43:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:43:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:43:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:43:31 [INFO] exp_shallowmodel: train time: 27.623s
12/10/2017 02:43:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:43:31 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:43:31 [INFO] exp_shallowmodel: f1_score:   0.277
12/10/2017 02:43:31 [INFO] exp_shallowmodel: classification report:
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:43:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.10      0.15        59
          C       0.00      0.00      0.00        12
          F       0.80      0.97      0.87       396
          R       0.15      0.05      0.08        55

avg / total       0.65      0.75      0.69       522

12/10/2017 02:43:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:43:31 [INFO] exp_shallowmodel: 
[[  6   0  42  11]
 [  1   0   9   2]
 [  8   0 384   4]
 [  5   0  47   3]]
12/10/2017 02:43:31 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 02:43:31 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:43:31 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:43:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:43:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:43:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:43:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:43:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:43:55 [INFO] exp_shallowmodel: train time: 24.477s
12/10/2017 02:43:55 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:43:55 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:43:55 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 02:43:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:43:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.15      0.23        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.87       396
          R       0.44      0.07      0.12        55

avg / total       0.70      0.76      0.70       522

12/10/2017 02:43:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:43:55 [INFO] exp_shallowmodel: 
[[  9   1  49   0]
 [  2   0  10   0]
 [  5   0 386   5]
 [  2   0  49   4]]
12/10/2017 02:43:55 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 02:43:55 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:43:55 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:43:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:43:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:43:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:43:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:43:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:44:34 [INFO] exp_shallowmodel: train time: 38.274s
12/10/2017 02:44:34 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:44:34 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:44:34 [INFO] exp_shallowmodel: f1_score:   0.292
12/10/2017 02:44:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:44:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.10      0.15        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.42      0.09      0.15        55

avg / total       0.67      0.76      0.69       522

12/10/2017 02:44:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:44:34 [INFO] exp_shallowmodel: 
[[  6   1  49   3]
 [  0   0  11   1]
 [  8   0 385   3]
 [  8   0  42   5]]
12/10/2017 02:44:34 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 02:44:34 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:44:34 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:44:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:44:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:44:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:44:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:44:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:45:01 [INFO] exp_shallowmodel: train time: 27.378s
12/10/2017 02:45:01 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:45:01 [INFO] exp_shallowmodel: accuracy:   0.748
12/10/2017 02:45:01 [INFO] exp_shallowmodel: f1_score:   0.297
12/10/2017 02:45:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:45:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.12      0.19        64
          C       0.00      0.00      0.00        14
          F       0.77      0.98      0.86       402
          R       0.45      0.08      0.14        63

avg / total       0.67      0.75      0.68       543

12/10/2017 02:45:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:45:01 [INFO] exp_shallowmodel: 
[[  8   0  53   3]
 [  1   0  13   0]
 [  5   1 393   3]
 [  6   0  52   5]]
12/10/2017 02:45:02 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 02:45:02 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:45:02 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:45:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:45:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:45:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:45:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:45:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:45:35 [INFO] exp_shallowmodel: train time: 33.934s
12/10/2017 02:45:35 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:45:35 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:45:35 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 02:45:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:45:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.17      0.25        59
          C       0.00      0.00      0.00        12
          F       0.78      0.95      0.86       396
          R       0.28      0.09      0.14        55

avg / total       0.67      0.75      0.69       522

12/10/2017 02:45:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:45:35 [INFO] exp_shallowmodel: 
[[ 10   1  45   3]
 [  1   0  10   1]
 [ 10   1 376   9]
 [  1   0  49   5]]
12/10/2017 02:45:36 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 02:45:36 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:45:36 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:45:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:45:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:45:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:45:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:45:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:46:04 [INFO] exp_shallowmodel: train time: 27.915s
12/10/2017 02:46:04 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:46:04 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:46:04 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 02:46:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:46:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.15      0.23        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.27      0.07      0.11        55

avg / total       0.69      0.76      0.70       522

12/10/2017 02:46:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:46:04 [INFO] exp_shallowmodel: 
[[  9   2  44   4]
 [  0   0  10   2]
 [  5   0 386   5]
 [  4   0  47   4]]
12/10/2017 02:46:04 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 02:46:04 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:46:04 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:46:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:46:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:46:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:46:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:46:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:46:48 [INFO] exp_shallowmodel: train time: 44.247s
12/10/2017 02:46:48 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:46:48 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:46:48 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 02:46:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:46:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.10      0.15        59
          C       0.50      0.08      0.14        12
          F       0.78      0.96      0.86       396
          R       0.33      0.07      0.12        55

avg / total       0.67      0.75      0.69       522

12/10/2017 02:46:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:46:48 [INFO] exp_shallowmodel: 
[[  6   0  49   4]
 [  2   1   9   0]
 [  9   1 382   4]
 [  3   0  48   4]]
12/10/2017 02:46:48 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 02:46:48 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:46:48 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:46:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:46:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:46:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:46:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:46:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:47:13 [INFO] exp_shallowmodel: train time: 24.764s
12/10/2017 02:47:13 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:47:13 [INFO] exp_shallowmodel: accuracy:   0.768
12/10/2017 02:47:13 [INFO] exp_shallowmodel: f1_score:   0.349
12/10/2017 02:47:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:47:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.14      0.21        59
          C       0.50      0.08      0.14        12
          F       0.79      0.97      0.88       396
          R       0.38      0.11      0.17        55

avg / total       0.70      0.77      0.71       522

12/10/2017 02:47:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:47:13 [INFO] exp_shallowmodel: 
[[  8   0  46   5]
 [  0   1  10   1]
 [  6   0 386   4]
 [  4   1  44   6]]
12/10/2017 02:47:13 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 02:47:13 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:47:13 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:47:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:47:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:47:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:47:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:47:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:47:40 [INFO] exp_shallowmodel: train time: 26.942s
12/10/2017 02:47:40 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:47:40 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:47:40 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 02:47:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:47:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.79      0.98      0.87       396
          R       0.29      0.09      0.14        55

avg / total       0.67      0.76      0.69       522

12/10/2017 02:47:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:47:40 [INFO] exp_shallowmodel: 
[[  5   1  48   5]
 [  1   0  10   1]
 [  3   0 387   6]
 [  5   1  44   5]]
12/10/2017 02:47:40 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 02:47:40 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:47:40 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:47:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:47:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:47:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:47:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:47:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:48:23 [INFO] exp_shallowmodel: train time: 43.005s
12/10/2017 02:48:23 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:48:23 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:48:23 [INFO] exp_shallowmodel: f1_score:   0.308
12/10/2017 02:48:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:48:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.10      0.15        59
          C       0.00      0.00      0.00        12
          F       0.79      0.95      0.86       396
          R       0.47      0.15      0.22        55

avg / total       0.68      0.75      0.69       522

12/10/2017 02:48:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:48:23 [INFO] exp_shallowmodel: 
[[  6   0  51   2]
 [  1   0  10   1]
 [ 10   3 377   6]
 [  5   1  41   8]]
12/10/2017 02:48:24 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 02:48:24 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:48:24 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:48:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:48:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:48:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:48:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:48:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:49:18 [INFO] exp_shallowmodel: train time: 53.808s
12/10/2017 02:49:18 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:49:18 [INFO] exp_shallowmodel: accuracy:   0.774
12/10/2017 02:49:18 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 02:49:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:49:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.17      0.27        59
          C       0.00      0.00      0.00        12
          F       0.79      0.98      0.87       396
          R       0.50      0.11      0.18        55

avg / total       0.72      0.77      0.71       522

12/10/2017 02:49:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:49:18 [INFO] exp_shallowmodel: 
[[ 10   0  46   3]
 [  0   0  12   0]
 [  4   1 388   3]
 [  2   1  46   6]]
12/10/2017 02:49:18 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 02:49:18 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:49:18 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:49:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:49:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:49:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:49:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:49:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:49:41 [INFO] exp_shallowmodel: train time: 23.489s
12/10/2017 02:49:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:49:41 [INFO] exp_shallowmodel: accuracy:   0.768
12/10/2017 02:49:41 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 02:49:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:49:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.19      0.26        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.86      0.11      0.19        55

avg / total       0.74      0.77      0.71       522

12/10/2017 02:49:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:49:41 [INFO] exp_shallowmodel: 
[[ 11   1  46   1]
 [  1   0  11   0]
 [ 11   1 384   0]
 [  2   0  47   6]]
12/10/2017 02:49:41 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 02:49:41 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:49:41 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:49:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:49:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:49:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:49:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:49:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:50:00 [INFO] exp_shallowmodel: train time: 18.658s
12/10/2017 02:50:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:50:00 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:50:00 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 02:50:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:50:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.10      0.16        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.56      0.16      0.25        55

avg / total       0.70      0.76      0.70       522

12/10/2017 02:50:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:50:00 [INFO] exp_shallowmodel: 
[[  6   0  51   2]
 [  0   0  12   0]
 [  7   1 383   5]
 [  4   1  41   9]]
12/10/2017 02:50:00 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 02:50:00 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:50:00 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:50:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:50:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:50:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:50:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:50:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:50:33 [INFO] exp_shallowmodel: train time: 32.376s
12/10/2017 02:50:33 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:50:33 [INFO] exp_shallowmodel: accuracy:   0.735
12/10/2017 02:50:33 [INFO] exp_shallowmodel: f1_score:   0.297
12/10/2017 02:50:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:50:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.11      0.17        64
          C       0.00      0.00      0.00        14
          F       0.77      0.96      0.85       402
          R       0.35      0.11      0.17        63

avg / total       0.65      0.73      0.67       543

12/10/2017 02:50:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:50:33 [INFO] exp_shallowmodel: 
[[  7   1  51   5]
 [  1   0  13   0]
 [  8   1 385   8]
 [  4   0  52   7]]
12/10/2017 02:50:33 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 02:50:33 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:50:33 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:50:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:50:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:50:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:50:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:50:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:51:09 [INFO] exp_shallowmodel: train time: 36.578s
12/10/2017 02:51:09 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:51:09 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:51:09 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 02:51:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:51:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.10      0.16        59
          C       0.33      0.08      0.13        12
          F       0.78      0.97      0.87       396
          R       0.45      0.09      0.15        55

avg / total       0.69      0.76      0.70       522

12/10/2017 02:51:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:51:09 [INFO] exp_shallowmodel: 
[[  6   1  50   2]
 [  1   1  10   0]
 [  5   1 386   4]
 [  3   0  47   5]]
12/10/2017 02:51:10 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 02:51:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:51:10 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:51:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:51:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:51:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:51:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:51:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:51:50 [INFO] exp_shallowmodel: train time: 40.333s
12/10/2017 02:51:50 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:51:50 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:51:50 [INFO] exp_shallowmodel: f1_score:   0.264
12/10/2017 02:51:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:51:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.86       396
          R       0.17      0.04      0.06        55

avg / total       0.64      0.75      0.68       522

12/10/2017 02:51:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:51:50 [INFO] exp_shallowmodel: 
[[  5   0  50   4]
 [  1   0  11   0]
 [  6   0 384   6]
 [  3   0  50   2]]
12/10/2017 02:51:50 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 02:51:50 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:51:50 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:51:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:51:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:51:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:51:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:51:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:52:21 [INFO] exp_shallowmodel: train time: 30.857s
12/10/2017 02:52:21 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:52:21 [INFO] exp_shallowmodel: accuracy:   0.774
12/10/2017 02:52:21 [INFO] exp_shallowmodel: f1_score:   0.325
12/10/2017 02:52:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:52:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.47      0.12      0.19        59
          C       0.00      0.00      0.00        12
          F       0.79      0.98      0.87       396
          R       0.67      0.15      0.24        55

avg / total       0.72      0.77      0.71       522

12/10/2017 02:52:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:52:21 [INFO] exp_shallowmodel: 
[[  7   0  50   2]
 [  1   0  11   0]
 [  5   0 389   2]
 [  2   0  45   8]]
12/10/2017 02:52:21 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 02:52:21 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:52:21 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:52:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:52:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:52:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:52:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:52:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:52:44 [INFO] exp_shallowmodel: train time: 22.928s
12/10/2017 02:52:44 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:52:44 [INFO] exp_shallowmodel: accuracy:   0.772
12/10/2017 02:52:44 [INFO] exp_shallowmodel: f1_score:   0.351
12/10/2017 02:52:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:52:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.14      0.21        59
          C       0.50      0.08      0.14        12
          F       0.80      0.98      0.88       396
          R       0.46      0.11      0.18        55

avg / total       0.71      0.77      0.71       522

12/10/2017 02:52:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:52:44 [INFO] exp_shallowmodel: 
[[  8   0  49   2]
 [  1   1   8   2]
 [  4   1 388   3]
 [  6   0  43   6]]
12/10/2017 02:52:44 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 02:52:44 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:52:44 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:52:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:52:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:52:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:52:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:52:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:53:07 [INFO] exp_shallowmodel: train time: 22.230s
12/10/2017 02:53:07 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:53:07 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:53:07 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 02:53:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:53:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.17      0.23        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.40      0.11      0.17        55

avg / total       0.69      0.76      0.70       522

12/10/2017 02:53:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:53:07 [INFO] exp_shallowmodel: 
[[ 10   1  46   2]
 [  1   0  10   1]
 [  9   1 380   6]
 [  7   0  42   6]]
12/10/2017 02:53:07 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 02:53:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:53:07 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:53:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:53:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:53:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:53:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:53:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:53:38 [INFO] exp_shallowmodel: train time: 31.492s
12/10/2017 02:53:38 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:53:38 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:53:38 [INFO] exp_shallowmodel: f1_score:   0.303
12/10/2017 02:53:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:53:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.14      0.20        59
          C       0.00      0.00      0.00        12
          F       0.80      0.96      0.87       396
          R       0.33      0.09      0.14        55

avg / total       0.68      0.76      0.70       522

12/10/2017 02:53:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:53:38 [INFO] exp_shallowmodel: 
[[  8   3  43   5]
 [  1   0  11   0]
 [  8   1 382   5]
 [  6   0  44   5]]
12/10/2017 02:53:39 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 02:53:39 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:53:39 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:53:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:53:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:53:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:53:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:53:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:54:00 [INFO] exp_shallowmodel: train time: 21.785s
12/10/2017 02:54:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:54:00 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:54:00 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 02:54:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:54:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.17      0.23        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.44      0.07      0.12        55

avg / total       0.69      0.76      0.70       522

12/10/2017 02:54:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:54:00 [INFO] exp_shallowmodel: 
[[ 10   0  46   3]
 [  0   0  12   0]
 [ 11   1 382   2]
 [  6   1  44   4]]
12/10/2017 02:54:01 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 02:54:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:54:01 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:54:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:54:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:54:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:54:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:54:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:54:26 [INFO] exp_shallowmodel: train time: 24.880s
12/10/2017 02:54:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:54:26 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:54:26 [INFO] exp_shallowmodel: f1_score:   0.339
12/10/2017 02:54:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:54:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.48      0.19      0.27        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.42      0.15      0.22        55

avg / total       0.70      0.77      0.71       522

12/10/2017 02:54:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:54:26 [INFO] exp_shallowmodel: 
[[ 11   0  46   2]
 [  1   0  10   1]
 [  7   0 381   8]
 [  4   0  43   8]]
12/10/2017 02:54:26 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 02:54:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:54:26 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:54:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:54:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:54:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:54:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:54:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:54:48 [INFO] exp_shallowmodel: train time: 22.375s
12/10/2017 02:54:48 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:54:48 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:54:48 [INFO] exp_shallowmodel: f1_score:   0.344
12/10/2017 02:54:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:54:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.10      0.16        59
          C       1.00      0.08      0.15        12
          F       0.79      0.97      0.87       396
          R       0.39      0.13      0.19        55

avg / total       0.70      0.76      0.70       522

12/10/2017 02:54:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:54:48 [INFO] exp_shallowmodel: 
[[  6   0  48   5]
 [  1   1  10   0]
 [  6   0 384   6]
 [  3   0  45   7]]
12/10/2017 02:54:48 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 02:54:48 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:54:48 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:54:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:54:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:54:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:54:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:54:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:55:16 [INFO] exp_shallowmodel: train time: 28.041s
12/10/2017 02:55:16 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:55:16 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 02:55:16 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 02:55:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:55:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.08      0.12        64
          C       0.00      0.00      0.00        14
          F       0.77      0.97      0.86       402
          R       0.41      0.11      0.18        63

avg / total       0.65      0.74      0.67       543

12/10/2017 02:55:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:55:16 [INFO] exp_shallowmodel: 
[[  5   0  54   5]
 [  3   0  10   1]
 [  8   1 389   4]
 [  4   0  52   7]]
12/10/2017 02:55:17 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 02:55:17 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:55:17 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:55:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:55:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:55:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:55:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:55:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:55:49 [INFO] exp_shallowmodel: train time: 32.110s
12/10/2017 02:55:49 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:55:49 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:55:49 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 02:55:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:55:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.14      0.20        59
          C       0.33      0.08      0.13        12
          F       0.78      0.96      0.86       396
          R       0.25      0.04      0.06        55

avg / total       0.67      0.75      0.69       522

12/10/2017 02:55:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:55:49 [INFO] exp_shallowmodel: 
[[  8   0  51   0]
 [  1   1  10   0]
 [  6   2 382   6]
 [  6   0  47   2]]
12/10/2017 02:55:49 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 02:55:49 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:55:49 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:55:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:55:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:55:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:55:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:55:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:56:14 [INFO] exp_shallowmodel: train time: 24.907s
12/10/2017 02:56:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:56:14 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:56:14 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:56:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:56:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.12      0.18        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.36      0.07      0.12        55

avg / total       0.68      0.76      0.69       522

12/10/2017 02:56:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:56:14 [INFO] exp_shallowmodel: 
[[  7   1  49   2]
 [  0   0  11   1]
 [  6   0 386   4]
 [  5   1  45   4]]
12/10/2017 02:56:14 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 02:56:14 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:56:14 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:56:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:56:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:56:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:56:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:56:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:56:37 [INFO] exp_shallowmodel: train time: 23.031s
12/10/2017 02:56:37 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:56:37 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:56:37 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 02:56:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:56:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.10      0.16        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.36      0.15      0.21        55

avg / total       0.68      0.76      0.70       522

12/10/2017 02:56:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:56:37 [INFO] exp_shallowmodel: 
[[  6   0  46   7]
 [  1   0  10   1]
 [  7   1 382   6]
 [  3   0  44   8]]
12/10/2017 02:56:37 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 02:56:37 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:56:37 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:56:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:56:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:56:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:56:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:56:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:57:05 [INFO] exp_shallowmodel: train time: 27.857s
12/10/2017 02:57:05 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:57:05 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:57:05 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:57:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:57:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.15      0.22        59
          C       0.00      0.00      0.00        12
          F       0.80      0.96      0.87       396
          R       0.18      0.05      0.08        55

avg / total       0.67      0.75      0.69       522

12/10/2017 02:57:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:57:05 [INFO] exp_shallowmodel: 
[[  9   0  45   5]
 [  3   0   9   0]
 [  4   2 381   9]
 [  7   1  44   3]]
12/10/2017 02:57:05 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 02:57:05 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:57:05 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:57:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:57:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:57:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:57:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:57:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:57:33 [INFO] exp_shallowmodel: train time: 27.614s
12/10/2017 02:57:33 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:57:33 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 02:57:33 [INFO] exp_shallowmodel: f1_score:   0.364
12/10/2017 02:57:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:57:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.20      0.28        59
          C       1.00      0.08      0.15        12
          F       0.80      0.97      0.88       396
          R       0.36      0.09      0.14        55

avg / total       0.72      0.77      0.72       522

12/10/2017 02:57:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:57:33 [INFO] exp_shallowmodel: 
[[ 12   0  44   3]
 [  0   1  11   0]
 [  6   0 384   6]
 [  8   0  42   5]]
12/10/2017 02:57:33 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 02:57:33 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:57:33 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:57:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:57:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:57:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:57:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:57:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:57:55 [INFO] exp_shallowmodel: train time: 21.597s
12/10/2017 02:57:55 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:57:55 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:57:55 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 02:57:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:57:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.47      0.12      0.19        59
          C       0.00      0.00      0.00        12
          F       0.79      0.98      0.88       396
          R       0.33      0.09      0.14        55

avg / total       0.69      0.77      0.70       522

12/10/2017 02:57:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:57:55 [INFO] exp_shallowmodel: 
[[  7   0  48   4]
 [  0   0  10   2]
 [  3   1 388   4]
 [  5   1  44   5]]
12/10/2017 02:57:55 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 02:57:55 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:57:55 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:57:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:57:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:57:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:57:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:57:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:58:29 [INFO] exp_shallowmodel: train time: 33.842s
12/10/2017 02:58:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:58:29 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:58:29 [INFO] exp_shallowmodel: f1_score:   0.305
12/10/2017 02:58:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:58:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.14      0.19        59
          C       0.00      0.00      0.00        12
          F       0.80      0.96      0.87       396
          R       0.32      0.11      0.16        55

avg / total       0.67      0.75      0.70       522

12/10/2017 02:58:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:58:29 [INFO] exp_shallowmodel: 
[[  8   1  41   9]
 [  0   0  12   0]
 [ 13   0 379   4]
 [  5   0  44   6]]
12/10/2017 02:58:29 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 02:58:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:58:29 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:58:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:58:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:58:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:58:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:58:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:59:13 [INFO] exp_shallowmodel: train time: 43.563s
12/10/2017 02:59:13 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:59:13 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:59:13 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 02:59:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:59:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.14      0.21        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.87       396
          R       0.40      0.07      0.12        55

avg / total       0.68      0.76      0.69       522

12/10/2017 02:59:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:59:13 [INFO] exp_shallowmodel: 
[[  8   0  50   1]
 [  1   0  11   0]
 [  5   0 386   5]
 [  5   0  46   4]]
12/10/2017 02:59:13 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 02:59:13 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:59:13 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:59:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:59:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:59:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:59:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:59:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:59:36 [INFO] exp_shallowmodel: train time: 23.673s
12/10/2017 02:59:36 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:59:36 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:59:36 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 02:59:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:59:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.47      0.12      0.19        59
          C       0.50      0.08      0.14        12
          F       0.79      0.98      0.87       396
          R       0.38      0.09      0.15        55

avg / total       0.70      0.77      0.70       522

12/10/2017 02:59:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:59:36 [INFO] exp_shallowmodel: 
[[  7   0  47   5]
 [  0   1  11   0]
 [  6   0 387   3]
 [  2   1  47   5]]
12/10/2017 02:59:37 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 02:59:37 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:59:37 [INFO] exp_shallowmodel: #(feature) = 1352
12/10/2017 02:59:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:59:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:59:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:59:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:59:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:00:00 [INFO] exp_shallowmodel: train time: 23.221s
12/10/2017 03:00:00 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:00:00 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 03:00:00 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 03:00:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:00:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.47      0.14      0.22        64
          C       0.00      0.00      0.00        14
          F       0.77      0.98      0.86       402
          R       0.54      0.11      0.18        63

avg / total       0.69      0.76      0.69       543

12/10/2017 03:00:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:00:00 [INFO] exp_shallowmodel: 
[[  9   2  50   3]
 [  1   0  12   1]
 [  6   0 394   2]
 [  3   0  53   7]]
Done: 20171210-030001
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
