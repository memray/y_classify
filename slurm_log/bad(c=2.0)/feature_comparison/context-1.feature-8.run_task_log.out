/ihome/pbrusilosky/rum20/.conda/envs/py36/bin/python -m dialogue.classify.task_runner -selected_feature_set_id 8 -selected_context_id 1
No. of param settings = 1
[('deep_model', False), ('selected_context_id', 1), ('selected_feature_set_id', 8), ('similarity_feature', False)]
12/10/2017 02:14:12 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:12 [INFO] configuration: selected_context_id  :   1
12/10/2017 02:14:12 [INFO] configuration: selected_feature_set_id  :   8
12/10/2017 02:14:12 [INFO] configuration: similarity_feature  :   False
12/10/2017 02:14:12 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:12 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:12 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:12 [INFO] configuration: timemark  :   20171210-021412
12/10/2017 02:14:12 [INFO] configuration: context_set  :   current
12/10/2017 02:14:12 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:12 [INFO] configuration: utterance_range  :   ['current_user_utterance']
12/10/2017 02:14:12 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:12 [INFO] configuration: feature_set  :   8-skipthought
12/10/2017 02:14:12 [INFO] configuration: feature_set_number  :   ['11']
12/10/2017 02:14:12 [INFO] configuration: experiment_name  :   20171210-021412.context=current.feature=8-skipthought.similarity=false
12/10/2017 02:14:12 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021412.context=current.feature=8-skipthought.similarity=false
12/10/2017 02:14:12 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021412.context=current.feature=8-skipthought.similarity=false/output.log
12/10/2017 02:14:12 [INFO] configuration: valid_type  :   {'F', 'R', 'C', 'A'}
12/10/2017 02:14:12 [INFO] configuration: data_name  :   
12/10/2017 02:14:12 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:12 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:12 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:12 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:12 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:12 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:12 [INFO] configuration: #division  :   5
12/10/2017 02:14:12 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:12 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:12 [INFO] configuration: action_words  :   {'north', 'telephone', 'item', 'temperature', 'centre', 'ani', 'show', 'alarm', 'video', 'temperatur', 'skip', 'volum', 'remov', 'shuffl', 'tell', 'remove', 'share', 'expensive', 'cast', 'food', 'member', 'start', 'moderate', 'light', 'clear', 'discard', 'any', 'remind', 'volume', 'moder', 'room', 'list', 'else', 'part', 'items', 'findcar', 'south', 'els', 'snooze', 'matter', 'expens', 'help', 'area', 'address', 'watch', 'play', 'shuffle', 'song', 'music', 'post', 'reminder', 'time', 'turn', 'stop', 'telephon', 'price', 'phone', 'number', 'snooz', 'reminders', 'centr', 'cheap', 'next', 'add', 'delete', 'delet', 'reminds', 'findcare', 'weather', 'timer'}
12/10/2017 02:14:12 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:12 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:12 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:12 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:12 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:12 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:12 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:12 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:12 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:12 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:12 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:12 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:12 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:12 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:12 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:12 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:12 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:12 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:12 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 1, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:12 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:15 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:15 [INFO] task_runner: context=current, feature=8-skipthought
12/10/2017 02:14:15 [INFO] task_runner: retained feature numbers=[11.1]
12/10/2017 02:14:15 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:15 [INFO] task_runner: #(feature)=2400
12/10/2017 02:14:15 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:16 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:14:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:28 [INFO] exp_shallowmodel: train time: 132.328s
12/10/2017 02:16:28 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:16:28 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 02:16:28 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 02:16:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.62      0.60       164
          F       0.66      0.76      0.71       268
          R       0.48      0.33      0.39       125

avg / total       0.58      0.61      0.59       571

12/10/2017 02:16:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:28 [INFO] exp_shallowmodel: 
[[  0   6   4   4]
 [  1 101  44  18]
 [  1  40 204  23]
 [  0  27  57  41]]
12/10/2017 02:16:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:16:28 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:28 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:16:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:58 [INFO] exp_shallowmodel: train time: 149.924s
12/10/2017 02:18:58 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:18:58 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 02:18:58 [INFO] exp_shallowmodel: f1_score:   0.438
12/10/2017 02:18:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.53      0.49      0.51       164
          F       0.66      0.74      0.69       268
          R       0.47      0.42      0.45       125

avg / total       0.57      0.58      0.57       571

12/10/2017 02:18:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:58 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  2  81  52  29]
 [  2  44 197  25]
 [  1  25  46  53]]
12/10/2017 02:18:59 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:18:59 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:59 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:18:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:14 [INFO] exp_shallowmodel: train time: 135.429s
12/10/2017 02:21:14 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:21:14 [INFO] exp_shallowmodel: accuracy:   0.567
12/10/2017 02:21:14 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 02:21:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.07      0.09        14
          C       0.50      0.58      0.54       164
          F       0.67      0.75      0.71       268
          R       0.38      0.22      0.28       125

avg / total       0.54      0.57      0.55       571

12/10/2017 02:21:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:14 [INFO] exp_shallowmodel: 
[[  1   7   4   2]
 [  2  95  43  24]
 [  1  47 200  20]
 [  5  41  51  28]]
12/10/2017 02:21:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:21:15 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:21:15 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:21:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:29 [INFO] exp_shallowmodel: train time: 134.011s
12/10/2017 02:23:29 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:23:29 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:23:29 [INFO] exp_shallowmodel: f1_score:   0.418
12/10/2017 02:23:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.52      0.59      0.55       164
          F       0.65      0.74      0.69       268
          R       0.41      0.26      0.31       125

avg / total       0.55      0.57      0.55       571

12/10/2017 02:23:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:29 [INFO] exp_shallowmodel: 
[[  1   4   6   3]
 [  1  96  47  20]
 [  0  46 198  24]
 [  1  40  52  32]]
12/10/2017 02:23:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:23:29 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:23:29 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:23:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:02 [INFO] exp_shallowmodel: train time: 153.414s
12/10/2017 02:26:02 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:26:02 [INFO] exp_shallowmodel: accuracy:   0.552
12/10/2017 02:26:02 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 02:26:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.54      0.51       164
          F       0.65      0.70      0.67       268
          R       0.41      0.30      0.35       125

avg / total       0.53      0.55      0.54       571

12/10/2017 02:26:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:02 [INFO] exp_shallowmodel: 
[[  0   4   8   2]
 [  1  89  48  26]
 [  3  51 188  26]
 [  0  41  46  38]]
12/10/2017 02:26:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:26:03 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:26:03 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:26:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:42 [INFO] exp_shallowmodel: train time: 158.767s
12/10/2017 02:28:42 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:28:42 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:28:42 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 02:28:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.58      0.54       164
          F       0.64      0.72      0.68       268
          R       0.45      0.28      0.34       125

avg / total       0.55      0.57      0.55       571

12/10/2017 02:28:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:42 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  2  95  50  17]
 [  3  49 193  23]
 [  2  39  49  35]]
12/10/2017 02:28:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:28:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:28:42 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:28:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:31:14 [INFO] exp_shallowmodel: train time: 151.611s
12/10/2017 02:31:14 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:31:14 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 02:31:14 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:31:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:31:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.53      0.56       164
          F       0.68      0.72      0.70       268
          R       0.35      0.40      0.37       125

avg / total       0.57      0.58      0.57       571

12/10/2017 02:31:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:31:14 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  1  87  41  35]
 [  0  21 192  55]
 [  1  32  42  50]]
12/10/2017 02:31:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:31:14 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:31:14 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:31:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:31:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:31:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:31:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:31:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:31 [INFO] exp_shallowmodel: train time: 137.197s
12/10/2017 02:33:31 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:33:31 [INFO] exp_shallowmodel: accuracy:   0.550
12/10/2017 02:33:31 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 02:33:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.51      0.50      0.50       164
          F       0.64      0.72      0.68       268
          R       0.37      0.30      0.33       125

avg / total       0.53      0.55      0.54       571

12/10/2017 02:33:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:31 [INFO] exp_shallowmodel: 
[[  1   4   5   4]
 [  1  82  52  29]
 [  2  41 194  31]
 [  3  35  50  37]]
12/10/2017 02:33:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:33:32 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:33:32 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:33:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:35:57 [INFO] exp_shallowmodel: train time: 145.494s
12/10/2017 02:35:57 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:35:57 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 02:35:57 [INFO] exp_shallowmodel: f1_score:   0.456
12/10/2017 02:35:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:35:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        14
          C       0.59      0.64      0.61       164
          F       0.67      0.77      0.72       268
          R       0.48      0.30      0.37       125

avg / total       0.60      0.61      0.60       571

12/10/2017 02:35:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:35:57 [INFO] exp_shallowmodel: 
[[  1   4   5   4]
 [  0 105  42  17]
 [  0  41 207  20]
 [  1  29  57  38]]
12/10/2017 02:35:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:35:58 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:35:58 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:35:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:35:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:35:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:35:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:35:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:38:18 [INFO] exp_shallowmodel: train time: 140.328s
12/10/2017 02:38:18 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:38:18 [INFO] exp_shallowmodel: accuracy:   0.563
12/10/2017 02:38:18 [INFO] exp_shallowmodel: f1_score:   0.388
12/10/2017 02:38:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:38:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.55      0.41      0.47       169
          F       0.61      0.79      0.69       271
          R       0.44      0.36      0.39       130

avg / total       0.54      0.56      0.54       586

12/10/2017 02:38:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:38:18 [INFO] exp_shallowmodel: 
[[  0   4   7   5]
 [  0  69  68  32]
 [  3  30 214  24]
 [  0  22  61  47]]
12/10/2017 02:38:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:38:19 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:38:19 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:38:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:38:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:38:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:38:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:38:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:40:34 [INFO] exp_shallowmodel: train time: 135.608s
12/10/2017 02:40:34 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:40:34 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:40:34 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 02:40:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:40:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.47      0.50       164
          F       0.66      0.72      0.69       268
          R       0.42      0.42      0.42       125

avg / total       0.55      0.57      0.56       571

12/10/2017 02:40:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:40:34 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  1  77  50  36]
 [  3  39 194  32]
 [  0  28  45  52]]
12/10/2017 02:40:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:40:35 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:40:35 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:40:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:40:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:40:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:40:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:40:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:42:51 [INFO] exp_shallowmodel: train time: 136.440s
12/10/2017 02:42:51 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:42:51 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 02:42:51 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 02:42:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:42:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.59      0.53       164
          F       0.68      0.68      0.68       268
          R       0.42      0.34      0.38       125

avg / total       0.55      0.56      0.56       571

12/10/2017 02:42:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:42:51 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  0  96  39  29]
 [  3  54 183  28]
 [  0  40  42  43]]
12/10/2017 02:42:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:42:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:42:51 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:42:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:42:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:42:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:42:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:42:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:45:12 [INFO] exp_shallowmodel: train time: 140.066s
12/10/2017 02:45:12 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:45:12 [INFO] exp_shallowmodel: accuracy:   0.532
12/10/2017 02:45:12 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 02:45:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:45:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.21      0.29        14
          C       0.53      0.33      0.41       164
          F       0.58      0.78      0.67       268
          R       0.36      0.30      0.33       125

avg / total       0.52      0.53      0.51       571

12/10/2017 02:45:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:45:12 [INFO] exp_shallowmodel: 
[[  3   1   7   3]
 [  0  54  78  32]
 [  1  27 210  30]
 [  3  19  66  37]]
12/10/2017 02:45:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:45:12 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:45:12 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:45:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:45:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:45:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:45:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:45:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:47:35 [INFO] exp_shallowmodel: train time: 143.069s
12/10/2017 02:47:35 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:47:35 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:47:35 [INFO] exp_shallowmodel: f1_score:   0.430
12/10/2017 02:47:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:47:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.07      0.09        14
          C       0.55      0.57      0.56       164
          F       0.66      0.69      0.68       268
          R       0.42      0.38      0.39       125

avg / total       0.56      0.57      0.57       571

12/10/2017 02:47:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:47:35 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  1  93  44  26]
 [  4  43 186  35]
 [  3  29  46  47]]
12/10/2017 02:47:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:47:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:47:36 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:47:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:47:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:47:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:47:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:47:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:49:49 [INFO] exp_shallowmodel: train time: 133.227s
12/10/2017 02:49:49 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:49:49 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 02:49:49 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 02:49:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:49:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.54      0.49      0.52       164
          F       0.63      0.78      0.70       268
          R       0.46      0.32      0.38       125

avg / total       0.56      0.58      0.56       571

12/10/2017 02:49:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:49:49 [INFO] exp_shallowmodel: 
[[  1   7   4   2]
 [  0  81  65  18]
 [  2  29 210  27]
 [  0  32  53  40]]
12/10/2017 02:49:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:49:49 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:49:49 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:49:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:49:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:49:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:49:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:49:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:52:04 [INFO] exp_shallowmodel: train time: 134.778s
12/10/2017 02:52:04 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:52:04 [INFO] exp_shallowmodel: accuracy:   0.552
12/10/2017 02:52:04 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:52:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:52:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.54      0.60      0.57       164
          F       0.66      0.67      0.66       268
          R       0.34      0.30      0.31       125

avg / total       0.54      0.55      0.55       571

12/10/2017 02:52:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:52:04 [INFO] exp_shallowmodel: 
[[  1   4   4   5]
 [  3  98  37  26]
 [  1  46 179  42]
 [  3  33  52  37]]
12/10/2017 02:52:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:52:04 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:52:04 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:52:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:52:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:52:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:52:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:52:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:54:58 [INFO] exp_shallowmodel: train time: 173.439s
12/10/2017 02:54:58 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:54:58 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 02:54:58 [INFO] exp_shallowmodel: f1_score:   0.425
12/10/2017 02:54:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:54:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.63      0.59       164
          F       0.70      0.72      0.71       268
          R       0.44      0.37      0.40       125

avg / total       0.58      0.60      0.59       571

12/10/2017 02:54:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:54:58 [INFO] exp_shallowmodel: 
[[  0   2   7   5]
 [  1 103  30  30]
 [  1  50 194  23]
 [  1  33  45  46]]
12/10/2017 02:54:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:54:58 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:54:58 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:54:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:54:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:54:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:54:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:54:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:57:15 [INFO] exp_shallowmodel: train time: 136.543s
12/10/2017 02:57:15 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:57:15 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:57:15 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:57:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:57:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.59      0.55       164
          F       0.65      0.72      0.68       268
          R       0.42      0.30      0.35       125

avg / total       0.55      0.57      0.56       571

12/10/2017 02:57:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:57:15 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  2  97  41  24]
 [  0  51 192  25]
 [  0  34  54  37]]
12/10/2017 02:57:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 02:57:15 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:57:15 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:57:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:57:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:57:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:57:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:57:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:59:45 [INFO] exp_shallowmodel: train time: 149.552s
12/10/2017 02:59:45 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 02:59:45 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:59:45 [INFO] exp_shallowmodel: f1_score:   0.445
12/10/2017 02:59:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:59:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.07      0.11        14
          C       0.54      0.63      0.58       164
          F       0.68      0.74      0.71       268
          R       0.48      0.31      0.38       125

avg / total       0.58      0.60      0.58       571

12/10/2017 02:59:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:59:45 [INFO] exp_shallowmodel: 
[[  1   3   6   4]
 [  1 104  48  11]
 [  2  41 198  27]
 [  0  45  41  39]]
12/10/2017 02:59:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 02:59:45 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:59:45 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 02:59:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:59:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:59:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:59:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:59:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:02:04 [INFO] exp_shallowmodel: train time: 138.469s
12/10/2017 03:02:04 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:02:04 [INFO] exp_shallowmodel: accuracy:   0.558
12/10/2017 03:02:04 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 03:02:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:02:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.06      0.11        16
          C       0.50      0.75      0.60       169
          F       0.68      0.59      0.63       271
          R       0.41      0.30      0.35       130

avg / total       0.56      0.56      0.55       586

12/10/2017 03:02:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:02:04 [INFO] exp_shallowmodel: 
[[  1   7   5   3]
 [  1 127  20  21]
 [  0  80 160  31]
 [  1  41  49  39]]
12/10/2017 03:02:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 03:02:04 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:02:04 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:02:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:02:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:02:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:02:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:02:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:04:07 [INFO] exp_shallowmodel: train time: 122.512s
12/10/2017 03:04:07 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:04:07 [INFO] exp_shallowmodel: accuracy:   0.557
12/10/2017 03:04:07 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 03:04:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:04:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.46      0.48      0.47       164
          F       0.66      0.72      0.69       268
          R       0.44      0.37      0.40       125

avg / total       0.54      0.56      0.55       571

12/10/2017 03:04:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:04:07 [INFO] exp_shallowmodel: 
[[  1   5   5   3]
 [  1  79  54  30]
 [  1  50 192  25]
 [  2  36  41  46]]
12/10/2017 03:04:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 03:04:07 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:04:07 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:04:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:04:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:04:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:04:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:04:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:06:20 [INFO] exp_shallowmodel: train time: 133.135s
12/10/2017 03:06:20 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:06:20 [INFO] exp_shallowmodel: accuracy:   0.510
12/10/2017 03:06:20 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 03:06:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:06:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.47      0.46      0.47       164
          F       0.60      0.71      0.65       268
          R       0.28      0.20      0.23       125

avg / total       0.48      0.51      0.49       571

12/10/2017 03:06:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:06:20 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  1  76  63  24]
 [  2  40 190  36]
 [  2  42  56  25]]
12/10/2017 03:06:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 03:06:21 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:06:21 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:06:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:06:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:06:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:06:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:06:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:08:37 [INFO] exp_shallowmodel: train time: 136.131s
12/10/2017 03:08:37 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:08:37 [INFO] exp_shallowmodel: accuracy:   0.585
12/10/2017 03:08:37 [INFO] exp_shallowmodel: f1_score:   0.429
12/10/2017 03:08:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:08:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.58      0.58      0.58       164
          F       0.63      0.75      0.68       268
          R       0.46      0.29      0.35       125

avg / total       0.56      0.58      0.57       571

12/10/2017 03:08:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:08:37 [INFO] exp_shallowmodel: 
[[  1   4   6   3]
 [  3  95  51  15]
 [  1  41 202  24]
 [  1  25  63  36]]
12/10/2017 03:08:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 03:08:37 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:08:37 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:08:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:08:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:08:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:08:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:08:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:10:42 [INFO] exp_shallowmodel: train time: 125.142s
12/10/2017 03:10:42 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:10:42 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 03:10:42 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 03:10:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:10:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.47      0.52       164
          F       0.66      0.76      0.71       268
          R       0.47      0.45      0.46       125

avg / total       0.58      0.59      0.58       571

12/10/2017 03:10:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:10:42 [INFO] exp_shallowmodel: 
[[  0   4   3   7]
 [  3  77  60  24]
 [  1  30 205  32]
 [  1  24  44  56]]
12/10/2017 03:10:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 03:10:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:10:43 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:10:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:10:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:10:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:10:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:10:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:12:57 [INFO] exp_shallowmodel: train time: 134.094s
12/10/2017 03:12:57 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:12:57 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 03:12:57 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 03:12:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:12:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        14
          C       0.53      0.53      0.53       164
          F       0.64      0.76      0.70       268
          R       0.38      0.26      0.31       125

avg / total       0.55      0.57      0.55       571

12/10/2017 03:12:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:12:57 [INFO] exp_shallowmodel: 
[[  1   4   7   2]
 [  0  87  48  29]
 [  0  40 204  24]
 [  1  32  59  33]]
12/10/2017 03:12:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 03:12:57 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:12:57 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:12:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:12:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:12:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:12:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:12:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:15:13 [INFO] exp_shallowmodel: train time: 135.835s
12/10/2017 03:15:13 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:15:13 [INFO] exp_shallowmodel: accuracy:   0.567
12/10/2017 03:15:13 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 03:15:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:15:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.59      0.57       164
          F       0.65      0.70      0.67       268
          R       0.39      0.33      0.36       125

avg / total       0.55      0.57      0.56       571

12/10/2017 03:15:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:15:13 [INFO] exp_shallowmodel: 
[[  0   5   6   3]
 [  1  96  37  30]
 [  5  46 187  30]
 [  2  25  57  41]]
12/10/2017 03:15:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 03:15:14 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:15:14 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:15:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:15:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:15:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:15:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:15:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:17:34 [INFO] exp_shallowmodel: train time: 140.293s
12/10/2017 03:17:34 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:17:34 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 03:17:34 [INFO] exp_shallowmodel: f1_score:   0.448
12/10/2017 03:17:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:17:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.14      0.22        14
          C       0.53      0.48      0.51       164
          F       0.65      0.79      0.71       268
          R       0.42      0.30      0.35       125

avg / total       0.56      0.58      0.56       571

12/10/2017 03:17:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:17:34 [INFO] exp_shallowmodel: 
[[  2   2   7   3]
 [  1  79  56  28]
 [  1  33 212  22]
 [  0  34  53  38]]
12/10/2017 03:17:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 03:17:34 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:17:34 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:17:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:17:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:17:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:17:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:17:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:19:41 [INFO] exp_shallowmodel: train time: 126.536s
12/10/2017 03:19:41 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:19:41 [INFO] exp_shallowmodel: accuracy:   0.595
12/10/2017 03:19:41 [INFO] exp_shallowmodel: f1_score:   0.425
12/10/2017 03:19:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:19:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.59      0.56       164
          F       0.68      0.72      0.70       268
          R       0.49      0.40      0.44       125

avg / total       0.58      0.60      0.59       571

12/10/2017 03:19:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:19:41 [INFO] exp_shallowmodel: 
[[  0   5   5   4]
 [  2  96  42  24]
 [  1  48 194  25]
 [  0  32  43  50]]
12/10/2017 03:19:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 03:19:41 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:19:41 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:19:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:19:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:19:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:19:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:19:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:21:40 [INFO] exp_shallowmodel: train time: 118.465s
12/10/2017 03:21:40 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:21:40 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 03:21:40 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 03:21:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:21:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.60      0.56       164
          F       0.68      0.72      0.70       268
          R       0.47      0.35      0.40       125

avg / total       0.57      0.59      0.58       571

12/10/2017 03:21:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:21:40 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  1  98  38  27]
 [  2  53 194  19]
 [  4  31  46  44]]
12/10/2017 03:21:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 03:21:40 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:21:40 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:21:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:21:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:21:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:21:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:21:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:23:43 [INFO] exp_shallowmodel: train time: 122.600s
12/10/2017 03:23:43 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:23:43 [INFO] exp_shallowmodel: accuracy:   0.565
12/10/2017 03:23:43 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 03:23:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:23:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.06      0.09        16
          C       0.50      0.61      0.55       169
          F       0.65      0.70      0.68       271
          R       0.46      0.28      0.34       130

avg / total       0.55      0.56      0.55       586

12/10/2017 03:23:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:23:43 [INFO] exp_shallowmodel: 
[[  1   7   6   2]
 [  1 103  41  24]
 [  2  61 191  17]
 [  3  35  56  36]]
12/10/2017 03:23:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 03:23:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:23:43 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:23:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:23:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:23:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:23:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:23:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:25:43 [INFO] exp_shallowmodel: train time: 119.852s
12/10/2017 03:25:43 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:25:43 [INFO] exp_shallowmodel: accuracy:   0.541
12/10/2017 03:25:43 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 03:25:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:25:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.53      0.51       164
          F       0.66      0.67      0.66       268
          R       0.37      0.34      0.36       125

avg / total       0.53      0.54      0.54       571

12/10/2017 03:25:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:25:43 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  3  87  43  31]
 [  1  50 179  38]
 [  0  38  44  43]]
12/10/2017 03:25:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 03:25:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:25:43 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:25:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:25:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:25:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:25:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:25:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:27:43 [INFO] exp_shallowmodel: train time: 120.175s
12/10/2017 03:27:43 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:27:43 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 03:27:43 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 03:27:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:27:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.64      0.61       164
          F       0.68      0.71      0.69       268
          R       0.37      0.31      0.34       125

avg / total       0.57      0.59      0.58       571

12/10/2017 03:27:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:27:43 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  0 105  28  31]
 [  5  42 191  30]
 [  1  28  57  39]]
12/10/2017 03:27:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 03:27:44 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:27:44 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:27:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:27:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:27:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:27:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:27:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:29:54 [INFO] exp_shallowmodel: train time: 130.156s
12/10/2017 03:29:54 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:29:54 [INFO] exp_shallowmodel: accuracy:   0.567
12/10/2017 03:29:54 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 03:29:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:29:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.52      0.55      0.54       164
          F       0.66      0.72      0.69       268
          R       0.39      0.32      0.35       125

avg / total       0.55      0.57      0.56       571

12/10/2017 03:29:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:29:54 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  1  90  42  31]
 [  1  48 193  26]
 [  0  31  54  40]]
12/10/2017 03:29:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 03:29:54 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:29:54 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:29:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:29:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:29:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:29:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:29:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:32:05 [INFO] exp_shallowmodel: train time: 130.874s
12/10/2017 03:32:05 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:32:05 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 03:32:05 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 03:32:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:32:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.60      0.58       164
          F       0.65      0.77      0.71       268
          R       0.43      0.26      0.33       125

avg / total       0.56      0.59      0.57       571

12/10/2017 03:32:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:32:05 [INFO] exp_shallowmodel: 
[[  0   8   3   3]
 [  0  99  45  20]
 [  0  41 207  20]
 [  1  28  63  33]]
12/10/2017 03:32:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 03:32:06 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:32:06 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:32:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:32:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:32:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:32:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:32:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:34:23 [INFO] exp_shallowmodel: train time: 137.494s
12/10/2017 03:34:23 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:34:23 [INFO] exp_shallowmodel: accuracy:   0.602
12/10/2017 03:34:23 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 03:34:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:34:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.61      0.57       164
          F       0.70      0.76      0.73       268
          R       0.47      0.32      0.38       125

avg / total       0.58      0.60      0.59       571

12/10/2017 03:34:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:34:23 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  1 100  43  20]
 [  3  39 204  22]
 [  0  47  38  40]]
12/10/2017 03:34:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 03:34:24 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:34:24 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:34:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:34:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:34:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:34:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:34:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:36:42 [INFO] exp_shallowmodel: train time: 138.371s
12/10/2017 03:36:42 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:36:42 [INFO] exp_shallowmodel: accuracy:   0.552
12/10/2017 03:36:42 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 03:36:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:36:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.54      0.55      0.54       164
          F       0.65      0.72      0.68       268
          R       0.32      0.25      0.28       125

avg / total       0.53      0.55      0.54       571

12/10/2017 03:36:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:36:42 [INFO] exp_shallowmodel: 
[[  1   2   8   3]
 [  0  91  44  29]
 [  2  39 192  35]
 [  3  38  53  31]]
12/10/2017 03:36:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 03:36:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:36:42 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:36:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:36:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:36:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:36:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:36:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:39:00 [INFO] exp_shallowmodel: train time: 137.192s
12/10/2017 03:39:00 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:39:00 [INFO] exp_shallowmodel: accuracy:   0.548
12/10/2017 03:39:00 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 03:39:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:39:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.47      0.48      0.48       164
          F       0.64      0.72      0.68       268
          R       0.42      0.33      0.37       125

avg / total       0.53      0.55      0.53       571

12/10/2017 03:39:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:39:00 [INFO] exp_shallowmodel: 
[[  0   6   4   4]
 [  1  79  58  26]
 [  0  48 193  27]
 [  1  35  48  41]]
12/10/2017 03:39:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 03:39:00 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:39:00 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:39:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:39:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:39:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:39:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:39:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:41:15 [INFO] exp_shallowmodel: train time: 135.114s
12/10/2017 03:41:15 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:41:15 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 03:41:15 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 03:41:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:41:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.49      0.48      0.48       164
          F       0.66      0.74      0.70       268
          R       0.49      0.42      0.45       125

avg / total       0.56      0.58      0.57       571

12/10/2017 03:41:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:41:15 [INFO] exp_shallowmodel: 
[[  1   7   4   2]
 [  1  78  57  28]
 [  1  45 198  24]
 [  2  30  41  52]]
12/10/2017 03:41:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 03:41:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:41:16 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:41:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:41:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:41:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:41:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:41:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:43:20 [INFO] exp_shallowmodel: train time: 124.338s
12/10/2017 03:43:20 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:43:20 [INFO] exp_shallowmodel: accuracy:   0.553
12/10/2017 03:43:20 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 03:43:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:43:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.54      0.52       164
          F       0.65      0.68      0.67       268
          R       0.41      0.36      0.38       125

avg / total       0.54      0.55      0.55       571

12/10/2017 03:43:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:43:20 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  1  88  45  30]
 [  2  53 183  30]
 [  2  33  45  45]]
12/10/2017 03:43:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 03:43:20 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:43:20 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:43:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:43:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:43:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:43:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:43:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:45:32 [INFO] exp_shallowmodel: train time: 131.274s
12/10/2017 03:45:32 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:45:32 [INFO] exp_shallowmodel: accuracy:   0.544
12/10/2017 03:45:32 [INFO] exp_shallowmodel: f1_score:   0.381
12/10/2017 03:45:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:45:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.49      0.56      0.52       169
          F       0.64      0.68      0.66       271
          R       0.39      0.31      0.34       130

avg / total       0.52      0.54      0.53       586

12/10/2017 03:45:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:45:32 [INFO] exp_shallowmodel: 
[[  0   3   8   5]
 [  0  94  50  25]
 [  1  52 185  33]
 [  1  42  47  40]]
12/10/2017 03:45:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 03:45:32 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:45:32 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:45:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:45:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:45:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:45:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:45:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:47:39 [INFO] exp_shallowmodel: train time: 127.408s
12/10/2017 03:47:39 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:47:39 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 03:47:39 [INFO] exp_shallowmodel: f1_score:   0.438
12/10/2017 03:47:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:47:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.52      0.55      0.54       164
          F       0.68      0.69      0.69       268
          R       0.44      0.42      0.43       125

avg / total       0.57      0.58      0.57       571

12/10/2017 03:47:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:47:39 [INFO] exp_shallowmodel: 
[[  1   5   5   3]
 [  2  91  39  32]
 [  1  52 185  30]
 [  2  28  43  52]]
12/10/2017 03:47:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 03:47:40 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:47:40 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:47:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:47:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:47:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:47:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:47:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:49:49 [INFO] exp_shallowmodel: train time: 129.502s
12/10/2017 03:49:49 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:49:49 [INFO] exp_shallowmodel: accuracy:   0.555
12/10/2017 03:49:49 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 03:49:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:49:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.52      0.53       164
          F       0.62      0.74      0.67       268
          R       0.38      0.28      0.32       125

avg / total       0.53      0.56      0.54       571

12/10/2017 03:49:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:49:49 [INFO] exp_shallowmodel: 
[[  0   4   8   2]
 [  0  85  60  19]
 [  0  35 197  36]
 [  1  35  54  35]]
12/10/2017 03:49:50 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 03:49:50 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:49:50 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:49:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:49:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:49:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:49:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:49:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:51:52 [INFO] exp_shallowmodel: train time: 122.362s
12/10/2017 03:51:52 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:51:52 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 03:51:52 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 03:51:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:51:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.49      0.52       164
          F       0.63      0.79      0.70       268
          R       0.49      0.32      0.39       125

avg / total       0.56      0.58      0.56       571

12/10/2017 03:51:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:51:52 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  0  81  61  22]
 [  5  36 211  16]
 [  1  26  58  40]]
12/10/2017 03:51:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 03:51:52 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:51:52 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:51:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:51:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:51:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:51:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:51:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:54:04 [INFO] exp_shallowmodel: train time: 131.831s
12/10/2017 03:54:04 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:54:04 [INFO] exp_shallowmodel: accuracy:   0.555
12/10/2017 03:54:04 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 03:54:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:54:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.49      0.52      0.51       164
          F       0.64      0.72      0.68       268
          R       0.42      0.30      0.35       125

avg / total       0.54      0.56      0.54       571

12/10/2017 03:54:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:54:04 [INFO] exp_shallowmodel: 
[[  1   8   3   2]
 [  3  86  55  20]
 [  1  45 193  29]
 [  2  35  51  37]]
12/10/2017 03:54:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 03:54:05 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:54:05 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:54:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:54:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:54:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:54:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:54:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:56:18 [INFO] exp_shallowmodel: train time: 132.925s
12/10/2017 03:56:18 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:56:18 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 03:56:18 [INFO] exp_shallowmodel: f1_score:   0.437
12/10/2017 03:56:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:56:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.54      0.60      0.57       164
          F       0.66      0.72      0.69       268
          R       0.45      0.33      0.38       125

avg / total       0.57      0.59      0.57       571

12/10/2017 03:56:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:56:18 [INFO] exp_shallowmodel: 
[[  1   7   5   1]
 [  1  99  39  25]
 [  2  47 194  25]
 [  1  29  54  41]]
12/10/2017 03:56:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 03:56:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:56:18 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:56:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:56:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:56:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:56:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:56:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:58:10 [INFO] exp_shallowmodel: train time: 111.694s
12/10/2017 03:58:10 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:58:10 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 03:58:10 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 03:58:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:58:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.54      0.55      0.55       164
          F       0.68      0.76      0.72       268
          R       0.44      0.33      0.38       125

avg / total       0.57      0.59      0.58       571

12/10/2017 03:58:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:58:10 [INFO] exp_shallowmodel: 
[[  1   3   4   6]
 [  0  91  48  25]
 [  2  40 205  21]
 [  4  35  45  41]]
12/10/2017 03:58:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 03:58:10 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:58:10 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 03:58:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:58:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:58:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:58:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:58:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:00:19 [INFO] exp_shallowmodel: train time: 129.084s
12/10/2017 04:00:19 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:00:19 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 04:00:19 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 04:00:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:00:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.51      0.53       164
          F       0.64      0.76      0.70       268
          R       0.39      0.30      0.34       125

avg / total       0.55      0.57      0.55       571

12/10/2017 04:00:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:00:19 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  1  84  51  28]
 [  2  35 204  27]
 [  1  29  57  38]]
12/10/2017 04:00:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 04:00:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:00:20 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:00:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:00:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:00:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:00:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:00:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:02:17 [INFO] exp_shallowmodel: train time: 117.197s
12/10/2017 04:02:17 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:02:17 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 04:02:17 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 04:02:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:02:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        14
          C       0.49      0.44      0.46       164
          F       0.62      0.74      0.68       268
          R       0.39      0.32      0.35       125

avg / total       0.53      0.55      0.53       571

12/10/2017 04:02:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:02:17 [INFO] exp_shallowmodel: 
[[  1   0   8   5]
 [  1  72  60  31]
 [  0  43 199  26]
 [  0  32  53  40]]
12/10/2017 04:02:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 04:02:17 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 04:02:17 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:02:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:02:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:02:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:02:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:02:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:04:26 [INFO] exp_shallowmodel: train time: 128.576s
12/10/2017 04:04:26 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:04:26 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 04:04:26 [INFO] exp_shallowmodel: f1_score:   0.443
12/10/2017 04:04:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:04:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.54      0.60      0.57       164
          F       0.67      0.73      0.70       268
          R       0.42      0.33      0.37       125

avg / total       0.59      0.59      0.58       571

12/10/2017 04:04:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:04:26 [INFO] exp_shallowmodel: 
[[  1   5   3   5]
 [  0  98  49  17]
 [  0  37 196  35]
 [  0  40  44  41]]
12/10/2017 04:04:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 04:04:26 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 04:04:26 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:04:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:04:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:04:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:04:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:04:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:06:33 [INFO] exp_shallowmodel: train time: 126.558s
12/10/2017 04:06:33 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:06:33 [INFO] exp_shallowmodel: accuracy:   0.561
12/10/2017 04:06:33 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 04:06:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:06:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.52      0.56      0.54       169
          F       0.64      0.71      0.67       271
          R       0.44      0.33      0.38       130

avg / total       0.54      0.56      0.55       586

12/10/2017 04:06:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:06:33 [INFO] exp_shallowmodel: 
[[  0   4   6   6]
 [  2  94  55  18]
 [  2  46 192  31]
 [  1  37  49  43]]
12/10/2017 04:06:36 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 04:06:36 [INFO] task_runner: context=current, feature=8-skipthought
12/10/2017 04:06:36 [INFO] task_runner: retained feature numbers=[11.1]
12/10/2017 04:06:36 [INFO] task_runner: #(data)=5934
12/10/2017 04:06:36 [INFO] task_runner: #(feature)=2400
12/10/2017 04:06:36 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 04:06:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 04:06:37 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:06:37 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:06:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:06:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:06:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:06:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:06:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:08:59 [INFO] exp_shallowmodel: train time: 142.365s
12/10/2017 04:08:59 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:08:59 [INFO] exp_shallowmodel: accuracy:   0.525
12/10/2017 04:08:59 [INFO] exp_shallowmodel: f1_score:   0.362
12/10/2017 04:08:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:08:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.62      0.52       169
          F       0.69      0.63      0.66       281
          R       0.30      0.24      0.27       122

avg / total       0.52      0.53      0.52       592

12/10/2017 04:08:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:08:59 [INFO] exp_shallowmodel: 
[[  0   7   6   7]
 [  2 105  38  24]
 [  1  67 177  36]
 [  3  56  34  29]]
12/10/2017 04:08:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 04:08:59 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:08:59 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:08:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:08:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:08:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:08:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:08:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:11:23 [INFO] exp_shallowmodel: train time: 143.333s
12/10/2017 04:11:23 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:11:23 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 04:11:23 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 04:11:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:11:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.05      0.06        20
          C       0.46      0.70      0.56       169
          F       0.75      0.64      0.69       281
          R       0.42      0.29      0.34       122

avg / total       0.58      0.56      0.56       592

12/10/2017 04:11:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:11:23 [INFO] exp_shallowmodel: 
[[  1   6   9   4]
 [  5 118  26  20]
 [  2  74 180  25]
 [  3  58  26  35]]
12/10/2017 04:11:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 04:11:23 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:11:23 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:11:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:11:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:11:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:11:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:11:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:13:45 [INFO] exp_shallowmodel: train time: 141.476s
12/10/2017 04:13:45 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:13:45 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 04:13:45 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 04:13:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:13:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.46      0.49       169
          F       0.67      0.77      0.72       281
          R       0.37      0.35      0.36       122

avg / total       0.54      0.57      0.56       592

12/10/2017 04:13:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:13:45 [INFO] exp_shallowmodel: 
[[  0   6   7   7]
 [  1  78  52  38]
 [  0  37 217  27]
 [  2  30  47  43]]
12/10/2017 04:13:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 04:13:45 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:13:45 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:13:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:13:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:13:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:13:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:13:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:16:03 [INFO] exp_shallowmodel: train time: 137.941s
12/10/2017 04:16:03 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:16:03 [INFO] exp_shallowmodel: accuracy:   0.549
12/10/2017 04:16:03 [INFO] exp_shallowmodel: f1_score:   0.373
12/10/2017 04:16:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:16:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.56      0.43      0.49       169
          F       0.63      0.77      0.69       281
          R       0.33      0.30      0.32       122

avg / total       0.53      0.55      0.53       592

12/10/2017 04:16:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:16:03 [INFO] exp_shallowmodel: 
[[  0   4  10   6]
 [  1  73  59  36]
 [  3  31 215  32]
 [  3  23  59  37]]
12/10/2017 04:16:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 04:16:03 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:16:03 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:16:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:16:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:16:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:16:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:16:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:18:25 [INFO] exp_shallowmodel: train time: 141.413s
12/10/2017 04:18:25 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:18:25 [INFO] exp_shallowmodel: accuracy:   0.537
12/10/2017 04:18:25 [INFO] exp_shallowmodel: f1_score:   0.372
12/10/2017 04:18:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:18:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.54      0.53       169
          F       0.65      0.69      0.67       281
          R       0.32      0.27      0.29       122

avg / total       0.52      0.54      0.53       592

12/10/2017 04:18:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:18:25 [INFO] exp_shallowmodel: 
[[  0   4   7   9]
 [  2  91  46  30]
 [  7  48 194  32]
 [  4  32  53  33]]
12/10/2017 04:18:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 04:18:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:18:25 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:18:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:18:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:18:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:18:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:18:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:20:38 [INFO] exp_shallowmodel: train time: 132.744s
12/10/2017 04:20:38 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:20:38 [INFO] exp_shallowmodel: accuracy:   0.505
12/10/2017 04:20:38 [INFO] exp_shallowmodel: f1_score:   0.361
12/10/2017 04:20:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:20:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.40      0.56      0.46       169
          F       0.68      0.63      0.65       281
          R       0.33      0.22      0.27       122

avg / total       0.51      0.51      0.50       592

12/10/2017 04:20:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:20:38 [INFO] exp_shallowmodel: 
[[  1  12   5   2]
 [  3  94  44  28]
 [  2  78 177  24]
 [  6  53  36  27]]
12/10/2017 04:20:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 04:20:38 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:20:38 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:20:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:20:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:20:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:20:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:20:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:22:46 [INFO] exp_shallowmodel: train time: 127.680s
12/10/2017 04:22:46 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:22:46 [INFO] exp_shallowmodel: accuracy:   0.520
12/10/2017 04:22:46 [INFO] exp_shallowmodel: f1_score:   0.375
12/10/2017 04:22:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:22:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.44      0.47      0.45       169
          F       0.66      0.68      0.67       281
          R       0.32      0.30      0.31       122

avg / total       0.51      0.52      0.51       592

12/10/2017 04:22:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:22:46 [INFO] exp_shallowmodel: 
[[  1   7   3   9]
 [  4  79  55  31]
 [  2  51 192  36]
 [  2  44  40  36]]
12/10/2017 04:22:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 04:22:46 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:22:46 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:22:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:22:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:22:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:22:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:22:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:24:57 [INFO] exp_shallowmodel: train time: 130.837s
12/10/2017 04:24:57 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:24:57 [INFO] exp_shallowmodel: accuracy:   0.534
12/10/2017 04:24:57 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 04:24:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:24:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.15      0.24        20
          C       0.47      0.43      0.45       169
          F       0.62      0.74      0.67       281
          R       0.34      0.28      0.31       122

avg / total       0.52      0.53      0.52       592

12/10/2017 04:24:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:24:57 [INFO] exp_shallowmodel: 
[[  3   3  10   4]
 [  1  72  63  33]
 [  0  45 207  29]
 [  1  33  54  34]]
12/10/2017 04:24:58 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 04:24:58 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:24:58 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:24:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:24:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:24:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:24:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:24:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:27:10 [INFO] exp_shallowmodel: train time: 132.496s
12/10/2017 04:27:10 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:27:10 [INFO] exp_shallowmodel: accuracy:   0.557
12/10/2017 04:27:10 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 04:27:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:27:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.05      0.07        20
          C       0.48      0.75      0.59       169
          F       0.71      0.62      0.67       281
          R       0.35      0.22      0.27       122

avg / total       0.55      0.56      0.54       592

12/10/2017 04:27:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:27:10 [INFO] exp_shallowmodel: 
[[  1   5   9   5]
 [  1 127  25  16]
 [  2  74 175  30]
 [  3  56  36  27]]
12/10/2017 04:27:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 04:27:11 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:27:11 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:27:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:27:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:27:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:27:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:27:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:29:22 [INFO] exp_shallowmodel: train time: 131.824s
12/10/2017 04:29:22 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:29:22 [INFO] exp_shallowmodel: accuracy:   0.553
12/10/2017 04:29:22 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 04:29:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:29:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.45      0.68      0.54       172
          F       0.72      0.66      0.69       283
          R       0.36      0.25      0.30       123

avg / total       0.54      0.55      0.54       606

12/10/2017 04:29:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:29:22 [INFO] exp_shallowmodel: 
[[  0  10   9   9]
 [  0 117  29  26]
 [  3  74 187  19]
 [  0  57  35  31]]
12/10/2017 04:29:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 04:29:23 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:29:23 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:29:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:29:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:29:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:29:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:29:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:31:43 [INFO] exp_shallowmodel: train time: 139.811s
12/10/2017 04:31:43 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:31:43 [INFO] exp_shallowmodel: accuracy:   0.561
12/10/2017 04:31:43 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 04:31:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:31:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.49      0.66      0.56       169
          F       0.72      0.63      0.67       281
          R       0.37      0.34      0.36       122

avg / total       0.57      0.56      0.56       592

12/10/2017 04:31:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:31:43 [INFO] exp_shallowmodel: 
[[  1   5   7   7]
 [  0 111  29  29]
 [  2  66 178  35]
 [  1  46  33  42]]
12/10/2017 04:31:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 04:31:43 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:31:43 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:31:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:31:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:31:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:31:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:31:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:34:06 [INFO] exp_shallowmodel: train time: 142.988s
12/10/2017 04:34:06 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:34:06 [INFO] exp_shallowmodel: accuracy:   0.525
12/10/2017 04:34:06 [INFO] exp_shallowmodel: f1_score:   0.356
12/10/2017 04:34:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:34:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.47      0.49      0.48       169
          F       0.62      0.71      0.66       281
          R       0.35      0.25      0.29       122

avg / total       0.50      0.53      0.51       592

12/10/2017 04:34:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:34:06 [INFO] exp_shallowmodel: 
[[  0   8   7   5]
 [  0  82  64  23]
 [  3  51 199  28]
 [  5  34  53  30]]
12/10/2017 04:34:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 04:34:06 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:34:06 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:34:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:34:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:34:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:34:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:34:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:36:22 [INFO] exp_shallowmodel: train time: 135.226s
12/10/2017 04:36:22 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:36:22 [INFO] exp_shallowmodel: accuracy:   0.557
12/10/2017 04:36:22 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 04:36:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:36:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.50      0.52       169
          F       0.65      0.73      0.69       281
          R       0.35      0.33      0.34       122

avg / total       0.54      0.56      0.54       592

12/10/2017 04:36:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:36:22 [INFO] exp_shallowmodel: 
[[  0   3   9   8]
 [  1  84  56  28]
 [  2  36 206  37]
 [  3  32  47  40]]
12/10/2017 04:36:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 04:36:22 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:36:22 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:36:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:36:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:36:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:36:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:36:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:38:47 [INFO] exp_shallowmodel: train time: 144.890s
12/10/2017 04:38:47 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:38:47 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 04:38:47 [INFO] exp_shallowmodel: f1_score:   0.430
12/10/2017 04:38:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:38:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.10      0.14        20
          C       0.51      0.66      0.57       169
          F       0.71      0.68      0.69       281
          R       0.36      0.28      0.31       122

avg / total       0.56      0.57      0.56       592

12/10/2017 04:38:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:38:47 [INFO] exp_shallowmodel: 
[[  2   3  10   5]
 [  3 111  27  28]
 [  1  61 191  28]
 [  2  44  42  34]]
12/10/2017 04:38:47 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 04:38:47 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:38:47 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:38:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:38:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:38:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:38:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:38:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:41:07 [INFO] exp_shallowmodel: train time: 139.670s
12/10/2017 04:41:07 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:41:07 [INFO] exp_shallowmodel: accuracy:   0.547
12/10/2017 04:41:07 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 04:41:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:41:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.15      0.17        20
          C       0.44      0.57      0.50       169
          F       0.75      0.64      0.69       281
          R       0.38      0.37      0.37       122

avg / total       0.57      0.55      0.55       592

12/10/2017 04:41:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:41:07 [INFO] exp_shallowmodel: 
[[  3   8   4   5]
 [  4  96  29  40]
 [  4  67 180  30]
 [  4  45  28  45]]
12/10/2017 04:41:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 04:41:07 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:41:07 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:41:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:41:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:41:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:41:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:41:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:43:27 [INFO] exp_shallowmodel: train time: 139.305s
12/10/2017 04:43:27 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:43:27 [INFO] exp_shallowmodel: accuracy:   0.542
12/10/2017 04:43:27 [INFO] exp_shallowmodel: f1_score:   0.371
12/10/2017 04:43:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:43:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.44      0.47       169
          F       0.62      0.74      0.68       281
          R       0.37      0.31      0.34       122

avg / total       0.52      0.54      0.53       592

12/10/2017 04:43:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:43:27 [INFO] exp_shallowmodel: 
[[  0   6   7   7]
 [  4  74  66  25]
 [  1  38 209  33]
 [  2  26  56  38]]
12/10/2017 04:43:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 04:43:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:43:27 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:43:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:43:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:43:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:43:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:43:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:45:38 [INFO] exp_shallowmodel: train time: 131.188s
12/10/2017 04:45:38 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:45:38 [INFO] exp_shallowmodel: accuracy:   0.544
12/10/2017 04:45:38 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 04:45:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:45:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.10      0.13        20
          C       0.49      0.53      0.51       169
          F       0.64      0.72      0.67       281
          R       0.36      0.24      0.29       122

avg / total       0.52      0.54      0.53       592

12/10/2017 04:45:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:45:38 [INFO] exp_shallowmodel: 
[[  2   2  11   5]
 [  3  90  55  21]
 [  2  52 201  26]
 [  3  41  49  29]]
12/10/2017 04:45:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 04:45:39 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:45:39 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:45:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:45:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:45:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:45:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:45:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:47:55 [INFO] exp_shallowmodel: train time: 136.214s
12/10/2017 04:47:55 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:47:55 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 04:47:55 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 04:47:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:47:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.05      0.07        20
          C       0.50      0.66      0.57       169
          F       0.76      0.70      0.73       281
          R       0.35      0.30      0.32       122

avg / total       0.58      0.58      0.58       592

12/10/2017 04:47:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:47:55 [INFO] exp_shallowmodel: 
[[  1   4   5  10]
 [  1 112  23  33]
 [  5  55 196  25]
 [  0  51  35  36]]
12/10/2017 04:47:55 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 04:47:55 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:47:55 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:47:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:47:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:47:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:47:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:47:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:50:21 [INFO] exp_shallowmodel: train time: 146.061s
12/10/2017 04:50:21 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:50:21 [INFO] exp_shallowmodel: accuracy:   0.544
12/10/2017 04:50:21 [INFO] exp_shallowmodel: f1_score:   0.435
12/10/2017 04:50:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:50:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.20      0.29        20
          C       0.44      0.48      0.46       169
          F       0.66      0.73      0.69       281
          R       0.35      0.26      0.30       122

avg / total       0.53      0.54      0.53       592

12/10/2017 04:50:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:50:21 [INFO] exp_shallowmodel: 
[[  4   9   6   1]
 [  1  81  53  34]
 [  1  51 205  24]
 [  2  43  45  32]]
12/10/2017 04:50:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 04:50:22 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:50:22 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:50:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:50:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:50:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:50:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:50:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:52:39 [INFO] exp_shallowmodel: train time: 136.925s
12/10/2017 04:52:39 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:52:39 [INFO] exp_shallowmodel: accuracy:   0.530
12/10/2017 04:52:39 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 04:52:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:52:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.07      0.10        28
          C       0.43      0.60      0.50       172
          F       0.74      0.63      0.68       283
          R       0.34      0.30      0.32       123

avg / total       0.54      0.53      0.53       606

12/10/2017 04:52:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:52:39 [INFO] exp_shallowmodel: 
[[  2  14   4   8]
 [  2 104  30  36]
 [  3  74 178  28]
 [  4  52  30  37]]
12/10/2017 04:52:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 04:52:39 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:52:39 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:52:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:52:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:52:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:52:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:52:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:54:45 [INFO] exp_shallowmodel: train time: 125.856s
12/10/2017 04:54:45 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:54:45 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 04:54:45 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 04:54:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:54:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.10      0.13        20
          C       0.48      0.52      0.50       169
          F       0.68      0.72      0.70       281
          R       0.31      0.26      0.28       122

avg / total       0.53      0.55      0.54       592

12/10/2017 04:54:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:54:45 [INFO] exp_shallowmodel: 
[[  2   3   7   8]
 [  5  88  46  30]
 [  3  43 201  34]
 [  1  48  41  32]]
12/10/2017 04:54:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 04:54:45 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:54:45 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:54:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:54:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:54:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:54:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:54:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:57:14 [INFO] exp_shallowmodel: train time: 148.969s
12/10/2017 04:57:14 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:57:14 [INFO] exp_shallowmodel: accuracy:   0.568
12/10/2017 04:57:14 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 04:57:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:57:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.10      0.13        20
          C       0.47      0.78      0.59       169
          F       0.74      0.62      0.68       281
          R       0.41      0.23      0.29       122

avg / total       0.58      0.57      0.55       592

12/10/2017 04:57:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:57:14 [INFO] exp_shallowmodel: 
[[  2   8   6   4]
 [  2 131  25  11]
 [  3  77 175  26]
 [  4  61  29  28]]
12/10/2017 04:57:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 04:57:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:57:15 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:57:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:57:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:57:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:57:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:57:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:59:44 [INFO] exp_shallowmodel: train time: 149.637s
12/10/2017 04:59:44 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:59:44 [INFO] exp_shallowmodel: accuracy:   0.537
12/10/2017 04:59:44 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 04:59:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:59:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.58      0.53       169
          F       0.65      0.68      0.67       281
          R       0.34      0.24      0.28       122

avg / total       0.52      0.54      0.52       592

12/10/2017 04:59:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:59:44 [INFO] exp_shallowmodel: 
[[  0   7   9   4]
 [  2  98  47  22]
 [  3  56 191  31]
 [  7  40  46  29]]
12/10/2017 04:59:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 04:59:45 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:59:45 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 04:59:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:59:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:59:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:59:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:59:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:01:58 [INFO] exp_shallowmodel: train time: 133.623s
12/10/2017 05:01:58 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:01:58 [INFO] exp_shallowmodel: accuracy:   0.535
12/10/2017 05:01:58 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 05:01:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:01:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.10      0.16        20
          C       0.48      0.47      0.47       169
          F       0.63      0.72      0.67       281
          R       0.34      0.28      0.31       122

avg / total       0.52      0.54      0.52       592

12/10/2017 05:01:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:01:58 [INFO] exp_shallowmodel: 
[[  2   3   6   9]
 [  1  79  63  26]
 [  2  47 202  30]
 [  0  37  51  34]]
12/10/2017 05:01:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 05:01:59 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:01:59 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:01:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:01:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:01:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:01:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:01:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:04:14 [INFO] exp_shallowmodel: train time: 135.472s
12/10/2017 05:04:14 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:04:14 [INFO] exp_shallowmodel: accuracy:   0.520
12/10/2017 05:04:14 [INFO] exp_shallowmodel: f1_score:   0.372
12/10/2017 05:04:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:04:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.48      0.43      0.46       169
          F       0.61      0.71      0.66       281
          R       0.33      0.29      0.31       122

avg / total       0.50      0.52      0.51       592

12/10/2017 05:04:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:04:14 [INFO] exp_shallowmodel: 
[[  1   3   8   8]
 [  3  73  62  31]
 [  1  49 199  32]
 [  4  26  57  35]]
12/10/2017 05:04:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 05:04:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:04:15 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:04:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:04:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:04:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:04:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:04:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:06:32 [INFO] exp_shallowmodel: train time: 137.579s
12/10/2017 05:06:32 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:06:32 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 05:06:32 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 05:06:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:06:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.69      0.58       169
          F       0.72      0.65      0.68       281
          R       0.36      0.30      0.32       122

avg / total       0.56      0.56      0.56       592

12/10/2017 05:06:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:06:32 [INFO] exp_shallowmodel: 
[[  0   8   6   6]
 [  0 116  27  26]
 [  3  64 182  32]
 [  4  43  39  36]]
12/10/2017 05:06:33 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 05:06:33 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:06:33 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:06:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:06:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:06:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:06:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:06:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:08:47 [INFO] exp_shallowmodel: train time: 134.012s
12/10/2017 05:08:47 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:08:47 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 05:08:47 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 05:08:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:08:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.50      0.53      0.51       169
          F       0.66      0.72      0.69       281
          R       0.37      0.29      0.32       122

avg / total       0.54      0.56      0.54       592

12/10/2017 05:08:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:08:47 [INFO] exp_shallowmodel: 
[[  1   5  11   3]
 [  2  90  44  33]
 [  3  51 203  24]
 [  3  35  49  35]]
12/10/2017 05:08:47 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 05:08:47 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:08:47 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:08:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:08:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:08:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:08:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:08:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:11:18 [INFO] exp_shallowmodel: train time: 151.154s
12/10/2017 05:11:18 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:11:18 [INFO] exp_shallowmodel: accuracy:   0.530
12/10/2017 05:11:18 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 05:11:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:11:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.10      0.13        20
          C       0.44      0.58      0.50       169
          F       0.68      0.65      0.66       281
          R       0.35      0.26      0.30       122

avg / total       0.53      0.53      0.52       592

12/10/2017 05:11:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:11:18 [INFO] exp_shallowmodel: 
[[  2  10   4   4]
 [  3  98  39  29]
 [  2  70 182  27]
 [  3  44  43  32]]
12/10/2017 05:11:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 05:11:19 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:11:19 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:11:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:11:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:11:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:11:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:11:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:13:35 [INFO] exp_shallowmodel: train time: 136.657s
12/10/2017 05:13:35 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:13:35 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 05:13:35 [INFO] exp_shallowmodel: f1_score:   0.388
12/10/2017 05:13:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:13:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.54      0.49       169
          F       0.71      0.72      0.72       281
          R       0.38      0.31      0.34       122

avg / total       0.55      0.56      0.55       592

12/10/2017 05:13:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:13:35 [INFO] exp_shallowmodel: 
[[  0   6   8   6]
 [  1  91  45  32]
 [  3  52 202  24]
 [  4  51  29  38]]
12/10/2017 05:13:36 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 05:13:36 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 05:13:36 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:13:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:13:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:13:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:13:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:13:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:15:49 [INFO] exp_shallowmodel: train time: 133.688s
12/10/2017 05:15:49 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:15:49 [INFO] exp_shallowmodel: accuracy:   0.591
12/10/2017 05:15:49 [INFO] exp_shallowmodel: f1_score:   0.462
12/10/2017 05:15:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:15:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.14      0.23        28
          C       0.53      0.59      0.56       172
          F       0.69      0.76      0.72       283
          R       0.40      0.29      0.34       123

avg / total       0.58      0.59      0.57       606

12/10/2017 05:15:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:15:49 [INFO] exp_shallowmodel: 
[[  4   9  11   4]
 [  0 102  44  26]
 [  2  40 216  25]
 [  1  43  43  36]]
12/10/2017 05:15:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 05:15:50 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:15:50 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:15:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:15:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:15:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:15:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:15:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:18:09 [INFO] exp_shallowmodel: train time: 139.536s
12/10/2017 05:18:09 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:18:09 [INFO] exp_shallowmodel: accuracy:   0.584
12/10/2017 05:18:09 [INFO] exp_shallowmodel: f1_score:   0.465
12/10/2017 05:18:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:18:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.15      0.20        20
          C       0.48      0.67      0.56       169
          F       0.78      0.66      0.71       281
          R       0.41      0.37      0.39       122

avg / total       0.60      0.58      0.59       592

12/10/2017 05:18:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:18:09 [INFO] exp_shallowmodel: 
[[  3  11   2   4]
 [  2 113  26  28]
 [  3  59 185  34]
 [  2  51  24  45]]
12/10/2017 05:18:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 05:18:10 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:18:10 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:18:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:18:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:18:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:18:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:18:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:20:29 [INFO] exp_shallowmodel: train time: 139.589s
12/10/2017 05:20:29 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:20:29 [INFO] exp_shallowmodel: accuracy:   0.537
12/10/2017 05:20:29 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 05:20:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:20:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.46      0.60      0.52       169
          F       0.72      0.62      0.67       281
          R       0.33      0.32      0.32       122

avg / total       0.55      0.54      0.54       592

12/10/2017 05:20:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:20:29 [INFO] exp_shallowmodel: 
[[  2   6   5   7]
 [  2 102  27  38]
 [  2  69 175  35]
 [  1  47  35  39]]
12/10/2017 05:20:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 05:20:30 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:20:30 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:20:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:20:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:20:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:20:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:20:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:22:50 [INFO] exp_shallowmodel: train time: 140.374s
12/10/2017 05:22:50 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:22:50 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 05:22:50 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 05:22:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:22:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.05      0.08        20
          C       0.46      0.71      0.56       169
          F       0.77      0.64      0.70       281
          R       0.37      0.27      0.31       122

avg / total       0.58      0.56      0.56       592

12/10/2017 05:22:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:22:50 [INFO] exp_shallowmodel: 
[[  1  11   4   4]
 [  5 120  21  23]
 [  0  71 180  30]
 [  0  59  30  33]]
12/10/2017 05:22:51 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 05:22:51 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:22:51 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:22:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:22:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:22:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:22:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:22:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:25:02 [INFO] exp_shallowmodel: train time: 131.490s
12/10/2017 05:25:02 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:25:02 [INFO] exp_shallowmodel: accuracy:   0.541
12/10/2017 05:25:02 [INFO] exp_shallowmodel: f1_score:   0.373
12/10/2017 05:25:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:25:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.72      0.56       169
          F       0.71      0.61      0.66       281
          R       0.36      0.23      0.28       122

avg / total       0.54      0.54      0.53       592

12/10/2017 05:25:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:25:02 [INFO] exp_shallowmodel: 
[[  0   7   8   5]
 [  1 121  30  17]
 [  2  80 171  28]
 [  3  59  32  28]]
12/10/2017 05:25:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 05:25:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:25:02 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:25:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:25:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:25:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:25:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:25:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:27:19 [INFO] exp_shallowmodel: train time: 137.011s
12/10/2017 05:27:19 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:27:19 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 05:27:19 [INFO] exp_shallowmodel: f1_score:   0.388
12/10/2017 05:27:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:27:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.53      0.50      0.51       169
          F       0.63      0.77      0.69       281
          R       0.37      0.24      0.29       122

avg / total       0.53      0.56      0.54       592

12/10/2017 05:27:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:27:19 [INFO] exp_shallowmodel: 
[[  1   8  10   1]
 [  2  84  63  20]
 [  4  33 215  29]
 [  5  34  54  29]]
12/10/2017 05:27:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 05:27:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:27:20 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:27:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:27:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:27:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:27:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:27:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:29:30 [INFO] exp_shallowmodel: train time: 129.723s
12/10/2017 05:29:30 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:29:30 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 05:29:30 [INFO] exp_shallowmodel: f1_score:   0.378
12/10/2017 05:29:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:29:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.46      0.48       169
          F       0.65      0.74      0.69       281
          R       0.34      0.33      0.33       122

avg / total       0.53      0.55      0.54       592

12/10/2017 05:29:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:29:30 [INFO] exp_shallowmodel: 
[[  0   1  10   9]
 [  2  77  52  38]
 [  0  42 209  30]
 [  3  29  50  40]]
12/10/2017 05:29:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 05:29:30 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:29:30 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:29:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:29:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:29:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:29:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:29:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:31:57 [INFO] exp_shallowmodel: train time: 147.057s
12/10/2017 05:31:57 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:31:57 [INFO] exp_shallowmodel: accuracy:   0.508
12/10/2017 05:31:57 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 05:31:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:31:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.15      0.19        20
          C       0.40      0.66      0.50       169
          F       0.72      0.60      0.65       281
          R       0.26      0.16      0.19       122

avg / total       0.52      0.51      0.50       592

12/10/2017 05:31:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:31:57 [INFO] exp_shallowmodel: 
[[  3  10   2   5]
 [  3 111  28  27]
 [  1  90 168  22]
 [  4  65  34  19]]
12/10/2017 05:31:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 05:31:57 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:31:57 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:31:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:31:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:31:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:31:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:31:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:34:12 [INFO] exp_shallowmodel: train time: 134.088s
12/10/2017 05:34:12 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:34:12 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 05:34:12 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 05:34:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:34:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.45      0.63      0.52       169
          F       0.71      0.64      0.67       281
          R       0.39      0.30      0.34       122

avg / total       0.55      0.55      0.54       592

12/10/2017 05:34:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:34:12 [INFO] exp_shallowmodel: 
[[  1   5   7   7]
 [  3 106  34  26]
 [  3  75 179  24]
 [  2  50  33  37]]
12/10/2017 05:34:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 05:34:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:34:12 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:34:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:34:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:34:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:34:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:34:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:36:25 [INFO] exp_shallowmodel: train time: 133.150s
12/10/2017 05:36:25 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:36:25 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 05:36:25 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 05:36:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:36:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.05      0.07        20
          C       0.50      0.48      0.49       169
          F       0.64      0.77      0.70       281
          R       0.34      0.23      0.27       122

avg / total       0.52      0.55      0.53       592

12/10/2017 05:36:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:36:25 [INFO] exp_shallowmodel: 
[[  1   6  11   2]
 [  1  81  60  27]
 [  1  38 216  26]
 [  7  36  51  28]]
12/10/2017 05:36:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 05:36:25 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 05:36:25 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:36:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:36:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:36:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:36:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:36:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:38:45 [INFO] exp_shallowmodel: train time: 139.859s
12/10/2017 05:38:45 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:38:45 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 05:38:45 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 05:38:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:38:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.07      0.11        28
          C       0.45      0.68      0.54       172
          F       0.75      0.64      0.69       283
          R       0.35      0.28      0.31       123

avg / total       0.56      0.55      0.54       606

12/10/2017 05:38:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:38:45 [INFO] exp_shallowmodel: 
[[  2   8   5  13]
 [  3 117  29  23]
 [  0  74 181  28]
 [  2  60  27  34]]
12/10/2017 05:38:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 05:38:46 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:38:46 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:38:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:38:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:38:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:38:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:38:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:41:15 [INFO] exp_shallowmodel: train time: 149.562s
12/10/2017 05:41:15 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:41:15 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 05:41:15 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 05:41:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:41:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.48      0.69      0.56       169
          F       0.73      0.64      0.68       281
          R       0.32      0.26      0.29       122

avg / total       0.56      0.55      0.55       592

12/10/2017 05:41:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:41:15 [INFO] exp_shallowmodel: 
[[  1   7   4   8]
 [  1 116  23  29]
 [  1  69 179  32]
 [  1  51  38  32]]
12/10/2017 05:41:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 05:41:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:41:16 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:41:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:41:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:41:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:41:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:41:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:43:46 [INFO] exp_shallowmodel: train time: 150.175s
12/10/2017 05:43:46 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:43:46 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 05:43:46 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 05:43:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:43:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.51      0.54      0.52       169
          F       0.63      0.71      0.67       281
          R       0.34      0.25      0.29       122

avg / total       0.52      0.55      0.53       592

12/10/2017 05:43:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:43:46 [INFO] exp_shallowmodel: 
[[  1   3   9   7]
 [  1  91  59  18]
 [  1  45 200  35]
 [  1  41  49  31]]
12/10/2017 05:43:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 05:43:46 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:43:46 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:43:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:43:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:43:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:43:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:43:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:46:21 [INFO] exp_shallowmodel: train time: 154.454s
12/10/2017 05:46:21 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:46:21 [INFO] exp_shallowmodel: accuracy:   0.519
12/10/2017 05:46:21 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 05:46:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:46:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.10      0.14        20
          C       0.42      0.57      0.49       169
          F       0.67      0.65      0.66       281
          R       0.31      0.21      0.25       122

avg / total       0.51      0.52      0.51       592

12/10/2017 05:46:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:46:21 [INFO] exp_shallowmodel: 
[[  2  12   4   2]
 [  1  96  47  25]
 [  2  65 183  31]
 [  4  53  39  26]]
12/10/2017 05:46:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 05:46:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:46:21 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:46:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:46:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:46:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:46:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:46:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:48:40 [INFO] exp_shallowmodel: train time: 138.842s
12/10/2017 05:48:40 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:48:40 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 05:48:40 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 05:48:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:48:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.68      0.58       169
          F       0.72      0.66      0.69       281
          R       0.45      0.36      0.40       122

avg / total       0.58      0.58      0.58       592

12/10/2017 05:48:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:48:40 [INFO] exp_shallowmodel: 
[[  0   7   9   4]
 [  4 115  28  22]
 [  3  64 186  28]
 [  0  44  34  44]]
12/10/2017 05:48:40 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 05:48:40 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:48:40 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:48:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:48:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:48:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:48:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:48:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:51:06 [INFO] exp_shallowmodel: train time: 145.573s
12/10/2017 05:51:06 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:51:06 [INFO] exp_shallowmodel: accuracy:   0.505
12/10/2017 05:51:06 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 05:51:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:51:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.15      0.21        20
          C       0.42      0.35      0.38       169
          F       0.64      0.72      0.68       281
          R       0.28      0.29      0.28       122

avg / total       0.49      0.51      0.49       592

12/10/2017 05:51:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:51:06 [INFO] exp_shallowmodel: 
[[  3   6   3   8]
 [  1  59  65  44]
 [  3  38 202  38]
 [  2  38  47  35]]
12/10/2017 05:51:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 05:51:06 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:51:06 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:51:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:51:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:51:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:51:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:51:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:53:25 [INFO] exp_shallowmodel: train time: 138.838s
12/10/2017 05:53:25 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:53:25 [INFO] exp_shallowmodel: accuracy:   0.525
12/10/2017 05:53:25 [INFO] exp_shallowmodel: f1_score:   0.354
12/10/2017 05:53:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:53:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.40      0.45       169
          F       0.57      0.75      0.65       281
          R       0.38      0.27      0.32       122

avg / total       0.50      0.53      0.50       592

12/10/2017 05:53:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:53:25 [INFO] exp_shallowmodel: 
[[  0   5  10   5]
 [  1  67  81  20]
 [  4  38 211  28]
 [  3  19  67  33]]
12/10/2017 05:53:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 05:53:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:53:26 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:53:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:53:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:53:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:53:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:53:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:55:42 [INFO] exp_shallowmodel: train time: 136.742s
12/10/2017 05:55:42 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:55:42 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 05:55:42 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 05:55:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:55:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.47      0.44      0.45       169
          F       0.64      0.75      0.69       281
          R       0.38      0.30      0.33       122

avg / total       0.52      0.55      0.53       592

12/10/2017 05:55:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:55:42 [INFO] exp_shallowmodel: 
[[  2   3   8   7]
 [  2  74  66  27]
 [  0  45 211  25]
 [  3  37  46  36]]
12/10/2017 05:55:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 05:55:43 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:55:43 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:55:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:55:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:55:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:55:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:55:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:58:02 [INFO] exp_shallowmodel: train time: 139.606s
12/10/2017 05:58:02 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 05:58:02 [INFO] exp_shallowmodel: accuracy:   0.530
12/10/2017 05:58:02 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 05:58:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:58:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.05      0.07        20
          C       0.51      0.43      0.47       169
          F       0.67      0.73      0.70       281
          R       0.26      0.28      0.27       122

avg / total       0.52      0.53      0.52       592

12/10/2017 05:58:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:58:02 [INFO] exp_shallowmodel: 
[[  1   6   8   5]
 [  1  73  42  53]
 [  3  31 206  41]
 [  2  34  52  34]]
12/10/2017 05:58:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 05:58:03 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:58:03 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 05:58:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:58:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:58:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:58:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:58:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:00:30 [INFO] exp_shallowmodel: train time: 147.409s
12/10/2017 06:00:30 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:00:30 [INFO] exp_shallowmodel: accuracy:   0.561
12/10/2017 06:00:30 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 06:00:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:00:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.54      0.53       169
          F       0.66      0.69      0.68       281
          R       0.40      0.37      0.38       122

avg / total       0.54      0.56      0.55       592

12/10/2017 06:00:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:00:30 [INFO] exp_shallowmodel: 
[[  0   3  11   6]
 [  2  92  48  27]
 [  2  49 195  35]
 [  0  37  40  45]]
12/10/2017 06:00:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 06:00:31 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 06:00:31 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:00:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:00:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:00:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:00:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:00:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:02:52 [INFO] exp_shallowmodel: train time: 141.265s
12/10/2017 06:02:52 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:02:52 [INFO] exp_shallowmodel: accuracy:   0.525
12/10/2017 06:02:52 [INFO] exp_shallowmodel: f1_score:   0.368
12/10/2017 06:02:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:02:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.06        28
          C       0.48      0.43      0.45       172
          F       0.58      0.75      0.65       283
          R       0.39      0.25      0.31       123

avg / total       0.49      0.52      0.50       606

12/10/2017 06:02:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:02:52 [INFO] exp_shallowmodel: 
[[  1   6  16   5]
 [  2  74  79  17]
 [  0  45 212  26]
 [  3  29  60  31]]
12/10/2017 06:02:57 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 06:02:57 [INFO] task_runner: context=current, feature=8-skipthought
12/10/2017 06:02:57 [INFO] task_runner: retained feature numbers=[11.1]
12/10/2017 06:02:57 [INFO] task_runner: #(data)=3530
12/10/2017 06:02:57 [INFO] task_runner: #(feature)=2400
12/10/2017 06:02:57 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 06:02:57 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 06:02:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:02:57 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:02:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:02:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:02:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:02:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:02:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:03:27 [INFO] exp_shallowmodel: train time: 29.617s
12/10/2017 06:03:27 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:03:27 [INFO] exp_shallowmodel: accuracy:   0.662
12/10/2017 06:03:27 [INFO] exp_shallowmodel: f1_score:   0.292
12/10/2017 06:03:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:03:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.12      0.07      0.09        27
          F       0.73      0.89      0.80       250
          R       0.31      0.15      0.21        52

avg / total       0.59      0.66      0.61       352

12/10/2017 06:03:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:03:27 [INFO] exp_shallowmodel: 
[[  1   2  18   2]
 [  0   2  22   3]
 [  3  12 222  13]
 [  1   1  42   8]]
12/10/2017 06:03:27 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 06:03:27 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:03:27 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:03:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:03:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:03:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:03:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:03:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:03:54 [INFO] exp_shallowmodel: train time: 27.550s
12/10/2017 06:03:54 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:03:54 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 06:03:54 [INFO] exp_shallowmodel: f1_score:   0.326
12/10/2017 06:03:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:03:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.46      0.22      0.30        27
          F       0.73      0.90      0.81       250
          R       0.37      0.13      0.20        52

avg / total       0.61      0.68      0.63       352

12/10/2017 06:03:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:03:54 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   6  20   1]
 [  6   7 226  11]
 [  4   0  41   7]]
12/10/2017 06:03:55 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 06:03:55 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:03:55 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:03:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:03:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:03:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:03:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:03:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:04:26 [INFO] exp_shallowmodel: train time: 30.910s
12/10/2017 06:04:26 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:04:26 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 06:04:26 [INFO] exp_shallowmodel: f1_score:   0.303
12/10/2017 06:04:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:04:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.11      0.17        27
          F       0.73      0.93      0.82       250
          R       0.42      0.15      0.23        52

avg / total       0.61      0.69      0.63       352

12/10/2017 06:04:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:04:26 [INFO] exp_shallowmodel: 
[[  0   2  20   1]
 [  0   3  22   2]
 [  5   4 233   8]
 [  0   0  44   8]]
12/10/2017 06:04:26 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 06:04:26 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:04:26 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:04:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:04:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:04:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:04:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:04:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:04:57 [INFO] exp_shallowmodel: train time: 30.974s
12/10/2017 06:04:57 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:04:57 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 06:04:57 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 06:04:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:04:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.25      0.07      0.11        27
          F       0.73      0.94      0.82       250
          R       0.33      0.10      0.15        52

avg / total       0.60      0.69      0.62       352

12/10/2017 06:04:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:04:57 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   2  24   1]
 [  4   5 235   6]
 [  0   1  46   5]]
12/10/2017 06:04:57 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 06:04:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:04:57 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:04:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:04:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:04:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:04:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:04:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:05:27 [INFO] exp_shallowmodel: train time: 30.488s
12/10/2017 06:05:27 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:05:27 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 06:05:27 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 06:05:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:05:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.09      0.13        23
          C       0.21      0.11      0.15        27
          F       0.74      0.92      0.82       250
          R       0.42      0.15      0.23        52

avg / total       0.62      0.69      0.63       352

12/10/2017 06:05:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:05:27 [INFO] exp_shallowmodel: 
[[  2   2  19   0]
 [  2   3  20   2]
 [  3   8 230   9]
 [  0   1  43   8]]
12/10/2017 06:05:28 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 06:05:28 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:05:28 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:05:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:05:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:05:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:05:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:05:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:05:57 [INFO] exp_shallowmodel: train time: 29.163s
12/10/2017 06:05:57 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:05:57 [INFO] exp_shallowmodel: accuracy:   0.685
12/10/2017 06:05:57 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 06:05:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:05:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.31      0.19      0.23        27
          F       0.73      0.92      0.81       250
          R       0.29      0.10      0.14        52

avg / total       0.58      0.68      0.62       352

12/10/2017 06:05:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:05:57 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   5  20   2]
 [  2   7 231  10]
 [  0   4  43   5]]
12/10/2017 06:05:57 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 06:05:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:05:57 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:05:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:05:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:05:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:05:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:05:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:06:25 [INFO] exp_shallowmodel: train time: 28.064s
12/10/2017 06:06:25 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:06:25 [INFO] exp_shallowmodel: accuracy:   0.670
12/10/2017 06:06:25 [INFO] exp_shallowmodel: f1_score:   0.269
12/10/2017 06:06:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:06:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.04      0.06        23
          C       0.43      0.11      0.18        27
          F       0.72      0.92      0.81       250
          R       0.07      0.02      0.03        52

avg / total       0.56      0.67      0.60       352

12/10/2017 06:06:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:06:25 [INFO] exp_shallowmodel: 
[[  1   1  21   0]
 [  3   3  19   2]
 [  5   2 231  12]
 [  1   1  49   1]]
12/10/2017 06:06:25 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 06:06:25 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:06:25 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:06:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:06:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:06:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:06:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:06:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:06:55 [INFO] exp_shallowmodel: train time: 30.099s
12/10/2017 06:06:55 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:06:55 [INFO] exp_shallowmodel: accuracy:   0.685
12/10/2017 06:06:55 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 06:06:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:06:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.20      0.07      0.11        27
          F       0.73      0.93      0.82       250
          R       0.29      0.12      0.16        52

avg / total       0.59      0.68      0.62       352

12/10/2017 06:06:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:06:55 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   2  20   5]
 [  4   6 232   8]
 [  0   2  44   6]]
12/10/2017 06:06:56 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 06:06:56 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:06:56 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:06:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:06:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:06:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:06:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:06:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:07:23 [INFO] exp_shallowmodel: train time: 27.706s
12/10/2017 06:07:23 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:07:23 [INFO] exp_shallowmodel: accuracy:   0.685
12/10/2017 06:07:23 [INFO] exp_shallowmodel: f1_score:   0.305
12/10/2017 06:07:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:07:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.45      0.19      0.26        27
          F       0.73      0.92      0.81       250
          R       0.26      0.10      0.14        52

avg / total       0.59      0.68      0.62       352

12/10/2017 06:07:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:07:23 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  0   5  22   0]
 [  4   5 231  10]
 [  1   1  45   5]]
12/10/2017 06:07:24 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 06:07:24 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:07:24 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:07:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:07:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:07:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:07:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:07:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:07:53 [INFO] exp_shallowmodel: train time: 29.061s
12/10/2017 06:07:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:07:53 [INFO] exp_shallowmodel: accuracy:   0.671
12/10/2017 06:07:53 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 06:07:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:07:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        25
          C       0.14      0.07      0.10        27
          F       0.72      0.93      0.81       251
          R       0.39      0.12      0.18        59

avg / total       0.58      0.67      0.60       362

12/10/2017 06:07:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:07:53 [INFO] exp_shallowmodel: 
[[  1   0  23   1]
 [  0   2  22   3]
 [  4   7 233   7]
 [  0   5  47   7]]
12/10/2017 06:07:53 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 06:07:53 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:07:53 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:07:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:07:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:07:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:07:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:07:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:08:20 [INFO] exp_shallowmodel: train time: 27.045s
12/10/2017 06:08:20 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:08:20 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 06:08:20 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 06:08:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:08:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.30      0.11      0.16        27
          F       0.75      0.94      0.83       250
          R       0.28      0.13      0.18        52

avg / total       0.61      0.70      0.64       352

12/10/2017 06:08:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:08:20 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   3  19   5]
 [  2   4 234  10]
 [  2   3  40   7]]
12/10/2017 06:08:20 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 06:08:20 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:08:20 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:08:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:08:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:08:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:08:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:08:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:08:45 [INFO] exp_shallowmodel: train time: 24.629s
12/10/2017 06:08:45 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:08:45 [INFO] exp_shallowmodel: accuracy:   0.668
12/10/2017 06:08:45 [INFO] exp_shallowmodel: f1_score:   0.282
12/10/2017 06:08:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:08:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.19      0.24        27
          F       0.73      0.91      0.81       250
          R       0.14      0.06      0.08        52

avg / total       0.57      0.67      0.61       352

12/10/2017 06:08:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:08:45 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  0   5  20   2]
 [  3   7 227  13]
 [  2   2  45   3]]
12/10/2017 06:08:45 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 06:08:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:08:45 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:08:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:08:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:08:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:08:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:08:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:09:19 [INFO] exp_shallowmodel: train time: 34.025s
12/10/2017 06:09:19 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:09:19 [INFO] exp_shallowmodel: accuracy:   0.665
12/10/2017 06:09:19 [INFO] exp_shallowmodel: f1_score:   0.252
12/10/2017 06:09:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:09:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.29      0.07      0.12        27
          F       0.73      0.92      0.81       250
          R       0.13      0.06      0.08        52

avg / total       0.56      0.66      0.60       352

12/10/2017 06:09:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:09:19 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  1   2  23   1]
 [  1   4 229  16]
 [  5   1  43   3]]
12/10/2017 06:09:19 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 06:09:19 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:09:19 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:09:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:09:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:09:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:09:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:09:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:09:50 [INFO] exp_shallowmodel: train time: 30.701s
12/10/2017 06:09:50 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:09:50 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 06:09:50 [INFO] exp_shallowmodel: f1_score:   0.321
12/10/2017 06:09:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:09:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.33      0.11      0.17        27
          F       0.73      0.93      0.82       250
          R       0.42      0.15      0.23        52

avg / total       0.62      0.70      0.63       352

12/10/2017 06:09:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:09:50 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   3  24   0]
 [  3   5 233   9]
 [  0   1  43   8]]
12/10/2017 06:09:50 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 06:09:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:09:50 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:09:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:09:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:09:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:09:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:09:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:10:22 [INFO] exp_shallowmodel: train time: 31.571s
12/10/2017 06:10:22 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:10:22 [INFO] exp_shallowmodel: accuracy:   0.685
12/10/2017 06:10:22 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 06:10:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:10:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.18      0.07      0.11        27
          F       0.73      0.92      0.81       250
          R       0.41      0.17      0.24        52

avg / total       0.59      0.68      0.62       352

12/10/2017 06:10:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:10:22 [INFO] exp_shallowmodel: 
[[  0   2  20   1]
 [  1   2  23   1]
 [  3   6 230  11]
 [  0   1  42   9]]
12/10/2017 06:10:22 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 06:10:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:10:22 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:10:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:10:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:10:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:10:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:10:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:10:56 [INFO] exp_shallowmodel: train time: 33.687s
12/10/2017 06:10:56 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:10:56 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 06:10:56 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 06:10:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:10:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.27      0.11      0.16        27
          F       0.75      0.96      0.84       250
          R       0.47      0.13      0.21        52

avg / total       0.62      0.71      0.64       352

12/10/2017 06:10:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:10:56 [INFO] exp_shallowmodel: 
[[  0   1  22   0]
 [  0   3  20   4]
 [  2   5 239   4]
 [  5   2  38   7]]
12/10/2017 06:10:56 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 06:10:56 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:10:56 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:10:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:10:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:10:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:10:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:10:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:11:28 [INFO] exp_shallowmodel: train time: 32.112s
12/10/2017 06:11:28 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:11:28 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 06:11:28 [INFO] exp_shallowmodel: f1_score:   0.322
12/10/2017 06:11:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:11:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.09      0.11        23
          C       0.27      0.11      0.16        27
          F       0.75      0.92      0.83       250
          R       0.35      0.13      0.19        52

avg / total       0.61      0.69      0.63       352

12/10/2017 06:11:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:11:28 [INFO] exp_shallowmodel: 
[[  2   0  18   3]
 [  1   3  21   2]
 [  6   6 230   8]
 [  5   2  38   7]]
12/10/2017 06:11:28 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 06:11:28 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:11:28 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:11:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:11:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:11:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:11:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:11:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:11:59 [INFO] exp_shallowmodel: train time: 30.264s
12/10/2017 06:11:59 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:11:59 [INFO] exp_shallowmodel: accuracy:   0.670
12/10/2017 06:11:59 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 06:11:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:11:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.09      0.12        23
          C       0.47      0.26      0.33        27
          F       0.73      0.90      0.81       250
          R       0.11      0.04      0.06        52

avg / total       0.58      0.67      0.61       352

12/10/2017 06:11:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:11:59 [INFO] exp_shallowmodel: 
[[  2   0  21   0]
 [  2   7  14   4]
 [  6   7 225  12]
 [  1   1  48   2]]
12/10/2017 06:11:59 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 06:11:59 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:11:59 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:11:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:11:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:11:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:11:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:11:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:12:31 [INFO] exp_shallowmodel: train time: 32.609s
12/10/2017 06:12:31 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:12:31 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 06:12:31 [INFO] exp_shallowmodel: f1_score:   0.278
12/10/2017 06:12:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:12:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.23      0.11      0.15        27
          F       0.72      0.93      0.81       250
          R       0.33      0.10      0.15        52

avg / total       0.58      0.68      0.61       352

12/10/2017 06:12:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:12:31 [INFO] exp_shallowmodel: 
[[  0   2  20   1]
 [  0   3  22   2]
 [  3   8 232   7]
 [  0   0  47   5]]
12/10/2017 06:12:32 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 06:12:32 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:12:32 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:12:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:12:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:12:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:12:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:12:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:13:01 [INFO] exp_shallowmodel: train time: 29.424s
12/10/2017 06:13:01 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:13:01 [INFO] exp_shallowmodel: accuracy:   0.674
12/10/2017 06:13:01 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 06:13:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:13:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.27      0.11      0.16        27
          F       0.72      0.94      0.82       251
          R       0.29      0.08      0.13        59

avg / total       0.57      0.67      0.60       362

12/10/2017 06:13:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:13:01 [INFO] exp_shallowmodel: 
[[  0   1  20   4]
 [  0   3  21   3]
 [  5   5 236   5]
 [  1   2  51   5]]
12/10/2017 06:13:01 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 06:13:01 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:13:01 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:13:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:13:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:13:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:13:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:13:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:13:33 [INFO] exp_shallowmodel: train time: 31.967s
12/10/2017 06:13:33 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:13:33 [INFO] exp_shallowmodel: accuracy:   0.665
12/10/2017 06:13:33 [INFO] exp_shallowmodel: f1_score:   0.284
12/10/2017 06:13:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:13:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        23
          C       0.29      0.19      0.23        27
          F       0.74      0.91      0.82       250
          R       0.05      0.02      0.03        52

avg / total       0.56      0.66      0.61       352

12/10/2017 06:13:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:13:33 [INFO] exp_shallowmodel: 
[[  1   1  16   5]
 [  1   5  17   4]
 [  4   8 227  11]
 [  2   3  46   1]]
12/10/2017 06:13:33 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 06:13:33 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:13:33 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:13:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:13:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:13:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:13:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:13:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:14:03 [INFO] exp_shallowmodel: train time: 29.109s
12/10/2017 06:14:03 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:14:03 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 06:14:03 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 06:14:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:14:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.07        23
          C       0.08      0.04      0.05        27
          F       0.73      0.92      0.81       250
          R       0.44      0.15      0.23        52

avg / total       0.60      0.68      0.62       352

12/10/2017 06:14:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:14:03 [INFO] exp_shallowmodel: 
[[  1   2  18   2]
 [  0   1  24   2]
 [  5  10 229   6]
 [  0   0  44   8]]
12/10/2017 06:14:03 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 06:14:03 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:14:03 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:14:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:14:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:14:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:14:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:14:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:14:32 [INFO] exp_shallowmodel: train time: 29.622s
12/10/2017 06:14:32 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:14:32 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 06:14:32 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 06:14:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:14:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.31      0.15      0.20        27
          F       0.73      0.92      0.81       250
          R       0.26      0.10      0.14        52

avg / total       0.58      0.68      0.61       352

12/10/2017 06:14:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:14:32 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  0   4  20   3]
 [  3   7 230  10]
 [  2   1  44   5]]
12/10/2017 06:14:33 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 06:14:33 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:14:33 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:14:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:14:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:14:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:14:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:14:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:15:01 [INFO] exp_shallowmodel: train time: 28.239s
12/10/2017 06:15:01 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:15:01 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 06:15:01 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 06:15:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:15:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.04      0.06        23
          C       0.36      0.15      0.21        27
          F       0.72      0.91      0.81       250
          R       0.33      0.10      0.15        52

avg / total       0.60      0.68      0.61       352

12/10/2017 06:15:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:15:01 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   4  22   1]
 [  7   7 228   8]
 [  2   0  45   5]]
12/10/2017 06:15:01 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 06:15:01 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:15:01 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:15:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:15:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:15:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:15:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:15:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:15:32 [INFO] exp_shallowmodel: train time: 30.799s
12/10/2017 06:15:32 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:15:32 [INFO] exp_shallowmodel: accuracy:   0.673
12/10/2017 06:15:32 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 06:15:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:15:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.24      0.15      0.18        27
          F       0.73      0.90      0.81       250
          R       0.33      0.15      0.21        52

avg / total       0.60      0.67      0.62       352

12/10/2017 06:15:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:15:32 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   4  22   1]
 [  3  11 224  12]
 [  1   1  42   8]]
12/10/2017 06:15:32 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 06:15:32 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:15:32 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:15:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:15:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:15:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:15:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:15:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:16:04 [INFO] exp_shallowmodel: train time: 31.621s
12/10/2017 06:16:04 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:16:04 [INFO] exp_shallowmodel: accuracy:   0.685
12/10/2017 06:16:04 [INFO] exp_shallowmodel: f1_score:   0.333
12/10/2017 06:16:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:16:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.44      0.15      0.22        27
          F       0.73      0.91      0.81       250
          R       0.35      0.17      0.23        52

avg / total       0.62      0.68      0.63       352

12/10/2017 06:16:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:16:04 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   4  22   1]
 [  3   4 227  16]
 [  0   1  42   9]]
12/10/2017 06:16:04 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 06:16:04 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:16:04 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:16:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:16:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:16:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:16:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:16:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:16:34 [INFO] exp_shallowmodel: train time: 30.104s
12/10/2017 06:16:34 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:16:34 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 06:16:34 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 06:16:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:16:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.24      0.15      0.18        27
          F       0.75      0.93      0.83       250
          R       0.24      0.08      0.12        52

avg / total       0.59      0.69      0.63       352

12/10/2017 06:16:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:16:34 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  1   4  20   2]
 [  2   4 233  11]
 [  3   9  36   4]]
12/10/2017 06:16:34 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 06:16:34 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:16:34 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:16:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:16:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:16:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:16:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:16:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:17:05 [INFO] exp_shallowmodel: train time: 30.325s
12/10/2017 06:17:05 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:17:05 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 06:17:05 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 06:17:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:17:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        23
          C       0.50      0.22      0.31        27
          F       0.73      0.93      0.82       250
          R       0.21      0.06      0.09        52

avg / total       0.60      0.69      0.62       352

12/10/2017 06:17:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:17:05 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  2   6  17   2]
 [  3   6 232   9]
 [  3   0  46   3]]
12/10/2017 06:17:05 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 06:17:05 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:17:05 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:17:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:17:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:17:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:17:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:17:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:17:35 [INFO] exp_shallowmodel: train time: 30.577s
12/10/2017 06:17:35 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:17:35 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 06:17:35 [INFO] exp_shallowmodel: f1_score:   0.287
12/10/2017 06:17:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:17:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        23
          C       0.20      0.11      0.14        27
          F       0.73      0.92      0.82       250
          R       0.29      0.08      0.12        52

avg / total       0.59      0.68      0.61       352

12/10/2017 06:17:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:17:35 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   3  22   2]
 [  4  10 231   5]
 [  3   2  43   4]]
12/10/2017 06:17:36 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 06:17:36 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:17:36 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:17:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:17:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:17:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:17:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:17:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:18:05 [INFO] exp_shallowmodel: train time: 29.170s
12/10/2017 06:18:05 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:18:05 [INFO] exp_shallowmodel: accuracy:   0.657
12/10/2017 06:18:05 [INFO] exp_shallowmodel: f1_score:   0.296
12/10/2017 06:18:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:18:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        25
          C       0.23      0.11      0.15        27
          F       0.71      0.90      0.79       251
          R       0.37      0.12      0.18        59

avg / total       0.58      0.66      0.59       362

12/10/2017 06:18:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:18:05 [INFO] exp_shallowmodel: 
[[  1   0  22   2]
 [  1   3  23   0]
 [  7   7 227  10]
 [  0   3  49   7]]
12/10/2017 06:18:05 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 06:18:05 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:18:05 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:18:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:18:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:18:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:18:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:18:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:18:35 [INFO] exp_shallowmodel: train time: 30.184s
12/10/2017 06:18:35 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:18:35 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 06:18:35 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 06:18:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:18:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.40      0.15      0.22        27
          F       0.72      0.93      0.81       250
          R       0.29      0.08      0.12        52

avg / total       0.60      0.69      0.62       352

12/10/2017 06:18:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:18:35 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  1   4  22   0]
 [  2   5 233  10]
 [  1   1  46   4]]
12/10/2017 06:18:35 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 06:18:35 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:18:35 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:18:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:18:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:18:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:18:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:18:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:19:07 [INFO] exp_shallowmodel: train time: 31.716s
12/10/2017 06:19:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:19:07 [INFO] exp_shallowmodel: accuracy:   0.662
12/10/2017 06:19:07 [INFO] exp_shallowmodel: f1_score:   0.296
12/10/2017 06:19:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:19:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.31      0.19      0.23        27
          F       0.74      0.89      0.81       250
          R       0.19      0.12      0.14        52

avg / total       0.58      0.66      0.61       352

12/10/2017 06:19:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:19:07 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  1   5  19   2]
 [  2   6 222  20]
 [  1   4  41   6]]
12/10/2017 06:19:07 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 06:19:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:19:07 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:19:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:19:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:19:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:19:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:19:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:19:41 [INFO] exp_shallowmodel: train time: 33.315s
12/10/2017 06:19:41 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:19:41 [INFO] exp_shallowmodel: accuracy:   0.670
12/10/2017 06:19:41 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 06:19:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:19:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.04      0.05        23
          C       0.33      0.15      0.21        27
          F       0.72      0.90      0.80       250
          R       0.44      0.13      0.21        52

avg / total       0.61      0.67      0.62       352

12/10/2017 06:19:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:19:41 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  1   4  21   1]
 [ 11   7 224   8]
 [  1   1  43   7]]
12/10/2017 06:19:41 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 06:19:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:19:41 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:19:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:19:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:19:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:19:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:19:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:20:14 [INFO] exp_shallowmodel: train time: 32.983s
12/10/2017 06:20:14 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:20:14 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 06:20:14 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 06:20:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:20:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.07        23
          C       0.25      0.15      0.19        27
          F       0.74      0.93      0.83       250
          R       0.29      0.10      0.14        52

avg / total       0.60      0.69      0.63       352

12/10/2017 06:20:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:20:14 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  1   4  20   2]
 [  2   7 233   8]
 [  2   5  40   5]]
12/10/2017 06:20:14 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 06:20:14 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:20:14 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:20:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:20:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:20:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:20:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:20:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:20:46 [INFO] exp_shallowmodel: train time: 31.720s
12/10/2017 06:20:46 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:20:46 [INFO] exp_shallowmodel: accuracy:   0.665
12/10/2017 06:20:46 [INFO] exp_shallowmodel: f1_score:   0.240
12/10/2017 06:20:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:20:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.14      0.04      0.06        27
          F       0.71      0.92      0.80       250
          R       0.08      0.02      0.03        52

avg / total       0.54      0.66      0.58       352

12/10/2017 06:20:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:20:46 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  1   1  24   1]
 [  3   5 231  11]
 [  0   1  50   1]]
12/10/2017 06:20:46 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 06:20:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:20:46 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:20:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:20:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:20:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:20:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:20:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:21:17 [INFO] exp_shallowmodel: train time: 30.811s
12/10/2017 06:21:17 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:21:17 [INFO] exp_shallowmodel: accuracy:   0.662
12/10/2017 06:21:17 [INFO] exp_shallowmodel: f1_score:   0.252
12/10/2017 06:21:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:21:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        23
          C       0.08      0.04      0.05        27
          F       0.72      0.91      0.80       250
          R       0.21      0.06      0.09        52

avg / total       0.56      0.66      0.59       352

12/10/2017 06:21:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:21:17 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   1  26   0]
 [  6   7 228   9]
 [  1   4  44   3]]
12/10/2017 06:21:17 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 06:21:17 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:21:17 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:21:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:21:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:21:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:21:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:21:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:21:46 [INFO] exp_shallowmodel: train time: 28.436s
12/10/2017 06:21:46 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:21:46 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 06:21:46 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 06:21:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:21:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.15      0.21        27
          F       0.75      0.94      0.84       250
          R       0.47      0.15      0.23        52

avg / total       0.63      0.70      0.64       352

12/10/2017 06:21:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:21:46 [INFO] exp_shallowmodel: 
[[  0   3  19   1]
 [  0   4  19   4]
 [  6   4 236   4]
 [  2   1  41   8]]
12/10/2017 06:21:46 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 06:21:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:21:46 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:21:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:21:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:21:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:21:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:21:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:22:17 [INFO] exp_shallowmodel: train time: 31.506s
12/10/2017 06:22:17 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:22:17 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 06:22:17 [INFO] exp_shallowmodel: f1_score:   0.300
12/10/2017 06:22:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:22:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.22      0.15      0.18        27
          F       0.74      0.91      0.82       250
          R       0.32      0.15      0.21        52

avg / total       0.59      0.68      0.62       352

12/10/2017 06:22:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:22:17 [INFO] exp_shallowmodel: 
[[  0   2  18   3]
 [  0   4  21   2]
 [  1  10 227  12]
 [  1   2  41   8]]
12/10/2017 06:22:18 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 06:22:18 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:22:18 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:22:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:22:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:22:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:22:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:22:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:22:46 [INFO] exp_shallowmodel: train time: 28.807s
12/10/2017 06:22:46 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:22:46 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 06:22:46 [INFO] exp_shallowmodel: f1_score:   0.297
12/10/2017 06:22:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:22:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.33      0.11      0.17        27
          F       0.73      0.92      0.82       250
          R       0.25      0.10      0.14        52

avg / total       0.59      0.68      0.62       352

12/10/2017 06:22:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:22:46 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   3  21   3]
 [  3   5 231  11]
 [  3   1  43   5]]
12/10/2017 06:22:47 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 06:22:47 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:22:47 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:22:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:22:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:22:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:22:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:22:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:23:13 [INFO] exp_shallowmodel: train time: 26.174s
12/10/2017 06:23:13 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:23:13 [INFO] exp_shallowmodel: accuracy:   0.657
12/10/2017 06:23:13 [INFO] exp_shallowmodel: f1_score:   0.253
12/10/2017 06:23:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:23:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.25      0.11      0.15        27
          F       0.71      0.93      0.80       251
          R       0.12      0.03      0.05        59

avg / total       0.53      0.66      0.58       362

12/10/2017 06:23:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:23:13 [INFO] exp_shallowmodel: 
[[  0   1  23   1]
 [  0   3  21   3]
 [  1   7 233  10]
 [  4   1  52   2]]
12/10/2017 06:23:13 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 06:23:13 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:23:13 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:23:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:23:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:23:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:23:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:23:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:23:43 [INFO] exp_shallowmodel: train time: 30.289s
12/10/2017 06:23:43 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:23:43 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 06:23:43 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 06:23:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:23:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.21      0.11      0.15        27
          F       0.73      0.92      0.81       250
          R       0.44      0.13      0.21        52

avg / total       0.60      0.68      0.62       352

12/10/2017 06:23:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:23:43 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  2   3  21   1]
 [  6   9 229   6]
 [  0   2  43   7]]
12/10/2017 06:23:44 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 06:23:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:23:44 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:23:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:23:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:23:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:23:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:23:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:24:13 [INFO] exp_shallowmodel: train time: 29.334s
12/10/2017 06:24:13 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:24:13 [INFO] exp_shallowmodel: accuracy:   0.662
12/10/2017 06:24:13 [INFO] exp_shallowmodel: f1_score:   0.300
12/10/2017 06:24:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:24:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.04      0.06        23
          C       0.19      0.15      0.17        27
          F       0.74      0.89      0.81       250
          R       0.30      0.12      0.17        52

avg / total       0.59      0.66      0.61       352

12/10/2017 06:24:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:24:13 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  1   4  21   1]
 [  6  12 222  10]
 [  3   4  39   6]]
12/10/2017 06:24:13 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 06:24:13 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:24:13 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:24:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:24:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:24:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:24:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:24:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:24:41 [INFO] exp_shallowmodel: train time: 27.796s
12/10/2017 06:24:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:24:41 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 06:24:41 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 06:24:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:24:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.44      0.26      0.33        27
          F       0.74      0.93      0.82       250
          R       0.24      0.08      0.12        52

avg / total       0.59      0.69      0.63       352

12/10/2017 06:24:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:24:41 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   7  17   3]
 [  4   6 232   8]
 [  0   3  45   4]]
12/10/2017 06:24:41 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 06:24:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:24:41 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:24:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:24:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:24:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:24:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:24:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:25:11 [INFO] exp_shallowmodel: train time: 29.614s
12/10/2017 06:25:11 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:25:11 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 06:25:11 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 06:25:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:25:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.06        23
          C       0.27      0.11      0.16        27
          F       0.72      0.87      0.79       250
          R       0.15      0.08      0.10        52

avg / total       0.56      0.64      0.59       352

12/10/2017 06:25:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:25:11 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  0   3  22   2]
 [  9   7 217  17]
 [  2   0  46   4]]
12/10/2017 06:25:11 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 06:25:11 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:25:11 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:25:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:25:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:25:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:25:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:25:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:25:40 [INFO] exp_shallowmodel: train time: 29.299s
12/10/2017 06:25:40 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:25:40 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 06:25:40 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 06:25:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:25:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.09      0.13        23
          C       0.25      0.15      0.19        27
          F       0.74      0.93      0.82       250
          R       0.31      0.08      0.12        52

avg / total       0.61      0.69      0.63       352

12/10/2017 06:25:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:25:40 [INFO] exp_shallowmodel: 
[[  2   2  19   0]
 [  0   4  21   2]
 [  2   8 233   7]
 [  4   2  42   4]]
12/10/2017 06:25:41 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 06:25:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:25:41 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:25:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:25:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:25:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:25:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:25:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:26:09 [INFO] exp_shallowmodel: train time: 28.466s
12/10/2017 06:26:09 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:26:09 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 06:26:09 [INFO] exp_shallowmodel: f1_score:   0.258
12/10/2017 06:26:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:26:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.08      0.04      0.05        27
          F       0.75      0.93      0.83       250
          R       0.23      0.12      0.15        52

avg / total       0.57      0.68      0.62       352

12/10/2017 06:26:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:26:09 [INFO] exp_shallowmodel: 
[[  0   1  17   5]
 [  0   1  21   5]
 [  3   5 232  10]
 [  1   5  40   6]]
12/10/2017 06:26:09 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 06:26:09 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:26:09 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:26:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:26:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:26:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:26:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:26:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:26:36 [INFO] exp_shallowmodel: train time: 27.210s
12/10/2017 06:26:36 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:26:36 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 06:26:36 [INFO] exp_shallowmodel: f1_score:   0.322
12/10/2017 06:26:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:26:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.44      0.15      0.22        27
          F       0.74      0.92      0.82       250
          R       0.43      0.17      0.25        52

avg / total       0.62      0.69      0.64       352

12/10/2017 06:26:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:26:36 [INFO] exp_shallowmodel: 
[[  0   1  20   2]
 [  1   4  21   1]
 [  6   4 231   9]
 [  2   0  41   9]]
12/10/2017 06:26:37 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 06:26:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:26:37 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:26:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:26:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:26:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:26:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:26:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:27:06 [INFO] exp_shallowmodel: train time: 29.625s
12/10/2017 06:27:06 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:27:06 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 06:27:06 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 06:27:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:27:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.46      0.22      0.30        27
          F       0.73      0.94      0.82       250
          R       0.09      0.02      0.03        52

avg / total       0.58      0.69      0.62       352

12/10/2017 06:27:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:27:06 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  0   6  20   1]
 [  2   4 236   8]
 [  1   2  48   1]]
12/10/2017 06:27:06 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 06:27:06 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:27:06 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:27:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:27:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:27:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:27:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:27:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:27:36 [INFO] exp_shallowmodel: train time: 29.644s
12/10/2017 06:27:36 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:27:36 [INFO] exp_shallowmodel: accuracy:   0.670
12/10/2017 06:27:36 [INFO] exp_shallowmodel: f1_score:   0.277
12/10/2017 06:27:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:27:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.22      0.07      0.11        27
          F       0.73      0.91      0.81       250
          R       0.30      0.13      0.19        52

avg / total       0.58      0.67      0.61       352

12/10/2017 06:27:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:27:36 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  1   2  22   2]
 [  6   6 227  11]
 [  3   1  41   7]]
12/10/2017 06:27:36 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 06:27:36 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:27:36 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:27:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:27:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:27:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:27:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:27:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:28:04 [INFO] exp_shallowmodel: train time: 27.909s
12/10/2017 06:28:04 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:28:04 [INFO] exp_shallowmodel: accuracy:   0.677
12/10/2017 06:28:04 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 06:28:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:28:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.06        25
          C       0.38      0.11      0.17        27
          F       0.71      0.92      0.81       251
          R       0.39      0.15      0.22        59

avg / total       0.60      0.68      0.61       362

12/10/2017 06:28:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:28:04 [INFO] exp_shallowmodel: 
[[  1   0  23   1]
 [  1   3  21   2]
 [  3   5 232  11]
 [  1   0  49   9]]
12/10/2017 06:28:10 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 06:28:10 [INFO] task_runner: context=current, feature=8-skipthought
12/10/2017 06:28:10 [INFO] task_runner: retained feature numbers=[11.1]
12/10/2017 06:28:10 [INFO] task_runner: #(data)=5241
12/10/2017 06:28:10 [INFO] task_runner: #(feature)=2400
12/10/2017 06:28:10 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 06:28:10 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 06:28:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:28:10 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:28:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:28:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:28:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:28:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:28:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:29:38 [INFO] exp_shallowmodel: train time: 87.702s
12/10/2017 06:29:38 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:29:38 [INFO] exp_shallowmodel: accuracy:   0.718
12/10/2017 06:29:38 [INFO] exp_shallowmodel: f1_score:   0.367
12/10/2017 06:29:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:29:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.20      0.24        59
          C       0.25      0.08      0.12        12
          F       0.81      0.88      0.84       396
          R       0.30      0.24      0.27        55

avg / total       0.68      0.72      0.70       522

12/10/2017 06:29:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:29:38 [INFO] exp_shallowmodel: 
[[ 12   0  38   9]
 [  1   1  10   0]
 [ 24   2 349  21]
 [  6   1  35  13]]
12/10/2017 06:29:38 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 06:29:38 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:29:38 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:29:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:29:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:29:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:29:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:29:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:31:03 [INFO] exp_shallowmodel: train time: 85.227s
12/10/2017 06:31:03 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:31:03 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 06:31:03 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 06:31:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:31:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.19      0.20        59
          C       0.00      0.00      0.00        12
          F       0.81      0.86      0.83       396
          R       0.19      0.15      0.16        55

avg / total       0.66      0.69      0.67       522

12/10/2017 06:31:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:31:03 [INFO] exp_shallowmodel: 
[[ 11   2  39   7]
 [  4   0   8   0]
 [ 27   2 339  28]
 [ 11   4  32   8]]
12/10/2017 06:31:04 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 06:31:04 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:31:04 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:31:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:31:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:31:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:31:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:31:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:32:36 [INFO] exp_shallowmodel: train time: 92.190s
12/10/2017 06:32:36 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:32:36 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 06:32:36 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 06:32:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:32:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.29      0.30        59
          C       0.50      0.17      0.25        12
          F       0.80      0.86      0.83       396
          R       0.20      0.15      0.17        55

avg / total       0.68      0.71      0.69       522

12/10/2017 06:32:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:32:36 [INFO] exp_shallowmodel: 
[[ 17   1  35   6]
 [  3   2   6   1]
 [ 28   1 342  25]
 [  5   0  42   8]]
12/10/2017 06:32:36 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 06:32:36 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:32:36 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:32:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:32:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:32:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:32:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:32:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:34:08 [INFO] exp_shallowmodel: train time: 91.469s
12/10/2017 06:34:08 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:34:08 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 06:34:08 [INFO] exp_shallowmodel: f1_score:   0.359
12/10/2017 06:34:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:34:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.27      0.26        59
          C       0.14      0.08      0.11        12
          F       0.83      0.86      0.84       396
          R       0.27      0.20      0.23        55

avg / total       0.69      0.70      0.70       522

12/10/2017 06:34:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:34:08 [INFO] exp_shallowmodel: 
[[ 16   2  36   5]
 [  2   1   3   6]
 [ 35   2 340  19]
 [ 12   2  30  11]]
12/10/2017 06:34:08 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 06:34:08 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:34:08 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:34:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:34:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:34:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:34:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:34:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:35:44 [INFO] exp_shallowmodel: train time: 95.997s
12/10/2017 06:35:44 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:35:44 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 06:35:44 [INFO] exp_shallowmodel: f1_score:   0.346
12/10/2017 06:35:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:35:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.24      0.29        59
          C       0.17      0.08      0.11        12
          F       0.81      0.88      0.84       396
          R       0.16      0.13      0.14        55

avg / total       0.68      0.71      0.69       522

12/10/2017 06:35:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:35:44 [INFO] exp_shallowmodel: 
[[ 14   1  35   9]
 [  2   1   7   2]
 [ 18   1 350  27]
 [  4   3  41   7]]
12/10/2017 06:35:44 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 06:35:44 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:35:44 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:35:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:35:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:35:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:35:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:35:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:37:18 [INFO] exp_shallowmodel: train time: 94.045s
12/10/2017 06:37:18 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:37:18 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 06:37:18 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 06:37:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:37:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.19      0.21        59
          C       0.00      0.00      0.00        12
          F       0.83      0.88      0.85       396
          R       0.27      0.24      0.25        55

avg / total       0.69      0.71      0.70       522

12/10/2017 06:37:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:37:18 [INFO] exp_shallowmodel: 
[[ 11   1  32  15]
 [  1   0  11   0]
 [ 21   6 349  20]
 [ 12   1  29  13]]
12/10/2017 06:37:19 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 06:37:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:37:19 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:37:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:37:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:37:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:37:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:37:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:38:55 [INFO] exp_shallowmodel: train time: 96.241s
12/10/2017 06:38:55 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:38:55 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 06:38:55 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 06:38:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:38:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.19      0.22        59
          C       0.29      0.17      0.21        12
          F       0.82      0.89      0.85       396
          R       0.28      0.24      0.26        55

avg / total       0.69      0.72      0.70       522

12/10/2017 06:38:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:38:55 [INFO] exp_shallowmodel: 
[[ 11   2  35  11]
 [  1   2   8   1]
 [ 21   3 351  21]
 [  7   0  35  13]]
12/10/2017 06:38:55 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 06:38:55 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:38:55 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:38:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:38:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:38:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:38:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:38:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:40:24 [INFO] exp_shallowmodel: train time: 88.260s
12/10/2017 06:40:24 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:40:24 [INFO] exp_shallowmodel: accuracy:   0.720
12/10/2017 06:40:24 [INFO] exp_shallowmodel: f1_score:   0.378
12/10/2017 06:40:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:40:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.22      0.26        59
          C       0.50      0.08      0.14        12
          F       0.81      0.88      0.85       396
          R       0.27      0.25      0.26        55

avg / total       0.69      0.72      0.70       522

12/10/2017 06:40:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:40:24 [INFO] exp_shallowmodel: 
[[ 13   0  35  11]
 [  2   1   7   2]
 [ 23   1 348  24]
 [  4   0  37  14]]
12/10/2017 06:40:24 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 06:40:24 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:40:24 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:40:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:40:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:40:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:40:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:40:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:41:53 [INFO] exp_shallowmodel: train time: 88.644s
12/10/2017 06:41:53 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:41:53 [INFO] exp_shallowmodel: accuracy:   0.720
12/10/2017 06:41:53 [INFO] exp_shallowmodel: f1_score:   0.346
12/10/2017 06:41:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:41:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.20      0.24        59
          C       0.25      0.08      0.12        12
          F       0.82      0.90      0.86       396
          R       0.20      0.15      0.17        55

avg / total       0.68      0.72      0.70       522

12/10/2017 06:41:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:41:53 [INFO] exp_shallowmodel: 
[[ 12   0  40   7]
 [  2   1   7   2]
 [ 16   1 355  24]
 [ 13   2  32   8]]
12/10/2017 06:41:53 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 06:41:53 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:41:53 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:41:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:41:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:41:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:41:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:41:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:43:15 [INFO] exp_shallowmodel: train time: 81.777s
12/10/2017 06:43:15 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:43:15 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 06:43:15 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 06:43:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:43:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.28      0.30        64
          C       0.00      0.00      0.00        14
          F       0.81      0.88      0.84       402
          R       0.30      0.21      0.25        63

avg / total       0.67      0.71      0.69       543

12/10/2017 06:43:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:43:15 [INFO] exp_shallowmodel: 
[[ 18   0  37   9]
 [  3   0   8   3]
 [ 23   8 353  18]
 [ 12   0  38  13]]
12/10/2017 06:43:15 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 06:43:15 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:43:15 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:43:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:43:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:43:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:43:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:43:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:44:50 [INFO] exp_shallowmodel: train time: 94.484s
12/10/2017 06:44:50 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:44:50 [INFO] exp_shallowmodel: accuracy:   0.703
12/10/2017 06:44:50 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 06:44:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:44:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.19      0.22        59
          C       0.33      0.17      0.22        12
          F       0.80      0.86      0.83       396
          R       0.26      0.24      0.25        55

avg / total       0.67      0.70      0.69       522

12/10/2017 06:44:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:44:50 [INFO] exp_shallowmodel: 
[[ 11   1  39   8]
 [  0   2   9   1]
 [ 24   3 341  28]
 [  6   0  36  13]]
12/10/2017 06:44:50 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 06:44:50 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:44:50 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:44:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:44:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:44:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:44:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:44:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:46:19 [INFO] exp_shallowmodel: train time: 89.349s
12/10/2017 06:46:19 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:46:19 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 06:46:19 [INFO] exp_shallowmodel: f1_score:   0.390
12/10/2017 06:46:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:46:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.32      0.30        59
          C       0.33      0.17      0.22        12
          F       0.84      0.86      0.85       396
          R       0.23      0.16      0.19        55

avg / total       0.70      0.71      0.70       522

12/10/2017 06:46:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:46:19 [INFO] exp_shallowmodel: 
[[ 19   1  29  10]
 [  2   2   7   1]
 [ 34   0 342  20]
 [ 13   3  30   9]]
12/10/2017 06:46:20 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 06:46:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:46:20 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:46:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:46:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:46:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:46:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:46:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:47:47 [INFO] exp_shallowmodel: train time: 87.704s
12/10/2017 06:47:47 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:47:47 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 06:47:47 [INFO] exp_shallowmodel: f1_score:   0.304
12/10/2017 06:47:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:47:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.14      0.16        59
          C       0.00      0.00      0.00        12
          F       0.82      0.90      0.86       396
          R       0.23      0.18      0.20        55

avg / total       0.67      0.71      0.69       522

12/10/2017 06:47:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:47:47 [INFO] exp_shallowmodel: 
[[  8   1  41   9]
 [  6   0   6   0]
 [ 16   1 355  24]
 [ 14   1  30  10]]
12/10/2017 06:47:48 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 06:47:48 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:47:48 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:47:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:47:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:47:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:47:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:47:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:49:12 [INFO] exp_shallowmodel: train time: 83.933s
12/10/2017 06:49:12 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:49:12 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 06:49:12 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 06:49:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:49:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.15      0.16        59
          C       0.00      0.00      0.00        12
          F       0.79      0.86      0.82       396
          R       0.33      0.22      0.26        55

avg / total       0.66      0.69      0.67       522

12/10/2017 06:49:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:49:12 [INFO] exp_shallowmodel: 
[[  9   1  43   6]
 [  1   0  10   1]
 [ 36   4 339  17]
 [  7   1  35  12]]
12/10/2017 06:49:12 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 06:49:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:49:12 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:49:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:49:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:49:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:49:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:49:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:50:41 [INFO] exp_shallowmodel: train time: 89.241s
12/10/2017 06:50:41 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:50:41 [INFO] exp_shallowmodel: accuracy:   0.732
12/10/2017 06:50:41 [INFO] exp_shallowmodel: f1_score:   0.374
12/10/2017 06:50:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:50:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.19      0.22        59
          C       0.25      0.08      0.12        12
          F       0.83      0.90      0.86       396
          R       0.31      0.27      0.29        55

avg / total       0.70      0.73      0.71       522

12/10/2017 06:50:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:50:41 [INFO] exp_shallowmodel: 
[[ 11   1  31  16]
 [  2   1   8   1]
 [ 22   2 355  17]
 [  5   0  35  15]]
12/10/2017 06:50:42 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 06:50:42 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:50:42 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:50:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:50:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:50:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:50:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:50:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:52:24 [INFO] exp_shallowmodel: train time: 102.747s
12/10/2017 06:52:24 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:52:24 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 06:52:24 [INFO] exp_shallowmodel: f1_score:   0.363
12/10/2017 06:52:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:52:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.17      0.19        59
          C       0.22      0.17      0.19        12
          F       0.81      0.89      0.85       396
          R       0.28      0.18      0.22        55

avg / total       0.68      0.71      0.69       522

12/10/2017 06:52:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:52:24 [INFO] exp_shallowmodel: 
[[ 10   1  39   9]
 [  5   2   5   0]
 [ 22   6 351  17]
 [  7   0  38  10]]
12/10/2017 06:52:25 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 06:52:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:52:25 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:52:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:52:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:52:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:52:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:52:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:53:56 [INFO] exp_shallowmodel: train time: 90.823s
12/10/2017 06:53:56 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:53:56 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 06:53:56 [INFO] exp_shallowmodel: f1_score:   0.344
12/10/2017 06:53:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:53:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.19      0.22        59
          C       0.10      0.08      0.09        12
          F       0.82      0.86      0.84       396
          R       0.24      0.22      0.23        55

avg / total       0.68      0.70      0.69       522

12/10/2017 06:53:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:53:56 [INFO] exp_shallowmodel: 
[[ 11   2  38   8]
 [  0   1   9   2]
 [ 20   6 342  28]
 [ 12   1  30  12]]
12/10/2017 06:53:56 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 06:53:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:53:56 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:53:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:53:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:53:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:53:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:53:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:55:25 [INFO] exp_shallowmodel: train time: 89.002s
12/10/2017 06:55:25 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:55:25 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 06:55:25 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 06:55:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:55:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.20      0.21        59
          C       0.17      0.08      0.11        12
          F       0.82      0.85      0.83       396
          R       0.24      0.22      0.23        55

avg / total       0.67      0.69      0.68       522

12/10/2017 06:55:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:55:25 [INFO] exp_shallowmodel: 
[[ 12   3  34  10]
 [  3   1   7   1]
 [ 31   1 337  27]
 [  8   1  34  12]]
12/10/2017 06:55:25 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 06:55:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:55:25 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:55:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:55:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:55:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:55:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:55:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:56:59 [INFO] exp_shallowmodel: train time: 94.146s
12/10/2017 06:56:59 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 06:56:59 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 06:56:59 [INFO] exp_shallowmodel: f1_score:   0.313
12/10/2017 06:56:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:56:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.24      0.28        59
          C       0.00      0.00      0.00        12
          F       0.80      0.89      0.84       396
          R       0.16      0.11      0.13        55

avg / total       0.66      0.71      0.69       522

12/10/2017 06:56:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:56:59 [INFO] exp_shallowmodel: 
[[ 14   2  36   7]
 [  0   0   9   3]
 [ 19   3 352  22]
 [  8   0  41   6]]
12/10/2017 06:57:00 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 06:57:00 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:57:00 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:57:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:57:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:57:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:57:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:57:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:58:31 [INFO] exp_shallowmodel: train time: 91.447s
12/10/2017 06:58:31 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:58:31 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 06:58:31 [INFO] exp_shallowmodel: f1_score:   0.368
12/10/2017 06:58:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:58:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.28      0.31        64
          C       0.20      0.07      0.11        14
          F       0.81      0.89      0.85       402
          R       0.26      0.17      0.21        63

avg / total       0.67      0.71      0.69       543

12/10/2017 06:58:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:58:31 [INFO] exp_shallowmodel: 
[[ 18   1  35  10]
 [  1   1   8   4]
 [ 24   3 358  17]
 [  9   0  43  11]]
12/10/2017 06:58:32 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 06:58:32 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:58:32 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 06:58:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:58:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:58:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:58:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:58:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:00:01 [INFO] exp_shallowmodel: train time: 89.248s
12/10/2017 07:00:01 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:00:01 [INFO] exp_shallowmodel: accuracy:   0.720
12/10/2017 07:00:01 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 07:00:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:00:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.19      0.21        59
          C       0.00      0.00      0.00        12
          F       0.83      0.88      0.85       396
          R       0.30      0.27      0.29        55

avg / total       0.69      0.72      0.70       522

12/10/2017 07:00:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:00:01 [INFO] exp_shallowmodel: 
[[ 11   2  31  15]
 [  1   0   9   2]
 [ 27   1 350  18]
 [  5   1  34  15]]
12/10/2017 07:00:01 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 07:00:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:00:01 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:00:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:00:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:00:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:00:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:00:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:01:28 [INFO] exp_shallowmodel: train time: 86.457s
12/10/2017 07:01:28 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:01:28 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 07:01:28 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 07:01:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:01:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.24      0.27        59
          C       1.00      0.17      0.29        12
          F       0.81      0.88      0.84       396
          R       0.19      0.16      0.18        55

avg / total       0.69      0.71      0.70       522

12/10/2017 07:01:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:01:28 [INFO] exp_shallowmodel: 
[[ 14   0  37   8]
 [  1   2   6   3]
 [ 22   0 347  27]
 [  9   0  37   9]]
12/10/2017 07:01:28 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 07:01:28 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:01:28 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:01:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:01:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:01:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:01:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:01:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:02:57 [INFO] exp_shallowmodel: train time: 89.201s
12/10/2017 07:02:57 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:02:57 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 07:02:57 [INFO] exp_shallowmodel: f1_score:   0.358
12/10/2017 07:02:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:02:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.25      0.26        59
          C       0.33      0.08      0.13        12
          F       0.82      0.88      0.85       396
          R       0.24      0.16      0.19        55

avg / total       0.68      0.71      0.69       522

12/10/2017 07:02:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:02:57 [INFO] exp_shallowmodel: 
[[ 15   0  35   9]
 [  4   1   5   2]
 [ 29   2 347  18]
 [  9   0  37   9]]
12/10/2017 07:02:58 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 07:02:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:02:58 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:02:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:02:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:02:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:02:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:02:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:04:26 [INFO] exp_shallowmodel: train time: 88.527s
12/10/2017 07:04:26 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:04:26 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 07:04:26 [INFO] exp_shallowmodel: f1_score:   0.340
12/10/2017 07:04:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:04:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.24      0.28        59
          C       0.00      0.00      0.00        12
          F       0.81      0.88      0.84       396
          R       0.26      0.22      0.24        55

avg / total       0.68      0.72      0.70       522

12/10/2017 07:04:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:04:26 [INFO] exp_shallowmodel: 
[[ 14   1  41   3]
 [  4   0   7   1]
 [ 16   2 348  30]
 [  7   1  35  12]]
12/10/2017 07:04:26 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 07:04:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:04:26 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:04:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:04:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:04:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:04:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:04:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:05:59 [INFO] exp_shallowmodel: train time: 92.174s
12/10/2017 07:05:59 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:05:59 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 07:05:59 [INFO] exp_shallowmodel: f1_score:   0.340
12/10/2017 07:05:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:05:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.15      0.18        59
          C       0.25      0.08      0.12        12
          F       0.80      0.86      0.83       396
          R       0.24      0.22      0.23        55

avg / total       0.66      0.69      0.68       522

12/10/2017 07:05:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:05:59 [INFO] exp_shallowmodel: 
[[  9   2  40   8]
 [  1   1  10   0]
 [ 26   0 340  30]
 [  7   1  35  12]]
12/10/2017 07:05:59 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 07:05:59 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:05:59 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:05:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:05:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:05:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:05:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:05:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:07:29 [INFO] exp_shallowmodel: train time: 90.302s
12/10/2017 07:07:29 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:07:29 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 07:07:29 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 07:07:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:07:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.20      0.21        59
          C       0.17      0.08      0.11        12
          F       0.82      0.87      0.84       396
          R       0.22      0.16      0.19        55

avg / total       0.67      0.70      0.68       522

12/10/2017 07:07:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:07:29 [INFO] exp_shallowmodel: 
[[ 12   1  38   8]
 [  1   1   8   2]
 [ 28   2 344  22]
 [ 12   2  32   9]]
12/10/2017 07:07:30 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 07:07:30 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:07:30 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:07:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:07:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:07:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:07:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:07:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:08:56 [INFO] exp_shallowmodel: train time: 86.402s
12/10/2017 07:08:56 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:08:56 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 07:08:56 [INFO] exp_shallowmodel: f1_score:   0.321
12/10/2017 07:08:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:08:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.14      0.16        59
          C       0.00      0.00      0.00        12
          F       0.81      0.88      0.84       396
          R       0.36      0.24      0.29        55

avg / total       0.67      0.71      0.69       522

12/10/2017 07:08:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:08:56 [INFO] exp_shallowmodel: 
[[  8   4  40   7]
 [  0   0  12   0]
 [ 26   5 349  16]
 [  9   1  32  13]]
12/10/2017 07:08:56 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 07:08:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:08:56 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:08:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:08:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:08:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:08:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:08:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:10:31 [INFO] exp_shallowmodel: train time: 94.090s
12/10/2017 07:10:31 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:10:31 [INFO] exp_shallowmodel: accuracy:   0.703
12/10/2017 07:10:31 [INFO] exp_shallowmodel: f1_score:   0.339
12/10/2017 07:10:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:10:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.20      0.20        59
          C       0.00      0.00      0.00        12
          F       0.82      0.86      0.84       396
          R       0.36      0.29      0.32        55

avg / total       0.68      0.70      0.69       522

12/10/2017 07:10:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:10:31 [INFO] exp_shallowmodel: 
[[ 12   0  38   9]
 [  2   0   7   3]
 [ 38   2 339  17]
 [  9   0  30  16]]
12/10/2017 07:10:31 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 07:10:31 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:10:31 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:10:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:10:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:10:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:10:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:10:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:12:00 [INFO] exp_shallowmodel: train time: 89.371s
12/10/2017 07:12:00 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:12:00 [INFO] exp_shallowmodel: accuracy:   0.720
12/10/2017 07:12:00 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 07:12:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:12:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.29      0.32        59
          C       0.33      0.08      0.13        12
          F       0.81      0.87      0.84       396
          R       0.26      0.22      0.24        55

avg / total       0.69      0.72      0.70       522

12/10/2017 07:12:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:12:00 [INFO] exp_shallowmodel: 
[[ 17   0  36   6]
 [  2   1   9   0]
 [ 20   2 346  28]
 [  7   0  36  12]]
12/10/2017 07:12:01 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 07:12:01 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 07:12:01 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:12:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:12:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:12:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:12:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:12:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:13:23 [INFO] exp_shallowmodel: train time: 82.805s
12/10/2017 07:13:23 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:13:23 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 07:13:23 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 07:13:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:13:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.23      0.27        64
          C       0.25      0.14      0.18        14
          F       0.81      0.89      0.85       402
          R       0.32      0.25      0.28        63

avg / total       0.68      0.72      0.70       543

12/10/2017 07:13:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:13:23 [INFO] exp_shallowmodel: 
[[ 15   2  38   9]
 [  2   2   9   1]
 [ 19   3 356  24]
 [ 10   1  36  16]]
12/10/2017 07:13:24 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 07:13:24 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:13:24 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:13:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:13:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:13:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:13:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:13:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:14:47 [INFO] exp_shallowmodel: train time: 83.319s
12/10/2017 07:14:47 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:14:47 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 07:14:47 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 07:14:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:14:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.20      0.22        59
          C       0.10      0.08      0.09        12
          F       0.81      0.88      0.84       396
          R       0.23      0.13      0.16        55

avg / total       0.67      0.71      0.68       522

12/10/2017 07:14:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:14:47 [INFO] exp_shallowmodel: 
[[ 12   1  37   9]
 [  3   1   8   0]
 [ 26   6 349  15]
 [  9   2  37   7]]
12/10/2017 07:14:47 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 07:14:47 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:14:47 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:14:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:14:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:14:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:14:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:14:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:16:14 [INFO] exp_shallowmodel: train time: 86.160s
12/10/2017 07:16:14 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:16:14 [INFO] exp_shallowmodel: accuracy:   0.695
12/10/2017 07:16:14 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 07:16:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:16:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.19      0.21        59
          C       0.20      0.08      0.12        12
          F       0.81      0.87      0.84       396
          R       0.17      0.15      0.16        55

avg / total       0.66      0.70      0.68       522

12/10/2017 07:16:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:16:14 [INFO] exp_shallowmodel: 
[[ 11   0  36  12]
 [  2   1   9   0]
 [ 21   4 343  28]
 [ 10   0  37   8]]
12/10/2017 07:16:14 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 07:16:14 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:16:14 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:16:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:16:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:16:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:16:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:16:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:17:47 [INFO] exp_shallowmodel: train time: 92.541s
12/10/2017 07:17:47 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:17:47 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 07:17:47 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 07:17:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:17:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.19      0.20        59
          C       0.10      0.08      0.09        12
          F       0.82      0.86      0.84       396
          R       0.42      0.38      0.40        55

avg / total       0.70      0.71      0.70       522

12/10/2017 07:17:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:17:47 [INFO] exp_shallowmodel: 
[[ 11   3  39   6]
 [  1   1   9   1]
 [ 30   4 340  22]
 [  7   2  25  21]]
12/10/2017 07:17:47 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 07:17:47 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:17:47 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:17:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:17:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:17:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:17:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:17:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:19:22 [INFO] exp_shallowmodel: train time: 95.466s
12/10/2017 07:19:22 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:19:22 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 07:19:22 [INFO] exp_shallowmodel: f1_score:   0.350
12/10/2017 07:19:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:19:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.31      0.31        59
          C       0.00      0.00      0.00        12
          F       0.83      0.86      0.85       396
          R       0.25      0.24      0.24        55

avg / total       0.69      0.71      0.70       522

12/10/2017 07:19:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:19:22 [INFO] exp_shallowmodel: 
[[ 18   1  28  12]
 [  2   0   8   2]
 [ 28   1 341  26]
 [  9   1  32  13]]
12/10/2017 07:19:23 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 07:19:23 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:19:23 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:19:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:19:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:19:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:19:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:19:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:20:51 [INFO] exp_shallowmodel: train time: 87.811s
12/10/2017 07:20:51 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:20:51 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 07:20:51 [INFO] exp_shallowmodel: f1_score:   0.334
12/10/2017 07:20:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:20:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.12      0.15        59
          C       1.00      0.08      0.15        12
          F       0.81      0.89      0.85       396
          R       0.19      0.18      0.19        55

avg / total       0.68      0.71      0.68       522

12/10/2017 07:20:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:20:51 [INFO] exp_shallowmodel: 
[[  7   0  40  12]
 [  2   1   5   4]
 [ 19   0 351  26]
 [  8   0  37  10]]
12/10/2017 07:20:51 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 07:20:51 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:20:51 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:20:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:20:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:20:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:20:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:20:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:22:32 [INFO] exp_shallowmodel: train time: 100.752s
12/10/2017 07:22:32 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:22:32 [INFO] exp_shallowmodel: accuracy:   0.728
12/10/2017 07:22:32 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 07:22:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:22:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.24      0.27        59
          C       0.33      0.17      0.22        12
          F       0.82      0.90      0.86       396
          R       0.22      0.15      0.17        55

avg / total       0.69      0.73      0.70       522

12/10/2017 07:22:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:22:32 [INFO] exp_shallowmodel: 
[[ 14   2  34   9]
 [  3   2   7   0]
 [ 18   2 356  20]
 [  8   0  39   8]]
12/10/2017 07:22:32 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 07:22:32 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:22:32 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:22:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:22:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:22:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:22:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:22:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:23:59 [INFO] exp_shallowmodel: train time: 86.873s
12/10/2017 07:23:59 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:23:59 [INFO] exp_shallowmodel: accuracy:   0.739
12/10/2017 07:23:59 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 07:23:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:23:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.27      0.33        59
          C       0.30      0.25      0.27        12
          F       0.83      0.91      0.87       396
          R       0.19      0.15      0.16        55

avg / total       0.70      0.74      0.72       522

12/10/2017 07:23:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:23:59 [INFO] exp_shallowmodel: 
[[ 16   1  31  11]
 [  0   3   6   3]
 [ 15   2 359  20]
 [  7   4  36   8]]
12/10/2017 07:23:59 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 07:23:59 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:23:59 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:23:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:23:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:23:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:23:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:23:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:25:32 [INFO] exp_shallowmodel: train time: 93.250s
12/10/2017 07:25:32 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:25:32 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 07:25:32 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 07:25:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:25:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.17      0.21        59
          C       0.00      0.00      0.00        12
          F       0.81      0.88      0.85       396
          R       0.23      0.20      0.21        55

avg / total       0.67      0.71      0.69       522

12/10/2017 07:25:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:25:33 [INFO] exp_shallowmodel: 
[[ 10   2  36  11]
 [  1   0   8   3]
 [ 18   5 350  23]
 [  7   0  37  11]]
12/10/2017 07:25:33 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 07:25:33 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:25:33 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:25:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:25:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:25:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:25:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:25:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:27:03 [INFO] exp_shallowmodel: train time: 89.998s
12/10/2017 07:27:03 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:27:03 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 07:27:03 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 07:27:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:27:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.17      0.19        59
          C       0.40      0.17      0.24        12
          F       0.82      0.89      0.85       396
          R       0.36      0.25      0.30        55

avg / total       0.69      0.72      0.70       522

12/10/2017 07:27:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:27:03 [INFO] exp_shallowmodel: 
[[ 10   0  39  10]
 [  3   2   7   0]
 [ 27   3 351  15]
 [  9   0  32  14]]
12/10/2017 07:27:03 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 07:27:03 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 07:27:03 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:27:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:27:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:27:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:27:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:27:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:28:35 [INFO] exp_shallowmodel: train time: 91.380s
12/10/2017 07:28:35 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:28:35 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 07:28:35 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 07:28:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:28:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.25      0.28        64
          C       0.22      0.14      0.17        14
          F       0.80      0.88      0.84       402
          R       0.35      0.24      0.28        63

avg / total       0.68      0.71      0.69       543

12/10/2017 07:28:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:28:35 [INFO] exp_shallowmodel: 
[[ 16   2  39   7]
 [  1   2   9   2]
 [ 24   5 354  19]
 [ 10   0  38  15]]
12/10/2017 07:28:35 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 07:28:35 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:28:35 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:28:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:28:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:28:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:28:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:28:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:30:10 [INFO] exp_shallowmodel: train time: 95.245s
12/10/2017 07:30:10 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:30:10 [INFO] exp_shallowmodel: accuracy:   0.703
12/10/2017 07:30:10 [INFO] exp_shallowmodel: f1_score:   0.343
12/10/2017 07:30:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:30:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.24      0.26        59
          C       0.33      0.08      0.13        12
          F       0.80      0.87      0.84       396
          R       0.17      0.13      0.15        55

avg / total       0.67      0.70      0.68       522

12/10/2017 07:30:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:30:10 [INFO] exp_shallowmodel: 
[[ 14   0  35  10]
 [  3   1   7   1]
 [ 28   1 345  22]
 [  5   1  42   7]]
12/10/2017 07:30:11 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 07:30:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:30:11 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:30:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:30:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:30:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:30:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:30:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:31:46 [INFO] exp_shallowmodel: train time: 95.558s
12/10/2017 07:31:46 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:31:46 [INFO] exp_shallowmodel: accuracy:   0.718
12/10/2017 07:31:46 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 07:31:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:31:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.15      0.17        59
          C       0.00      0.00      0.00        12
          F       0.83      0.90      0.86       396
          R       0.28      0.18      0.22        55

avg / total       0.68      0.72      0.70       522

12/10/2017 07:31:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:31:46 [INFO] exp_shallowmodel: 
[[  9   1  39  10]
 [  1   0   8   3]
 [ 23   4 356  13]
 [ 17   1  27  10]]
12/10/2017 07:31:46 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 07:31:46 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:31:46 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:31:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:31:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:31:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:31:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:31:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:33:16 [INFO] exp_shallowmodel: train time: 89.614s
12/10/2017 07:33:16 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:33:16 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 07:33:16 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 07:33:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:33:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.20      0.23        59
          C       0.00      0.00      0.00        12
          F       0.82      0.85      0.84       396
          R       0.30      0.33      0.31        55

avg / total       0.69      0.70      0.70       522

12/10/2017 07:33:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:33:16 [INFO] exp_shallowmodel: 
[[ 12   2  33  12]
 [  1   0   8   3]
 [ 27   4 338  27]
 [  6   0  31  18]]
12/10/2017 07:33:16 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 07:33:16 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:33:16 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:33:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:33:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:33:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:33:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:33:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:34:44 [INFO] exp_shallowmodel: train time: 87.447s
12/10/2017 07:34:44 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:34:44 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 07:34:44 [INFO] exp_shallowmodel: f1_score:   0.365
12/10/2017 07:34:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:34:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.34      0.33        59
          C       0.00      0.00      0.00        12
          F       0.82      0.87      0.84       396
          R       0.37      0.24      0.29        55

avg / total       0.70      0.72      0.71       522

12/10/2017 07:34:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:34:44 [INFO] exp_shallowmodel: 
[[ 20   0  35   4]
 [  4   0   8   0]
 [ 31   2 345  18]
 [  8   0  34  13]]
12/10/2017 07:34:44 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 07:34:44 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:34:44 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:34:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:34:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:34:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:34:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:34:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:36:10 [INFO] exp_shallowmodel: train time: 86.022s
12/10/2017 07:36:10 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:36:10 [INFO] exp_shallowmodel: accuracy:   0.703
12/10/2017 07:36:10 [INFO] exp_shallowmodel: f1_score:   0.343
12/10/2017 07:36:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:36:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.27      0.29        59
          C       0.11      0.08      0.10        12
          F       0.81      0.87      0.84       396
          R       0.18      0.13      0.15        55

avg / total       0.67      0.70      0.69       522

12/10/2017 07:36:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:36:10 [INFO] exp_shallowmodel: 
[[ 16   2  36   5]
 [  1   1   9   1]
 [ 24   3 343  26]
 [ 10   3  35   7]]
12/10/2017 07:36:11 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 07:36:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:36:11 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:36:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:36:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:36:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:36:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:36:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:37:35 [INFO] exp_shallowmodel: train time: 84.109s
12/10/2017 07:37:35 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:37:35 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 07:37:35 [INFO] exp_shallowmodel: f1_score:   0.341
12/10/2017 07:37:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:37:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.19      0.20        59
          C       0.50      0.08      0.14        12
          F       0.82      0.89      0.85       396
          R       0.20      0.15      0.17        55

avg / total       0.68      0.71      0.69       522

12/10/2017 07:37:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:37:35 [INFO] exp_shallowmodel: 
[[ 11   1  34  13]
 [  1   1   9   1]
 [ 27   0 351  18]
 [ 11   0  36   8]]
12/10/2017 07:37:35 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 07:37:35 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:37:35 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:37:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:37:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:37:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:37:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:37:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:39:06 [INFO] exp_shallowmodel: train time: 90.474s
12/10/2017 07:39:06 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:39:06 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 07:39:06 [INFO] exp_shallowmodel: f1_score:   0.351
12/10/2017 07:39:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:39:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.14      0.16        59
          C       0.17      0.08      0.11        12
          F       0.81      0.88      0.84       396
          R       0.31      0.27      0.29        55

avg / total       0.68      0.71      0.69       522

12/10/2017 07:39:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:39:06 [INFO] exp_shallowmodel: 
[[  8   1  38  12]
 [  1   1   8   2]
 [ 25   4 347  20]
 [  7   0  33  15]]
12/10/2017 07:39:06 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 07:39:06 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:39:06 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:39:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:39:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:39:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:39:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:39:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:40:36 [INFO] exp_shallowmodel: train time: 90.209s
12/10/2017 07:40:36 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:40:36 [INFO] exp_shallowmodel: accuracy:   0.695
12/10/2017 07:40:36 [INFO] exp_shallowmodel: f1_score:   0.301
12/10/2017 07:40:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:40:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.17      0.19        59
          C       0.00      0.00      0.00        12
          F       0.81      0.87      0.84       396
          R       0.20      0.16      0.18        55

avg / total       0.66      0.70      0.67       522

12/10/2017 07:40:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:40:36 [INFO] exp_shallowmodel: 
[[ 10   1  36  12]
 [  1   0  10   1]
 [ 27   1 344  24]
 [  9   0  37   9]]
12/10/2017 07:40:37 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 07:40:37 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:40:37 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:40:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:40:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:40:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:40:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:40:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:42:07 [INFO] exp_shallowmodel: train time: 90.687s
12/10/2017 07:42:07 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 07:42:07 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 07:42:07 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 07:42:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:42:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.22      0.24        59
          C       0.50      0.17      0.25        12
          F       0.81      0.87      0.84       396
          R       0.20      0.16      0.18        55

avg / total       0.68      0.70      0.69       522

12/10/2017 07:42:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:42:07 [INFO] exp_shallowmodel: 
[[ 13   0  35  11]
 [  3   2   6   1]
 [ 27   2 344  23]
 [  7   0  39   9]]
12/10/2017 07:42:08 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 07:42:08 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 07:42:08 [INFO] exp_shallowmodel: #(feature) = 2400
12/10/2017 07:42:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:42:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:42:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:42:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:42:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:43:45 [INFO] exp_shallowmodel: train time: 97.172s
12/10/2017 07:43:45 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 07:43:45 [INFO] exp_shallowmodel: accuracy:   0.718
12/10/2017 07:43:45 [INFO] exp_shallowmodel: f1_score:   0.364
12/10/2017 07:43:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:43:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.30      0.34        64
          C       0.00      0.00      0.00        14
          F       0.80      0.89      0.84       402
          R       0.33      0.24      0.28        63

avg / total       0.68      0.72      0.69       543

12/10/2017 07:43:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:43:45 [INFO] exp_shallowmodel: 
[[ 19   1  39   5]
 [  2   0  10   2]
 [ 21   1 356  24]
 [  6   1  41  15]]
Done: 20171210-074345
