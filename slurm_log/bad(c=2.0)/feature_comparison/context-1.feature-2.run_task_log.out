/ihome/pbrusilosky/rum20/.conda/envs/py36/bin/python -m dialogue.classify.task_runner -selected_feature_set_id 2 -selected_context_id 1
No. of param settings = 1
[('deep_model', False), ('selected_context_id', 1), ('selected_feature_set_id', 2), ('similarity_feature', False)]
12/10/2017 02:14:33 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:33 [INFO] configuration: selected_context_id  :   1
12/10/2017 02:14:33 [INFO] configuration: selected_feature_set_id  :   2
12/10/2017 02:14:33 [INFO] configuration: similarity_feature  :   False
12/10/2017 02:14:33 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:33 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:33 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:33 [INFO] configuration: timemark  :   20171210-021433
12/10/2017 02:14:33 [INFO] configuration: context_set  :   current
12/10/2017 02:14:33 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:33 [INFO] configuration: utterance_range  :   ['current_user_utterance']
12/10/2017 02:14:33 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:33 [INFO] configuration: feature_set  :   2-lexical
12/10/2017 02:14:33 [INFO] configuration: feature_set_number  :   ['4']
12/10/2017 02:14:33 [INFO] configuration: experiment_name  :   20171210-021433.context=current.feature=2-lexical.similarity=false
12/10/2017 02:14:33 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021433.context=current.feature=2-lexical.similarity=false
12/10/2017 02:14:33 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021433.context=current.feature=2-lexical.similarity=false/output.log
12/10/2017 02:14:33 [INFO] configuration: valid_type  :   {'F', 'C', 'R', 'A'}
12/10/2017 02:14:33 [INFO] configuration: data_name  :   
12/10/2017 02:14:33 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:33 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:33 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:33 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:33 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:33 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:33 [INFO] configuration: #division  :   5
12/10/2017 02:14:33 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:33 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:33 [INFO] configuration: action_words  :   {'next', 'address', 'item', 'matter', 'turn', 'video', 'list', 'music', 'cheap', 'any', 'snooze', 'number', 'moder', 'reminder', 'remov', 'timer', 'telephone', 'south', 'start', 'delet', 'els', 'findcare', 'area', 'temperatur', 'skip', 'part', 'north', 'reminds', 'else', 'temperature', 'snooz', 'reminders', 'phone', 'song', 'delete', 'play', 'expensive', 'discard', 'telephon', 'show', 'add', 'time', 'price', 'weather', 'volum', 'tell', 'shuffl', 'share', 'remind', 'food', 'cast', 'volume', 'member', 'clear', 'items', 'ani', 'findcar', 'room', 'moderate', 'help', 'light', 'shuffle', 'centre', 'expens', 'centr', 'remove', 'post', 'alarm', 'watch', 'stop'}
12/10/2017 02:14:33 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:33 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:33 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:33 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:33 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:33 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:33 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:33 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:33 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:33 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:33 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:33 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:33 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:33 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:33 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:33 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:33 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:33 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:33 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 1, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:33 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:36 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:36 [INFO] task_runner: context=current, feature=2-lexical
12/10/2017 02:14:36 [INFO] task_runner: retained feature numbers=[4.1]
12/10/2017 02:14:36 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:36 [INFO] task_runner: #(feature)=927
12/10/2017 02:14:36 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:36 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:10 [INFO] exp_shallowmodel: train time: 34.150s
12/10/2017 02:15:10 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:15:10 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:15:10 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:15:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.57      0.57       164
          F       0.63      0.80      0.71       268
          R       0.39      0.21      0.27       125

avg / total       0.54      0.58      0.55       571

12/10/2017 02:15:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:10 [INFO] exp_shallowmodel: 
[[  0   6   5   3]
 [  0  93  51  20]
 [  0  36 214  18]
 [  1  29  69  26]]
12/10/2017 02:15:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:15:10 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:10 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:15:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:46 [INFO] exp_shallowmodel: train time: 36.066s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 02:15:46 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 02:15:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.55      0.51      0.53       164
          F       0.62      0.76      0.69       268
          R       0.44      0.31      0.36       125

avg / total       0.57      0.57      0.56       571

12/10/2017 02:15:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:46 [INFO] exp_shallowmodel: 
[[  1   4   7   2]
 [  0  83  55  26]
 [  0  41 205  22]
 [  0  23  63  39]]
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:15:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:46 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:23 [INFO] exp_shallowmodel: train time: 36.484s
12/10/2017 02:16:23 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:16:23 [INFO] exp_shallowmodel: accuracy:   0.602
12/10/2017 02:16:23 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 02:16:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.55      0.56       164
          F       0.68      0.82      0.74       268
          R       0.40      0.27      0.32       125

avg / total       0.57      0.60      0.58       571

12/10/2017 02:16:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:23 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  1  91  46  26]
 [  0  28 219  21]
 [  2  37  52  34]]
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:16:23 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:23 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:05 [INFO] exp_shallowmodel: train time: 42.660s
12/10/2017 02:17:05 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:17:05 [INFO] exp_shallowmodel: accuracy:   0.560
12/10/2017 02:17:05 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 02:17:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.52      0.52       164
          F       0.62      0.75      0.68       268
          R       0.42      0.28      0.33       125

avg / total       0.53      0.56      0.54       571

12/10/2017 02:17:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:05 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0  85  58  21]
 [  1  42 200  25]
 [  1  34  55  35]]
12/10/2017 02:17:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:17:06 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:06 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:17:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:38 [INFO] exp_shallowmodel: train time: 32.409s
12/10/2017 02:17:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:17:38 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:17:38 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 02:17:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.51      0.53       164
          F       0.62      0.81      0.70       268
          R       0.39      0.22      0.28       125

avg / total       0.53      0.57      0.54       571

12/10/2017 02:17:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:38 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0  83  62  19]
 [  0  31 217  20]
 [  0  35  63  27]]
12/10/2017 02:17:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:17:38 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:38 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:17:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:09 [INFO] exp_shallowmodel: train time: 30.660s
12/10/2017 02:18:09 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:18:09 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 02:18:09 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:18:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.56      0.55       164
          F       0.65      0.80      0.72       268
          R       0.45      0.26      0.33       125

avg / total       0.56      0.59      0.57       571

12/10/2017 02:18:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:09 [INFO] exp_shallowmodel: 
[[  0   8   4   2]
 [  0  92  52  20]
 [  0  37 214  17]
 [  1  32  60  32]]
12/10/2017 02:18:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:18:09 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:09 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:18:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:41 [INFO] exp_shallowmodel: train time: 32.193s
12/10/2017 02:18:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:18:41 [INFO] exp_shallowmodel: accuracy:   0.632
12/10/2017 02:18:41 [INFO] exp_shallowmodel: f1_score:   0.435
12/10/2017 02:18:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.60      0.61       164
          F       0.68      0.83      0.75       268
          R       0.51      0.31      0.39       125

avg / total       0.60      0.63      0.61       571

12/10/2017 02:18:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:41 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  1  99  44  20]
 [  0  30 223  15]
 [  1  31  54  39]]
12/10/2017 02:18:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:18:41 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:41 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:18:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:08 [INFO] exp_shallowmodel: train time: 26.834s
12/10/2017 02:19:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:19:08 [INFO] exp_shallowmodel: accuracy:   0.557
12/10/2017 02:19:08 [INFO] exp_shallowmodel: f1_score:   0.376
12/10/2017 02:19:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.58      0.54       164
          F       0.64      0.72      0.68       268
          R       0.36      0.23      0.28       125

avg / total       0.53      0.56      0.54       571

12/10/2017 02:19:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:08 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  0  95  50  19]
 [  1  46 194  27]
 [  0  41  55  29]]
12/10/2017 02:19:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:19:08 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:19:08 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:19:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:42 [INFO] exp_shallowmodel: train time: 33.548s
12/10/2017 02:19:42 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:19:42 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:19:42 [INFO] exp_shallowmodel: f1_score:   0.439
12/10/2017 02:19:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.73      0.66       164
          F       0.67      0.73      0.70       268
          R       0.52      0.33      0.40       125

avg / total       0.60      0.62      0.60       571

12/10/2017 02:19:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:42 [INFO] exp_shallowmodel: 
[[  0   5   6   3]
 [  0 119  35  10]
 [  0  47 196  25]
 [  0  27  57  41]]
12/10/2017 02:19:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:19:42 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:19:42 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:19:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:10 [INFO] exp_shallowmodel: train time: 28.431s
12/10/2017 02:20:10 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:20:10 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 02:20:10 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 02:20:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.06      0.12        16
          C       0.50      0.49      0.49       169
          F       0.61      0.79      0.69       271
          R       0.41      0.22      0.29       130

avg / total       0.55      0.56      0.53       586

12/10/2017 02:20:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:10 [INFO] exp_shallowmodel: 
[[  1   3   9   3]
 [  0  82  63  24]
 [  0  43 214  14]
 [  0  36  65  29]]
12/10/2017 02:20:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:20:11 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:20:11 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:20:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:42 [INFO] exp_shallowmodel: train time: 31.248s
12/10/2017 02:20:42 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:20:42 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 02:20:42 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 02:20:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.55      0.53       164
          F       0.63      0.77      0.70       268
          R       0.33      0.19      0.24       125

avg / total       0.52      0.56      0.53       571

12/10/2017 02:20:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:42 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0  90  53  21]
 [  0  37 207  24]
 [  0  44  57  24]]
12/10/2017 02:20:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:20:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:20:42 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:20:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:17 [INFO] exp_shallowmodel: train time: 34.601s
12/10/2017 02:21:17 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:17 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:21:17 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 02:21:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.51      0.53       164
          F       0.64      0.79      0.71       268
          R       0.46      0.31      0.37       125

avg / total       0.56      0.59      0.57       571

12/10/2017 02:21:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:17 [INFO] exp_shallowmodel: 
[[  0   7   4   3]
 [  0  84  57  23]
 [  1  35 212  20]
 [  0  28  58  39]]
12/10/2017 02:21:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:21:17 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:21:17 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:21:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:53 [INFO] exp_shallowmodel: train time: 36.169s
12/10/2017 02:21:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:53 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:21:53 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 02:21:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.54      0.53       164
          F       0.63      0.78      0.70       268
          R       0.52      0.30      0.38       125

avg / total       0.56      0.58      0.56       571

12/10/2017 02:21:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:53 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  0  88  62  14]
 [  0  42 208  18]
 [  1  33  54  37]]
12/10/2017 02:21:53 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:21:53 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:21:53 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:21:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:29 [INFO] exp_shallowmodel: train time: 36.192s
12/10/2017 02:22:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:22:29 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 02:22:29 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 02:22:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.58      0.55       164
          F       0.66      0.76      0.70       268
          R       0.51      0.32      0.39       125

avg / total       0.57      0.59      0.57       571

12/10/2017 02:22:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:29 [INFO] exp_shallowmodel: 
[[  0   5   4   5]
 [  1  95  49  19]
 [  0  51 203  14]
 [  2  30  53  40]]
12/10/2017 02:22:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:22:29 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:22:29 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:22:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:59 [INFO] exp_shallowmodel: train time: 29.748s
12/10/2017 02:22:59 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:22:59 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 02:22:59 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:22:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.52      0.53       164
          F       0.65      0.79      0.71       268
          R       0.39      0.25      0.30       125

avg / total       0.54      0.58      0.55       571

12/10/2017 02:22:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:59 [INFO] exp_shallowmodel: 
[[  0   3  11   0]
 [  0  86  52  26]
 [  0  32 213  23]
 [  1  40  53  31]]
12/10/2017 02:22:59 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:22:59 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:22:59 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:22:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:31 [INFO] exp_shallowmodel: train time: 31.933s
12/10/2017 02:23:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:23:31 [INFO] exp_shallowmodel: accuracy:   0.560
12/10/2017 02:23:31 [INFO] exp_shallowmodel: f1_score:   0.379
12/10/2017 02:23:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.56      0.55       164
          F       0.62      0.74      0.68       268
          R       0.39      0.23      0.29       125

avg / total       0.53      0.56      0.54       571

12/10/2017 02:23:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:31 [INFO] exp_shallowmodel: 
[[  0   2   5   7]
 [  1  92  56  15]
 [  1  44 199  24]
 [  2  34  60  29]]
12/10/2017 02:23:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:23:31 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:23:31 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:23:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:14 [INFO] exp_shallowmodel: train time: 42.688s
12/10/2017 02:24:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:24:14 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 02:24:14 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 02:24:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.59      0.60       164
          F       0.67      0.83      0.74       268
          R       0.44      0.26      0.33       125

avg / total       0.58      0.62      0.59       571

12/10/2017 02:24:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:14 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  1  97  47  19]
 [  1  27 222  18]
 [  1  33  58  33]]
12/10/2017 02:24:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:24:14 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:24:14 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:24:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:45 [INFO] exp_shallowmodel: train time: 30.575s
12/10/2017 02:24:45 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:24:45 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 02:24:45 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:24:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.55      0.56       164
          F       0.63      0.78      0.70       268
          R       0.48      0.31      0.38       125

avg / total       0.57      0.59      0.57       571

12/10/2017 02:24:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:45 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0  90  50  24]
 [  0  42 210  16]
 [  0  25  61  39]]
12/10/2017 02:24:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 02:24:45 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:24:45 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:24:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:09 [INFO] exp_shallowmodel: train time: 23.759s
12/10/2017 02:25:09 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:25:09 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 02:25:09 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 02:25:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.58      0.57       164
          F       0.65      0.78      0.71       268
          R       0.43      0.28      0.34       125

avg / total       0.56      0.59      0.57       571

12/10/2017 02:25:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:09 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  0  95  53  16]
 [  0  33 208  27]
 [  0  37  53  35]]
12/10/2017 02:25:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 02:25:09 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:25:09 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:25:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:35 [INFO] exp_shallowmodel: train time: 25.784s
12/10/2017 02:25:35 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:25:35 [INFO] exp_shallowmodel: accuracy:   0.558
12/10/2017 02:25:35 [INFO] exp_shallowmodel: f1_score:   0.374
12/10/2017 02:25:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.53      0.50      0.52       169
          F       0.61      0.78      0.69       271
          R       0.41      0.23      0.29       130

avg / total       0.52      0.56      0.53       586

12/10/2017 02:25:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:35 [INFO] exp_shallowmodel: 
[[  0   2   8   6]
 [  0  85  64  20]
 [  3  38 212  18]
 [  1  36  63  30]]
12/10/2017 02:25:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 02:25:35 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:25:35 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:25:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:03 [INFO] exp_shallowmodel: train time: 28.011s
12/10/2017 02:26:03 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:26:03 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 02:26:03 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 02:26:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.53      0.54       164
          F       0.64      0.74      0.69       268
          R       0.40      0.31      0.35       125

avg / total       0.54      0.57      0.55       571

12/10/2017 02:26:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:03 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  1  87  49  27]
 [  0  42 199  27]
 [  2  29  55  39]]
12/10/2017 02:26:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 02:26:03 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:26:03 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:26:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:34 [INFO] exp_shallowmodel: train time: 31.140s
12/10/2017 02:26:34 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:26:34 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 02:26:34 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 02:26:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.56      0.58       164
          F       0.64      0.76      0.70       268
          R       0.41      0.33      0.37       125

avg / total       0.57      0.59      0.58       571

12/10/2017 02:26:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:34 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0  92  51  21]
 [  1  28 205  34]
 [  2  27  55  41]]
12/10/2017 02:26:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 02:26:34 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:26:34 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:26:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:27:08 [INFO] exp_shallowmodel: train time: 33.313s
12/10/2017 02:27:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:27:08 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 02:27:08 [INFO] exp_shallowmodel: f1_score:   0.436
12/10/2017 02:27:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:27:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.07      0.11        14
          C       0.55      0.63      0.59       164
          F       0.65      0.76      0.70       268
          R       0.49      0.26      0.34       125

avg / total       0.58      0.60      0.58       571

12/10/2017 02:27:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:27:08 [INFO] exp_shallowmodel: 
[[  1   3   8   2]
 [  1 104  45  14]
 [  1  46 203  18]
 [  1  35  56  33]]
12/10/2017 02:27:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 02:27:08 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:27:08 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:27:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:27:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:27:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:27:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:27:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:27:38 [INFO] exp_shallowmodel: train time: 29.883s
12/10/2017 02:27:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:27:38 [INFO] exp_shallowmodel: accuracy:   0.609
12/10/2017 02:27:38 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 02:27:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:27:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.60      0.59       164
          F       0.65      0.81      0.72       268
          R       0.52      0.27      0.36       125

avg / total       0.58      0.61      0.58       571

12/10/2017 02:27:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:27:38 [INFO] exp_shallowmodel: 
[[  0   3   9   2]
 [  1  98  50  15]
 [  0  37 216  15]
 [  1  32  58  34]]
12/10/2017 02:27:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 02:27:38 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:27:38 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:27:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:27:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:27:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:27:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:27:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:14 [INFO] exp_shallowmodel: train time: 36.211s
12/10/2017 02:28:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:28:14 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 02:28:14 [INFO] exp_shallowmodel: f1_score:   0.395
12/10/2017 02:28:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.54      0.54       164
          F       0.65      0.82      0.72       268
          R       0.43      0.25      0.31       125

avg / total       0.56      0.59      0.56       571

12/10/2017 02:28:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:14 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  0  88  53  23]
 [  0  35 219  14]
 [  1  34  59  31]]
12/10/2017 02:28:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 02:28:14 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:28:14 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:28:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:29:00 [INFO] exp_shallowmodel: train time: 45.428s
12/10/2017 02:29:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:29:00 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 02:29:00 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:29:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:29:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.56      0.56       164
          F       0.64      0.75      0.69       268
          R       0.42      0.30      0.35       125

avg / total       0.55      0.58      0.56       571

12/10/2017 02:29:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:29:00 [INFO] exp_shallowmodel: 
[[  0   8   2   4]
 [  0  92  52  20]
 [  0  39 202  27]
 [  1  26  61  37]]
12/10/2017 02:29:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 02:29:00 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:29:00 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:29:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:29:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:29:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:29:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:29:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:29:38 [INFO] exp_shallowmodel: train time: 38.713s
12/10/2017 02:29:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:29:38 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 02:29:38 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 02:29:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:29:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.56      0.56       164
          F       0.65      0.80      0.72       268
          R       0.39      0.24      0.30       125

avg / total       0.55      0.59      0.56       571

12/10/2017 02:29:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:29:38 [INFO] exp_shallowmodel: 
[[  0   2   6   6]
 [  0  92  49  23]
 [  0  35 215  18]
 [  0  36  59  30]]
12/10/2017 02:29:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 02:29:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:29:39 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:29:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:29:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:29:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:29:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:29:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:30:16 [INFO] exp_shallowmodel: train time: 37.552s
12/10/2017 02:30:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:30:16 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 02:30:16 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 02:30:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:30:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.52      0.53       164
          F       0.64      0.81      0.72       268
          R       0.51      0.32      0.39       125

avg / total       0.57      0.60      0.58       571

12/10/2017 02:30:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:30:16 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0  85  59  20]
 [  1  34 218  15]
 [  0  31  54  40]]
12/10/2017 02:30:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 02:30:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:30:16 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:30:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:30:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:30:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:30:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:30:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:30:52 [INFO] exp_shallowmodel: train time: 36.106s
12/10/2017 02:30:52 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:30:52 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:30:52 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 02:30:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:30:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.59      0.56       164
          F       0.68      0.77      0.72       268
          R       0.45      0.30      0.36       125

avg / total       0.57      0.60      0.58       571

12/10/2017 02:30:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:30:52 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  0  97  45  22]
 [  0  41 207  20]
 [  0  41  46  38]]
12/10/2017 02:30:53 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 02:30:53 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:30:53 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:30:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:30:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:30:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:30:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:30:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:31:31 [INFO] exp_shallowmodel: train time: 38.614s
12/10/2017 02:31:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:31:31 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:31:31 [INFO] exp_shallowmodel: f1_score:   0.395
12/10/2017 02:31:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:31:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.54      0.54      0.54       169
          F       0.62      0.76      0.69       271
          R       0.44      0.29      0.35       130

avg / total       0.54      0.57      0.55       586

12/10/2017 02:31:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:31:31 [INFO] exp_shallowmodel: 
[[  0   4  10   2]
 [  0  91  55  23]
 [  0  40 207  24]
 [  0  32  60  38]]
12/10/2017 02:31:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 02:31:31 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:31:31 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:31:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:31:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:31:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:31:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:31:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:31:58 [INFO] exp_shallowmodel: train time: 26.239s
12/10/2017 02:31:58 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:31:58 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 02:31:58 [INFO] exp_shallowmodel: f1_score:   0.406
12/10/2017 02:31:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:31:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.57      0.57       164
          F       0.66      0.77      0.71       268
          R       0.41      0.30      0.34       125

avg / total       0.56      0.59      0.57       571

12/10/2017 02:31:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:31:58 [INFO] exp_shallowmodel: 
[[  0   2   5   7]
 [  0  94  49  21]
 [  0  36 207  25]
 [  0  36  52  37]]
12/10/2017 02:31:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 02:31:58 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:31:58 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:31:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:31:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:31:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:31:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:31:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:32:38 [INFO] exp_shallowmodel: train time: 40.513s
12/10/2017 02:32:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:32:38 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 02:32:38 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 02:32:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:32:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.55      0.56       164
          F       0.61      0.76      0.67       268
          R       0.39      0.22      0.28       125

avg / total       0.53      0.56      0.54       571

12/10/2017 02:32:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:32:38 [INFO] exp_shallowmodel: 
[[  0   1  12   1]
 [  0  91  52  21]
 [  1  42 204  21]
 [  1  28  69  27]]
12/10/2017 02:32:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 02:32:38 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:32:38 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:32:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:32:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:32:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:32:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:32:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:31 [INFO] exp_shallowmodel: train time: 52.199s
12/10/2017 02:33:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:33:31 [INFO] exp_shallowmodel: accuracy:   0.585
12/10/2017 02:33:31 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:33:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.62      0.57       164
          F       0.66      0.75      0.70       268
          R       0.42      0.26      0.33       125

avg / total       0.55      0.58      0.56       571

12/10/2017 02:33:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:31 [INFO] exp_shallowmodel: 
[[  0   6   5   3]
 [  0 101  43  20]
 [  0  46 200  22]
 [  0  35  57  33]]
12/10/2017 02:33:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 02:33:31 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:33:31 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:33:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:34:08 [INFO] exp_shallowmodel: train time: 37.029s
12/10/2017 02:34:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:34:08 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 02:34:08 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 02:34:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:34:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.60      0.56       164
          F       0.68      0.76      0.72       268
          R       0.46      0.30      0.36       125

avg / total       0.57      0.60      0.58       571

12/10/2017 02:34:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:34:08 [INFO] exp_shallowmodel: 
[[  0   8   5   1]
 [  0  99  41  24]
 [  1  44 205  18]
 [  0  37  51  37]]
12/10/2017 02:34:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 02:34:08 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:34:08 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:34:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:34:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:34:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:34:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:34:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:34:35 [INFO] exp_shallowmodel: train time: 26.851s
12/10/2017 02:34:35 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:34:35 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:34:35 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 02:34:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:34:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.57      0.56       164
          F       0.67      0.80      0.73       268
          R       0.44      0.27      0.34       125

avg / total       0.57      0.60      0.58       571

12/10/2017 02:34:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:34:35 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  0  93  54  17]
 [  0  31 215  22]
 [  1  44  46  34]]
12/10/2017 02:34:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 02:34:35 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:34:35 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:34:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:34:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:34:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:34:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:34:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:35:04 [INFO] exp_shallowmodel: train time: 29.294s
12/10/2017 02:35:04 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:35:04 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 02:35:04 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 02:35:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:35:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.54      0.52       164
          F       0.63      0.75      0.69       268
          R       0.42      0.25      0.31       125

avg / total       0.53      0.56      0.54       571

12/10/2017 02:35:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:35:04 [INFO] exp_shallowmodel: 
[[  0   3   5   6]
 [  0  89  62  13]
 [  0  44 201  23]
 [  3  41  50  31]]
12/10/2017 02:35:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 02:35:04 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:35:04 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:35:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:35:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:35:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:35:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:35:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:35:34 [INFO] exp_shallowmodel: train time: 29.667s
12/10/2017 02:35:34 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:35:34 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:35:34 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 02:35:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:35:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.61      0.54       164
          F       0.65      0.72      0.68       268
          R       0.44      0.24      0.31       125

avg / total       0.54      0.57      0.54       571

12/10/2017 02:35:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:35:34 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  0 100  42  22]
 [  0  61 193  14]
 [  1  37  57  30]]
12/10/2017 02:35:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 02:35:34 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:35:34 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:35:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:35:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:35:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:35:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:35:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:36:06 [INFO] exp_shallowmodel: train time: 31.510s
12/10/2017 02:36:06 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:36:06 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 02:36:06 [INFO] exp_shallowmodel: f1_score:   0.373
12/10/2017 02:36:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:36:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.48      0.48       164
          F       0.63      0.80      0.70       268
          R       0.43      0.24      0.31       125

avg / total       0.53      0.56      0.54       571

12/10/2017 02:36:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:36:06 [INFO] exp_shallowmodel: 
[[  0   5   8   1]
 [  0  78  63  23]
 [  0  39 214  15]
 [  1  39  55  30]]
12/10/2017 02:36:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 02:36:06 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:36:06 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:36:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:36:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:36:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:36:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:36:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:36:32 [INFO] exp_shallowmodel: train time: 25.860s
12/10/2017 02:36:32 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:36:32 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 02:36:32 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 02:36:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:36:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.55      0.54       164
          F       0.65      0.76      0.70       268
          R       0.44      0.30      0.35       125

avg / total       0.55      0.58      0.56       571

12/10/2017 02:36:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:36:32 [INFO] exp_shallowmodel: 
[[  0   3   5   6]
 [  1  90  46  27]
 [  2  48 203  15]
 [  2  30  56  37]]
12/10/2017 02:36:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 02:36:32 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:36:32 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:36:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:36:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:36:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:36:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:36:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:37:04 [INFO] exp_shallowmodel: train time: 32.426s
12/10/2017 02:37:04 [INFO] exp_shallowmodel: test time:  0.001s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:37:04 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 02:37:04 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 02:37:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:37:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.60      0.56      0.58       169
          F       0.62      0.77      0.69       271
          R       0.40      0.28      0.33       130

avg / total       0.55      0.58      0.56       586

12/10/2017 02:37:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:37:04 [INFO] exp_shallowmodel: 
[[  0   2  10   4]
 [  0  94  53  22]
 [  0  33 209  29]
 [  0  27  66  37]]
12/10/2017 02:37:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 02:37:04 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:37:04 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:37:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:37:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:37:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:37:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:37:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:37:47 [INFO] exp_shallowmodel: train time: 43.092s
12/10/2017 02:37:47 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:37:47 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 02:37:47 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 02:37:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:37:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.59      0.57       164
          F       0.65      0.77      0.70       268
          R       0.49      0.27      0.35       125

avg / total       0.57      0.59      0.57       571

12/10/2017 02:37:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:37:47 [INFO] exp_shallowmodel: 
[[  0   5   6   3]
 [  1  97  48  18]
 [  1  46 206  15]
 [  2  30  59  34]]
12/10/2017 02:37:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 02:37:48 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:37:48 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:37:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:37:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:37:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:37:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:37:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:38:16 [INFO] exp_shallowmodel: train time: 28.822s
12/10/2017 02:38:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:38:16 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:38:16 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 02:38:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:38:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.50      0.51       164
          F       0.62      0.79      0.69       268
          R       0.41      0.24      0.30       125

avg / total       0.53      0.57      0.54       571

12/10/2017 02:38:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:38:16 [INFO] exp_shallowmodel: 
[[  0   6   7   1]
 [  0  82  65  17]
 [  0  32 211  25]
 [  0  35  60  30]]
12/10/2017 02:38:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 02:38:17 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:38:17 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:38:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:38:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:38:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:38:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:38:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:38:40 [INFO] exp_shallowmodel: train time: 23.878s
12/10/2017 02:38:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:38:40 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 02:38:40 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 02:38:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:38:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.51      0.52       164
          F       0.65      0.78      0.71       268
          R       0.52      0.36      0.42       125

avg / total       0.57      0.59      0.57       571

12/10/2017 02:38:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:38:40 [INFO] exp_shallowmodel: 
[[  0   4   8   2]
 [  0  84  59  21]
 [  2  39 208  19]
 [  1  33  46  45]]
12/10/2017 02:38:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 02:38:41 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:38:41 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:38:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:38:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:38:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:38:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:38:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:39:12 [INFO] exp_shallowmodel: train time: 30.976s
12/10/2017 02:39:12 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:39:12 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 02:39:12 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 02:39:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:39:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.59      0.55       164
          F       0.66      0.77      0.71       268
          R       0.40      0.23      0.29       125

avg / total       0.55      0.58      0.56       571

12/10/2017 02:39:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:39:12 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  0  96  45  23]
 [  0  45 207  16]
 [  1  40  55  29]]
12/10/2017 02:39:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 02:39:12 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:39:12 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:39:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:39:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:39:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:39:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:39:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:39:39 [INFO] exp_shallowmodel: train time: 26.779s
12/10/2017 02:39:39 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:39:39 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 02:39:39 [INFO] exp_shallowmodel: f1_score:   0.421
12/10/2017 02:39:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:39:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.65      0.60       164
          F       0.67      0.75      0.71       268
          R       0.49      0.30      0.37       125

avg / total       0.58      0.61      0.59       571

12/10/2017 02:39:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:39:39 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  0 107  41  16]
 [  1  46 201  20]
 [  0  34  53  38]]
12/10/2017 02:39:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 02:39:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:39:39 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:39:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:39:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:39:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:39:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:39:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:39:59 [INFO] exp_shallowmodel: train time: 19.943s
12/10/2017 02:39:59 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:39:59 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 02:39:59 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:39:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:39:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.55      0.56       164
          F       0.66      0.81      0.72       268
          R       0.40      0.26      0.31       125

avg / total       0.56      0.59      0.57       571

12/10/2017 02:39:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:39:59 [INFO] exp_shallowmodel: 
[[  0   3   3   8]
 [  0  91  50  23]
 [  0  34 216  18]
 [  1  32  60  32]]
12/10/2017 02:39:59 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 02:39:59 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:39:59 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:39:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:39:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:39:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:39:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:39:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:40:28 [INFO] exp_shallowmodel: train time: 28.840s
12/10/2017 02:40:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:40:28 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 02:40:28 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 02:40:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:40:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.64      0.60       164
          F       0.66      0.78      0.71       268
          R       0.44      0.23      0.30       125

avg / total       0.57      0.60      0.57       571

12/10/2017 02:40:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:40:28 [INFO] exp_shallowmodel: 
[[  0   3   9   2]
 [  0 105  40  19]
 [  0  43 209  16]
 [  0  35  61  29]]
12/10/2017 02:40:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 02:40:28 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:40:28 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:40:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:40:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:40:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:40:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:40:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:41:01 [INFO] exp_shallowmodel: train time: 32.889s
12/10/2017 02:41:01 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:41:01 [INFO] exp_shallowmodel: accuracy:   0.550
12/10/2017 02:41:01 [INFO] exp_shallowmodel: f1_score:   0.381
12/10/2017 02:41:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:41:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.51      0.53       164
          F       0.61      0.72      0.66       268
          R       0.39      0.30      0.34       125

avg / total       0.53      0.55      0.53       571

12/10/2017 02:41:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:41:01 [INFO] exp_shallowmodel: 
[[  0   0  11   3]
 [  1  84  53  26]
 [  1  44 192  31]
 [  0  26  61  38]]
12/10/2017 02:41:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 02:41:01 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:41:01 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:41:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:41:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:41:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:41:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:41:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:41:40 [INFO] exp_shallowmodel: train time: 39.107s
12/10/2017 02:41:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:41:40 [INFO] exp_shallowmodel: accuracy:   0.604
12/10/2017 02:41:40 [INFO] exp_shallowmodel: f1_score:   0.418
12/10/2017 02:41:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:41:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.62      0.62       164
          F       0.66      0.77      0.71       268
          R       0.40      0.30      0.34       125

avg / total       0.58      0.60      0.59       571

12/10/2017 02:41:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:41:40 [INFO] exp_shallowmodel: 
[[  0   2   5   7]
 [  0 101  46  17]
 [  1  29 207  31]
 [  1  30  57  37]]
12/10/2017 02:41:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 02:41:40 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:41:40 [INFO] exp_shallowmodel: #(feature) = 927
12/10/2017 02:41:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:41:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:41:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:41:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:41:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:42:17 [INFO] exp_shallowmodel: train time: 37.402s
12/10/2017 02:42:17 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:42:17 [INFO] exp_shallowmodel: accuracy:   0.584
12/10/2017 02:42:17 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 02:42:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:42:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.54      0.53      0.54       169
          F       0.64      0.79      0.70       271
          R       0.48      0.30      0.37       130

avg / total       0.56      0.58      0.56       586

12/10/2017 02:42:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:42:17 [INFO] exp_shallowmodel: 
[[  0   3   8   5]
 [  2  90  55  22]
 [  1  41 213  16]
 [  1  32  58  39]]
12/10/2017 02:42:21 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:42:21 [INFO] task_runner: context=current, feature=2-lexical
12/10/2017 02:42:21 [INFO] task_runner: retained feature numbers=[4.1]
12/10/2017 02:42:21 [INFO] task_runner: #(data)=5934
12/10/2017 02:42:21 [INFO] task_runner: #(feature)=1292
12/10/2017 02:42:21 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:42:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 02:42:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:42:21 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:42:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:42:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:42:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:42:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:42:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:43:15 [INFO] exp_shallowmodel: train time: 53.557s
12/10/2017 02:43:15 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:43:15 [INFO] exp_shallowmodel: accuracy:   0.595
12/10/2017 02:43:15 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:43:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:43:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.70      0.58       169
          F       0.73      0.71      0.72       281
          R       0.42      0.27      0.33       122

avg / total       0.58      0.59      0.58       592

12/10/2017 02:43:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:43:15 [INFO] exp_shallowmodel: 
[[  0   8   8   4]
 [  0 119  28  22]
 [  1  61 200  19]
 [  1  51  37  33]]
12/10/2017 02:43:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 02:43:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:43:15 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:43:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:43:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:43:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:43:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:43:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:44:23 [INFO] exp_shallowmodel: train time: 68.181s
12/10/2017 02:44:23 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:44:23 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:44:23 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 02:44:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:44:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.69      0.58       169
          F       0.69      0.69      0.69       281
          R       0.40      0.22      0.29       122

avg / total       0.55      0.57      0.55       592

12/10/2017 02:44:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:44:23 [INFO] exp_shallowmodel: 
[[  0   4  12   4]
 [  2 116  33  18]
 [  1  67 195  18]
 [  6  45  44  27]]
12/10/2017 02:44:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 02:44:23 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:44:23 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:44:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:44:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:44:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:44:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:44:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:45:24 [INFO] exp_shallowmodel: train time: 60.483s
12/10/2017 02:45:24 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:45:24 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 02:45:24 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 02:45:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:45:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.05      0.08        20
          C       0.49      0.64      0.56       169
          F       0.70      0.70      0.70       281
          R       0.40      0.27      0.32       122

avg / total       0.56      0.58      0.56       592

12/10/2017 02:45:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:45:24 [INFO] exp_shallowmodel: 
[[  1   4  11   4]
 [  2 109  33  25]
 [  0  63 198  20]
 [  3  45  41  33]]
12/10/2017 02:45:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 02:45:24 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:45:24 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:45:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:45:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:45:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:45:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:45:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:46:31 [INFO] exp_shallowmodel: train time: 66.475s
12/10/2017 02:46:31 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:46:31 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 02:46:31 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 02:46:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:46:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.65      0.56       169
          F       0.68      0.72      0.70       281
          R       0.52      0.30      0.38       122

avg / total       0.57      0.59      0.57       592

12/10/2017 02:46:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:46:31 [INFO] exp_shallowmodel: 
[[  0  10   7   3]
 [  1 110  44  14]
 [  1  62 201  17]
 [  2  40  43  37]]
12/10/2017 02:46:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 02:46:31 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:46:31 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:46:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:46:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:46:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:46:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:46:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:47:44 [INFO] exp_shallowmodel: train time: 73.217s
12/10/2017 02:47:44 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:47:44 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:47:44 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 02:47:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:47:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.63      0.56       169
          F       0.66      0.71      0.68       281
          R       0.43      0.26      0.33       122

avg / total       0.55      0.57      0.55       592

12/10/2017 02:47:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:47:44 [INFO] exp_shallowmodel: 
[[  0   5   8   7]
 [  1 106  45  17]
 [  3  60 200  18]
 [  1  38  51  32]]
12/10/2017 02:47:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 02:47:44 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:47:44 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:47:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:47:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:47:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:47:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:47:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:48:42 [INFO] exp_shallowmodel: train time: 58.251s
12/10/2017 02:48:42 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:48:42 [INFO] exp_shallowmodel: accuracy:   0.557
12/10/2017 02:48:42 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:48:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:48:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.44      0.59      0.51       169
          F       0.67      0.69      0.68       281
          R       0.47      0.30      0.36       122

avg / total       0.55      0.56      0.55       592

12/10/2017 02:48:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:48:42 [INFO] exp_shallowmodel: 
[[  2  11   4   3]
 [  2  99  47  21]
 [  2  70 193  16]
 [  1  43  42  36]]
12/10/2017 02:48:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 02:48:43 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:48:43 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:48:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:48:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:48:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:48:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:48:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:49:26 [INFO] exp_shallowmodel: train time: 43.337s
12/10/2017 02:49:26 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:49:26 [INFO] exp_shallowmodel: accuracy:   0.600
12/10/2017 02:49:26 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 02:49:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:49:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.68      0.59       169
          F       0.73      0.72      0.73       281
          R       0.40      0.30      0.35       122

avg / total       0.58      0.60      0.58       592

12/10/2017 02:49:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:49:26 [INFO] exp_shallowmodel: 
[[  0   6   7   7]
 [  1 115  28  25]
 [  1  54 203  23]
 [  0  46  39  37]]
12/10/2017 02:49:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 02:49:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:49:26 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:49:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:49:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:49:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:49:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:49:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:50:10 [INFO] exp_shallowmodel: train time: 44.128s
12/10/2017 02:50:10 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:50:10 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:50:10 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 02:50:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:50:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.10      0.15        20
          C       0.48      0.53      0.50       169
          F       0.67      0.75      0.71       281
          R       0.40      0.26      0.32       122

avg / total       0.55      0.57      0.55       592

12/10/2017 02:50:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:50:10 [INFO] exp_shallowmodel: 
[[  2   7   5   6]
 [  1  90  52  26]
 [  1  52 211  17]
 [  2  40  48  32]]
12/10/2017 02:50:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 02:50:11 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:50:11 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:50:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:50:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:50:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:50:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:50:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:51:02 [INFO] exp_shallowmodel: train time: 51.190s
12/10/2017 02:51:02 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:51:02 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 02:51:02 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 02:51:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:51:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.48      0.67      0.56       169
          F       0.72      0.70      0.71       281
          R       0.40      0.27      0.32       122

avg / total       0.58      0.58      0.57       592

12/10/2017 02:51:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:51:02 [INFO] exp_shallowmodel: 
[[  1   4   9   6]
 [  0 113  33  23]
 [  0  65 196  20]
 [  1  53  35  33]]
12/10/2017 02:51:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 02:51:02 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:51:02 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:51:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:51:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:51:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:51:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:51:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:52:10 [INFO] exp_shallowmodel: train time: 67.856s
12/10/2017 02:52:10 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:52:10 [INFO] exp_shallowmodel: accuracy:   0.589
12/10/2017 02:52:10 [INFO] exp_shallowmodel: f1_score:   0.438
12/10/2017 02:52:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:52:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        28
          C       0.49      0.69      0.57       172
          F       0.72      0.71      0.72       283
          R       0.45      0.28      0.35       123

avg / total       0.58      0.59      0.57       606

12/10/2017 02:52:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:52:10 [INFO] exp_shallowmodel: 
[[  2  12   5   9]
 [  0 118  36  18]
 [  3  63 202  15]
 [  1  50  37  35]]
12/10/2017 02:52:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 02:52:10 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:52:10 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:52:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:52:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:52:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:52:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:52:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:53:22 [INFO] exp_shallowmodel: train time: 71.738s
12/10/2017 02:53:22 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:53:22 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:53:22 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:53:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:53:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.63      0.56       169
          F       0.71      0.76      0.73       281
          R       0.53      0.33      0.40       122

avg / total       0.59      0.61      0.59       592

12/10/2017 02:53:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:53:22 [INFO] exp_shallowmodel: 
[[  0   5  11   4]
 [  1 107  38  23]
 [  1  58 213   9]
 [  1  43  38  40]]
12/10/2017 02:53:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 02:53:22 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:53:22 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:53:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:53:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:53:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:53:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:53:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:54:35 [INFO] exp_shallowmodel: train time: 73.065s
12/10/2017 02:54:35 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:54:35 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 02:54:35 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:54:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:54:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.59      0.52       169
          F       0.68      0.71      0.70       281
          R       0.42      0.27      0.33       122

avg / total       0.54      0.56      0.55       592

12/10/2017 02:54:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:54:35 [INFO] exp_shallowmodel: 
[[  0  10   4   6]
 [  2 100  46  21]
 [  0  62 200  19]
 [  2  44  43  33]]
12/10/2017 02:54:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 02:54:35 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:54:35 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:54:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:54:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:54:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:54:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:54:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:55:56 [INFO] exp_shallowmodel: train time: 80.867s
12/10/2017 02:55:56 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:55:56 [INFO] exp_shallowmodel: accuracy:   0.547
12/10/2017 02:55:56 [INFO] exp_shallowmodel: f1_score:   0.374
12/10/2017 02:55:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:55:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.59      0.52       169
          F       0.68      0.69      0.68       281
          R       0.35      0.25      0.30       122

avg / total       0.53      0.55      0.53       592

12/10/2017 02:55:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:55:56 [INFO] exp_shallowmodel: 
[[  0  10   6   4]
 [  0  99  49  21]
 [  0  55 194  32]
 [  3  50  38  31]]
12/10/2017 02:55:56 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 02:55:56 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:55:56 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:55:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:55:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:55:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:55:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:55:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:57:02 [INFO] exp_shallowmodel: train time: 65.808s
12/10/2017 02:57:02 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:57:02 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 02:57:02 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 02:57:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:57:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.05      0.07        20
          C       0.48      0.56      0.52       169
          F       0.68      0.74      0.71       281
          R       0.44      0.31      0.36       122

avg / total       0.56      0.57      0.56       592

12/10/2017 02:57:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:57:02 [INFO] exp_shallowmodel: 
[[  1   6   8   5]
 [  2  94  47  26]
 [  3  53 207  18]
 [  1  41  42  38]]
12/10/2017 02:57:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 02:57:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:57:02 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:57:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:57:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:57:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:57:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:57:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:57:55 [INFO] exp_shallowmodel: train time: 52.456s
12/10/2017 02:57:55 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:57:55 [INFO] exp_shallowmodel: accuracy:   0.593
12/10/2017 02:57:55 [INFO] exp_shallowmodel: f1_score:   0.425
12/10/2017 02:57:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:57:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.05      0.07        20
          C       0.49      0.70      0.57       169
          F       0.72      0.72      0.72       281
          R       0.48      0.25      0.33       122

avg / total       0.59      0.59      0.58       592

12/10/2017 02:57:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:57:55 [INFO] exp_shallowmodel: 
[[  1   7   9   3]
 [  5 118  29  17]
 [  1  66 201  13]
 [  1  51  39  31]]
12/10/2017 02:57:55 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 02:57:55 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:57:55 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:57:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:57:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:57:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:57:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:57:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:58:59 [INFO] exp_shallowmodel: train time: 64.191s
12/10/2017 02:58:59 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:58:59 [INFO] exp_shallowmodel: accuracy:   0.591
12/10/2017 02:58:59 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 02:58:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:58:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.65      0.56       169
          F       0.71      0.70      0.71       281
          R       0.50      0.34      0.41       122

avg / total       0.58      0.59      0.58       592

12/10/2017 02:58:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:58:59 [INFO] exp_shallowmodel: 
[[  0   7   6   7]
 [  3 110  35  21]
 [  1  68 198  14]
 [  1  40  39  42]]
12/10/2017 02:58:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 02:58:59 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:58:59 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:58:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:58:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:58:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:58:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:58:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:59:54 [INFO] exp_shallowmodel: train time: 54.757s
12/10/2017 02:59:54 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:59:54 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 02:59:54 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:59:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:59:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.51      0.50       169
          F       0.65      0.79      0.71       281
          R       0.47      0.30      0.37       122

avg / total       0.55      0.58      0.56       592

12/10/2017 02:59:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:59:54 [INFO] exp_shallowmodel: 
[[  0   4  10   6]
 [  1  86  62  20]
 [  0  44 221  16]
 [  1  38  46  37]]
12/10/2017 02:59:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 02:59:54 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:59:54 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 02:59:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:59:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:59:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:59:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:59:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:01:03 [INFO] exp_shallowmodel: train time: 68.761s
12/10/2017 03:01:03 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:01:03 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 03:01:03 [INFO] exp_shallowmodel: f1_score:   0.442
12/10/2017 03:01:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:01:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.10      0.15        20
          C       0.49      0.70      0.58       169
          F       0.73      0.68      0.70       281
          R       0.41      0.29      0.34       122

avg / total       0.58      0.58      0.57       592

12/10/2017 03:01:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:01:03 [INFO] exp_shallowmodel: 
[[  2   6   7   5]
 [  1 118  27  23]
 [  2  66 190  23]
 [  1  50  36  35]]
12/10/2017 03:01:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 03:01:03 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:01:03 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:01:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:01:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:01:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:01:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:01:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:02:01 [INFO] exp_shallowmodel: train time: 57.850s
12/10/2017 03:02:01 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:02:01 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 03:02:01 [INFO] exp_shallowmodel: f1_score:   0.431
12/10/2017 03:02:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:02:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.48      0.65      0.55       169
          F       0.69      0.67      0.68       281
          R       0.42      0.30      0.35       122

avg / total       0.56      0.57      0.56       592

12/10/2017 03:02:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:02:01 [INFO] exp_shallowmodel: 
[[  2  10   6   2]
 [  1 110  37  21]
 [  1  66 187  27]
 [  3  43  40  36]]
12/10/2017 03:02:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 03:02:01 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 03:02:01 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:02:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:02:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:02:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:02:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:02:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:02:59 [INFO] exp_shallowmodel: train time: 57.923s
12/10/2017 03:02:59 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:02:59 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 03:02:59 [INFO] exp_shallowmodel: f1_score:   0.418
12/10/2017 03:02:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:02:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.06        28
          C       0.49      0.67      0.57       172
          F       0.70      0.72      0.71       283
          R       0.44      0.27      0.33       123

avg / total       0.57      0.58      0.56       606

12/10/2017 03:02:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:02:59 [INFO] exp_shallowmodel: 
[[  1  12   9   6]
 [  0 116  39  17]
 [  2  59 203  19]
 [  3  50  37  33]]
12/10/2017 03:03:00 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 03:03:00 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:03:00 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:03:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:03:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:03:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:03:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:03:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:04:13 [INFO] exp_shallowmodel: train time: 73.075s
12/10/2017 03:04:13 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:04:13 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 03:04:13 [INFO] exp_shallowmodel: f1_score:   0.406
12/10/2017 03:04:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:04:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.48      0.69      0.57       169
          F       0.72      0.71      0.72       281
          R       0.35      0.20      0.26       122

avg / total       0.56      0.58      0.56       592

12/10/2017 03:04:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:04:13 [INFO] exp_shallowmodel: 
[[  1   5   9   5]
 [  1 116  29  23]
 [  0  63 200  18]
 [  3  56  38  25]]
12/10/2017 03:04:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 03:04:13 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:04:13 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:04:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:04:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:04:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:04:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:04:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:05:27 [INFO] exp_shallowmodel: train time: 74.603s
12/10/2017 03:05:27 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:05:27 [INFO] exp_shallowmodel: accuracy:   0.591
12/10/2017 03:05:27 [INFO] exp_shallowmodel: f1_score:   0.442
12/10/2017 03:05:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:05:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.49      0.72      0.58       169
          F       0.73      0.66      0.69       281
          R       0.50      0.35      0.41       122

avg / total       0.60      0.59      0.58       592

12/10/2017 03:05:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:05:27 [INFO] exp_shallowmodel: 
[[  1   5   9   5]
 [  1 121  27  20]
 [  0  78 185  18]
 [  3  45  31  43]]
12/10/2017 03:05:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 03:05:28 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:05:28 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:05:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:05:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:05:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:05:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:05:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:06:29 [INFO] exp_shallowmodel: train time: 61.744s
12/10/2017 03:06:29 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:06:29 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 03:06:29 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 03:06:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:06:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.49      0.69      0.57       169
          F       0.72      0.71      0.72       281
          R       0.44      0.25      0.32       122

avg / total       0.58      0.59      0.57       592

12/10/2017 03:06:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:06:29 [INFO] exp_shallowmodel: 
[[  1   7  10   2]
 [  1 117  30  21]
 [  2  64 200  15]
 [  5  51  36  30]]
12/10/2017 03:06:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 03:06:30 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:06:30 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:06:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:06:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:06:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:06:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:06:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:07:25 [INFO] exp_shallowmodel: train time: 55.588s
12/10/2017 03:07:25 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:07:25 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 03:07:25 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 03:07:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:07:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.05      0.08        20
          C       0.44      0.56      0.49       169
          F       0.68      0.72      0.70       281
          R       0.38      0.24      0.29       122

avg / total       0.53      0.55      0.54       592

12/10/2017 03:07:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:07:25 [INFO] exp_shallowmodel: 
[[  1   7   7   5]
 [  3  95  44  27]
 [  1  64 201  15]
 [  1  49  43  29]]
12/10/2017 03:07:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 03:07:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:07:25 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:07:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:07:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:07:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:07:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:07:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:08:12 [INFO] exp_shallowmodel: train time: 46.765s
12/10/2017 03:08:12 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:08:12 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 03:08:12 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 03:08:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:08:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.05      0.08        20
          C       0.49      0.62      0.55       169
          F       0.70      0.75      0.72       281
          R       0.46      0.28      0.35       122

avg / total       0.57      0.59      0.57       592

12/10/2017 03:08:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:08:12 [INFO] exp_shallowmodel: 
[[  1   6   7   6]
 [  1 104  45  19]
 [  3  53 210  15]
 [  1  49  38  34]]
12/10/2017 03:08:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 03:08:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:08:12 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:08:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:08:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:08:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:08:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:08:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:09:05 [INFO] exp_shallowmodel: train time: 52.980s
12/10/2017 03:09:05 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:09:05 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 03:09:05 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 03:09:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:09:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.52      0.59      0.55       169
          F       0.67      0.75      0.71       281
          R       0.41      0.26      0.32       122

avg / total       0.55      0.58      0.56       592

12/10/2017 03:09:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:09:05 [INFO] exp_shallowmodel: 
[[  1   5  10   4]
 [  3  99  42  25]
 [  1  52 210  18]
 [  4  36  50  32]]
12/10/2017 03:09:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 03:09:06 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:09:06 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:09:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:09:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:09:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:09:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:09:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:09:56 [INFO] exp_shallowmodel: train time: 50.835s
12/10/2017 03:09:56 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:09:56 [INFO] exp_shallowmodel: accuracy:   0.584
12/10/2017 03:09:56 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 03:09:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:09:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.05      0.08        20
          C       0.49      0.66      0.56       169
          F       0.72      0.70      0.71       281
          R       0.43      0.30      0.36       122

avg / total       0.58      0.58      0.57       592

12/10/2017 03:09:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:09:56 [INFO] exp_shallowmodel: 
[[  1   8   7   4]
 [  1 112  34  22]
 [  1  61 196  23]
 [  3  48  34  37]]
12/10/2017 03:09:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 03:09:57 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:09:57 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:09:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:09:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:09:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:09:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:09:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:10:35 [INFO] exp_shallowmodel: train time: 38.712s
12/10/2017 03:10:35 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:10:35 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 03:10:35 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 03:10:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:10:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.70      0.58       169
          F       0.72      0.68      0.70       281
          R       0.47      0.33      0.39       122

avg / total       0.58      0.59      0.58       592

12/10/2017 03:10:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:10:35 [INFO] exp_shallowmodel: 
[[  0  10   4   6]
 [  2 119  28  20]
 [  1  71 190  19]
 [  0  41  41  40]]
12/10/2017 03:10:36 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 03:10:36 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:10:36 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:10:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:10:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:10:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:10:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:10:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:11:47 [INFO] exp_shallowmodel: train time: 71.304s
12/10/2017 03:11:47 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:11:47 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 03:11:47 [INFO] exp_shallowmodel: f1_score:   0.439
12/10/2017 03:11:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:11:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.72      0.61       169
          F       0.73      0.72      0.72       281
          R       0.50      0.36      0.42       122

avg / total       0.60      0.62      0.60       592

12/10/2017 03:11:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:11:47 [INFO] exp_shallowmodel: 
[[  0   4  12   4]
 [  0 121  27  21]
 [  1  59 202  19]
 [  0  41  37  44]]
12/10/2017 03:11:47 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 03:11:47 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 03:11:47 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:11:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:11:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:11:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:11:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:11:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:12:55 [INFO] exp_shallowmodel: train time: 67.635s
12/10/2017 03:12:55 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:12:55 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 03:12:55 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 03:12:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:12:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.48      0.68      0.57       172
          F       0.74      0.75      0.75       283
          R       0.35      0.21      0.26       123

avg / total       0.55      0.59      0.56       606

12/10/2017 03:12:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:12:55 [INFO] exp_shallowmodel: 
[[  0  16   5   7]
 [  1 117  30  24]
 [  0  52 213  18]
 [  1  57  39  26]]
12/10/2017 03:12:55 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 03:12:55 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:12:55 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:12:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:12:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:12:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:12:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:12:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:14:02 [INFO] exp_shallowmodel: train time: 66.614s
12/10/2017 03:14:02 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:14:02 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 03:14:02 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 03:14:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:14:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.10      0.15        20
          C       0.47      0.59      0.52       169
          F       0.68      0.73      0.70       281
          R       0.44      0.26      0.33       122

avg / total       0.56      0.57      0.56       592

12/10/2017 03:14:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:14:02 [INFO] exp_shallowmodel: 
[[  2   7   5   6]
 [  2  99  52  16]
 [  2  54 206  19]
 [  0  49  41  32]]
12/10/2017 03:14:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 03:14:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:14:02 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:14:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:14:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:14:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:14:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:14:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:15:01 [INFO] exp_shallowmodel: train time: 59.038s
12/10/2017 03:15:01 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:15:01 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 03:15:01 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 03:15:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:15:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.67      0.58       169
          F       0.72      0.71      0.72       281
          R       0.48      0.34      0.40       122

avg / total       0.59      0.60      0.59       592

12/10/2017 03:15:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:15:01 [INFO] exp_shallowmodel: 
[[  0   6   9   5]
 [  2 114  33  20]
 [  0  61 200  20]
 [  0  44  36  42]]
12/10/2017 03:15:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 03:15:01 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:15:01 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:15:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:15:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:15:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:15:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:15:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:16:08 [INFO] exp_shallowmodel: train time: 67.308s
12/10/2017 03:16:08 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:16:08 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 03:16:08 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 03:16:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:16:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.05      0.08        20
          C       0.48      0.62      0.54       169
          F       0.69      0.71      0.70       281
          R       0.49      0.30      0.37       122

avg / total       0.57      0.58      0.57       592

12/10/2017 03:16:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:16:08 [INFO] exp_shallowmodel: 
[[  1   6   9   4]
 [  3 105  44  17]
 [  0  63 200  18]
 [  2  45  38  37]]
12/10/2017 03:16:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 03:16:09 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:16:09 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:16:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:16:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:16:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:16:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:16:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:17:16 [INFO] exp_shallowmodel: train time: 67.437s
12/10/2017 03:17:16 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:17:16 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 03:17:16 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 03:17:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:17:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.69      0.58       169
          F       0.71      0.69      0.70       281
          R       0.44      0.27      0.34       122

avg / total       0.57      0.58      0.57       592

12/10/2017 03:17:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:17:16 [INFO] exp_shallowmodel: 
[[  0   6   9   5]
 [  3 117  30  19]
 [  2  66 195  18]
 [  2  46  41  33]]
12/10/2017 03:17:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 03:17:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:17:16 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:17:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:17:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:17:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:17:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:17:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:18:25 [INFO] exp_shallowmodel: train time: 69.065s
12/10/2017 03:18:25 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:18:25 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 03:18:25 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 03:18:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:18:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.47      0.58      0.52       169
          F       0.67      0.73      0.70       281
          R       0.51      0.30      0.37       122

avg / total       0.56      0.57      0.56       592

12/10/2017 03:18:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:18:25 [INFO] exp_shallowmodel: 
[[  0  12   7   1]
 [  1  98  52  18]
 [  2  59 205  15]
 [  1  41  44  36]]
12/10/2017 03:18:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 03:18:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:18:26 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:18:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:18:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:18:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:18:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:18:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:19:11 [INFO] exp_shallowmodel: train time: 45.661s
12/10/2017 03:19:11 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:19:11 [INFO] exp_shallowmodel: accuracy:   0.600
12/10/2017 03:19:11 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 03:19:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:19:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.68      0.57       169
          F       0.73      0.72      0.73       281
          R       0.47      0.30      0.37       122

avg / total       0.59      0.60      0.58       592

12/10/2017 03:19:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:19:11 [INFO] exp_shallowmodel: 
[[  0   4   7   9]
 [  2 115  30  22]
 [  1  66 203  11]
 [  0  48  37  37]]
12/10/2017 03:19:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 03:19:11 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:19:11 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:19:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:19:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:19:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:19:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:19:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:20:01 [INFO] exp_shallowmodel: train time: 49.910s
12/10/2017 03:20:01 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:20:01 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 03:20:01 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 03:20:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:20:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.05      0.07        20
          C       0.46      0.66      0.54       169
          F       0.73      0.68      0.71       281
          R       0.43      0.30      0.35       122

avg / total       0.57      0.57      0.57       592

12/10/2017 03:20:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:20:01 [INFO] exp_shallowmodel: 
[[  1  12   3   4]
 [  3 111  31  24]
 [  2  68 192  19]
 [  1  48  37  36]]
12/10/2017 03:20:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 03:20:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:20:02 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:20:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:20:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:20:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:20:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:20:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:20:52 [INFO] exp_shallowmodel: train time: 49.995s
12/10/2017 03:20:52 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:20:52 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 03:20:52 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 03:20:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:20:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.62      0.55       169
          F       0.69      0.72      0.70       281
          R       0.40      0.26      0.32       122

avg / total       0.55      0.57      0.55       592

12/10/2017 03:20:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:20:52 [INFO] exp_shallowmodel: 
[[  0   4  10   6]
 [  1 105  40  23]
 [  1  59 201  20]
 [  2  47  41  32]]
12/10/2017 03:20:52 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 03:20:52 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:20:52 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:20:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:20:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:20:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:20:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:20:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:21:47 [INFO] exp_shallowmodel: train time: 55.604s
12/10/2017 03:21:47 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:21:47 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 03:21:47 [INFO] exp_shallowmodel: f1_score:   0.381
12/10/2017 03:21:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:21:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.44      0.56      0.49       169
          F       0.67      0.71      0.69       281
          R       0.44      0.28      0.34       122

avg / total       0.54      0.55      0.54       592

12/10/2017 03:21:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:21:47 [INFO] exp_shallowmodel: 
[[  0   9   8   3]
 [  1  95  47  26]
 [  1  67 199  14]
 [  1  46  41  34]]
12/10/2017 03:21:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 03:21:48 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 03:21:48 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:21:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:21:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:21:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:21:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:21:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:22:48 [INFO] exp_shallowmodel: train time: 60.428s
12/10/2017 03:22:48 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:22:48 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 03:22:48 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 03:22:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:22:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.07        28
          C       0.46      0.60      0.52       172
          F       0.68      0.73      0.71       283
          R       0.41      0.24      0.31       123

avg / total       0.56      0.57      0.54       606

12/10/2017 03:22:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:22:48 [INFO] exp_shallowmodel: 
[[  1  10   7  10]
 [  0 104  53  15]
 [  0  57 208  18]
 [  1  55  37  30]]
12/10/2017 03:22:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 03:22:48 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:22:48 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:22:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:22:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:22:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:22:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:22:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:23:53 [INFO] exp_shallowmodel: train time: 65.037s
12/10/2017 03:23:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:23:53 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 03:23:53 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 03:23:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:23:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.55      0.54      0.54       169
          F       0.66      0.82      0.73       281
          R       0.49      0.29      0.36       122

avg / total       0.57      0.60      0.58       592

12/10/2017 03:23:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:23:53 [INFO] exp_shallowmodel: 
[[  0   4  13   3]
 [  1  91  61  16]
 [  1  32 230  18]
 [  3  38  46  35]]
12/10/2017 03:23:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 03:23:53 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:23:53 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:23:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:23:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:23:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:23:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:23:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:24:55 [INFO] exp_shallowmodel: train time: 61.113s
12/10/2017 03:24:55 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:24:55 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 03:24:55 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 03:24:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:24:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.55      0.53       169
          F       0.67      0.75      0.71       281
          R       0.41      0.32      0.36       122

avg / total       0.55      0.58      0.56       592

12/10/2017 03:24:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:24:55 [INFO] exp_shallowmodel: 
[[  0   5   6   9]
 [  1  93  53  22]
 [  1  46 210  24]
 [  0  39  44  39]]
12/10/2017 03:24:55 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 03:24:55 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:24:55 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:24:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:24:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:24:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:24:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:24:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:26:16 [INFO] exp_shallowmodel: train time: 81.557s
12/10/2017 03:26:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:26:16 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 03:26:16 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 03:26:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:26:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.59      0.53       169
          F       0.67      0.74      0.71       281
          R       0.48      0.30      0.37       122

avg / total       0.56      0.58      0.56       592

12/10/2017 03:26:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:26:16 [INFO] exp_shallowmodel: 
[[  0   7   8   5]
 [  1  99  51  18]
 [  1  55 209  16]
 [  0  43  43  36]]
12/10/2017 03:26:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 03:26:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:26:17 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:26:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:26:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:26:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:26:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:26:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:27:11 [INFO] exp_shallowmodel: train time: 54.432s
12/10/2017 03:27:11 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:27:11 [INFO] exp_shallowmodel: accuracy:   0.598
12/10/2017 03:27:11 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 03:27:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:27:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.67      0.58       169
          F       0.72      0.71      0.72       281
          R       0.50      0.33      0.40       122

avg / total       0.59      0.60      0.59       592

12/10/2017 03:27:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:27:11 [INFO] exp_shallowmodel: 
[[  0   7   8   5]
 [  6 114  35  14]
 [  1  59 200  21]
 [  2  46  34  40]]
12/10/2017 03:27:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 03:27:11 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:27:11 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:27:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:27:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:27:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:27:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:27:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:28:00 [INFO] exp_shallowmodel: train time: 49.197s
12/10/2017 03:28:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:28:00 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 03:28:00 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 03:28:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:28:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.56      0.53       169
          F       0.67      0.77      0.72       281
          R       0.46      0.31      0.37       122

avg / total       0.56      0.59      0.57       592

12/10/2017 03:28:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:28:00 [INFO] exp_shallowmodel: 
[[  0   8   6   6]
 [  2  95  52  20]
 [  1  46 215  19]
 [  0  38  46  38]]
12/10/2017 03:28:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 03:28:01 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:28:01 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:28:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:28:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:28:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:28:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:28:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:28:52 [INFO] exp_shallowmodel: train time: 50.998s
12/10/2017 03:28:52 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:28:52 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 03:28:52 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 03:28:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:28:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.70      0.57       169
          F       0.67      0.66      0.66       281
          R       0.46      0.26      0.33       122

avg / total       0.55      0.57      0.55       592

12/10/2017 03:28:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:28:52 [INFO] exp_shallowmodel: 
[[  0   5  11   4]
 [  1 118  35  15]
 [  1  76 185  19]
 [  0  45  45  32]]
12/10/2017 03:28:52 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 03:28:52 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:28:52 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:28:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:28:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:28:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:28:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:28:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:29:40 [INFO] exp_shallowmodel: train time: 48.661s
12/10/2017 03:29:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:29:40 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 03:29:40 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 03:29:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:29:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.48      0.66      0.55       169
          F       0.71      0.70      0.70       281
          R       0.47      0.29      0.36       122

avg / total       0.57      0.58      0.57       592

12/10/2017 03:29:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:29:40 [INFO] exp_shallowmodel: 
[[  1   6   8   5]
 [  2 111  38  18]
 [  1  66 197  17]
 [  1  50  36  35]]
12/10/2017 03:29:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 03:29:41 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:29:41 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:29:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:29:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:29:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:29:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:29:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:30:44 [INFO] exp_shallowmodel: train time: 63.055s
12/10/2017 03:30:44 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:30:44 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 03:30:44 [INFO] exp_shallowmodel: f1_score:   0.455
12/10/2017 03:30:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:30:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.51      0.68      0.59       169
          F       0.75      0.74      0.74       281
          R       0.43      0.29      0.34       122

avg / total       0.60      0.61      0.60       592

12/10/2017 03:30:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:30:44 [INFO] exp_shallowmodel: 
[[  2   8   6   4]
 [  1 115  27  26]
 [  0  56 208  17]
 [  4  45  38  35]]
12/10/2017 03:30:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 03:30:44 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:30:44 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:30:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:30:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:30:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:30:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:30:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:31:27 [INFO] exp_shallowmodel: train time: 42.983s
12/10/2017 03:31:27 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:31:27 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 03:31:27 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 03:31:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:31:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.64      0.53       169
          F       0.70      0.67      0.69       281
          R       0.43      0.30      0.35       122

avg / total       0.55      0.56      0.55       592

12/10/2017 03:31:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:31:27 [INFO] exp_shallowmodel: 
[[  0   9   5   6]
 [  1 108  42  18]
 [  1  67 189  24]
 [  1  52  33  36]]
12/10/2017 03:31:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 03:31:27 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 03:31:27 [INFO] exp_shallowmodel: #(feature) = 1292
12/10/2017 03:31:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:31:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:31:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:31:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:31:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:32:32 [INFO] exp_shallowmodel: train time: 65.134s
12/10/2017 03:32:32 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:32:32 [INFO] exp_shallowmodel: accuracy:   0.589
12/10/2017 03:32:32 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 03:32:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:32:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.06        28
          C       0.49      0.63      0.55       172
          F       0.71      0.76      0.73       283
          R       0.43      0.27      0.33       123

avg / total       0.57      0.59      0.57       606

12/10/2017 03:32:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:32:32 [INFO] exp_shallowmodel: 
[[  1  15   7   5]
 [  1 108  37  26]
 [  0  55 215  13]
 [  3  43  44  33]]
12/10/2017 03:32:37 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 03:32:37 [INFO] task_runner: context=current, feature=2-lexical
12/10/2017 03:32:37 [INFO] task_runner: retained feature numbers=[4.1]
12/10/2017 03:32:37 [INFO] task_runner: #(data)=3530
12/10/2017 03:32:37 [INFO] task_runner: #(feature)=2755
12/10/2017 03:32:37 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 03:32:37 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 03:32:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:32:37 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:32:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:32:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:32:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:32:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:32:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:32:50 [INFO] exp_shallowmodel: train time: 12.348s
12/10/2017 03:32:50 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:32:50 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 03:32:50 [INFO] exp_shallowmodel: f1_score:   0.342
12/10/2017 03:32:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:32:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.15      0.21        27
          F       0.76      0.92      0.84       250
          R       0.46      0.25      0.33        52

avg / total       0.64      0.70      0.66       352

12/10/2017 03:32:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:32:50 [INFO] exp_shallowmodel: 
[[  0   1  17   5]
 [  2   4  20   1]
 [  6   4 231   9]
 [  2   3  34  13]]
12/10/2017 03:32:50 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 03:32:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:32:50 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:32:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:32:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:32:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:32:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:32:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:33:03 [INFO] exp_shallowmodel: train time: 12.526s
12/10/2017 03:33:03 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:33:03 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 03:33:03 [INFO] exp_shallowmodel: f1_score:   0.370
12/10/2017 03:33:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:33:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.33      0.15      0.21        27
          F       0.76      0.92      0.83       250
          R       0.46      0.25      0.33        52

avg / total       0.65      0.70      0.66       352

12/10/2017 03:33:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:33:03 [INFO] exp_shallowmodel: 
[[  2   0  19   2]
 [  1   4  21   1]
 [  4   5 229  12]
 [  3   3  33  13]]
12/10/2017 03:33:03 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 03:33:03 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:33:03 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:33:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:33:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:33:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:33:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:33:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:33:16 [INFO] exp_shallowmodel: train time: 12.603s
12/10/2017 03:33:16 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:33:16 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 03:33:16 [INFO] exp_shallowmodel: f1_score:   0.366
12/10/2017 03:33:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:33:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.09      0.12        23
          C       0.31      0.19      0.23        27
          F       0.75      0.91      0.82       250
          R       0.46      0.21      0.29        52

avg / total       0.64      0.70      0.65       352

12/10/2017 03:33:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:33:16 [INFO] exp_shallowmodel: 
[[  2   1  19   1]
 [  2   5  17   3]
 [  6   8 227   9]
 [  1   2  38  11]]
12/10/2017 03:33:16 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 03:33:16 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:33:16 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:33:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:33:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:33:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:33:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:33:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:33:29 [INFO] exp_shallowmodel: train time: 13.355s
12/10/2017 03:33:29 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:33:29 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 03:33:29 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 03:33:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:33:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.09      0.11        23
          C       0.40      0.22      0.29        27
          F       0.77      0.92      0.84       250
          R       0.54      0.27      0.36        52

avg / total       0.67      0.71      0.68       352

12/10/2017 03:33:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:33:29 [INFO] exp_shallowmodel: 
[[  2   1  19   1]
 [  2   6  16   3]
 [  6   7 229   8]
 [  3   1  34  14]]
12/10/2017 03:33:29 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 03:33:29 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:33:29 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:33:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:33:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:33:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:33:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:33:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:33:43 [INFO] exp_shallowmodel: train time: 14.037s
12/10/2017 03:33:43 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:33:43 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 03:33:43 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 03:33:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:33:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.09      0.11        23
          C       0.47      0.26      0.33        27
          F       0.77      0.88      0.82       250
          R       0.41      0.29      0.34        52

avg / total       0.65      0.69      0.67       352

12/10/2017 03:33:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:33:43 [INFO] exp_shallowmodel: 
[[  2   0  17   4]
 [  2   7  14   4]
 [  8   8 220  14]
 [  3   0  34  15]]
12/10/2017 03:33:44 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 03:33:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:33:44 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:33:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:33:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:33:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:33:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:33:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:33:57 [INFO] exp_shallowmodel: train time: 13.347s
12/10/2017 03:33:57 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:33:57 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 03:33:57 [INFO] exp_shallowmodel: f1_score:   0.366
12/10/2017 03:33:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:33:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.13      0.20        23
          C       0.33      0.15      0.21        27
          F       0.78      0.91      0.84       250
          R       0.26      0.19      0.22        52

avg / total       0.64      0.70      0.66       352

12/10/2017 03:33:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:33:57 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  1   4  12  10]
 [  1   5 228  16]
 [  2   2  38  10]]
12/10/2017 03:33:57 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 03:33:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:33:57 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:33:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:33:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:33:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:33:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:33:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:34:11 [INFO] exp_shallowmodel: train time: 14.115s
12/10/2017 03:34:11 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:34:11 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 03:34:11 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 03:34:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:34:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.60      0.33      0.43        27
          F       0.78      0.93      0.85       250
          R       0.41      0.23      0.30        52

avg / total       0.66      0.72      0.68       352

12/10/2017 03:34:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:34:11 [INFO] exp_shallowmodel: 
[[  0   3  17   3]
 [  2   9  10   6]
 [  6   3 233   8]
 [  2   0  38  12]]
12/10/2017 03:34:12 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 03:34:12 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:34:12 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:34:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:34:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:34:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:34:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:34:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:34:27 [INFO] exp_shallowmodel: train time: 14.782s
12/10/2017 03:34:27 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:34:27 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 03:34:27 [INFO] exp_shallowmodel: f1_score:   0.323
12/10/2017 03:34:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:34:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.13      0.18        23
          C       0.18      0.07      0.11        27
          F       0.76      0.90      0.82       250
          R       0.24      0.15      0.19        52

avg / total       0.61      0.68      0.63       352

12/10/2017 03:34:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:34:27 [INFO] exp_shallowmodel: 
[[  3   2  15   3]
 [  3   2  14   8]
 [  4   6 225  15]
 [  1   1  42   8]]
12/10/2017 03:34:27 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 03:34:27 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:34:27 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:34:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:34:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:34:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:34:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:34:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:34:41 [INFO] exp_shallowmodel: train time: 14.673s
12/10/2017 03:34:41 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:34:41 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 03:34:41 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 03:34:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:34:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.17      0.22        23
          C       0.24      0.15      0.18        27
          F       0.78      0.90      0.83       250
          R       0.39      0.23      0.29        52

avg / total       0.64      0.70      0.66       352

12/10/2017 03:34:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:34:41 [INFO] exp_shallowmodel: 
[[  4   1  15   3]
 [  2   4  16   5]
 [  5   9 225  11]
 [  3   3  34  12]]
12/10/2017 03:34:42 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 03:34:42 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 03:34:42 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:34:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:34:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:34:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:34:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:34:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:34:55 [INFO] exp_shallowmodel: train time: 12.907s
12/10/2017 03:34:55 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:34:55 [INFO] exp_shallowmodel: accuracy:   0.660
12/10/2017 03:34:55 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 03:34:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:34:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.29      0.15      0.20        27
          F       0.73      0.91      0.81       251
          R       0.24      0.10      0.14        59

avg / total       0.57      0.66      0.60       362

12/10/2017 03:34:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:34:55 [INFO] exp_shallowmodel: 
[[  0   1  19   5]
 [  3   4  19   1]
 [  5   4 229  13]
 [  2   5  46   6]]
12/10/2017 03:34:55 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 03:34:55 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:34:55 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:34:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:34:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:34:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:34:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:34:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:35:09 [INFO] exp_shallowmodel: train time: 13.676s
12/10/2017 03:35:09 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:35:09 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 03:35:09 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 03:35:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:35:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.36      0.19      0.24        27
          F       0.77      0.93      0.84       250
          R       0.50      0.29      0.37        52

avg / total       0.66      0.72      0.68       352

12/10/2017 03:35:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:35:09 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   5  18   4]
 [  5   5 232   8]
 [  1   3  33  15]]
12/10/2017 03:35:09 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 03:35:09 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:35:09 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:35:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:35:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:35:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:35:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:35:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:35:22 [INFO] exp_shallowmodel: train time: 13.417s
12/10/2017 03:35:22 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:35:22 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 03:35:22 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 03:35:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:35:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.06        23
          C       0.33      0.15      0.21        27
          F       0.77      0.91      0.84       250
          R       0.29      0.19      0.23        52

avg / total       0.62      0.69      0.65       352

12/10/2017 03:35:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:35:22 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  3   4  13   7]
 [  5   4 227  14]
 [  3   3  36  10]]
12/10/2017 03:35:23 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 03:35:23 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:35:23 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:35:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:35:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:35:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:35:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:35:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:35:36 [INFO] exp_shallowmodel: train time: 13.550s
12/10/2017 03:35:36 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:35:36 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 03:35:36 [INFO] exp_shallowmodel: f1_score:   0.351
12/10/2017 03:35:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:35:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.09      0.11        23
          C       0.43      0.22      0.29        27
          F       0.76      0.92      0.84       250
          R       0.26      0.12      0.16        52

avg / total       0.62      0.70      0.65       352

12/10/2017 03:35:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:35:36 [INFO] exp_shallowmodel: 
[[  2   0  17   4]
 [  1   6  16   4]
 [  5   5 231   9]
 [  4   3  39   6]]
12/10/2017 03:35:36 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 03:35:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:35:36 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:35:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:35:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:35:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:35:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:35:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:35:52 [INFO] exp_shallowmodel: train time: 15.998s
12/10/2017 03:35:52 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:35:52 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 03:35:52 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 03:35:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:35:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.30      0.39        23
          C       0.29      0.07      0.12        27
          F       0.78      0.94      0.85       250
          R       0.31      0.19      0.24        52

avg / total       0.66      0.72      0.68       352

12/10/2017 03:35:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:35:52 [INFO] exp_shallowmodel: 
[[  7   1  13   2]
 [  2   2  16   7]
 [  1   1 235  13]
 [  3   3  36  10]]
12/10/2017 03:35:53 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 03:35:53 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:35:53 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:35:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:35:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:35:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:35:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:35:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:36:06 [INFO] exp_shallowmodel: train time: 13.725s
12/10/2017 03:36:06 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:36:06 [INFO] exp_shallowmodel: accuracy:   0.670
12/10/2017 03:36:06 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 03:36:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:36:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.09      0.11        23
          C       0.24      0.15      0.18        27
          F       0.76      0.89      0.82       250
          R       0.30      0.15      0.20        52

avg / total       0.61      0.67      0.63       352

12/10/2017 03:36:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:36:06 [INFO] exp_shallowmodel: 
[[  2   1  18   2]
 [  2   4  17   4]
 [  5  10 222  13]
 [  5   2  37   8]]
12/10/2017 03:36:07 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 03:36:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:36:07 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:36:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:36:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:36:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:36:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:36:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:36:19 [INFO] exp_shallowmodel: train time: 11.952s
12/10/2017 03:36:19 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:36:19 [INFO] exp_shallowmodel: accuracy:   0.670
12/10/2017 03:36:19 [INFO] exp_shallowmodel: f1_score:   0.283
12/10/2017 03:36:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:36:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.15      0.07      0.10        27
          F       0.76      0.90      0.82       250
          R       0.26      0.17      0.21        52

avg / total       0.59      0.67      0.62       352

12/10/2017 03:36:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:36:19 [INFO] exp_shallowmodel: 
[[  0   1  18   4]
 [  2   2  16   7]
 [  5   6 225  14]
 [  1   4  38   9]]
12/10/2017 03:36:19 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 03:36:19 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:36:19 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:36:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:36:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:36:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:36:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:36:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:36:32 [INFO] exp_shallowmodel: train time: 13.128s
12/10/2017 03:36:32 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:36:32 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 03:36:32 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 03:36:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:36:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.38      0.19      0.25        27
          F       0.76      0.92      0.83       250
          R       0.50      0.27      0.35        52

avg / total       0.66      0.71      0.67       352

12/10/2017 03:36:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:36:32 [INFO] exp_shallowmodel: 
[[  2   1  17   3]
 [  2   5  19   1]
 [  3   7 230  10]
 [  3   0  35  14]]
12/10/2017 03:36:32 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 03:36:32 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:36:32 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:36:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:36:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:36:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:36:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:36:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:36:45 [INFO] exp_shallowmodel: train time: 12.492s
12/10/2017 03:36:45 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:36:45 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 03:36:45 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 03:36:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:36:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.04      0.06        23
          C       0.44      0.15      0.22        27
          F       0.75      0.92      0.83       250
          R       0.25      0.12      0.16        52

avg / total       0.61      0.69      0.63       352

12/10/2017 03:36:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:36:45 [INFO] exp_shallowmodel: 
[[  1   0  16   6]
 [  1   4  19   3]
 [  7   3 231   9]
 [  2   2  42   6]]
12/10/2017 03:36:45 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 03:36:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:36:45 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:36:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:36:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:36:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:36:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:36:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:36:58 [INFO] exp_shallowmodel: train time: 13.281s
12/10/2017 03:36:58 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:36:58 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 03:36:58 [INFO] exp_shallowmodel: f1_score:   0.340
12/10/2017 03:36:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:36:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.17      0.20        23
          C       0.12      0.04      0.06        27
          F       0.75      0.90      0.82       250
          R       0.42      0.21      0.28        52

avg / total       0.62      0.69      0.64       352

12/10/2017 03:36:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:36:58 [INFO] exp_shallowmodel: 
[[  4   0  18   1]
 [  3   1  18   5]
 [  9   6 226   9]
 [  1   1  39  11]]
12/10/2017 03:36:59 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 03:36:59 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 03:36:59 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:36:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:36:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:36:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:36:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:36:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:37:14 [INFO] exp_shallowmodel: train time: 14.958s
12/10/2017 03:37:14 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:37:14 [INFO] exp_shallowmodel: accuracy:   0.666
12/10/2017 03:37:14 [INFO] exp_shallowmodel: f1_score:   0.310
12/10/2017 03:37:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:37:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.04      0.06        25
          C       0.36      0.15      0.21        27
          F       0.76      0.91      0.83       251
          R       0.19      0.12      0.15        59

avg / total       0.59      0.67      0.62       362

12/10/2017 03:37:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:37:14 [INFO] exp_shallowmodel: 
[[  1   0  19   5]
 [  1   4  13   9]
 [  4   2 229  16]
 [  5   5  42   7]]
12/10/2017 03:37:14 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 03:37:14 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:37:14 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:37:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:37:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:37:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:37:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:37:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:37:29 [INFO] exp_shallowmodel: train time: 15.492s
12/10/2017 03:37:29 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:37:29 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 03:37:29 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 03:37:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:37:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.47      0.26      0.33        27
          F       0.78      0.93      0.85       250
          R       0.47      0.27      0.34        52

avg / total       0.67      0.72      0.68       352

12/10/2017 03:37:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:37:29 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  2   7  16   2]
 [  3   3 233  11]
 [  1   4  33  14]]
12/10/2017 03:37:30 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 03:37:30 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:37:30 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:37:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:37:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:37:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:37:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:37:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:37:44 [INFO] exp_shallowmodel: train time: 14.116s
12/10/2017 03:37:44 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:37:44 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 03:37:44 [INFO] exp_shallowmodel: f1_score:   0.374
12/10/2017 03:37:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:37:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.13      0.16        23
          C       0.26      0.19      0.22        27
          F       0.78      0.92      0.84       250
          R       0.50      0.19      0.28        52

avg / total       0.66      0.71      0.67       352

12/10/2017 03:37:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:37:44 [INFO] exp_shallowmodel: 
[[  3   1  19   0]
 [  2   5  17   3]
 [  5   7 231   7]
 [  5   6  31  10]]
12/10/2017 03:37:44 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 03:37:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:37:44 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:37:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:37:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:37:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:37:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:37:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:37:59 [INFO] exp_shallowmodel: train time: 14.448s
12/10/2017 03:37:59 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:37:59 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 03:37:59 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 03:37:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:37:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.22      0.29        23
          C       0.27      0.15      0.19        27
          F       0.78      0.93      0.85       250
          R       0.36      0.19      0.25        52

avg / total       0.66      0.72      0.67       352

12/10/2017 03:37:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:37:59 [INFO] exp_shallowmodel: 
[[  5   0  16   2]
 [  1   4  13   9]
 [  2   8 233   7]
 [  3   3  36  10]]
12/10/2017 03:37:59 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 03:37:59 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:37:59 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:37:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:37:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:37:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:37:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:37:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:38:13 [INFO] exp_shallowmodel: train time: 13.929s
12/10/2017 03:38:13 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:38:13 [INFO] exp_shallowmodel: accuracy:   0.670
12/10/2017 03:38:13 [INFO] exp_shallowmodel: f1_score:   0.285
12/10/2017 03:38:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:38:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.22      0.07      0.11        27
          F       0.74      0.90      0.81       250
          R       0.29      0.17      0.22        52

avg / total       0.59      0.67      0.62       352

12/10/2017 03:38:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:38:13 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   2  20   5]
 [  5   6 225  14]
 [  4   1  38   9]]
12/10/2017 03:38:13 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 03:38:13 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:38:13 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:38:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:38:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:38:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:38:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:38:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:38:27 [INFO] exp_shallowmodel: train time: 13.592s
12/10/2017 03:38:27 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:38:27 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 03:38:27 [INFO] exp_shallowmodel: f1_score:   0.352
12/10/2017 03:38:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:38:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.46      0.22      0.30        27
          F       0.78      0.89      0.83       250
          R       0.31      0.25      0.28        52

avg / total       0.63      0.69      0.65       352

12/10/2017 03:38:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:38:27 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  1   6  10  10]
 [  7   5 223  15]
 [  2   2  35  13]]
12/10/2017 03:38:27 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 03:38:27 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:38:27 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:38:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:38:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:38:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:38:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:38:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:38:40 [INFO] exp_shallowmodel: train time: 12.866s
12/10/2017 03:38:40 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:38:40 [INFO] exp_shallowmodel: accuracy:   0.685
12/10/2017 03:38:40 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 03:38:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:38:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.09      0.12        23
          C       0.23      0.11      0.15        27
          F       0.75      0.90      0.82       250
          R       0.39      0.23      0.29        52

avg / total       0.62      0.68      0.64       352

12/10/2017 03:38:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:38:40 [INFO] exp_shallowmodel: 
[[  2   0  19   2]
 [  0   3  20   4]
 [  4   9 224  13]
 [  3   1  36  12]]
12/10/2017 03:38:40 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 03:38:40 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:38:40 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:38:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:38:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:38:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:38:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:38:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:38:52 [INFO] exp_shallowmodel: train time: 12.421s
12/10/2017 03:38:52 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:38:52 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 03:38:52 [INFO] exp_shallowmodel: f1_score:   0.362
12/10/2017 03:38:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:38:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.04      0.06        23
          C       0.33      0.19      0.24        27
          F       0.77      0.91      0.84       250
          R       0.42      0.25      0.31        52

avg / total       0.64      0.70      0.66       352

12/10/2017 03:38:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:38:52 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  5   5  14   3]
 [  2   8 228  12]
 [  3   2  34  13]]
12/10/2017 03:38:53 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 03:38:53 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:38:53 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:38:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:38:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:38:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:38:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:38:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:39:06 [INFO] exp_shallowmodel: train time: 13.416s
12/10/2017 03:39:06 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:39:06 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 03:39:06 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 03:39:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:39:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.13      0.19        23
          C       0.40      0.22      0.29        27
          F       0.76      0.92      0.84       250
          R       0.42      0.21      0.28        52

avg / total       0.66      0.71      0.67       352

12/10/2017 03:39:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:39:06 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  0   6  17   4]
 [  5   6 231   8]
 [  1   2  38  11]]
12/10/2017 03:39:06 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 03:39:06 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:39:06 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:39:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:39:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:39:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:39:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:39:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:39:22 [INFO] exp_shallowmodel: train time: 15.376s
12/10/2017 03:39:22 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:39:22 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 03:39:22 [INFO] exp_shallowmodel: f1_score:   0.359
12/10/2017 03:39:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:39:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.09      0.13        23
          C       0.29      0.15      0.20        27
          F       0.77      0.93      0.84       250
          R       0.37      0.21      0.27        52

avg / total       0.64      0.71      0.66       352

12/10/2017 03:39:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:39:22 [INFO] exp_shallowmodel: 
[[  2   1  13   7]
 [  1   4  17   5]
 [  4   7 232   7]
 [  1   2  38  11]]
12/10/2017 03:39:22 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 03:39:22 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 03:39:22 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:39:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:39:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:39:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:39:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:39:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:39:36 [INFO] exp_shallowmodel: train time: 14.306s
12/10/2017 03:39:36 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:39:36 [INFO] exp_shallowmodel: accuracy:   0.691
12/10/2017 03:39:36 [INFO] exp_shallowmodel: f1_score:   0.364
12/10/2017 03:39:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:39:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.08      0.11        25
          C       0.38      0.22      0.28        27
          F       0.75      0.92      0.83       251
          R       0.42      0.17      0.24        59

avg / total       0.63      0.69      0.64       362

12/10/2017 03:39:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:39:36 [INFO] exp_shallowmodel: 
[[  2   1  18   4]
 [  0   6  19   2]
 [  7   4 232   8]
 [  2   5  42  10]]
12/10/2017 03:39:37 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 03:39:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:39:37 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:39:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:39:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:39:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:39:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:39:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:39:52 [INFO] exp_shallowmodel: train time: 14.977s
12/10/2017 03:39:52 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:39:52 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 03:39:52 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 03:39:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:39:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.17      0.22        23
          C       0.32      0.26      0.29        27
          F       0.79      0.91      0.85       250
          R       0.41      0.21      0.28        52

avg / total       0.66      0.71      0.68       352

12/10/2017 03:39:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:39:52 [INFO] exp_shallowmodel: 
[[  4   0  16   3]
 [  4   7  13   3]
 [  3   9 228  10]
 [  3   6  32  11]]
12/10/2017 03:39:52 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 03:39:52 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:39:52 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:39:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:39:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:39:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:39:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:39:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:40:09 [INFO] exp_shallowmodel: train time: 17.390s
12/10/2017 03:40:09 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:40:09 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 03:40:09 [INFO] exp_shallowmodel: f1_score:   0.357
12/10/2017 03:40:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:40:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.33      0.19      0.24        27
          F       0.76      0.92      0.83       250
          R       0.39      0.23      0.29        52

avg / total       0.64      0.70      0.66       352

12/10/2017 03:40:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:40:09 [INFO] exp_shallowmodel: 
[[  1   0  18   4]
 [  0   5  17   5]
 [  3   8 229  10]
 [  1   2  37  12]]
12/10/2017 03:40:10 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 03:40:10 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:40:10 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:40:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:40:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:40:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:40:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:40:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:40:28 [INFO] exp_shallowmodel: train time: 18.140s
12/10/2017 03:40:28 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:40:28 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 03:40:28 [INFO] exp_shallowmodel: f1_score:   0.388
12/10/2017 03:40:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:40:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.17      0.24        23
          C       0.30      0.11      0.16        27
          F       0.78      0.94      0.85       250
          R       0.41      0.23      0.30        52

avg / total       0.66      0.72      0.68       352

12/10/2017 03:40:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:40:28 [INFO] exp_shallowmodel: 
[[  4   1  16   2]
 [  2   3  15   7]
 [  2   5 235   8]
 [  2   1  37  12]]
12/10/2017 03:40:28 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 03:40:28 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:40:28 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:40:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:40:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:40:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:40:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:40:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:40:43 [INFO] exp_shallowmodel: train time: 14.803s
12/10/2017 03:40:43 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:40:43 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 03:40:43 [INFO] exp_shallowmodel: f1_score:   0.357
12/10/2017 03:40:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:40:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.17      0.24        23
          C       0.18      0.07      0.11        27
          F       0.77      0.91      0.83       250
          R       0.32      0.21      0.26        52

avg / total       0.63      0.69      0.65       352

12/10/2017 03:40:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:40:43 [INFO] exp_shallowmodel: 
[[  4   2  13   4]
 [  1   2  19   5]
 [  4   5 227  14]
 [  2   2  37  11]]
12/10/2017 03:40:43 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 03:40:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:40:43 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:40:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:40:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:40:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:40:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:40:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:40:55 [INFO] exp_shallowmodel: train time: 11.595s
12/10/2017 03:40:55 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:40:55 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 03:40:55 [INFO] exp_shallowmodel: f1_score:   0.371
12/10/2017 03:40:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:40:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.07        23
          C       0.40      0.15      0.22        27
          F       0.78      0.95      0.86       250
          R       0.47      0.27      0.34        52

avg / total       0.66      0.73      0.68       352

12/10/2017 03:40:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:40:55 [INFO] exp_shallowmodel: 
[[  1   1  16   5]
 [  1   4  18   4]
 [  1   4 238   7]
 [  3   1  34  14]]
12/10/2017 03:40:55 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 03:40:55 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:40:55 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:40:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:40:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:40:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:40:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:40:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:41:06 [INFO] exp_shallowmodel: train time: 10.728s
12/10/2017 03:41:06 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:41:06 [INFO] exp_shallowmodel: accuracy:   0.665
12/10/2017 03:41:06 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 03:41:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:41:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.21      0.15      0.17        27
          F       0.76      0.87      0.81       250
          R       0.33      0.25      0.28        52

avg / total       0.60      0.66      0.63       352

12/10/2017 03:41:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:41:06 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  1   4  18   4]
 [  5   8 217  20]
 [  0   6  33  13]]
12/10/2017 03:41:06 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 03:41:06 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:41:06 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:41:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:41:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:41:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:41:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:41:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:41:18 [INFO] exp_shallowmodel: train time: 12.410s
12/10/2017 03:41:18 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:41:18 [INFO] exp_shallowmodel: accuracy:   0.668
12/10/2017 03:41:18 [INFO] exp_shallowmodel: f1_score:   0.349
12/10/2017 03:41:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:41:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.17      0.21        23
          C       0.27      0.15      0.19        27
          F       0.77      0.88      0.82       250
          R       0.23      0.15      0.18        52

avg / total       0.61      0.67      0.64       352

12/10/2017 03:41:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:41:18 [INFO] exp_shallowmodel: 
[[  4   1  14   4]
 [  1   4  15   7]
 [  9   6 219  16]
 [  2   4  38   8]]
12/10/2017 03:41:19 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 03:41:19 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:41:19 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:41:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:41:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:41:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:41:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:41:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:41:32 [INFO] exp_shallowmodel: train time: 13.106s
12/10/2017 03:41:32 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:41:32 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 03:41:32 [INFO] exp_shallowmodel: f1_score:   0.322
12/10/2017 03:41:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:41:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.20      0.11      0.14        27
          F       0.75      0.92      0.83       250
          R       0.33      0.13      0.19        52

avg / total       0.61      0.69      0.64       352

12/10/2017 03:41:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:41:32 [INFO] exp_shallowmodel: 
[[  2   1  16   4]
 [  0   3  20   4]
 [  5   8 231   6]
 [  3   3  39   7]]
12/10/2017 03:41:32 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 03:41:32 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:41:32 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:41:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:41:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:41:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:41:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:41:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:41:43 [INFO] exp_shallowmodel: train time: 11.043s
12/10/2017 03:41:43 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:41:43 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 03:41:43 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 03:41:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:41:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.24      0.15      0.18        27
          F       0.77      0.90      0.83       250
          R       0.31      0.19      0.24        52

avg / total       0.61      0.68      0.64       352

12/10/2017 03:41:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:41:43 [INFO] exp_shallowmodel: 
[[  0   1  15   7]
 [  1   4  19   3]
 [  6   7 225  12]
 [  3   5  34  10]]
12/10/2017 03:41:43 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 03:41:43 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 03:41:43 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:41:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:41:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:41:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:41:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:41:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:41:58 [INFO] exp_shallowmodel: train time: 14.301s
12/10/2017 03:41:58 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:41:58 [INFO] exp_shallowmodel: accuracy:   0.685
12/10/2017 03:41:58 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 03:41:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:41:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.04      0.06        25
          C       0.47      0.26      0.33        27
          F       0.74      0.90      0.81       251
          R       0.42      0.24      0.30        59

avg / total       0.63      0.69      0.64       362

12/10/2017 03:41:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:41:58 [INFO] exp_shallowmodel: 
[[  1   1  20   3]
 [  0   7  18   2]
 [  6   5 226  14]
 [  3   2  40  14]]
12/10/2017 03:41:58 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 03:41:58 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:41:58 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:41:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:41:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:41:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:41:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:41:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:42:11 [INFO] exp_shallowmodel: train time: 13.155s
12/10/2017 03:42:11 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:42:11 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 03:42:11 [INFO] exp_shallowmodel: f1_score:   0.323
12/10/2017 03:42:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:42:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.04      0.06        23
          C       0.29      0.15      0.20        27
          F       0.76      0.90      0.82       250
          R       0.29      0.17      0.22        52

avg / total       0.61      0.68      0.63       352

12/10/2017 03:42:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:42:11 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  3   4  15   5]
 [  5   7 224  14]
 [  2   3  38   9]]
12/10/2017 03:42:11 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 03:42:11 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:42:11 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:42:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:42:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:42:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:42:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:42:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:42:26 [INFO] exp_shallowmodel: train time: 14.801s
12/10/2017 03:42:26 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:42:26 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 03:42:26 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 03:42:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:42:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.09      0.13        23
          C       0.31      0.15      0.20        27
          F       0.75      0.93      0.83       250
          R       0.32      0.13      0.19        52

avg / total       0.62      0.70      0.64       352

12/10/2017 03:42:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:42:26 [INFO] exp_shallowmodel: 
[[  2   1  16   4]
 [  1   4  20   2]
 [  2   6 233   9]
 [  3   2  40   7]]
12/10/2017 03:42:26 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 03:42:26 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:42:26 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:42:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:42:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:42:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:42:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:42:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:42:41 [INFO] exp_shallowmodel: train time: 14.897s
12/10/2017 03:42:41 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:42:41 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 03:42:41 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 03:42:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:42:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.09      0.11        23
          C       0.47      0.26      0.33        27
          F       0.80      0.92      0.86       250
          R       0.44      0.29      0.35        52

avg / total       0.68      0.72      0.69       352

12/10/2017 03:42:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:42:41 [INFO] exp_shallowmodel: 
[[  2   2  13   6]
 [  3   7  13   4]
 [  5   5 231   9]
 [  3   1  33  15]]
12/10/2017 03:42:42 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 03:42:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:42:42 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:42:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:42:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:42:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:42:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:42:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:42:56 [INFO] exp_shallowmodel: train time: 14.536s
12/10/2017 03:42:56 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:42:56 [INFO] exp_shallowmodel: accuracy:   0.673
12/10/2017 03:42:56 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 03:42:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:42:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.13      0.18        23
          C       0.31      0.15      0.20        27
          F       0.74      0.90      0.81       250
          R       0.22      0.12      0.15        52

avg / total       0.60      0.67      0.63       352

12/10/2017 03:42:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:42:56 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  0   4  19   4]
 [  5   7 224  14]
 [  2   1  43   6]]
12/10/2017 03:42:56 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 03:42:56 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:42:56 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:42:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:42:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:42:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:42:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:42:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:43:10 [INFO] exp_shallowmodel: train time: 13.661s
12/10/2017 03:43:10 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:43:10 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 03:43:10 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 03:43:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:43:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.13      0.15        23
          C       0.29      0.19      0.23        27
          F       0.77      0.89      0.83       250
          R       0.42      0.25      0.31        52

avg / total       0.64      0.69      0.66       352

12/10/2017 03:43:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:43:10 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  1   5  17   4]
 [  9   8 222  11]
 [  3   3  33  13]]
12/10/2017 03:43:10 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 03:43:10 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:43:10 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:43:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:43:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:43:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:43:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:43:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:43:26 [INFO] exp_shallowmodel: train time: 15.181s
12/10/2017 03:43:26 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:43:26 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 03:43:26 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 03:43:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:43:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.13      0.19        23
          C       0.29      0.19      0.23        27
          F       0.77      0.92      0.84       250
          R       0.40      0.23      0.29        52

avg / total       0.65      0.71      0.67       352

12/10/2017 03:43:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:43:26 [INFO] exp_shallowmodel: 
[[  3   1  17   2]
 [  1   5  13   8]
 [  4   9 229   8]
 [  1   2  37  12]]
12/10/2017 03:43:26 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 03:43:26 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:43:26 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:43:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:43:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:43:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:43:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:43:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:43:41 [INFO] exp_shallowmodel: train time: 15.545s
12/10/2017 03:43:41 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:43:41 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 03:43:41 [INFO] exp_shallowmodel: f1_score:   0.334
12/10/2017 03:43:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:43:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.31      0.15      0.20        27
          F       0.76      0.93      0.84       250
          R       0.36      0.17      0.23        52

avg / total       0.63      0.70      0.65       352

12/10/2017 03:43:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:43:41 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  1   4  20   2]
 [  1   3 233  13]
 [  4   5  34   9]]
12/10/2017 03:43:42 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 03:43:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:43:42 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:43:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:43:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:43:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:43:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:43:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:43:57 [INFO] exp_shallowmodel: train time: 15.810s
12/10/2017 03:43:57 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:43:57 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 03:43:57 [INFO] exp_shallowmodel: f1_score:   0.365
12/10/2017 03:43:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:43:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.17      0.21        23
          C       0.23      0.11      0.15        27
          F       0.77      0.89      0.83       250
          R       0.34      0.23      0.28        52

avg / total       0.63      0.69      0.65       352

12/10/2017 03:43:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:43:57 [INFO] exp_shallowmodel: 
[[  4   0  16   3]
 [  2   3  17   5]
 [  7   5 223  15]
 [  3   5  32  12]]
12/10/2017 03:43:58 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 03:43:58 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 03:43:58 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:43:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:43:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:43:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:43:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:43:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:44:15 [INFO] exp_shallowmodel: train time: 16.950s
12/10/2017 03:44:15 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:44:15 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 03:44:15 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 03:44:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:44:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.13      0.16        23
          C       0.50      0.19      0.27        27
          F       0.75      0.92      0.83       250
          R       0.45      0.19      0.27        52

avg / total       0.66      0.71      0.66       352

12/10/2017 03:44:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:44:15 [INFO] exp_shallowmodel: 
[[  3   0  18   2]
 [  2   5  18   2]
 [  8   3 231   8]
 [  1   2  39  10]]
12/10/2017 03:44:15 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 03:44:15 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 03:44:15 [INFO] exp_shallowmodel: #(feature) = 2755
12/10/2017 03:44:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:44:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:44:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:44:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:44:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:44:28 [INFO] exp_shallowmodel: train time: 12.685s
12/10/2017 03:44:28 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:44:28 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 03:44:28 [INFO] exp_shallowmodel: f1_score:   0.342
12/10/2017 03:44:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:44:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.36      0.15      0.21        27
          F       0.74      0.94      0.83       251
          R       0.54      0.24      0.33        59

avg / total       0.63      0.70      0.64       362

12/10/2017 03:44:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:44:28 [INFO] exp_shallowmodel: 
[[  0   1  22   2]
 [  3   4  19   1]
 [  2   4 236   9]
 [  1   2  42  14]]
12/10/2017 03:44:33 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 03:44:33 [INFO] task_runner: context=current, feature=2-lexical
12/10/2017 03:44:33 [INFO] task_runner: retained feature numbers=[4.1]
12/10/2017 03:44:33 [INFO] task_runner: #(data)=5241
12/10/2017 03:44:33 [INFO] task_runner: #(feature)=2898
12/10/2017 03:44:33 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 03:44:34 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 03:44:34 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:44:34 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:44:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:44:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:44:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:44:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:44:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:45:14 [INFO] exp_shallowmodel: train time: 40.287s
12/10/2017 03:45:14 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:45:14 [INFO] exp_shallowmodel: accuracy:   0.745
12/10/2017 03:45:14 [INFO] exp_shallowmodel: f1_score:   0.322
12/10/2017 03:45:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:45:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.16      0.08      0.11        59
          C       0.00      0.00      0.00        12
          F       0.81      0.94      0.87       396
          R       0.45      0.24      0.31        55

avg / total       0.68      0.75      0.70       522

12/10/2017 03:45:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:45:14 [INFO] exp_shallowmodel: 
[[  5   0  48   6]
 [  3   0   8   1]
 [ 15   1 371   9]
 [  9   0  33  13]]
12/10/2017 03:45:14 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 03:45:14 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:45:14 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:45:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:45:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:45:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:45:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:45:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:45:59 [INFO] exp_shallowmodel: train time: 45.140s
12/10/2017 03:45:59 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:45:59 [INFO] exp_shallowmodel: accuracy:   0.732
12/10/2017 03:45:59 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 03:45:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:45:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.15      0.18        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.29      0.18      0.22        55

avg / total       0.68      0.73      0.70       522

12/10/2017 03:45:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:45:59 [INFO] exp_shallowmodel: 
[[  9   1  40   9]
 [  3   0   8   1]
 [ 17   2 363  14]
 [ 14   1  30  10]]
12/10/2017 03:46:00 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 03:46:00 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:46:00 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:46:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:46:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:46:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:46:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:46:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:46:48 [INFO] exp_shallowmodel: train time: 48.118s
12/10/2017 03:46:48 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:46:48 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 03:46:48 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 03:46:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:46:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.25      0.30        59
          C       0.00      0.00      0.00        12
          F       0.82      0.94      0.88       396
          R       0.58      0.27      0.37        55

avg / total       0.73      0.77      0.74       522

12/10/2017 03:46:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:46:48 [INFO] exp_shallowmodel: 
[[ 15   1  39   4]
 [  2   0  10   0]
 [ 14   3 372   7]
 [ 10   0  30  15]]
12/10/2017 03:46:48 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 03:46:48 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:46:48 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:46:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:46:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:46:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:46:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:46:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:47:49 [INFO] exp_shallowmodel: train time: 60.973s
12/10/2017 03:47:49 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 03:47:49 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 03:47:49 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 03:47:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:47:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.15      0.19        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.32      0.22      0.26        55

avg / total       0.69      0.74      0.71       522

12/10/2017 03:47:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:47:49 [INFO] exp_shallowmodel: 
[[  9   1  40   9]
 [  1   0   9   2]
 [ 11   5 366  14]
 [ 13   0  30  12]]
12/10/2017 03:47:50 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 03:47:50 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:47:50 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:47:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:47:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:47:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:47:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:47:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:48:29 [INFO] exp_shallowmodel: train time: 39.549s
12/10/2017 03:48:29 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:48:29 [INFO] exp_shallowmodel: accuracy:   0.745
12/10/2017 03:48:29 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 03:48:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:48:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.25      0.30        59
          C       0.25      0.08      0.12        12
          F       0.81      0.93      0.87       396
          R       0.24      0.11      0.15        55

avg / total       0.69      0.75      0.71       522

12/10/2017 03:48:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:48:29 [INFO] exp_shallowmodel: 
[[ 15   1  37   6]
 [  2   1   8   1]
 [ 15   2 367  12]
 [  9   0  40   6]]
12/10/2017 03:48:30 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 03:48:30 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:48:30 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:48:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:48:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:48:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:48:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:48:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:49:18 [INFO] exp_shallowmodel: train time: 48.591s
12/10/2017 03:49:18 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:49:18 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 03:49:18 [INFO] exp_shallowmodel: f1_score:   0.371
12/10/2017 03:49:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:49:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.17      0.23        59
          C       0.20      0.08      0.12        12
          F       0.81      0.94      0.87       396
          R       0.41      0.20      0.27        55

avg / total       0.70      0.76      0.72       522

12/10/2017 03:49:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:49:18 [INFO] exp_shallowmodel: 
[[ 10   1  44   4]
 [  1   1   9   1]
 [ 11   1 373  11]
 [  7   2  35  11]]
12/10/2017 03:49:19 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 03:49:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:49:19 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:49:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:49:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:49:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:49:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:49:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:50:12 [INFO] exp_shallowmodel: train time: 53.116s
12/10/2017 03:50:12 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:50:12 [INFO] exp_shallowmodel: accuracy:   0.782
12/10/2017 03:50:12 [INFO] exp_shallowmodel: f1_score:   0.448
12/10/2017 03:50:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:50:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.25      0.32        59
          C       0.29      0.17      0.21        12
          F       0.83      0.95      0.89       396
          R       0.53      0.29      0.38        55

avg / total       0.74      0.78      0.75       522

12/10/2017 03:50:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:50:12 [INFO] exp_shallowmodel: 
[[ 15   3  34   7]
 [  1   2   8   1]
 [ 13   2 375   6]
 [  6   0  33  16]]
12/10/2017 03:50:12 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 03:50:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:50:12 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:50:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:50:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:50:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:50:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:50:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:51:19 [INFO] exp_shallowmodel: train time: 66.735s
12/10/2017 03:51:19 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:51:19 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 03:51:19 [INFO] exp_shallowmodel: f1_score:   0.368
12/10/2017 03:51:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:51:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.22      0.28        59
          C       0.00      0.00      0.00        12
          F       0.83      0.94      0.88       396
          R       0.40      0.25      0.31        55

avg / total       0.71      0.77      0.73       522

12/10/2017 03:51:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:51:19 [INFO] exp_shallowmodel: 
[[ 13   0  36  10]
 [  0   0  10   2]
 [ 13   1 373   9]
 [  8   0  33  14]]
12/10/2017 03:51:20 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 03:51:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:51:20 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:51:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:51:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:51:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:51:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:51:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:52:33 [INFO] exp_shallowmodel: train time: 73.849s
12/10/2017 03:52:33 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:52:33 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 03:52:33 [INFO] exp_shallowmodel: f1_score:   0.367
12/10/2017 03:52:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:52:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.19      0.24        59
          C       0.33      0.08      0.13        12
          F       0.81      0.94      0.87       396
          R       0.35      0.16      0.22        55

avg / total       0.70      0.76      0.72       522

12/10/2017 03:52:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:52:33 [INFO] exp_shallowmodel: 
[[ 11   0  43   5]
 [  0   1   8   3]
 [ 12   1 374   9]
 [ 11   1  34   9]]
12/10/2017 03:52:34 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 03:52:34 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 03:52:34 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:52:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:52:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:52:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:52:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:52:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:53:20 [INFO] exp_shallowmodel: train time: 46.061s
12/10/2017 03:53:20 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:53:20 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 03:53:20 [INFO] exp_shallowmodel: f1_score:   0.340
12/10/2017 03:53:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:53:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.23      0.27        64
          C       0.00      0.00      0.00        14
          F       0.79      0.91      0.84       402
          R       0.42      0.17      0.25        63

avg / total       0.67      0.72      0.69       543

12/10/2017 03:53:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:53:20 [INFO] exp_shallowmodel: 
[[ 15   0  47   2]
 [  3   0  10   1]
 [ 23   0 367  12]
 [  7   2  43  11]]
12/10/2017 03:53:20 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 03:53:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:53:20 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:53:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:53:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:53:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:53:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:53:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:54:04 [INFO] exp_shallowmodel: train time: 43.946s
12/10/2017 03:54:04 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:54:04 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 03:54:04 [INFO] exp_shallowmodel: f1_score:   0.351
12/10/2017 03:54:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:54:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.19      0.24        59
          C       0.00      0.00      0.00        12
          F       0.81      0.93      0.87       396
          R       0.41      0.24      0.30        55

avg / total       0.70      0.75      0.72       522

12/10/2017 03:54:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:54:04 [INFO] exp_shallowmodel: 
[[ 11   0  43   5]
 [  2   0   9   1]
 [ 12   2 369  13]
 [  9   1  32  13]]
12/10/2017 03:54:05 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 03:54:05 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:54:05 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:54:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:54:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:54:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:54:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:54:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:54:54 [INFO] exp_shallowmodel: train time: 48.924s
12/10/2017 03:54:54 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:54:54 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 03:54:54 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 03:54:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:54:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.25      0.31        59
          C       0.14      0.08      0.11        12
          F       0.84      0.95      0.89       396
          R       0.37      0.18      0.24        55

avg / total       0.72      0.77      0.74       522

12/10/2017 03:54:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:54:54 [INFO] exp_shallowmodel: 
[[ 15   1  36   7]
 [  2   1   8   1]
 [ 11   0 376   9]
 [ 10   5  30  10]]
12/10/2017 03:54:54 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 03:54:54 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:54:54 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:54:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:54:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:54:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:54:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:54:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:55:46 [INFO] exp_shallowmodel: train time: 51.975s
12/10/2017 03:55:46 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:55:46 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 03:55:46 [INFO] exp_shallowmodel: f1_score:   0.376
12/10/2017 03:55:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:55:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.15      0.21        59
          C       1.00      0.08      0.15        12
          F       0.82      0.94      0.88       396
          R       0.33      0.22      0.26        55

avg / total       0.72      0.76      0.72       522

12/10/2017 03:55:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:55:46 [INFO] exp_shallowmodel: 
[[  9   0  40  10]
 [  1   1  10   0]
 [  8   0 374  14]
 [  9   0  34  12]]
12/10/2017 03:55:47 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 03:55:47 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:55:47 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:55:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:55:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:55:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:55:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:55:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:56:36 [INFO] exp_shallowmodel: train time: 49.210s
12/10/2017 03:56:36 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:56:36 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 03:56:36 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 03:56:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:56:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.14      0.17        59
          C       0.00      0.00      0.00        12
          F       0.81      0.93      0.86       396
          R       0.48      0.27      0.35        55

avg / total       0.69      0.75      0.71       522

12/10/2017 03:56:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:56:36 [INFO] exp_shallowmodel: 
[[  8   0  45   6]
 [  4   0   8   0]
 [ 18   1 367  10]
 [  5   0  35  15]]
12/10/2017 03:56:36 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 03:56:36 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:56:36 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:56:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:56:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:56:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:56:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:56:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:57:50 [INFO] exp_shallowmodel: train time: 73.844s
12/10/2017 03:57:50 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:57:50 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 03:57:50 [INFO] exp_shallowmodel: f1_score:   0.431
12/10/2017 03:57:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:57:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.20      0.27        59
          C       0.50      0.17      0.25        12
          F       0.83      0.92      0.88       396
          R       0.35      0.31      0.33        55

avg / total       0.73      0.76      0.74       522

12/10/2017 03:57:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:57:50 [INFO] exp_shallowmodel: 
[[ 12   0  36  11]
 [  1   2   7   2]
 [ 11   1 366  18]
 [  6   1  31  17]]
12/10/2017 03:57:50 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 03:57:50 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:57:50 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:57:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:57:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:57:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:57:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:57:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:58:44 [INFO] exp_shallowmodel: train time: 53.736s
12/10/2017 03:58:44 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:58:44 [INFO] exp_shallowmodel: accuracy:   0.732
12/10/2017 03:58:44 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 03:58:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:58:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.19      0.24        59
          C       0.00      0.00      0.00        12
          F       0.81      0.92      0.86       396
          R       0.18      0.11      0.13        55

avg / total       0.67      0.73      0.70       522

12/10/2017 03:58:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:58:44 [INFO] exp_shallowmodel: 
[[ 11   0  41   7]
 [  2   0   7   3]
 [ 11   2 365  18]
 [  9   2  38   6]]
12/10/2017 03:58:45 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 03:58:45 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:58:45 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:58:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:58:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:58:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:58:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:58:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:59:50 [INFO] exp_shallowmodel: train time: 65.074s
12/10/2017 03:59:50 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 03:59:50 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 03:59:50 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 03:59:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:59:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.15      0.18        59
          C       0.25      0.08      0.12        12
          F       0.81      0.92      0.86       396
          R       0.45      0.24      0.31        55

avg / total       0.69      0.74      0.71       522

12/10/2017 03:59:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:59:50 [INFO] exp_shallowmodel: 
[[  9   1  43   6]
 [  2   1   9   0]
 [ 21   1 364  10]
 [  9   1  32  13]]
12/10/2017 03:59:50 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 03:59:50 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 03:59:50 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 03:59:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:59:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:59:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:59:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:59:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:00:29 [INFO] exp_shallowmodel: train time: 39.187s
12/10/2017 04:00:29 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:00:29 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 04:00:29 [INFO] exp_shallowmodel: f1_score:   0.361
12/10/2017 04:00:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:00:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.15      0.22        59
          C       0.00      0.00      0.00        12
          F       0.81      0.95      0.88       396
          R       0.48      0.27      0.35        55

avg / total       0.71      0.77      0.73       522

12/10/2017 04:00:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:00:29 [INFO] exp_shallowmodel: 
[[  9   2  44   4]
 [  3   0   7   2]
 [  8   2 376  10]
 [  4   1  35  15]]
12/10/2017 04:00:30 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 04:00:30 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:00:30 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:00:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:00:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:00:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:00:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:00:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:01:20 [INFO] exp_shallowmodel: train time: 50.695s
12/10/2017 04:01:20 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:01:20 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 04:01:20 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 04:01:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:01:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.27      0.30        59
          C       0.50      0.08      0.14        12
          F       0.82      0.93      0.87       396
          R       0.46      0.20      0.28        55

avg / total       0.72      0.76      0.73       522

12/10/2017 04:01:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:01:20 [INFO] exp_shallowmodel: 
[[ 16   0  40   3]
 [  1   1   8   2]
 [ 17   1 370   8]
 [ 12   0  32  11]]
12/10/2017 04:01:21 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 04:01:21 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 04:01:21 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:01:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:01:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:01:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:01:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:01:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:02:03 [INFO] exp_shallowmodel: train time: 42.203s
12/10/2017 04:02:03 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:02:03 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 04:02:03 [INFO] exp_shallowmodel: f1_score:   0.367
12/10/2017 04:02:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:02:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.41      0.27      0.32        64
          C       0.00      0.00      0.00        14
          F       0.81      0.94      0.87       402
          R       0.41      0.21      0.27        63

avg / total       0.70      0.75      0.72       543

12/10/2017 04:02:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:02:03 [INFO] exp_shallowmodel: 
[[ 17   2  38   7]
 [  0   0  13   1]
 [ 11   1 379  11]
 [ 13   0  37  13]]
12/10/2017 04:02:04 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 04:02:04 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:02:04 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:02:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:02:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:02:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:02:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:02:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:02:43 [INFO] exp_shallowmodel: train time: 39.357s
12/10/2017 04:02:43 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:02:43 [INFO] exp_shallowmodel: accuracy:   0.772
12/10/2017 04:02:43 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 04:02:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:02:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.31      0.36        59
          C       0.00      0.00      0.00        12
          F       0.84      0.93      0.88       396
          R       0.44      0.33      0.37        55

avg / total       0.73      0.77      0.75       522

12/10/2017 04:02:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:02:43 [INFO] exp_shallowmodel: 
[[ 18   1  30  10]
 [  0   0  10   2]
 [ 17   1 367  11]
 [  6   0  31  18]]
12/10/2017 04:02:43 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 04:02:43 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:02:43 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:02:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:02:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:02:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:02:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:02:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:03:29 [INFO] exp_shallowmodel: train time: 45.969s
12/10/2017 04:03:29 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:03:29 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 04:03:29 [INFO] exp_shallowmodel: f1_score:   0.406
12/10/2017 04:03:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:03:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.25      0.32        59
          C       0.25      0.08      0.12        12
          F       0.83      0.93      0.88       396
          R       0.38      0.25      0.30        55

avg / total       0.72      0.77      0.74       522

12/10/2017 04:03:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:03:29 [INFO] exp_shallowmodel: 
[[ 15   1  35   8]
 [  4   1   6   1]
 [ 12   0 370  14]
 [  5   2  34  14]]
12/10/2017 04:03:30 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 04:03:30 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:03:30 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:03:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:03:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:03:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:03:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:03:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:04:36 [INFO] exp_shallowmodel: train time: 66.441s
12/10/2017 04:04:36 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:04:36 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 04:04:36 [INFO] exp_shallowmodel: f1_score:   0.362
12/10/2017 04:04:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:04:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.27      0.31        59
          C       0.00      0.00      0.00        12
          F       0.83      0.93      0.88       396
          R       0.37      0.20      0.26        55

avg / total       0.71      0.76      0.73       522

12/10/2017 04:04:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:04:36 [INFO] exp_shallowmodel: 
[[ 16   0  35   8]
 [  2   0   9   1]
 [ 15   2 369  10]
 [ 10   1  33  11]]
12/10/2017 04:04:37 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 04:04:37 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:04:37 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:04:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:04:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:04:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:04:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:04:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:05:31 [INFO] exp_shallowmodel: train time: 54.712s
12/10/2017 04:05:31 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:05:31 [INFO] exp_shallowmodel: accuracy:   0.782
12/10/2017 04:05:31 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 04:05:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:05:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.27      0.32        59
          C       0.25      0.08      0.12        12
          F       0.84      0.95      0.89       396
          R       0.50      0.29      0.37        55

avg / total       0.74      0.78      0.75       522

12/10/2017 04:05:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:05:31 [INFO] exp_shallowmodel: 
[[ 16   0  34   9]
 [  2   1   7   2]
 [ 14   2 375   5]
 [  8   1  30  16]]
12/10/2017 04:05:32 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 04:05:32 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:05:32 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:05:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:05:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:05:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:05:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:05:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:06:17 [INFO] exp_shallowmodel: train time: 45.467s
12/10/2017 04:06:17 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:06:17 [INFO] exp_shallowmodel: accuracy:   0.778
12/10/2017 04:06:17 [INFO] exp_shallowmodel: f1_score:   0.373
12/10/2017 04:06:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:06:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.17      0.24        59
          C       0.00      0.00      0.00        12
          F       0.82      0.96      0.88       396
          R       0.50      0.29      0.37        55

avg / total       0.72      0.78      0.74       522

12/10/2017 04:06:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:06:17 [INFO] exp_shallowmodel: 
[[ 10   0  46   3]
 [  2   0   8   2]
 [  3   2 380  11]
 [  9   0  30  16]]
12/10/2017 04:06:18 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 04:06:18 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:06:18 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:06:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:06:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:06:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:06:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:06:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:07:09 [INFO] exp_shallowmodel: train time: 51.591s
12/10/2017 04:07:09 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:07:09 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 04:07:09 [INFO] exp_shallowmodel: f1_score:   0.349
12/10/2017 04:07:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:07:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.17      0.21        59
          C       0.00      0.00      0.00        12
          F       0.81      0.92      0.86       396
          R       0.44      0.25      0.32        55

avg / total       0.69      0.75      0.71       522

12/10/2017 04:07:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:07:09 [INFO] exp_shallowmodel: 
[[ 10   1  42   6]
 [  3   0   9   0]
 [ 17   1 366  12]
 [  5   1  35  14]]
12/10/2017 04:07:10 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 04:07:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:07:10 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:07:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:07:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:07:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:07:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:07:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:08:02 [INFO] exp_shallowmodel: train time: 52.665s
12/10/2017 04:08:02 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:08:02 [INFO] exp_shallowmodel: accuracy:   0.743
12/10/2017 04:08:02 [INFO] exp_shallowmodel: f1_score:   0.364
12/10/2017 04:08:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:08:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.27      0.32        59
          C       0.00      0.00      0.00        12
          F       0.81      0.91      0.86       396
          R       0.38      0.22      0.28        55

avg / total       0.70      0.74      0.72       522

12/10/2017 04:08:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:08:02 [INFO] exp_shallowmodel: 
[[ 16   1  39   3]
 [  1   0  11   0]
 [ 16   3 360  17]
 [  7   1  35  12]]
12/10/2017 04:08:03 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 04:08:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:08:03 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:08:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:08:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:08:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:08:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:08:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:08:56 [INFO] exp_shallowmodel: train time: 53.127s
12/10/2017 04:08:56 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:08:56 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 04:08:56 [INFO] exp_shallowmodel: f1_score:   0.351
12/10/2017 04:08:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:08:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.20      0.25        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.37      0.24      0.29        55

avg / total       0.70      0.75      0.72       522

12/10/2017 04:08:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:08:56 [INFO] exp_shallowmodel: 
[[ 12   1  41   5]
 [  0   0   9   3]
 [ 13   4 365  14]
 [ 13   0  29  13]]
12/10/2017 04:08:56 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 04:08:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:08:56 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:08:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:08:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:08:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:08:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:08:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:09:34 [INFO] exp_shallowmodel: train time: 37.754s
12/10/2017 04:09:34 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:09:34 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 04:09:34 [INFO] exp_shallowmodel: f1_score:   0.346
12/10/2017 04:09:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:09:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.15      0.19        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.41      0.27      0.33        55

avg / total       0.69      0.75      0.71       522

12/10/2017 04:09:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:09:34 [INFO] exp_shallowmodel: 
[[  9   1  42   7]
 [  2   0  10   0]
 [ 14   1 366  15]
 [  9   0  31  15]]
12/10/2017 04:09:35 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 04:09:35 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 04:09:35 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:09:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:09:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:09:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:09:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:09:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:10:14 [INFO] exp_shallowmodel: train time: 39.436s
12/10/2017 04:10:14 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:10:14 [INFO] exp_shallowmodel: accuracy:   0.731
12/10/2017 04:10:14 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 04:10:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:10:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.16      0.20        64
          C       0.00      0.00      0.00        14
          F       0.80      0.93      0.86       402
          R       0.35      0.21      0.26        63

avg / total       0.67      0.73      0.69       543

12/10/2017 04:10:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:10:14 [INFO] exp_shallowmodel: 
[[ 10   2  43   9]
 [  4   0   9   1]
 [ 14   0 374  14]
 [  8   1  41  13]]
12/10/2017 04:10:14 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 04:10:14 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:10:14 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:10:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:10:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:10:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:10:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:10:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:11:06 [INFO] exp_shallowmodel: train time: 51.669s
12/10/2017 04:11:06 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:11:06 [INFO] exp_shallowmodel: accuracy:   0.743
12/10/2017 04:11:06 [INFO] exp_shallowmodel: f1_score:   0.351
12/10/2017 04:11:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:11:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.14      0.16        59
          C       0.33      0.08      0.13        12
          F       0.82      0.93      0.87       396
          R       0.32      0.18      0.23        55

avg / total       0.69      0.74      0.71       522

12/10/2017 04:11:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:11:06 [INFO] exp_shallowmodel: 
[[  8   1  42   8]
 [  2   1   9   0]
 [ 13   1 369  13]
 [ 16   0  29  10]]
12/10/2017 04:11:07 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 04:11:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:11:07 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:11:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:11:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:11:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:11:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:11:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:11:49 [INFO] exp_shallowmodel: train time: 42.193s
12/10/2017 04:11:49 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:11:49 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 04:11:49 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 04:11:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:11:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.19      0.22        59
          C       0.00      0.00      0.00        12
          F       0.82      0.93      0.87       396
          R       0.33      0.18      0.24        55

avg / total       0.69      0.75      0.71       522

12/10/2017 04:11:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:11:49 [INFO] exp_shallowmodel: 
[[ 11   2  34  12]
 [  1   0  11   0]
 [ 19   0 369   8]
 [ 10   0  35  10]]
12/10/2017 04:11:49 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 04:11:49 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:11:49 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:11:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:11:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:11:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:11:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:11:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:12:33 [INFO] exp_shallowmodel: train time: 43.749s
12/10/2017 04:12:33 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:12:33 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 04:12:33 [INFO] exp_shallowmodel: f1_score:   0.368
12/10/2017 04:12:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:12:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.24      0.29        59
          C       0.00      0.00      0.00        12
          F       0.82      0.93      0.87       396
          R       0.41      0.25      0.31        55

avg / total       0.70      0.76      0.72       522

12/10/2017 04:12:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:12:33 [INFO] exp_shallowmodel: 
[[ 14   1  39   5]
 [  0   0   9   3]
 [ 17   0 367  12]
 [  6   0  35  14]]
12/10/2017 04:12:33 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 04:12:33 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:12:33 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:12:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:12:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:12:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:12:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:12:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:13:35 [INFO] exp_shallowmodel: train time: 61.444s
12/10/2017 04:13:35 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:13:35 [INFO] exp_shallowmodel: accuracy:   0.778
12/10/2017 04:13:35 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 04:13:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:13:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.51      0.36      0.42        59
          C       0.00      0.00      0.00        12
          F       0.82      0.94      0.88       396
          R       0.46      0.24      0.31        55

avg / total       0.73      0.78      0.75       522

12/10/2017 04:13:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:13:35 [INFO] exp_shallowmodel: 
[[ 21   0  35   3]
 [  2   0   9   1]
 [ 12   1 372  11]
 [  6   0  36  13]]
12/10/2017 04:13:35 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 04:13:35 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:13:35 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:13:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:13:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:13:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:13:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:13:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:14:30 [INFO] exp_shallowmodel: train time: 54.904s
12/10/2017 04:14:30 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:14:30 [INFO] exp_shallowmodel: accuracy:   0.774
12/10/2017 04:14:30 [INFO] exp_shallowmodel: f1_score:   0.440
12/10/2017 04:14:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:14:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.22      0.27        59
          C       0.50      0.25      0.33        12
          F       0.84      0.95      0.89       396
          R       0.38      0.20      0.26        55

avg / total       0.73      0.77      0.74       522

12/10/2017 04:14:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:14:30 [INFO] exp_shallowmodel: 
[[ 13   0  39   7]
 [  1   3   5   3]
 [  9   2 377   8]
 [ 13   1  30  11]]
12/10/2017 04:14:31 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 04:14:31 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:14:31 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:14:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:14:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:14:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:14:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:14:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:15:13 [INFO] exp_shallowmodel: train time: 42.405s
12/10/2017 04:15:13 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:15:13 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 04:15:13 [INFO] exp_shallowmodel: f1_score:   0.370
12/10/2017 04:15:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:15:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.20      0.25        59
          C       0.17      0.08      0.11        12
          F       0.81      0.92      0.86       396
          R       0.35      0.20      0.26        55

avg / total       0.69      0.74      0.71       522

12/10/2017 04:15:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:15:13 [INFO] exp_shallowmodel: 
[[ 12   1  41   5]
 [  3   1   8   0]
 [ 15   3 363  15]
 [  6   1  37  11]]
12/10/2017 04:15:13 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 04:15:13 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:15:13 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:15:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:15:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:15:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:15:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:15:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:15:55 [INFO] exp_shallowmodel: train time: 41.778s
12/10/2017 04:15:55 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:15:55 [INFO] exp_shallowmodel: accuracy:   0.776
12/10/2017 04:15:55 [INFO] exp_shallowmodel: f1_score:   0.467
12/10/2017 04:15:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:15:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.19      0.24        59
          C       0.50      0.33      0.40        12
          F       0.84      0.95      0.89       396
          R       0.45      0.27      0.34        55

avg / total       0.73      0.78      0.75       522

12/10/2017 04:15:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:15:55 [INFO] exp_shallowmodel: 
[[ 11   1  39   8]
 [  0   4   7   1]
 [ 10   2 375   9]
 [ 12   1  27  15]]
12/10/2017 04:15:56 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 04:15:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:15:56 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:15:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:15:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:15:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:15:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:15:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:16:46 [INFO] exp_shallowmodel: train time: 50.819s
12/10/2017 04:16:46 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:16:46 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 04:16:46 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 04:16:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:16:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.20      0.27        59
          C       0.50      0.08      0.14        12
          F       0.82      0.93      0.87       396
          R       0.35      0.25      0.29        55

avg / total       0.71      0.76      0.72       522

12/10/2017 04:16:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:16:46 [INFO] exp_shallowmodel: 
[[ 12   0  38   9]
 [  1   1   9   1]
 [ 11   1 368  16]
 [  6   0  35  14]]
12/10/2017 04:16:47 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 04:16:47 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:16:47 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:16:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:16:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:16:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:16:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:16:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:17:28 [INFO] exp_shallowmodel: train time: 41.332s
12/10/2017 04:17:28 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:17:28 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 04:17:28 [INFO] exp_shallowmodel: f1_score:   0.341
12/10/2017 04:17:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:17:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.14      0.17        59
          C       0.00      0.00      0.00        12
          F       0.82      0.94      0.88       396
          R       0.41      0.25      0.31        55

avg / total       0.69      0.75      0.72       522

12/10/2017 04:17:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:17:28 [INFO] exp_shallowmodel: 
[[  8   0  42   9]
 [  3   0   7   2]
 [ 14   1 372   9]
 [ 10   0  31  14]]
12/10/2017 04:17:29 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 04:17:29 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 04:17:29 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:17:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:17:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:17:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:17:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:17:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:18:26 [INFO] exp_shallowmodel: train time: 57.674s
12/10/2017 04:18:26 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:18:26 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 04:18:26 [INFO] exp_shallowmodel: f1_score:   0.435
12/10/2017 04:18:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:18:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.25      0.30        64
          C       0.50      0.14      0.22        14
          F       0.81      0.94      0.87       402
          R       0.53      0.25      0.34        63

avg / total       0.72      0.76      0.73       543

12/10/2017 04:18:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:18:26 [INFO] exp_shallowmodel: 
[[ 16   1  43   4]
 [  4   2   8   0]
 [ 13   0 379  10]
 [  9   1  37  16]]
12/10/2017 04:18:27 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 04:18:27 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:18:27 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:18:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:18:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:18:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:18:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:18:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:19:12 [INFO] exp_shallowmodel: train time: 45.601s
12/10/2017 04:19:12 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:19:12 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 04:19:12 [INFO] exp_shallowmodel: f1_score:   0.395
12/10/2017 04:19:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:19:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.20      0.26        59
          C       1.00      0.08      0.15        12
          F       0.82      0.94      0.87       396
          R       0.37      0.24      0.29        55

avg / total       0.72      0.76      0.73       522

12/10/2017 04:19:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:19:12 [INFO] exp_shallowmodel: 
[[ 12   0  39   8]
 [  4   1   7   0]
 [ 11   0 371  14]
 [  5   0  37  13]]
12/10/2017 04:19:13 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 04:19:13 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:19:13 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:19:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:19:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:19:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:19:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:19:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:20:06 [INFO] exp_shallowmodel: train time: 53.592s
12/10/2017 04:20:06 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:20:06 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 04:20:06 [INFO] exp_shallowmodel: f1_score:   0.343
12/10/2017 04:20:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:20:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.14      0.18        59
          C       0.00      0.00      0.00        12
          F       0.82      0.93      0.87       396
          R       0.39      0.27      0.32        55

avg / total       0.69      0.75      0.72       522

12/10/2017 04:20:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:20:06 [INFO] exp_shallowmodel: 
[[  8   1  44   6]
 [  0   0   9   3]
 [ 10   4 368  14]
 [ 12   0  28  15]]
12/10/2017 04:20:07 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 04:20:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:20:07 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:20:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:20:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:20:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:20:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:20:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:20:48 [INFO] exp_shallowmodel: train time: 41.067s
12/10/2017 04:20:48 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:20:48 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 04:20:48 [INFO] exp_shallowmodel: f1_score:   0.370
12/10/2017 04:20:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:20:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.31      0.34        59
          C       0.00      0.00      0.00        12
          F       0.83      0.93      0.88       396
          R       0.37      0.20      0.26        55

avg / total       0.71      0.76      0.73       522

12/10/2017 04:20:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:20:48 [INFO] exp_shallowmodel: 
[[ 18   1  35   5]
 [  1   0   9   2]
 [ 15   0 369  12]
 [ 12   1  31  11]]
12/10/2017 04:20:48 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 04:20:48 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:20:48 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:20:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:20:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:20:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:20:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:20:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:21:34 [INFO] exp_shallowmodel: train time: 45.982s
12/10/2017 04:21:34 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:21:34 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 04:21:34 [INFO] exp_shallowmodel: f1_score:   0.377
12/10/2017 04:21:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:21:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.24      0.28        59
          C       0.00      0.00      0.00        12
          F       0.84      0.93      0.88       396
          R       0.44      0.29      0.35        55

avg / total       0.72      0.76      0.74       522

12/10/2017 04:21:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:21:34 [INFO] exp_shallowmodel: 
[[ 14   1  37   7]
 [  3   0   6   3]
 [ 15   4 367  10]
 [ 10   1  28  16]]
12/10/2017 04:21:35 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 04:21:35 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:21:35 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:21:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:21:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:21:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:21:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:21:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:22:20 [INFO] exp_shallowmodel: train time: 45.079s
12/10/2017 04:22:20 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:22:20 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 04:22:20 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 04:22:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:22:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.22      0.27        59
          C       0.25      0.17      0.20        12
          F       0.83      0.93      0.88       396
          R       0.45      0.25      0.33        55

avg / total       0.72      0.76      0.73       522

12/10/2017 04:22:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:22:20 [INFO] exp_shallowmodel: 
[[ 13   1  37   8]
 [  1   2   7   2]
 [ 16   5 368   7]
 [  8   0  33  14]]
12/10/2017 04:22:20 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 04:22:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:22:20 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:22:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:22:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:22:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:22:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:22:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:23:10 [INFO] exp_shallowmodel: train time: 49.816s
12/10/2017 04:23:10 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:23:10 [INFO] exp_shallowmodel: accuracy:   0.743
12/10/2017 04:23:10 [INFO] exp_shallowmodel: f1_score:   0.379
12/10/2017 04:23:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:23:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.19      0.24        59
          C       0.40      0.17      0.24        12
          F       0.82      0.93      0.87       396
          R       0.22      0.15      0.17        55

avg / total       0.69      0.74      0.71       522

12/10/2017 04:23:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:23:10 [INFO] exp_shallowmodel: 
[[ 11   1  38   9]
 [  0   2   7   3]
 [ 10   2 367  17]
 [ 13   0  34   8]]
12/10/2017 04:23:11 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 04:23:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:23:11 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:23:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:23:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:23:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:23:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:23:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:23:49 [INFO] exp_shallowmodel: train time: 38.385s
12/10/2017 04:23:49 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:23:49 [INFO] exp_shallowmodel: accuracy:   0.734
12/10/2017 04:23:49 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 04:23:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:23:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.19      0.22        59
          C       0.00      0.00      0.00        12
          F       0.81      0.92      0.86       396
          R       0.28      0.15      0.19        55

avg / total       0.68      0.73      0.70       522

12/10/2017 04:23:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:23:49 [INFO] exp_shallowmodel: 
[[ 11   0  40   8]
 [  0   0  11   1]
 [ 19   1 364  12]
 [ 12   2  33   8]]
12/10/2017 04:23:49 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 04:23:49 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:23:49 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:23:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:23:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:23:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:23:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:23:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:24:42 [INFO] exp_shallowmodel: train time: 52.914s
12/10/2017 04:24:42 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:24:42 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 04:24:42 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 04:24:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:24:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.17      0.22        59
          C       0.00      0.00      0.00        12
          F       0.82      0.94      0.88       396
          R       0.24      0.15      0.18        55

avg / total       0.68      0.75      0.71       522

12/10/2017 04:24:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:24:42 [INFO] exp_shallowmodel: 
[[ 10   0  37  12]
 [  3   0   9   0]
 [  9   1 372  14]
 [ 10   2  35   8]]
12/10/2017 04:24:43 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 04:24:43 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 04:24:43 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:24:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:24:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:24:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:24:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:24:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:25:36 [INFO] exp_shallowmodel: train time: 53.236s
12/10/2017 04:25:36 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:25:36 [INFO] exp_shallowmodel: accuracy:   0.770
12/10/2017 04:25:36 [INFO] exp_shallowmodel: f1_score:   0.446
12/10/2017 04:25:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:25:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.27      0.31        59
          C       0.67      0.17      0.27        12
          F       0.83      0.93      0.88       396
          R       0.44      0.25      0.32        55

avg / total       0.74      0.77      0.74       522

12/10/2017 04:25:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:25:36 [INFO] exp_shallowmodel: 
[[ 16   1  35   7]
 [  1   2   9   0]
 [ 15   0 370  11]
 [ 11   0  30  14]]
12/10/2017 04:25:36 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 04:25:36 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 04:25:36 [INFO] exp_shallowmodel: #(feature) = 2898
12/10/2017 04:25:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:25:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:25:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:25:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:25:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:26:28 [INFO] exp_shallowmodel: train time: 51.143s
12/10/2017 04:26:28 [INFO] exp_shallowmodel: test time:  0.003s
12/10/2017 04:26:28 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 04:26:28 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 04:26:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:26:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.23      0.29        64
          C       0.25      0.07      0.11        14
          F       0.82      0.95      0.88       402
          R       0.49      0.27      0.35        63

avg / total       0.71      0.76      0.73       543

12/10/2017 04:26:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:26:28 [INFO] exp_shallowmodel: 
[[ 15   1  43   5]
 [  5   1   7   1]
 [  8   1 381  12]
 [ 10   1  35  17]]
Done: 20171210-042628
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
