/ihome/pbrusilosky/rum20/.conda/envs/py36/bin/python -m dialogue.classify.task_runner -selected_feature_set_id 5 -selected_context_id 2
No. of param settings = 1
[('deep_model', False), ('selected_context_id', 2), ('selected_feature_set_id', 5), ('similarity_feature', False)]
12/10/2017 02:14:30 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:30 [INFO] configuration: selected_context_id  :   2
12/10/2017 02:14:30 [INFO] configuration: selected_feature_set_id  :   5
12/10/2017 02:14:30 [INFO] configuration: similarity_feature  :   False
12/10/2017 02:14:30 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:30 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:30 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:30 [INFO] configuration: timemark  :   20171210-021430
12/10/2017 02:14:30 [INFO] configuration: context_set  :   last
12/10/2017 02:14:30 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:30 [INFO] configuration: utterance_range  :   ['current_user_utterance', 'last_system_utterance', 'current_user_utterance']
12/10/2017 02:14:30 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:30 [INFO] configuration: feature_set  :   5-lda
12/10/2017 02:14:30 [INFO] configuration: feature_set_number  :   ['8']
12/10/2017 02:14:30 [INFO] configuration: experiment_name  :   20171210-021430.context=last.feature=5-lda.similarity=false
12/10/2017 02:14:30 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021430.context=last.feature=5-lda.similarity=false
12/10/2017 02:14:30 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021430.context=last.feature=5-lda.similarity=false/output.log
12/10/2017 02:14:30 [INFO] configuration: valid_type  :   {'R', 'A', 'C', 'F'}
12/10/2017 02:14:30 [INFO] configuration: data_name  :   
12/10/2017 02:14:30 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:30 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:30 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:30 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:30 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:30 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:30 [INFO] configuration: #division  :   5
12/10/2017 02:14:30 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:30 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:30 [INFO] configuration: action_words  :   {'time', 'findcar', 'expens', 'moder', 'start', 'centre', 'address', 'area', 'share', 'volume', 'alarm', 'shuffle', 'telephone', 'reminders', 'reminds', 'light', 'delet', 'ani', 'temperatur', 'centr', 'timer', 'matter', 'remind', 'volum', 'turn', 'south', 'song', 'any', 'cheap', 'moderate', 'snooz', 'watch', 'else', 'phone', 'reminder', 'item', 'discard', 'remove', 'snooze', 'add', 'part', 'help', 'list', 'north', 'price', 'next', 'tell', 'number', 'telephon', 'expensive', 'play', 'findcare', 'post', 'cast', 'remov', 'stop', 'items', 'temperature', 'clear', 'food', 'weather', 'delete', 'show', 'shuffl', 'room', 'video', 'skip', 'member', 'els', 'music'}
12/10/2017 02:14:30 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:30 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:30 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:30 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:30 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:30 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:30 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:30 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:30 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:30 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:30 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:30 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:30 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:30 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:30 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:30 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:30 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:30 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:30 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 3, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:30 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:33 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:33 [INFO] task_runner: context=last, feature=5-lda
12/10/2017 02:14:33 [INFO] task_runner: retained feature numbers=[8.1]
12/10/2017 02:14:33 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:33 [INFO] task_runner: #(feature)=150
12/10/2017 02:14:33 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:33 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:33 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:14:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:40 [INFO] exp_shallowmodel: train time: 6.279s
12/10/2017 02:14:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:14:40 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 02:14:40 [INFO] exp_shallowmodel: f1_score:   0.465
12/10/2017 02:14:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        14
          C       0.59      0.66      0.63       164
          F       0.68      0.75      0.72       268
          R       0.48      0.34      0.39       125

avg / total       0.61      0.62      0.60       571

12/10/2017 02:14:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:40 [INFO] exp_shallowmodel: 
[[  1   1   8   4]
 [  0 109  34  21]
 [  1  44 202  21]
 [  0  30  53  42]]
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:14:40 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:40 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:46 [INFO] exp_shallowmodel: train time: 6.206s
12/10/2017 02:14:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:46 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 02:14:46 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 02:14:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.61      0.58       164
          F       0.64      0.72      0.68       268
          R       0.51      0.35      0.42       125

avg / total       0.57      0.59      0.58       571

12/10/2017 02:14:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:46 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  2 100  41  21]
 [  1  53 193  21]
 [  0  25  56  44]]
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:14:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:46 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:51 [INFO] exp_shallowmodel: train time: 5.611s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 02:14:51 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 02:14:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.66      0.61       164
          F       0.69      0.75      0.72       268
          R       0.46      0.32      0.38       125

avg / total       0.59      0.61      0.60       571

12/10/2017 02:14:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:51 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  0 108  35  21]
 [  1  43 202  22]
 [  0  35  50  40]]
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:57 [INFO] exp_shallowmodel: train time: 5.771s
12/10/2017 02:14:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:57 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:14:57 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 02:14:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.68      0.61       164
          F       0.68      0.71      0.69       268
          R       0.43      0.32      0.37       125

avg / total       0.57      0.60      0.58       571

12/10/2017 02:14:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:57 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  0 111  34  19]
 [  0  48 191  29]
 [  0  35  50  40]]
12/10/2017 02:14:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:14:57 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:57 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:14:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:05 [INFO] exp_shallowmodel: train time: 7.433s
12/10/2017 02:15:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:05 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 02:15:05 [INFO] exp_shallowmodel: f1_score:   0.450
12/10/2017 02:15:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.73      0.66       164
          F       0.68      0.74      0.71       268
          R       0.54      0.36      0.43       125

avg / total       0.61      0.63      0.62       571

12/10/2017 02:15:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:05 [INFO] exp_shallowmodel: 
[[  0   1   9   4]
 [  0 119  32  13]
 [  0  49 198  21]
 [  0  28  52  45]]
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:15:05 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:05 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:11 [INFO] exp_shallowmodel: train time: 6.730s
12/10/2017 02:15:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:11 [INFO] exp_shallowmodel: accuracy:   0.553
12/10/2017 02:15:11 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 02:15:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.62      0.56       164
          F       0.63      0.66      0.65       268
          R       0.40      0.29      0.34       125

avg / total       0.53      0.55      0.54       571

12/10/2017 02:15:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:11 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  0 102  45  17]
 [  1  57 178  32]
 [  0  37  52  36]]
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:15:11 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:11 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:20 [INFO] exp_shallowmodel: train time: 8.572s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: accuracy:   0.651
12/10/2017 02:15:20 [INFO] exp_shallowmodel: f1_score:   0.456
12/10/2017 02:15:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.81      0.72       164
          F       0.72      0.74      0.73       268
          R       0.47      0.32      0.38       125

avg / total       0.62      0.65      0.63       571

12/10/2017 02:15:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:20 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 133  17  14]
 [  0  40 199  29]
 [  0  33  52  40]]
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:29 [INFO] exp_shallowmodel: train time: 8.777s
12/10/2017 02:15:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:29 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 02:15:29 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 02:15:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.73      0.63       164
          F       0.67      0.66      0.67       268
          R       0.37      0.27      0.31       125

avg / total       0.55      0.58      0.56       571

12/10/2017 02:15:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:29 [INFO] exp_shallowmodel: 
[[  0   5   6   3]
 [  0 119  25  20]
 [  0  55 177  36]
 [  0  36  55  34]]
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:15:29 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:29 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:32 [INFO] exp_shallowmodel: train time: 3.086s
12/10/2017 02:15:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:32 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 02:15:32 [INFO] exp_shallowmodel: f1_score:   0.445
12/10/2017 02:15:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.74      0.65       164
          F       0.71      0.69      0.70       268
          R       0.50      0.38      0.43       125

avg / total       0.61      0.62      0.61       571

12/10/2017 02:15:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:32 [INFO] exp_shallowmodel: 
[[  0   1  10   3]
 [  0 121  23  20]
 [  1  57 185  25]
 [  2  32  43  48]]
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:15:32 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:15:32 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:37 [INFO] exp_shallowmodel: train time: 4.849s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:15:37 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 02:15:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.57      0.67      0.62       169
          F       0.66      0.71      0.69       271
          R       0.39      0.30      0.34       130

avg / total       0.56      0.59      0.57       586

12/10/2017 02:15:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:37 [INFO] exp_shallowmodel: 
[[  0   4   8   4]
 [  0 113  29  27]
 [  1  49 192  29]
 [  0  31  60  39]]
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:42 [INFO] exp_shallowmodel: train time: 4.921s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 02:15:42 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 02:15:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.68      0.63       164
          F       0.65      0.70      0.67       268
          R       0.47      0.33      0.39       125

avg / total       0.57      0.60      0.58       571

12/10/2017 02:15:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:42 [INFO] exp_shallowmodel: 
[[  0   1   7   6]
 [  0 112  35  17]
 [  1  56 188  23]
 [  0  24  60  41]]
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:45 [INFO] exp_shallowmodel: train time: 3.015s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 02:15:45 [INFO] exp_shallowmodel: f1_score:   0.430
12/10/2017 02:15:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.68      0.62       164
          F       0.69      0.74      0.71       268
          R       0.46      0.34      0.39       125

avg / total       0.59      0.61      0.60       571

12/10/2017 02:15:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:45 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 111  31  22]
 [  0  47 197  24]
 [  0  31  52  42]]
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:50 [INFO] exp_shallowmodel: train time: 5.347s
12/10/2017 02:15:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:50 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 02:15:50 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 02:15:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.65      0.58       164
          F       0.66      0.68      0.67       268
          R       0.36      0.25      0.29       125

avg / total       0.54      0.56      0.54       571

12/10/2017 02:15:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:50 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  0 107  32  25]
 [  0  58 183  27]
 [  0  39  55  31]]
12/10/2017 02:15:50 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:15:50 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:50 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:15:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:56 [INFO] exp_shallowmodel: train time: 5.750s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 02:15:56 [INFO] exp_shallowmodel: f1_score:   0.435
12/10/2017 02:15:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.70      0.64       164
          F       0.70      0.71      0.70       268
          R       0.44      0.37      0.40       125

avg / total       0.59      0.61      0.60       571

12/10/2017 02:15:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:56 [INFO] exp_shallowmodel: 
[[  0   2   7   5]
 [  2 114  26  22]
 [  1  46 189  32]
 [  0  30  49  46]]
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:04 [INFO] exp_shallowmodel: train time: 7.772s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 02:16:04 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 02:16:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.66      0.60       164
          F       0.68      0.72      0.70       268
          R       0.43      0.31      0.36       125

avg / total       0.57      0.60      0.58       571

12/10/2017 02:16:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:04 [INFO] exp_shallowmodel: 
[[  0   2  12   0]
 [  0 109  36  19]
 [  0  43 193  32]
 [  0  43  43  39]]
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:14 [INFO] exp_shallowmodel: train time: 10.546s
12/10/2017 02:16:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:16:14 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:16:14 [INFO] exp_shallowmodel: f1_score:   0.430
12/10/2017 02:16:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.73      0.63       164
          F       0.70      0.69      0.69       268
          R       0.47      0.34      0.39       125

avg / total       0.59      0.61      0.59       571

12/10/2017 02:16:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:14 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  1 120  29  14]
 [  0  53 185  30]
 [  0  38  45  42]]
12/10/2017 02:16:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:16:14 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:14 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:16:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:18 [INFO] exp_shallowmodel: train time: 4.151s
12/10/2017 02:16:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:18 [INFO] exp_shallowmodel: accuracy:   0.637
12/10/2017 02:16:18 [INFO] exp_shallowmodel: f1_score:   0.451
12/10/2017 02:16:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.73      0.67       164
          F       0.70      0.75      0.72       268
          R       0.48      0.35      0.41       125

avg / total       0.61      0.64      0.62       571

12/10/2017 02:16:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:18 [INFO] exp_shallowmodel: 
[[  0   3   5   6]
 [  0 119  29  16]
 [  1  40 201  26]
 [  1  28  52  44]]
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:16:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:18 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:24 [INFO] exp_shallowmodel: train time: 5.592s
12/10/2017 02:16:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:24 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 02:16:24 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 02:16:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.66      0.61       164
          F       0.67      0.75      0.71       268
          R       0.51      0.32      0.39       125

avg / total       0.59      0.61      0.59       571

12/10/2017 02:16:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:24 [INFO] exp_shallowmodel: 
[[  0   2   7   5]
 [  0 109  37  18]
 [  0  51 201  16]
 [  0  31  54  40]]
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 02:16:24 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:24 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:31 [INFO] exp_shallowmodel: train time: 6.687s
12/10/2017 02:16:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:31 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 02:16:31 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 02:16:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.70      0.64       164
          F       0.68      0.75      0.71       268
          R       0.49      0.31      0.38       125

avg / total       0.60      0.62      0.60       571

12/10/2017 02:16:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:31 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  0 115  34  15]
 [  0  45 201  22]
 [  0  34  52  39]]
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 02:16:31 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:16:31 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:41 [INFO] exp_shallowmodel: train time: 10.623s
12/10/2017 02:16:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:16:41 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 02:16:41 [INFO] exp_shallowmodel: f1_score:   0.438
12/10/2017 02:16:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.60      0.70      0.65       169
          F       0.67      0.74      0.70       271
          R       0.49      0.34      0.40       130

avg / total       0.59      0.62      0.60       586

12/10/2017 02:16:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:41 [INFO] exp_shallowmodel: 
[[  0   4   5   7]
 [  0 119  36  14]
 [  1  46 200  24]
 [  0  30  56  44]]
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 02:16:41 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:41 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:51 [INFO] exp_shallowmodel: train time: 9.120s
12/10/2017 02:16:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:51 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:16:51 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:16:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.66      0.61       164
          F       0.67      0.71      0.69       268
          R       0.39      0.30      0.33       125

avg / total       0.56      0.59      0.57       571

12/10/2017 02:16:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:51 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  0 109  31  24]
 [  1  47 189  31]
 [  0  34  54  37]]
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 02:16:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:51 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:56 [INFO] exp_shallowmodel: train time: 5.171s
12/10/2017 02:16:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:56 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 02:16:56 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 02:16:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.60      0.54       164
          F       0.67      0.68      0.67       268
          R       0.39      0.31      0.35       125

avg / total       0.54      0.56      0.55       571

12/10/2017 02:16:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:56 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0  98  36  30]
 [  0  56 182  30]
 [  1  41  44  39]]
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 02:16:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:56 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:03 [INFO] exp_shallowmodel: train time: 7.375s
12/10/2017 02:17:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:03 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 02:17:03 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 02:17:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.73      0.65       164
          F       0.68      0.71      0.70       268
          R       0.45      0.30      0.36       125

avg / total       0.59      0.61      0.59       571

12/10/2017 02:17:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:03 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  1 120  25  18]
 [  0  52 191  25]
 [  0  31  56  38]]
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 02:17:03 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:03 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:09 [INFO] exp_shallowmodel: train time: 5.512s
12/10/2017 02:17:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:09 [INFO] exp_shallowmodel: accuracy:   0.534
12/10/2017 02:17:09 [INFO] exp_shallowmodel: f1_score:   0.368
12/10/2017 02:17:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.47      0.45      0.46       164
          F       0.61      0.71      0.66       268
          R       0.41      0.32      0.36       125

avg / total       0.51      0.53      0.52       571

12/10/2017 02:17:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:09 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  0  74  68  22]
 [  0  45 191  32]
 [  0  35  50  40]]
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 02:17:09 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:09 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:12 [INFO] exp_shallowmodel: train time: 3.470s
12/10/2017 02:17:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:12 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 02:17:12 [INFO] exp_shallowmodel: f1_score:   0.447
12/10/2017 02:17:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.62      0.77      0.69       164
          F       0.67      0.71      0.69       268
          R       0.39      0.25      0.30       125

avg / total       0.58      0.61      0.59       571

12/10/2017 02:17:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:12 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  2 126  22  14]
 [  1  47 191  29]
 [  1  26  67  31]]
12/10/2017 02:17:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 02:17:12 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:12 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:17:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:16 [INFO] exp_shallowmodel: train time: 4.245s
12/10/2017 02:17:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:16 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:17:16 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 02:17:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.71      0.64       164
          F       0.69      0.71      0.70       268
          R       0.44      0.33      0.37       125

avg / total       0.59      0.61      0.59       571

12/10/2017 02:17:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:16 [INFO] exp_shallowmodel: 
[[  0   4   8   2]
 [  0 117  25  22]
 [  1  49 189  29]
 [  0  31  53  41]]
12/10/2017 02:17:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 02:17:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:16 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:17:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:22 [INFO] exp_shallowmodel: train time: 5.960s
12/10/2017 02:17:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:22 [INFO] exp_shallowmodel: accuracy:   0.618
12/10/2017 02:17:22 [INFO] exp_shallowmodel: f1_score:   0.467
12/10/2017 02:17:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        14
          C       0.59      0.68      0.63       164
          F       0.70      0.74      0.72       268
          R       0.44      0.34      0.39       125

avg / total       0.62      0.62      0.61       571

12/10/2017 02:17:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:22 [INFO] exp_shallowmodel: 
[[  1   1   6   6]
 [  0 112  32  20]
 [  0  42 197  29]
 [  0  34  48  43]]
12/10/2017 02:17:22 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 02:17:22 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:22 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:17:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:28 [INFO] exp_shallowmodel: train time: 5.684s
12/10/2017 02:17:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:28 [INFO] exp_shallowmodel: accuracy:   0.609
12/10/2017 02:17:28 [INFO] exp_shallowmodel: f1_score:   0.425
12/10/2017 02:17:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.66      0.61       164
          F       0.72      0.74      0.73       268
          R       0.41      0.33      0.37       125

avg / total       0.59      0.61      0.60       571

12/10/2017 02:17:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:28 [INFO] exp_shallowmodel: 
[[  0   3   4   7]
 [  0 109  30  25]
 [  0  44 198  26]
 [  1  40  43  41]]
12/10/2017 02:17:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 02:17:28 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:28 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:17:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:33 [INFO] exp_shallowmodel: train time: 5.212s
12/10/2017 02:17:33 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:17:33 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:17:33 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 02:17:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.68      0.59       164
          F       0.67      0.69      0.68       268
          R       0.45      0.31      0.37       125

avg / total       0.57      0.59      0.57       571

12/10/2017 02:17:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:33 [INFO] exp_shallowmodel: 
[[  0   1  10   3]
 [  0 111  33  20]
 [  0  59 185  24]
 [  0  39  47  39]]
12/10/2017 02:17:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 02:17:33 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:17:33 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:17:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:44 [INFO] exp_shallowmodel: train time: 10.854s
12/10/2017 02:17:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:44 [INFO] exp_shallowmodel: accuracy:   0.585
12/10/2017 02:17:44 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 02:17:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.61      0.70      0.65       169
          F       0.62      0.69      0.65       271
          R       0.43      0.28      0.34       130

avg / total       0.55      0.59      0.57       586

12/10/2017 02:17:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:44 [INFO] exp_shallowmodel: 
[[  0   3   9   4]
 [  0 118  36  15]
 [  0  52 188  31]
 [  0  21  72  37]]
12/10/2017 02:17:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 02:17:44 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:44 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:17:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:51 [INFO] exp_shallowmodel: train time: 6.743s
12/10/2017 02:17:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:51 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 02:17:51 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:17:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.65      0.59       164
          F       0.65      0.70      0.67       268
          R       0.40      0.26      0.32       125

avg / total       0.55      0.57      0.56       571

12/10/2017 02:17:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:51 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 107  38  19]
 [  0  53 188  27]
 [  0  37  55  33]]
12/10/2017 02:17:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 02:17:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:51 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:17:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:17:57 [INFO] exp_shallowmodel: train time: 5.797s
12/10/2017 02:17:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:17:57 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 02:17:57 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 02:17:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:17:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.66      0.62       164
          F       0.68      0.72      0.70       268
          R       0.43      0.34      0.38       125

avg / total       0.58      0.61      0.59       571

12/10/2017 02:17:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:17:57 [INFO] exp_shallowmodel: 
[[  0   1   8   5]
 [  0 109  31  24]
 [  0  47 194  27]
 [  0  29  53  43]]
12/10/2017 02:17:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 02:17:57 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:17:57 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:17:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:17:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:17:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:17:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:17:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:04 [INFO] exp_shallowmodel: train time: 7.072s
12/10/2017 02:18:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:04 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:18:04 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 02:18:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.56      0.66      0.61       164
          F       0.63      0.71      0.67       268
          R       0.45      0.27      0.34       125

avg / total       0.56      0.58      0.57       571

12/10/2017 02:18:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:04 [INFO] exp_shallowmodel: 
[[  1   1  10   2]
 [  0 109  40  15]
 [  2  52 189  25]
 [  0  31  60  34]]
12/10/2017 02:18:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 02:18:04 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:04 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:18:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:15 [INFO] exp_shallowmodel: train time: 10.873s
12/10/2017 02:18:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:15 [INFO] exp_shallowmodel: accuracy:   0.646
12/10/2017 02:18:15 [INFO] exp_shallowmodel: f1_score:   0.459
12/10/2017 02:18:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.67      0.65       164
          F       0.70      0.78      0.74       268
          R       0.50      0.40      0.44       125

avg / total       0.62      0.65      0.63       571

12/10/2017 02:18:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:15 [INFO] exp_shallowmodel: 
[[  0   5   5   4]
 [  1 110  35  18]
 [  0  31 209  28]
 [  0  26  49  50]]
12/10/2017 02:18:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 02:18:15 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:15 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:18:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:26 [INFO] exp_shallowmodel: train time: 11.111s
12/10/2017 02:18:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:18:26 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:18:26 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 02:18:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.71      0.64       164
          F       0.70      0.75      0.72       268
          R       0.46      0.31      0.37       125

avg / total       0.60      0.62      0.61       571

12/10/2017 02:18:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:26 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 117  30  17]
 [  1  41 200  26]
 [  0  41  45  39]]
12/10/2017 02:18:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 02:18:26 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:26 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:18:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:33 [INFO] exp_shallowmodel: train time: 7.036s
12/10/2017 02:18:33 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:33 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 02:18:33 [INFO] exp_shallowmodel: f1_score:   0.454
12/10/2017 02:18:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.72      0.67       164
          F       0.71      0.75      0.73       268
          R       0.47      0.38      0.42       125

avg / total       0.62      0.64      0.63       571

12/10/2017 02:18:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:33 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  0 118  31  15]
 [  1  32 200  35]
 [  0  33  45  47]]
12/10/2017 02:18:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 02:18:33 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:33 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:18:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:37 [INFO] exp_shallowmodel: train time: 3.875s
12/10/2017 02:18:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:37 [INFO] exp_shallowmodel: accuracy:   0.585
12/10/2017 02:18:37 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 02:18:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.66      0.60       164
          F       0.67      0.70      0.68       268
          R       0.42      0.30      0.35       125

avg / total       0.56      0.58      0.57       571

12/10/2017 02:18:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:37 [INFO] exp_shallowmodel: 
[[  0   5   6   3]
 [  1 109  32  22]
 [  0  54 188  26]
 [  0  33  55  37]]
12/10/2017 02:18:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 02:18:37 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:37 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:18:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:43 [INFO] exp_shallowmodel: train time: 5.717s
12/10/2017 02:18:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:43 [INFO] exp_shallowmodel: accuracy:   0.567
12/10/2017 02:18:43 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 02:18:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.63      0.56       164
          F       0.65      0.64      0.65       268
          R       0.48      0.38      0.42       125

avg / total       0.55      0.57      0.56       571

12/10/2017 02:18:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:43 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 104  40  20]
 [  0  65 172  31]
 [  0  34  43  48]]
12/10/2017 02:18:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 02:18:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:43 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:18:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:47 [INFO] exp_shallowmodel: train time: 4.111s
12/10/2017 02:18:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:47 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:18:47 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 02:18:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.68      0.62       164
          F       0.68      0.72      0.70       268
          R       0.40      0.30      0.34       125

avg / total       0.57      0.60      0.58       571

12/10/2017 02:18:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:47 [INFO] exp_shallowmodel: 
[[  0   3   5   6]
 [  0 111  29  24]
 [  0  48 194  26]
 [  0  32  56  37]]
12/10/2017 02:18:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 02:18:47 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:18:47 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:18:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:52 [INFO] exp_shallowmodel: train time: 5.240s
12/10/2017 02:18:52 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:18:52 [INFO] exp_shallowmodel: accuracy:   0.567
12/10/2017 02:18:52 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 02:18:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.56      0.60      0.58       169
          F       0.63      0.69      0.66       271
          R       0.41      0.33      0.37       130

avg / total       0.54      0.57      0.55       586

12/10/2017 02:18:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:52 [INFO] exp_shallowmodel: 
[[  0   3  10   3]
 [  0 102  45  22]
 [  0  47 187  37]
 [  1  31  55  43]]
12/10/2017 02:18:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 02:18:52 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:52 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:18:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:58 [INFO] exp_shallowmodel: train time: 5.974s
12/10/2017 02:18:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:18:58 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 02:18:58 [INFO] exp_shallowmodel: f1_score:   0.440
12/10/2017 02:18:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.70      0.62       164
          F       0.69      0.72      0.71       268
          R       0.53      0.36      0.43       125

avg / total       0.60      0.62      0.60       571

12/10/2017 02:18:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:58 [INFO] exp_shallowmodel: 
[[  0   6   5   3]
 [  0 115  32  17]
 [  0  54 194  20]
 [  0  30  50  45]]
12/10/2017 02:18:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 02:18:58 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:58 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:18:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:04 [INFO] exp_shallowmodel: train time: 5.504s
12/10/2017 02:19:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:19:04 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:19:04 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:19:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.67      0.62       164
          F       0.65      0.65      0.65       268
          R       0.39      0.35      0.37       125

avg / total       0.56      0.57      0.56       571

12/10/2017 02:19:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:04 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 110  34  20]
 [  1  47 173  47]
 [  0  33  48  44]]
12/10/2017 02:19:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 02:19:04 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:19:04 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:19:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:11 [INFO] exp_shallowmodel: train time: 7.409s
12/10/2017 02:19:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:19:11 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 02:19:11 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 02:19:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.64      0.58       164
          F       0.66      0.72      0.69       268
          R       0.47      0.30      0.37       125

avg / total       0.57      0.59      0.57       571

12/10/2017 02:19:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:11 [INFO] exp_shallowmodel: 
[[  0   4   9   1]
 [  0 105  40  19]
 [  0  51 194  23]
 [  0  38  49  38]]
12/10/2017 02:19:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 02:19:11 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:19:11 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:19:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:16 [INFO] exp_shallowmodel: train time: 4.818s
12/10/2017 02:19:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:19:16 [INFO] exp_shallowmodel: accuracy:   0.609
12/10/2017 02:19:16 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 02:19:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.65      0.60       164
          F       0.70      0.74      0.72       268
          R       0.46      0.34      0.39       125

avg / total       0.59      0.61      0.60       571

12/10/2017 02:19:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:16 [INFO] exp_shallowmodel: 
[[  0   2   7   5]
 [  0 107  33  24]
 [  0  48 198  22]
 [  1  36  45  43]]
12/10/2017 02:19:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 02:19:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:19:16 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:19:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:20 [INFO] exp_shallowmodel: train time: 4.423s
12/10/2017 02:19:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:19:20 [INFO] exp_shallowmodel: accuracy:   0.627
12/10/2017 02:19:20 [INFO] exp_shallowmodel: f1_score:   0.441
12/10/2017 02:19:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.69      0.65       164
          F       0.69      0.75      0.72       268
          R       0.47      0.34      0.40       125

avg / total       0.60      0.63      0.61       571

12/10/2017 02:19:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:20 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  1 113  31  19]
 [  0  41 202  25]
 [  0  29  53  43]]
12/10/2017 02:19:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 02:19:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:19:20 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:19:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:25 [INFO] exp_shallowmodel: train time: 5.110s
12/10/2017 02:19:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:19:25 [INFO] exp_shallowmodel: accuracy:   0.609
12/10/2017 02:19:25 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 02:19:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.69      0.63       164
          F       0.68      0.74      0.71       268
          R       0.44      0.29      0.35       125

avg / total       0.58      0.61      0.59       571

12/10/2017 02:19:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:25 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  0 113  33  18]
 [  2  44 199  23]
 [  0  35  54  36]]
12/10/2017 02:19:25 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 02:19:25 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:19:25 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:19:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:29 [INFO] exp_shallowmodel: train time: 3.717s
12/10/2017 02:19:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:19:29 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 02:19:29 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 02:19:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.67      0.63       164
          F       0.65      0.72      0.69       268
          R       0.38      0.26      0.31       125

avg / total       0.56      0.59      0.57       571

12/10/2017 02:19:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:29 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  0 110  36  18]
 [  2  41 194  31]
 [  0  31  61  33]]
12/10/2017 02:19:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 02:19:29 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:19:29 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:19:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:34 [INFO] exp_shallowmodel: train time: 5.014s
12/10/2017 02:19:34 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:19:34 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 02:19:34 [INFO] exp_shallowmodel: f1_score:   0.455
12/10/2017 02:19:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.07      0.11        14
          C       0.59      0.70      0.64       164
          F       0.67      0.71      0.69       268
          R       0.46      0.33      0.38       125

avg / total       0.59      0.61      0.59       571

12/10/2017 02:19:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:34 [INFO] exp_shallowmodel: 
[[  1   3   9   1]
 [  0 115  34  15]
 [  1  46 189  32]
 [  2  31  51  41]]
12/10/2017 02:19:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 02:19:34 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:19:34 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:19:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:47 [INFO] exp_shallowmodel: train time: 12.597s
12/10/2017 02:19:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:19:47 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 02:19:47 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 02:19:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.66      0.62       164
          F       0.67      0.72      0.69       268
          R       0.40      0.32      0.36       125

avg / total       0.57      0.60      0.58       571

12/10/2017 02:19:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:47 [INFO] exp_shallowmodel: 
[[  0   1   8   5]
 [  1 108  32  23]
 [  0  43 193  32]
 [  0  30  55  40]]
12/10/2017 02:19:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 02:19:47 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:19:47 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:19:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:59 [INFO] exp_shallowmodel: train time: 11.723s
12/10/2017 02:19:59 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:19:59 [INFO] exp_shallowmodel: accuracy:   0.602
12/10/2017 02:19:59 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:19:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.57      0.69      0.62       169
          F       0.68      0.72      0.70       271
          R       0.45      0.32      0.38       130

avg / total       0.58      0.60      0.59       586

12/10/2017 02:19:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:59 [INFO] exp_shallowmodel: 
[[  0   1  10   5]
 [  0 116  28  25]
 [  1  54 195  21]
 [  0  33  55  42]]
12/10/2017 02:20:02 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:20:02 [INFO] task_runner: context=last, feature=5-lda
12/10/2017 02:20:02 [INFO] task_runner: retained feature numbers=[8.1]
12/10/2017 02:20:02 [INFO] task_runner: #(data)=5934
12/10/2017 02:20:02 [INFO] task_runner: #(feature)=150
12/10/2017 02:20:02 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:20:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 02:20:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:02 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:06 [INFO] exp_shallowmodel: train time: 3.351s
12/10/2017 02:20:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:06 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 02:20:06 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 02:20:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.63      0.54       169
          F       0.70      0.74      0.72       281
          R       0.41      0.23      0.29       122

avg / total       0.55      0.58      0.56       592

12/10/2017 02:20:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:06 [INFO] exp_shallowmodel: 
[[  0   5  11   4]
 [  1 107  39  22]
 [  1  59 207  14]
 [  1  53  40  28]]
12/10/2017 02:20:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 02:20:06 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:06 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:09 [INFO] exp_shallowmodel: train time: 2.769s
12/10/2017 02:20:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:09 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:20:09 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 02:20:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.56      0.74      0.63       169
          F       0.71      0.76      0.74       281
          R       0.46      0.25      0.32       122

avg / total       0.59      0.62      0.60       592

12/10/2017 02:20:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:09 [INFO] exp_shallowmodel: 
[[  0   4  12   4]
 [  0 125  26  18]
 [  0  54 214  13]
 [  1  42  49  30]]
12/10/2017 02:20:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 02:20:09 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:09 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:12 [INFO] exp_shallowmodel: train time: 3.136s
12/10/2017 02:20:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:12 [INFO] exp_shallowmodel: accuracy:   0.605
12/10/2017 02:20:12 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 02:20:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.68      0.58       169
          F       0.73      0.77      0.75       281
          R       0.40      0.23      0.29       122

avg / total       0.57      0.60      0.58       592

12/10/2017 02:20:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:12 [INFO] exp_shallowmodel: 
[[  0   8   8   4]
 [  0 115  29  25]
 [  0  53 215  13]
 [  2  49  43  28]]
12/10/2017 02:20:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 02:20:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:12 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:16 [INFO] exp_shallowmodel: train time: 4.061s
12/10/2017 02:20:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:16 [INFO] exp_shallowmodel: accuracy:   0.603
12/10/2017 02:20:16 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 02:20:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.55      0.73      0.63       169
          F       0.69      0.73      0.71       281
          R       0.42      0.25      0.31       122

avg / total       0.57      0.60      0.58       592

12/10/2017 02:20:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:16 [INFO] exp_shallowmodel: 
[[  0   4  11   5]
 [  1 123  27  18]
 [  1  58 204  18]
 [  0  39  53  30]]
12/10/2017 02:20:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 02:20:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:16 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:18 [INFO] exp_shallowmodel: train time: 2.396s
12/10/2017 02:20:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:18 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:20:18 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 02:20:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.68      0.57       169
          F       0.70      0.72      0.71       281
          R       0.39      0.22      0.28       122

avg / total       0.55      0.58      0.56       592

12/10/2017 02:20:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:18 [INFO] exp_shallowmodel: 
[[  0   5   9   6]
 [  1 115  37  16]
 [  0  58 203  20]
 [  0  55  40  27]]
12/10/2017 02:20:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 02:20:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:18 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:21 [INFO] exp_shallowmodel: train time: 3.116s
12/10/2017 02:20:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:21 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 02:20:21 [INFO] exp_shallowmodel: f1_score:   0.371
12/10/2017 02:20:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.73      0.60       169
          F       0.69      0.72      0.70       281
          R       0.29      0.13      0.18       122

avg / total       0.53      0.58      0.54       592

12/10/2017 02:20:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:21 [INFO] exp_shallowmodel: 
[[  0   5   9   6]
 [  0 123  29  17]
 [  1  62 202  16]
 [  2  51  53  16]]
12/10/2017 02:20:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 02:20:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:21 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:24 [INFO] exp_shallowmodel: train time: 2.319s
12/10/2017 02:20:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:24 [INFO] exp_shallowmodel: accuracy:   0.605
12/10/2017 02:20:24 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 02:20:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.62      0.57       169
          F       0.70      0.80      0.75       281
          R       0.40      0.22      0.29       122

avg / total       0.57      0.60      0.58       592

12/10/2017 02:20:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:24 [INFO] exp_shallowmodel: 
[[  0   5   9   6]
 [  1 105  41  22]
 [  2  41 226  12]
 [  1  49  45  27]]
12/10/2017 02:20:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 02:20:24 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:24 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:26 [INFO] exp_shallowmodel: train time: 2.667s
12/10/2017 02:20:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:26 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:20:26 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:20:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.65      0.55       169
          F       0.70      0.72      0.71       281
          R       0.46      0.26      0.33       122

avg / total       0.56      0.58      0.56       592

12/10/2017 02:20:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:26 [INFO] exp_shallowmodel: 
[[  0  11   6   3]
 [  0 110  41  18]
 [  2  59 203  17]
 [  0  48  42  32]]
12/10/2017 02:20:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 02:20:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:26 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:32 [INFO] exp_shallowmodel: train time: 5.474s
12/10/2017 02:20:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:32 [INFO] exp_shallowmodel: accuracy:   0.584
12/10/2017 02:20:32 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 02:20:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.68      0.57       169
          F       0.70      0.73      0.71       281
          R       0.40      0.22      0.28       122

avg / total       0.56      0.58      0.56       592

12/10/2017 02:20:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:32 [INFO] exp_shallowmodel: 
[[  0   5  12   3]
 [  0 115  32  22]
 [  0  61 204  16]
 [  0  53  42  27]]
12/10/2017 02:20:32 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 02:20:32 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:20:32 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:37 [INFO] exp_shallowmodel: train time: 5.566s
12/10/2017 02:20:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:20:38 [INFO] exp_shallowmodel: accuracy:   0.607
12/10/2017 02:20:38 [INFO] exp_shallowmodel: f1_score:   0.413
12/10/2017 02:20:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.53      0.72      0.61       172
          F       0.72      0.76      0.74       283
          R       0.39      0.24      0.30       123

avg / total       0.57      0.61      0.58       606

12/10/2017 02:20:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:38 [INFO] exp_shallowmodel: 
[[  0   6  14   8]
 [  1 123  26  22]
 [  0  52 215  16]
 [  0  51  42  30]]
12/10/2017 02:20:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 02:20:38 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:38 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:43 [INFO] exp_shallowmodel: train time: 5.186s
12/10/2017 02:20:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:43 [INFO] exp_shallowmodel: accuracy:   0.610
12/10/2017 02:20:43 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 02:20:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.67      0.60       169
          F       0.73      0.79      0.76       281
          R       0.35      0.21      0.26       122

avg / total       0.57      0.61      0.58       592

12/10/2017 02:20:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:43 [INFO] exp_shallowmodel: 
[[  0   4   9   7]
 [  1 114  26  28]
 [  1  45 221  14]
 [  0  48  48  26]]
12/10/2017 02:20:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 02:20:43 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:43 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:46 [INFO] exp_shallowmodel: train time: 3.498s
12/10/2017 02:20:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:46 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:20:46 [INFO] exp_shallowmodel: f1_score:   0.367
12/10/2017 02:20:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.64      0.55       169
          F       0.70      0.74      0.72       281
          R       0.30      0.16      0.20       122

avg / total       0.53      0.57      0.54       592

12/10/2017 02:20:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:46 [INFO] exp_shallowmodel: 
[[  0   6   7   7]
 [  1 109  36  23]
 [  0  59 207  15]
 [  2  55  46  19]]
12/10/2017 02:20:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 02:20:46 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:46 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:49 [INFO] exp_shallowmodel: train time: 2.878s
12/10/2017 02:20:49 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:49 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 02:20:49 [INFO] exp_shallowmodel: f1_score:   0.388
12/10/2017 02:20:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.70      0.58       169
          F       0.69      0.71      0.70       281
          R       0.41      0.20      0.27       122

avg / total       0.55      0.58      0.55       592

12/10/2017 02:20:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:49 [INFO] exp_shallowmodel: 
[[  0   6  12   2]
 [  0 118  36  15]
 [  0  62 200  19]
 [  1  55  41  25]]
12/10/2017 02:20:49 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 02:20:49 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:49 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:53 [INFO] exp_shallowmodel: train time: 3.407s
12/10/2017 02:20:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:53 [INFO] exp_shallowmodel: accuracy:   0.591
12/10/2017 02:20:53 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:20:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.66      0.57       169
          F       0.71      0.75      0.73       281
          R       0.39      0.22      0.28       122

avg / total       0.56      0.59      0.57       592

12/10/2017 02:20:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:53 [INFO] exp_shallowmodel: 
[[  0   3  11   6]
 [  1 111  34  23]
 [  1  55 212  13]
 [  1  51  43  27]]
12/10/2017 02:20:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 02:20:53 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:53 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:57 [INFO] exp_shallowmodel: train time: 4.136s
12/10/2017 02:20:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:20:57 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 02:20:57 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 02:20:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.66      0.58       169
          F       0.69      0.77      0.73       281
          R       0.35      0.17      0.23       122

avg / total       0.55      0.59      0.56       592

12/10/2017 02:20:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:57 [INFO] exp_shallowmodel: 
[[  0   6  12   2]
 [  2 111  37  19]
 [  1  46 216  18]
 [  1  51  49  21]]
12/10/2017 02:20:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 02:20:57 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:20:57 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:20:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:01 [INFO] exp_shallowmodel: train time: 4.321s
12/10/2017 02:21:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:01 [INFO] exp_shallowmodel: accuracy:   0.595
12/10/2017 02:21:01 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:21:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        20
          C       0.50      0.69      0.58       169
          F       0.71      0.73      0.72       281
          R       0.43      0.24      0.31       122

avg / total       0.58      0.59      0.57       592

12/10/2017 02:21:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:01 [INFO] exp_shallowmodel: 
[[  1   7   7   5]
 [  0 117  33  19]
 [  2  60 205  14]
 [  0  51  42  29]]
12/10/2017 02:21:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 02:21:01 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:01 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:05 [INFO] exp_shallowmodel: train time: 4.017s
12/10/2017 02:21:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:05 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 02:21:05 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:21:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.50      0.70      0.58       169
          F       0.71      0.75      0.73       281
          R       0.47      0.21      0.29       122

avg / total       0.59      0.60      0.58       592

12/10/2017 02:21:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:05 [INFO] exp_shallowmodel: 
[[  1   5  12   2]
 [  1 118  33  17]
 [  0  60 211  10]
 [  0  53  43  26]]
12/10/2017 02:21:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 02:21:05 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:05 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:09 [INFO] exp_shallowmodel: train time: 4.224s
12/10/2017 02:21:09 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:09 [INFO] exp_shallowmodel: accuracy:   0.593
12/10/2017 02:21:09 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:21:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.72      0.61       169
          F       0.70      0.72      0.71       281
          R       0.38      0.21      0.27       122

avg / total       0.56      0.59      0.57       592

12/10/2017 02:21:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:09 [INFO] exp_shallowmodel: 
[[  0   1  12   7]
 [  3 122  26  18]
 [  0  60 203  18]
 [  0  48  48  26]]
12/10/2017 02:21:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 02:21:09 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:09 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:14 [INFO] exp_shallowmodel: train time: 4.319s
12/10/2017 02:21:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:14 [INFO] exp_shallowmodel: accuracy:   0.600
12/10/2017 02:21:14 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 02:21:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.73      0.62       169
          F       0.70      0.74      0.72       281
          R       0.38      0.20      0.27       122

avg / total       0.57      0.60      0.57       592

12/10/2017 02:21:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:14 [INFO] exp_shallowmodel: 
[[  0   8  10   2]
 [  0 123  28  18]
 [  1  53 207  20]
 [  2  45  50  25]]
12/10/2017 02:21:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 02:21:14 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:21:14 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:18 [INFO] exp_shallowmodel: train time: 4.583s
12/10/2017 02:21:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:18 [INFO] exp_shallowmodel: accuracy:   0.604
12/10/2017 02:21:18 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 02:21:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.54      0.67      0.60       172
          F       0.69      0.77      0.73       283
          R       0.44      0.25      0.32       123

avg / total       0.56      0.60      0.58       606

12/10/2017 02:21:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:18 [INFO] exp_shallowmodel: 
[[  0  11  13   4]
 [  0 116  44  12]
 [  2  39 219  23]
 [  1  48  43  31]]
12/10/2017 02:21:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 02:21:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:18 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:22 [INFO] exp_shallowmodel: train time: 4.138s
12/10/2017 02:21:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:22 [INFO] exp_shallowmodel: accuracy:   0.605
12/10/2017 02:21:22 [INFO] exp_shallowmodel: f1_score:   0.395
12/10/2017 02:21:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.69      0.59       169
          F       0.71      0.78      0.74       281
          R       0.40      0.18      0.25       122

avg / total       0.57      0.60      0.57       592

12/10/2017 02:21:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:22 [INFO] exp_shallowmodel: 
[[  0   4  14   2]
 [  0 117  34  18]
 [  1  48 219  13]
 [  0  59  41  22]]
12/10/2017 02:21:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 02:21:22 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:22 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:26 [INFO] exp_shallowmodel: train time: 3.757s
12/10/2017 02:21:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:26 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 02:21:26 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 02:21:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.72      0.58       169
          F       0.68      0.73      0.71       281
          R       0.48      0.18      0.26       122

avg / total       0.56      0.59      0.56       592

12/10/2017 02:21:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:26 [INFO] exp_shallowmodel: 
[[  0   4  12   4]
 [  0 121  40   8]
 [  0  63 206  12]
 [  0  57  43  22]]
12/10/2017 02:21:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 02:21:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:26 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:29 [INFO] exp_shallowmodel: train time: 2.942s
12/10/2017 02:21:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:29 [INFO] exp_shallowmodel: accuracy:   0.547
12/10/2017 02:21:29 [INFO] exp_shallowmodel: f1_score:   0.359
12/10/2017 02:21:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.47      0.63      0.54       169
          F       0.64      0.70      0.67       281
          R       0.36      0.16      0.23       122

avg / total       0.51      0.55      0.52       592

12/10/2017 02:21:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:29 [INFO] exp_shallowmodel: 
[[  0   6  11   3]
 [  1 107  43  18]
 [  1  69 197  14]
 [  0  46  56  20]]
12/10/2017 02:21:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 02:21:29 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:29 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:32 [INFO] exp_shallowmodel: train time: 2.611s
12/10/2017 02:21:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:32 [INFO] exp_shallowmodel: accuracy:   0.596
12/10/2017 02:21:32 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 02:21:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.76      0.62       169
          F       0.71      0.72      0.71       281
          R       0.40      0.19      0.26       122

avg / total       0.57      0.60      0.57       592

12/10/2017 02:21:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:32 [INFO] exp_shallowmodel: 
[[  0   6  12   2]
 [  0 129  22  18]
 [  2  63 201  15]
 [  1  51  47  23]]
12/10/2017 02:21:32 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 02:21:32 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:32 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:35 [INFO] exp_shallowmodel: train time: 2.629s
12/10/2017 02:21:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:35 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 02:21:35 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 02:21:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.52      0.72      0.61       169
          F       0.74      0.77      0.75       281
          R       0.40      0.20      0.27       122

avg / total       0.59      0.61      0.59       592

12/10/2017 02:21:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:35 [INFO] exp_shallowmodel: 
[[  1   5   7   7]
 [  1 122  28  18]
 [  2  51 215  13]
 [  0  55  42  25]]
12/10/2017 02:21:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 02:21:35 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:35 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:38 [INFO] exp_shallowmodel: train time: 3.504s
12/10/2017 02:21:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:38 [INFO] exp_shallowmodel: accuracy:   0.586
12/10/2017 02:21:38 [INFO] exp_shallowmodel: f1_score:   0.390
12/10/2017 02:21:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.69      0.57       169
          F       0.70      0.74      0.72       281
          R       0.41      0.20      0.27       122

avg / total       0.56      0.59      0.56       592

12/10/2017 02:21:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:38 [INFO] exp_shallowmodel: 
[[  0   7   8   5]
 [  0 116  34  19]
 [  1  62 207  11]
 [  2  50  46  24]]
12/10/2017 02:21:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 02:21:38 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:38 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:41 [INFO] exp_shallowmodel: train time: 3.277s
12/10/2017 02:21:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:41 [INFO] exp_shallowmodel: accuracy:   0.630
12/10/2017 02:21:41 [INFO] exp_shallowmodel: f1_score:   0.454
12/10/2017 02:21:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.54      0.70      0.61       169
          F       0.74      0.78      0.76       281
          R       0.44      0.29      0.35       122

avg / total       0.63      0.63      0.61       592

12/10/2017 02:21:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:41 [INFO] exp_shallowmodel: 
[[  1   6   7   6]
 [  0 118  25  26]
 [  0  49 219  13]
 [  0  44  43  35]]
12/10/2017 02:21:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 02:21:41 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:41 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:44 [INFO] exp_shallowmodel: train time: 2.547s
12/10/2017 02:21:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:44 [INFO] exp_shallowmodel: accuracy:   0.591
12/10/2017 02:21:44 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 02:21:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.65      0.55       169
          F       0.73      0.74      0.73       281
          R       0.43      0.26      0.32       122

avg / total       0.57      0.59      0.57       592

12/10/2017 02:21:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:44 [INFO] exp_shallowmodel: 
[[  0   6   8   6]
 [  1 110  31  27]
 [  1  62 208  10]
 [  1  50  39  32]]
12/10/2017 02:21:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 02:21:44 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:44 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:47 [INFO] exp_shallowmodel: train time: 2.806s
12/10/2017 02:21:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:47 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 02:21:47 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 02:21:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.70      0.61       169
          F       0.71      0.75      0.73       281
          R       0.35      0.21      0.27       122

avg / total       0.56      0.60      0.58       592

12/10/2017 02:21:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:47 [INFO] exp_shallowmodel: 
[[  0   5   8   7]
 [  1 118  35  15]
 [  0  43 212  26]
 [  0  54  42  26]]
12/10/2017 02:21:47 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 02:21:47 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:21:47 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:50 [INFO] exp_shallowmodel: train time: 3.703s
12/10/2017 02:21:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:50 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 02:21:50 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:21:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.53      0.67      0.59       172
          F       0.69      0.79      0.73       283
          R       0.38      0.20      0.26       123

avg / total       0.55      0.60      0.56       606

12/10/2017 02:21:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:50 [INFO] exp_shallowmodel: 
[[  0   8  12   8]
 [  0 115  39  18]
 [  0  47 223  13]
 [  1  47  51  24]]
12/10/2017 02:21:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 02:21:50 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:50 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:56 [INFO] exp_shallowmodel: train time: 5.396s
12/10/2017 02:21:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:21:56 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 02:21:56 [INFO] exp_shallowmodel: f1_score:   0.413
12/10/2017 02:21:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.75      0.62       169
          F       0.73      0.77      0.75       281
          R       0.47      0.20      0.29       122

avg / total       0.59      0.62      0.59       592

12/10/2017 02:21:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:56 [INFO] exp_shallowmodel: 
[[  0   8   8   4]
 [  2 127  31   9]
 [  0  51 215  15]
 [  0  55  42  25]]
12/10/2017 02:21:56 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 02:21:56 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:21:56 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:21:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:00 [INFO] exp_shallowmodel: train time: 4.229s
12/10/2017 02:22:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:00 [INFO] exp_shallowmodel: accuracy:   0.598
12/10/2017 02:22:00 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 02:22:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.69      0.58       169
          F       0.73      0.74      0.73       281
          R       0.41      0.24      0.30       122

avg / total       0.57      0.60      0.58       592

12/10/2017 02:22:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:00 [INFO] exp_shallowmodel: 
[[  0   4   7   9]
 [  0 117  31  21]
 [  0  62 208  11]
 [  2  52  39  29]]
12/10/2017 02:22:00 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 02:22:00 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:00 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:05 [INFO] exp_shallowmodel: train time: 4.825s
12/10/2017 02:22:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:05 [INFO] exp_shallowmodel: accuracy:   0.584
12/10/2017 02:22:05 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 02:22:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.70      0.59       169
          F       0.70      0.73      0.71       281
          R       0.35      0.19      0.25       122

avg / total       0.55      0.58      0.56       592

12/10/2017 02:22:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:05 [INFO] exp_shallowmodel: 
[[  0   6  10   4]
 [  0 118  29  22]
 [  1  59 205  16]
 [  1  49  49  23]]
12/10/2017 02:22:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 02:22:05 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:05 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:08 [INFO] exp_shallowmodel: train time: 2.966s
12/10/2017 02:22:08 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:22:08 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:22:08 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 02:22:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.55      0.73      0.62       169
          F       0.71      0.78      0.74       281
          R       0.46      0.21      0.29       122

avg / total       0.59      0.62      0.59       592

12/10/2017 02:22:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:08 [INFO] exp_shallowmodel: 
[[  0   5  10   5]
 [  0 123  32  14]
 [  0  49 220  12]
 [  0  48  48  26]]
12/10/2017 02:22:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 02:22:08 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:08 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:11 [INFO] exp_shallowmodel: train time: 2.822s
12/10/2017 02:22:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:11 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 02:22:11 [INFO] exp_shallowmodel: f1_score:   0.390
12/10/2017 02:22:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.70      0.58       169
          F       0.69      0.70      0.69       281
          R       0.40      0.22      0.29       122

avg / total       0.55      0.58      0.55       592

12/10/2017 02:22:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:11 [INFO] exp_shallowmodel: 
[[  0   9  10   1]
 [  0 118  33  18]
 [  0  63 197  21]
 [  0  49  46  27]]
12/10/2017 02:22:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 02:22:11 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:11 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:15 [INFO] exp_shallowmodel: train time: 3.971s
12/10/2017 02:22:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:22:15 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:22:15 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 02:22:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.49      0.67      0.57       169
          F       0.70      0.73      0.72       281
          R       0.37      0.20      0.26       122

avg / total       0.57      0.58      0.56       592

12/10/2017 02:22:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:15 [INFO] exp_shallowmodel: 
[[  1   3   9   7]
 [  1 114  31  23]
 [  0  64 205  12]
 [  0  50  47  25]]
12/10/2017 02:22:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 02:22:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:15 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:18 [INFO] exp_shallowmodel: train time: 3.328s
12/10/2017 02:22:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:18 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 02:22:18 [INFO] exp_shallowmodel: f1_score:   0.388
12/10/2017 02:22:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.66      0.57       169
          F       0.69      0.73      0.71       281
          R       0.39      0.21      0.28       122

avg / total       0.55      0.58      0.56       592

12/10/2017 02:22:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:18 [INFO] exp_shallowmodel: 
[[  0   5  11   4]
 [  1 111  38  19]
 [  2  55 206  18]
 [  0  51  45  26]]
12/10/2017 02:22:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 02:22:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:18 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:20 [INFO] exp_shallowmodel: train time: 1.538s
12/10/2017 02:22:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:20 [INFO] exp_shallowmodel: accuracy:   0.595
12/10/2017 02:22:20 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 02:22:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.69      0.58       169
          F       0.72      0.74      0.73       281
          R       0.38      0.22      0.28       122

avg / total       0.56      0.59      0.57       592

12/10/2017 02:22:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:20 [INFO] exp_shallowmodel: 
[[  0   4  12   4]
 [  1 116  27  25]
 [  0  56 209  16]
 [  0  54  41  27]]
12/10/2017 02:22:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 02:22:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:20 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:22 [INFO] exp_shallowmodel: train time: 2.710s
12/10/2017 02:22:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:22 [INFO] exp_shallowmodel: accuracy:   0.561
12/10/2017 02:22:22 [INFO] exp_shallowmodel: f1_score:   0.370
12/10/2017 02:22:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.58      0.53       169
          F       0.66      0.75      0.70       281
          R       0.33      0.20      0.25       122

avg / total       0.52      0.56      0.54       592

12/10/2017 02:22:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:22 [INFO] exp_shallowmodel: 
[[  0   6   9   5]
 [  0  98  47  24]
 [  1  51 210  19]
 [  0  46  52  24]]
12/10/2017 02:22:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 02:22:22 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:22:22 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:26 [INFO] exp_shallowmodel: train time: 4.010s
12/10/2017 02:22:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:26 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 02:22:26 [INFO] exp_shallowmodel: f1_score:   0.379
12/10/2017 02:22:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.48      0.66      0.56       172
          F       0.69      0.75      0.72       283
          R       0.37      0.18      0.24       123

avg / total       0.53      0.57      0.54       606

12/10/2017 02:22:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:26 [INFO] exp_shallowmodel: 
[[  0   9  13   6]
 [  0 113  40  19]
 [  1  56 213  13]
 [  1  57  43  22]]
12/10/2017 02:22:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 02:22:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:26 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:29 [INFO] exp_shallowmodel: train time: 2.147s
12/10/2017 02:22:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:29 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:22:29 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 02:22:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.47      0.70      0.56       169
          F       0.72      0.71      0.71       281
          R       0.42      0.23      0.30       122

avg / total       0.56      0.58      0.56       592

12/10/2017 02:22:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:29 [INFO] exp_shallowmodel: 
[[  0   8   7   5]
 [  0 118  32  19]
 [  1  67 199  14]
 [  0  56  38  28]]
12/10/2017 02:22:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 02:22:29 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:29 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:32 [INFO] exp_shallowmodel: train time: 3.802s
12/10/2017 02:22:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:32 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 02:22:32 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 02:22:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.50      0.70      0.58       169
          F       0.69      0.73      0.71       281
          R       0.34      0.16      0.22       122

avg / total       0.58      0.58      0.55       592

12/10/2017 02:22:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:32 [INFO] exp_shallowmodel: 
[[  1   2  11   6]
 [  0 119  34  16]
 [  0  60 205  16]
 [  0  57  45  20]]
12/10/2017 02:22:32 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 02:22:32 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:32 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:38 [INFO] exp_shallowmodel: train time: 5.029s
12/10/2017 02:22:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:38 [INFO] exp_shallowmodel: accuracy:   0.627
12/10/2017 02:22:38 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 02:22:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.55      0.71      0.62       169
          F       0.71      0.78      0.74       281
          R       0.49      0.27      0.35       122

avg / total       0.60      0.63      0.60       592

12/10/2017 02:22:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:38 [INFO] exp_shallowmodel: 
[[  0   8   6   6]
 [  0 120  32  17]
 [  1  50 218  12]
 [  0  40  49  33]]
12/10/2017 02:22:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 02:22:38 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:38 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:41 [INFO] exp_shallowmodel: train time: 3.387s
12/10/2017 02:22:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:41 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 02:22:41 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 02:22:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.71      0.57       169
          F       0.72      0.70      0.71       281
          R       0.40      0.22      0.28       122

avg / total       0.56      0.58      0.56       592

12/10/2017 02:22:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:41 [INFO] exp_shallowmodel: 
[[  0   2  13   5]
 [  0 120  25  24]
 [  0  73 196  12]
 [  0  56  39  27]]
12/10/2017 02:22:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 02:22:41 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:41 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:44 [INFO] exp_shallowmodel: train time: 2.991s
12/10/2017 02:22:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:44 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 02:22:44 [INFO] exp_shallowmodel: f1_score:   0.352
12/10/2017 02:22:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.62      0.52       169
          F       0.70      0.72      0.71       281
          R       0.24      0.14      0.18       122

avg / total       0.51      0.55      0.52       592

12/10/2017 02:22:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:44 [INFO] exp_shallowmodel: 
[[  0   6   9   5]
 [  1 105  31  32]
 [  0  63 201  17]
 [  0  59  46  17]]
12/10/2017 02:22:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 02:22:44 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:44 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:48 [INFO] exp_shallowmodel: train time: 3.911s
12/10/2017 02:22:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:48 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:22:48 [INFO] exp_shallowmodel: f1_score:   0.378
12/10/2017 02:22:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.73      0.59       169
          F       0.68      0.69      0.69       281
          R       0.37      0.17      0.23       122

avg / total       0.54      0.57      0.54       592

12/10/2017 02:22:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:48 [INFO] exp_shallowmodel: 
[[  0   3  10   7]
 [  1 124  32  12]
 [  0  70 194  17]
 [  0  52  49  21]]
12/10/2017 02:22:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 02:22:48 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:48 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:53 [INFO] exp_shallowmodel: train time: 4.684s
12/10/2017 02:22:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:53 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 02:22:53 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 02:22:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.63      0.55       169
          F       0.68      0.74      0.71       281
          R       0.52      0.28      0.36       122

avg / total       0.57      0.59      0.57       592

12/10/2017 02:22:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:53 [INFO] exp_shallowmodel: 
[[  0   5  10   5]
 [  2 106  48  13]
 [  0  59 208  14]
 [  1  46  41  34]]
12/10/2017 02:22:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 02:22:53 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:53 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:56 [INFO] exp_shallowmodel: train time: 3.783s
12/10/2017 02:22:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:22:56 [INFO] exp_shallowmodel: accuracy:   0.596
12/10/2017 02:22:56 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 02:22:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.52      0.68      0.59       169
          F       0.73      0.73      0.73       281
          R       0.36      0.25      0.30       122

avg / total       0.58      0.60      0.58       592

12/10/2017 02:22:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:56 [INFO] exp_shallowmodel: 
[[  1   2  11   6]
 [  1 115  25  28]
 [  1  54 206  20]
 [  1  51  39  31]]
12/10/2017 02:22:56 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 02:22:56 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:22:56 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:22:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:01 [INFO] exp_shallowmodel: train time: 4.528s
12/10/2017 02:23:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:01 [INFO] exp_shallowmodel: accuracy:   0.600
12/10/2017 02:23:01 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:23:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.66      0.58       169
          F       0.71      0.75      0.73       281
          R       0.44      0.26      0.33       122

avg / total       0.57      0.60      0.58       592

12/10/2017 02:23:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:01 [INFO] exp_shallowmodel: 
[[  0   7   7   6]
 [  1 112  42  14]
 [  1  49 211  20]
 [  2  50  38  32]]
12/10/2017 02:23:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 02:23:01 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:23:01 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:04 [INFO] exp_shallowmodel: train time: 3.273s
12/10/2017 02:23:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:04 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 02:23:04 [INFO] exp_shallowmodel: f1_score:   0.395
12/10/2017 02:23:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.52      0.70      0.60       172
          F       0.70      0.78      0.74       283
          R       0.39      0.18      0.24       123

avg / total       0.55      0.60      0.56       606

12/10/2017 02:23:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:04 [INFO] exp_shallowmodel: 
[[  0  10  13   5]
 [  0 121  35  16]
 [  1  47 221  14]
 [  0  55  46  22]]
12/10/2017 02:23:09 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:23:09 [INFO] task_runner: context=last, feature=5-lda
12/10/2017 02:23:09 [INFO] task_runner: retained feature numbers=[8.1]
12/10/2017 02:23:09 [INFO] task_runner: #(data)=3530
12/10/2017 02:23:09 [INFO] task_runner: #(feature)=150
12/10/2017 02:23:09 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:23:09 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 02:23:09 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:09 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:10 [INFO] exp_shallowmodel: train time: 0.632s
12/10/2017 02:23:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:10 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:23:10 [INFO] exp_shallowmodel: f1_score:   0.267
12/10/2017 02:23:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.17      0.04      0.06        27
          F       0.73      0.94      0.83       250
          R       0.24      0.08      0.12        52

avg / total       0.58      0.69      0.61       352

12/10/2017 02:23:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:10 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   1  21   5]
 [  4   5 236   5]
 [  2   0  46   4]]
12/10/2017 02:23:10 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 02:23:10 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:10 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:11 [INFO] exp_shallowmodel: train time: 0.717s
12/10/2017 02:23:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:11 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 02:23:11 [INFO] exp_shallowmodel: f1_score:   0.270
12/10/2017 02:23:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.25      0.04      0.06        27
          F       0.73      0.95      0.83       250
          R       0.21      0.08      0.11        52

avg / total       0.59      0.69      0.61       352

12/10/2017 02:23:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:11 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   1  23   3]
 [  2   0 238  10]
 [  0   2  46   4]]
12/10/2017 02:23:11 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 02:23:11 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:11 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:11 [INFO] exp_shallowmodel: train time: 0.794s
12/10/2017 02:23:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:11 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:23:11 [INFO] exp_shallowmodel: f1_score:   0.335
12/10/2017 02:23:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.09      0.14        23
          C       0.25      0.11      0.15        27
          F       0.75      0.96      0.84       250
          R       0.41      0.13      0.20        52

avg / total       0.64      0.71      0.65       352

12/10/2017 02:23:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:11 [INFO] exp_shallowmodel: 
[[  2   1  19   1]
 [  0   3  20   4]
 [  1   5 239   5]
 [  2   3  40   7]]
12/10/2017 02:23:11 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 02:23:11 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:11 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:12 [INFO] exp_shallowmodel: train time: 0.675s
12/10/2017 02:23:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:12 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 02:23:12 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 02:23:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.56      0.19      0.28        27
          F       0.73      0.94      0.82       250
          R       0.47      0.17      0.25        52

avg / total       0.63      0.70      0.64       352

12/10/2017 02:23:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:12 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   5  20   2]
 [  4   4 234   8]
 [  1   0  42   9]]
12/10/2017 02:23:12 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 02:23:12 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:12 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:13 [INFO] exp_shallowmodel: train time: 0.938s
12/10/2017 02:23:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:13 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 02:23:13 [INFO] exp_shallowmodel: f1_score:   0.265
12/10/2017 02:23:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.07      0.11        27
          F       0.73      0.95      0.82       250
          R       0.27      0.08      0.12        52

avg / total       0.58      0.69      0.61       352

12/10/2017 02:23:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:13 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   2  23   2]
 [  1   5 237   7]
 [  3   1  44   4]]
12/10/2017 02:23:13 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 02:23:13 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:13 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:14 [INFO] exp_shallowmodel: train time: 0.765s
12/10/2017 02:23:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:14 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:23:14 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 02:23:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.25      0.07      0.11        27
          F       0.74      0.97      0.84       250
          R       0.31      0.08      0.12        52

avg / total       0.61      0.71      0.63       352

12/10/2017 02:23:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:14 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   2  22   3]
 [  1   2 242   5]
 [  1   4  43   4]]
12/10/2017 02:23:14 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 02:23:14 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:14 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:15 [INFO] exp_shallowmodel: train time: 0.779s
12/10/2017 02:23:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:15 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:23:15 [INFO] exp_shallowmodel: f1_score:   0.335
12/10/2017 02:23:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.62      0.19      0.29        27
          F       0.75      0.96      0.84       250
          R       0.36      0.15      0.22        52

avg / total       0.63      0.72      0.65       352

12/10/2017 02:23:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:15 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  0   5  21   1]
 [  0   1 240   9]
 [  0   2  42   8]]
12/10/2017 02:23:15 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 02:23:15 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:15 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:16 [INFO] exp_shallowmodel: train time: 1.448s
12/10/2017 02:23:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:16 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 02:23:16 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 02:23:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.11      0.04      0.06        27
          F       0.73      0.94      0.82       250
          R       0.31      0.10      0.15        52

avg / total       0.59      0.69      0.62       352

12/10/2017 02:23:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:16 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  0   1  23   3]
 [  3   4 236   7]
 [  0   3  44   5]]
12/10/2017 02:23:16 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 02:23:16 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:16 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:18 [INFO] exp_shallowmodel: train time: 1.428s
12/10/2017 02:23:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:18 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:23:18 [INFO] exp_shallowmodel: f1_score:   0.282
12/10/2017 02:23:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.40      0.07      0.12        27
          F       0.73      0.94      0.82       250
          R       0.20      0.08      0.11        52

avg / total       0.59      0.69      0.62       352

12/10/2017 02:23:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:18 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  1   2  19   5]
 [  5   2 235   8]
 [  0   1  47   4]]
12/10/2017 02:23:18 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 02:23:18 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:23:18 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:19 [INFO] exp_shallowmodel: train time: 1.497s
12/10/2017 02:23:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:19 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:23:19 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 02:23:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       1.00      0.07      0.14        27
          F       0.72      0.95      0.82       251
          R       0.35      0.14      0.20        59

avg / total       0.63      0.69      0.61       362

12/10/2017 02:23:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:19 [INFO] exp_shallowmodel: 
[[  0   0  20   5]
 [  0   2  24   1]
 [  3   0 239   9]
 [  1   0  50   8]]
12/10/2017 02:23:19 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 02:23:19 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:19 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:20 [INFO] exp_shallowmodel: train time: 0.864s
12/10/2017 02:23:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:20 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 02:23:20 [INFO] exp_shallowmodel: f1_score:   0.255
12/10/2017 02:23:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.14      0.04      0.06        27
          F       0.73      0.93      0.82       250
          R       0.28      0.10      0.14        52

avg / total       0.57      0.68      0.61       352

12/10/2017 02:23:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:20 [INFO] exp_shallowmodel: 
[[  0   1  22   0]
 [  2   1  21   3]
 [  3   4 233  10]
 [  2   1  44   5]]
12/10/2017 02:23:20 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 02:23:20 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:20 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:21 [INFO] exp_shallowmodel: train time: 0.681s
12/10/2017 02:23:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:21 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:23:21 [INFO] exp_shallowmodel: f1_score:   0.287
12/10/2017 02:23:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.22      0.07      0.11        27
          F       0.73      0.95      0.83       250
          R       0.47      0.13      0.21        52

avg / total       0.61      0.70      0.63       352

12/10/2017 02:23:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:21 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  0   2  24   1]
 [  2   4 238   6]
 [  1   2  42   7]]
12/10/2017 02:23:21 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 02:23:21 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:21 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:22 [INFO] exp_shallowmodel: train time: 1.353s
12/10/2017 02:23:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:22 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:23:22 [INFO] exp_shallowmodel: f1_score:   0.340
12/10/2017 02:23:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.09      0.15        23
          C       0.60      0.11      0.19        27
          F       0.74      0.95      0.83       250
          R       0.35      0.13      0.19        52

avg / total       0.65      0.71      0.64       352

12/10/2017 02:23:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:22 [INFO] exp_shallowmodel: 
[[  2   0  17   4]
 [  0   3  24   0]
 [  2   1 238   9]
 [  0   1  44   7]]
12/10/2017 02:23:22 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 02:23:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:22 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:23 [INFO] exp_shallowmodel: train time: 0.709s
12/10/2017 02:23:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:23 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:23:23 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 02:23:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.43      0.11      0.18        27
          F       0.73      0.97      0.83       250
          R       0.42      0.10      0.16        52

avg / total       0.61      0.71      0.63       352

12/10/2017 02:23:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:23 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  0   3  23   1]
 [  1   2 242   5]
 [  1   1  45   5]]
12/10/2017 02:23:23 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 02:23:23 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:23 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:23 [INFO] exp_shallowmodel: train time: 0.607s
12/10/2017 02:23:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:23 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:23:23 [INFO] exp_shallowmodel: f1_score:   0.272
12/10/2017 02:23:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.25      0.04      0.06        27
          F       0.73      0.96      0.83       250
          R       0.33      0.08      0.12        52

avg / total       0.60      0.70      0.62       352

12/10/2017 02:23:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:23 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  2   1  22   2]
 [  3   2 241   4]
 [  1   1  46   4]]
12/10/2017 02:23:23 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 02:23:23 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:23 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:25 [INFO] exp_shallowmodel: train time: 1.396s
12/10/2017 02:23:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:25 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 02:23:25 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 02:23:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.67      0.15      0.24        27
          F       0.74      0.96      0.84       250
          R       0.21      0.08      0.11        52

avg / total       0.62      0.70      0.63       352

12/10/2017 02:23:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:25 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  0   4  20   3]
 [  2   1 239   8]
 [  2   0  46   4]]
12/10/2017 02:23:25 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 02:23:25 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:25 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:26 [INFO] exp_shallowmodel: train time: 1.655s
12/10/2017 02:23:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:26 [INFO] exp_shallowmodel: accuracy:   0.673
12/10/2017 02:23:26 [INFO] exp_shallowmodel: f1_score:   0.218
12/10/2017 02:23:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.14      0.04      0.06        27
          F       0.72      0.94      0.81       250
          R       0.00      0.00      0.00        52

avg / total       0.52      0.67      0.58       352

12/10/2017 02:23:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:26 [INFO] exp_shallowmodel: 
[[  0   1  20   2]
 [  0   1  24   2]
 [  1   4 236   9]
 [  1   1  50   0]]
12/10/2017 02:23:26 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 02:23:26 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:26 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:27 [INFO] exp_shallowmodel: train time: 0.759s
12/10/2017 02:23:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:27 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:23:27 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 02:23:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.29      0.07      0.12        27
          F       0.73      0.97      0.83       250
          R       0.69      0.17      0.28        52

avg / total       0.64      0.72      0.64       352

12/10/2017 02:23:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:27 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   2  24   1]
 [  1   4 242   3]
 [  0   1  42   9]]
12/10/2017 02:23:27 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 02:23:27 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:27 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:29 [INFO] exp_shallowmodel: train time: 1.430s
12/10/2017 02:23:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:29 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 02:23:29 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 02:23:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.09      0.15        23
          C       0.18      0.07      0.11        27
          F       0.74      0.93      0.82       250
          R       0.33      0.13      0.19        52

avg / total       0.62      0.69      0.63       352

12/10/2017 02:23:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:29 [INFO] exp_shallowmodel: 
[[  2   1  19   1]
 [  0   2  22   3]
 [  2   5 233  10]
 [  0   3  42   7]]
12/10/2017 02:23:29 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 02:23:29 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:23:29 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:30 [INFO] exp_shallowmodel: train time: 1.045s
12/10/2017 02:23:30 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:30 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:23:30 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 02:23:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.16      0.24        25
          C       0.17      0.04      0.06        27
          F       0.73      0.95      0.83       251
          R       0.47      0.15      0.23        59

avg / total       0.63      0.70      0.63       362

12/10/2017 02:23:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:30 [INFO] exp_shallowmodel: 
[[  4   1  19   1]
 [  0   1  25   1]
 [  2   2 239   8]
 [  3   2  45   9]]
12/10/2017 02:23:30 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 02:23:30 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:30 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:31 [INFO] exp_shallowmodel: train time: 1.144s
12/10/2017 02:23:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:31 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 02:23:31 [INFO] exp_shallowmodel: f1_score:   0.295
12/10/2017 02:23:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.11      0.17        27
          F       0.74      0.93      0.82       250
          R       0.32      0.13      0.19        52

avg / total       0.60      0.69      0.63       352

12/10/2017 02:23:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:31 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   3  21   3]
 [  5   2 233  10]
 [  1   4  40   7]]
12/10/2017 02:23:31 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 02:23:31 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:31 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:32 [INFO] exp_shallowmodel: train time: 1.258s
12/10/2017 02:23:32 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:32 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:23:32 [INFO] exp_shallowmodel: f1_score:   0.305
12/10/2017 02:23:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.43      0.11      0.18        27
          F       0.73      0.95      0.83       250
          R       0.29      0.10      0.14        52

avg / total       0.61      0.70      0.63       352

12/10/2017 02:23:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:32 [INFO] exp_shallowmodel: 
[[  1   1  20   1]
 [  0   3  22   2]
 [  2   2 237   9]
 [  2   1  44   5]]
12/10/2017 02:23:32 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 02:23:32 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:32 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:33 [INFO] exp_shallowmodel: train time: 1.268s
12/10/2017 02:23:33 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:33 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:23:33 [INFO] exp_shallowmodel: f1_score:   0.287
12/10/2017 02:23:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.10      0.04      0.05        27
          F       0.73      0.96      0.83       250
          R       0.40      0.12      0.18        52

avg / total       0.65      0.70      0.63       352

12/10/2017 02:23:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:33 [INFO] exp_shallowmodel: 
[[  1   2  18   2]
 [  0   1  25   1]
 [  0   5 239   6]
 [  0   2  44   6]]
12/10/2017 02:23:33 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 02:23:33 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:33 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:34 [INFO] exp_shallowmodel: train time: 0.998s
12/10/2017 02:23:34 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:34 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 02:23:34 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 02:23:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.20      0.04      0.06        27
          F       0.73      0.94      0.82       250
          R       0.33      0.12      0.17        52

avg / total       0.60      0.69      0.62       352

12/10/2017 02:23:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:34 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  1   1  24   1]
 [  2   3 235  10]
 [  1   1  44   6]]
12/10/2017 02:23:34 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 02:23:34 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:34 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:35 [INFO] exp_shallowmodel: train time: 0.790s
12/10/2017 02:23:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:35 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:23:35 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 02:23:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        23
          C       0.50      0.22      0.31        27
          F       0.75      0.94      0.84       250
          R       0.11      0.04      0.06        52

avg / total       0.60      0.70      0.63       352

12/10/2017 02:23:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:35 [INFO] exp_shallowmodel: 
[[  1   1  14   7]
 [  1   6  18   2]
 [  5   2 236   7]
 [  1   3  46   2]]
12/10/2017 02:23:35 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 02:23:35 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:35 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:36 [INFO] exp_shallowmodel: train time: 0.836s
12/10/2017 02:23:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:36 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 02:23:36 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 02:23:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.31      0.15      0.20        27
          F       0.73      0.92      0.82       250
          R       0.38      0.15      0.22        52

avg / total       0.62      0.69      0.63       352

12/10/2017 02:23:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:36 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   4  22   1]
 [  2   7 230  11]
 [  1   2  41   8]]
12/10/2017 02:23:36 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 02:23:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:36 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:37 [INFO] exp_shallowmodel: train time: 1.006s
12/10/2017 02:23:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:37 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 02:23:37 [INFO] exp_shallowmodel: f1_score:   0.255
12/10/2017 02:23:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.04      0.06        27
          F       0.72      0.93      0.81       250
          R       0.26      0.10      0.14        52

avg / total       0.57      0.68      0.60       352

12/10/2017 02:23:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:37 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  0   1  23   3]
 [  5   2 233  10]
 [  2   0  45   5]]
12/10/2017 02:23:37 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 02:23:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:37 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:38 [INFO] exp_shallowmodel: train time: 0.913s
12/10/2017 02:23:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:38 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:23:38 [INFO] exp_shallowmodel: f1_score:   0.287
12/10/2017 02:23:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.67      0.07      0.13        27
          F       0.73      0.95      0.82       250
          R       0.24      0.08      0.12        52

avg / total       0.62      0.70      0.62       352

12/10/2017 02:23:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:38 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  1   2  23   1]
 [  2   0 238  10]
 [  0   0  48   4]]
12/10/2017 02:23:38 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 02:23:38 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:38 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:39 [INFO] exp_shallowmodel: train time: 1.138s
12/10/2017 02:23:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:39 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 02:23:39 [INFO] exp_shallowmodel: f1_score:   0.242
12/10/2017 02:23:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.17      0.04      0.06        27
          F       0.73      0.94      0.82       250
          R       0.19      0.06      0.09        52

avg / total       0.56      0.68      0.60       352

12/10/2017 02:23:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:39 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   1  21   5]
 [  3   5 235   7]
 [  4   0  45   3]]
12/10/2017 02:23:39 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 02:23:39 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:23:39 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:40 [INFO] exp_shallowmodel: train time: 1.196s
12/10/2017 02:23:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:40 [INFO] exp_shallowmodel: accuracy:   0.691
12/10/2017 02:23:40 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 02:23:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        25
          C       0.38      0.11      0.17        27
          F       0.73      0.95      0.82       251
          R       0.38      0.14      0.20        59

avg / total       0.61      0.69      0.62       362

12/10/2017 02:23:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:40 [INFO] exp_shallowmodel: 
[[  1   1  19   4]
 [  0   3  23   1]
 [  2   3 238   8]
 [  2   1  48   8]]
12/10/2017 02:23:40 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 02:23:40 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:40 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:41 [INFO] exp_shallowmodel: train time: 0.888s
12/10/2017 02:23:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:41 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:23:41 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 02:23:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        23
          C       0.25      0.04      0.06        27
          F       0.74      0.95      0.83       250
          R       0.39      0.13      0.20        52

avg / total       0.61      0.70      0.63       352

12/10/2017 02:23:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:41 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  1   1  23   2]
 [  3   2 238   7]
 [  3   1  41   7]]
12/10/2017 02:23:41 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 02:23:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:41 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:42 [INFO] exp_shallowmodel: train time: 0.781s
12/10/2017 02:23:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:42 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 02:23:42 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 02:23:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.33      0.07      0.12        27
          F       0.74      0.95      0.83       250
          R       0.38      0.15      0.22        52

avg / total       0.63      0.70      0.64       352

12/10/2017 02:23:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:42 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  1   2  23   1]
 [  0   3 237  10]
 [  1   0  43   8]]
12/10/2017 02:23:42 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 02:23:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:42 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:44 [INFO] exp_shallowmodel: train time: 1.536s
12/10/2017 02:23:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:44 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:23:44 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 02:23:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.40      0.07      0.12        27
          F       0.73      0.96      0.83       250
          R       0.29      0.10      0.14        52

avg / total       0.59      0.70      0.62       352

12/10/2017 02:23:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:44 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  1   2  21   3]
 [  2   2 239   7]
 [  1   1  45   5]]
12/10/2017 02:23:44 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 02:23:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:44 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:44 [INFO] exp_shallowmodel: train time: 0.792s
12/10/2017 02:23:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:44 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:23:44 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 02:23:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.25      0.11      0.15        27
          F       0.75      0.96      0.84       250
          R       0.50      0.12      0.19        52

avg / total       0.64      0.71      0.64       352

12/10/2017 02:23:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:44 [INFO] exp_shallowmodel: 
[[  2   1  18   2]
 [  0   3  22   2]
 [  3   5 240   2]
 [  1   3  42   6]]
12/10/2017 02:23:44 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 02:23:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:44 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:45 [INFO] exp_shallowmodel: train time: 0.719s
12/10/2017 02:23:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:45 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:23:45 [INFO] exp_shallowmodel: f1_score:   0.348
12/10/2017 02:23:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.09      0.14        23
          C       0.43      0.11      0.18        27
          F       0.75      0.97      0.85       250
          R       0.42      0.15      0.23        52

avg / total       0.66      0.72      0.66       352

12/10/2017 02:23:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:45 [INFO] exp_shallowmodel: 
[[  2   0  16   5]
 [  0   3  23   1]
 [  1   2 242   5]
 [  2   2  40   8]]
12/10/2017 02:23:45 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 02:23:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:45 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:46 [INFO] exp_shallowmodel: train time: 0.833s
12/10/2017 02:23:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:46 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:23:46 [INFO] exp_shallowmodel: f1_score:   0.248
12/10/2017 02:23:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.73      0.95      0.83       250
          R       0.16      0.06      0.08        52

avg / total       0.57      0.69      0.60       352

12/10/2017 02:23:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:46 [INFO] exp_shallowmodel: 
[[  1   2  18   2]
 [  0   0  24   3]
 [  1   0 238  11]
 [  0   3  46   3]]
12/10/2017 02:23:46 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 02:23:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:46 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:47 [INFO] exp_shallowmodel: train time: 1.110s
12/10/2017 02:23:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:47 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:23:47 [INFO] exp_shallowmodel: f1_score:   0.337
12/10/2017 02:23:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.09      0.15        23
          C       0.36      0.15      0.21        27
          F       0.74      0.93      0.82       250
          R       0.27      0.12      0.16        52

avg / total       0.64      0.70      0.63       352

12/10/2017 02:23:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:47 [INFO] exp_shallowmodel: 
[[  2   3  17   1]
 [  0   4  21   2]
 [  0   4 233  13]
 [  1   0  45   6]]
12/10/2017 02:23:47 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 02:23:47 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:47 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:48 [INFO] exp_shallowmodel: train time: 0.798s
12/10/2017 02:23:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:48 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:23:48 [INFO] exp_shallowmodel: f1_score:   0.296
12/10/2017 02:23:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.23      0.11      0.15        27
          F       0.74      0.92      0.82       250
          R       0.36      0.15      0.22        52

avg / total       0.59      0.69      0.63       352

12/10/2017 02:23:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:48 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  0   3  21   3]
 [  2   7 231  10]
 [  1   2  41   8]]
12/10/2017 02:23:48 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 02:23:48 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:48 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:49 [INFO] exp_shallowmodel: train time: 0.942s
12/10/2017 02:23:49 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:49 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:23:49 [INFO] exp_shallowmodel: f1_score:   0.305
12/10/2017 02:23:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.29      0.15      0.20        27
          F       0.75      0.94      0.83       250
          R       0.21      0.08      0.11        52

avg / total       0.61      0.70      0.63       352

12/10/2017 02:23:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:49 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   4  17   6]
 [  1   7 236   6]
 [  1   2  45   4]]
12/10/2017 02:23:49 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 02:23:49 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:23:49 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:50 [INFO] exp_shallowmodel: train time: 1.057s
12/10/2017 02:23:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:50 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 02:23:50 [INFO] exp_shallowmodel: f1_score:   0.269
12/10/2017 02:23:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.33      0.07      0.12        27
          F       0.72      0.93      0.81       251
          R       0.23      0.10      0.14        59

avg / total       0.56      0.67      0.60       362

12/10/2017 02:23:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:50 [INFO] exp_shallowmodel: 
[[  0   1  24   0]
 [  1   2  17   7]
 [  3   1 234  13]
 [  1   2  50   6]]
12/10/2017 02:23:50 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 02:23:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:50 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:51 [INFO] exp_shallowmodel: train time: 1.078s
12/10/2017 02:23:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:51 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:23:51 [INFO] exp_shallowmodel: f1_score:   0.373
12/10/2017 02:23:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.13      0.21        23
          C       0.50      0.19      0.27        27
          F       0.75      0.95      0.84       250
          R       0.33      0.12      0.17        52

avg / total       0.66      0.72      0.65       352

12/10/2017 02:23:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:51 [INFO] exp_shallowmodel: 
[[  3   0  19   1]
 [  0   5  19   3]
 [  1   3 238   8]
 [  1   2  43   6]]
12/10/2017 02:23:51 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 02:23:51 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:51 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:52 [INFO] exp_shallowmodel: train time: 0.877s
12/10/2017 02:23:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:52 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:23:52 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 02:23:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.07      0.12        27
          F       0.74      0.96      0.84       250
          R       0.56      0.19      0.29        52

avg / total       0.63      0.72      0.64       352

12/10/2017 02:23:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:52 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   2  23   2]
 [  1   3 241   5]
 [  0   1  41  10]]
12/10/2017 02:23:52 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 02:23:52 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:52 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:53 [INFO] exp_shallowmodel: train time: 0.937s
12/10/2017 02:23:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:53 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 02:23:53 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 02:23:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.60      0.11      0.19        27
          F       0.74      0.96      0.83       250
          R       0.26      0.10      0.14        52

avg / total       0.63      0.70      0.63       352

12/10/2017 02:23:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:53 [INFO] exp_shallowmodel: 
[[  1   0  17   5]
 [  0   3  23   1]
 [  2   1 239   8]
 [  0   1  46   5]]
12/10/2017 02:23:53 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 02:23:53 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:53 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:54 [INFO] exp_shallowmodel: train time: 0.935s
12/10/2017 02:23:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:54 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 02:23:54 [INFO] exp_shallowmodel: f1_score:   0.284
12/10/2017 02:23:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.40      0.15      0.22        27
          F       0.73      0.95      0.83       250
          R       0.25      0.06      0.09        52

avg / total       0.59      0.70      0.62       352

12/10/2017 02:23:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:54 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   4  20   3]
 [  3   5 238   4]
 [  2   1  46   3]]
12/10/2017 02:23:54 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 02:23:54 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:54 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:55 [INFO] exp_shallowmodel: train time: 0.954s
12/10/2017 02:23:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:55 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:23:55 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 02:23:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.09      0.14        23
          C       0.67      0.07      0.13        27
          F       0.73      0.95      0.83       250
          R       0.26      0.10      0.14        52

avg / total       0.64      0.70      0.63       352

12/10/2017 02:23:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:55 [INFO] exp_shallowmodel: 
[[  2   0  18   3]
 [  0   2  24   1]
 [  2   0 238  10]
 [  1   1  45   5]]
12/10/2017 02:23:55 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 02:23:55 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:55 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:56 [INFO] exp_shallowmodel: train time: 1.108s
12/10/2017 02:23:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:56 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:23:56 [INFO] exp_shallowmodel: f1_score:   0.340
12/10/2017 02:23:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.40      0.15      0.22        27
          F       0.76      0.95      0.85       250
          R       0.31      0.17      0.22        52

avg / total       0.64      0.71      0.66       352

12/10/2017 02:23:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:56 [INFO] exp_shallowmodel: 
[[  1   2  19   1]
 [  0   4  14   9]
 [  1   2 237  10]
 [  1   2  40   9]]
12/10/2017 02:23:56 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 02:23:56 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:56 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:58 [INFO] exp_shallowmodel: train time: 1.895s
12/10/2017 02:23:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:23:58 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 02:23:58 [INFO] exp_shallowmodel: f1_score:   0.269
12/10/2017 02:23:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.15      0.23        27
          F       0.73      0.94      0.82       250
          R       0.06      0.02      0.03        52

avg / total       0.56      0.68      0.60       352

12/10/2017 02:23:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:58 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  0   4  23   0]
 [  4   0 234  12]
 [  2   3  46   1]]
12/10/2017 02:23:58 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 02:23:58 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:23:58 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:23:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:00 [INFO] exp_shallowmodel: train time: 1.899s
12/10/2017 02:24:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:00 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:24:00 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 02:24:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.12      0.04      0.06        27
          F       0.74      0.96      0.84       250
          R       0.38      0.12      0.18        52

avg / total       0.62      0.71      0.63       352

12/10/2017 02:24:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:00 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   1  24   2]
 [  0   3 241   6]
 [  1   3  42   6]]
12/10/2017 02:24:00 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 02:24:00 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:24:00 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:01 [INFO] exp_shallowmodel: train time: 1.234s
12/10/2017 02:24:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:01 [INFO] exp_shallowmodel: accuracy:   0.685
12/10/2017 02:24:01 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 02:24:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.09      0.13        23
          C       0.33      0.15      0.21        27
          F       0.74      0.92      0.82       250
          R       0.25      0.12      0.16        52

avg / total       0.61      0.68      0.63       352

12/10/2017 02:24:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:01 [INFO] exp_shallowmodel: 
[[  2   4  16   1]
 [  1   4  20   2]
 [  3   3 229  15]
 [  1   1  44   6]]
12/10/2017 02:24:01 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 02:24:01 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:24:01 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:02 [INFO] exp_shallowmodel: train time: 0.838s
12/10/2017 02:24:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:02 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:24:02 [INFO] exp_shallowmodel: f1_score:   0.339
12/10/2017 02:24:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.07        25
          C       0.40      0.15      0.22        27
          F       0.72      0.96      0.83       251
          R       0.56      0.15      0.24        59

avg / total       0.66      0.71      0.63       362

12/10/2017 02:24:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:02 [INFO] exp_shallowmodel: 
[[  1   0  23   1]
 [  0   4  22   1]
 [  1   3 242   5]
 [  0   3  47   9]]
12/10/2017 02:24:08 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:24:08 [INFO] task_runner: context=last, feature=5-lda
12/10/2017 02:24:08 [INFO] task_runner: retained feature numbers=[8.1]
12/10/2017 02:24:08 [INFO] task_runner: #(data)=5241
12/10/2017 02:24:08 [INFO] task_runner: #(feature)=150
12/10/2017 02:24:08 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:24:08 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 02:24:08 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:08 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:09 [INFO] exp_shallowmodel: train time: 1.480s
12/10/2017 02:24:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:09 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:24:09 [INFO] exp_shallowmodel: f1_score:   0.268
12/10/2017 02:24:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.44      0.07      0.12        55

avg / total       0.67      0.75      0.68       522

12/10/2017 02:24:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:09 [INFO] exp_shallowmodel: 
[[  3   0  54   2]
 [  0   0  12   0]
 [  6   0 387   3]
 [  0   0  51   4]]
12/10/2017 02:24:09 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 02:24:09 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:09 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:11 [INFO] exp_shallowmodel: train time: 1.728s
12/10/2017 02:24:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:11 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:24:11 [INFO] exp_shallowmodel: f1_score:   0.253
12/10/2017 02:24:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.33      0.04      0.07        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:24:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:11 [INFO] exp_shallowmodel: 
[[  3   0  54   2]
 [  0   0  12   0]
 [  6   1 387   2]
 [  3   0  50   2]]
12/10/2017 02:24:11 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 02:24:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:11 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:13 [INFO] exp_shallowmodel: train time: 1.863s
12/10/2017 02:24:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:13 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:24:13 [INFO] exp_shallowmodel: f1_score:   0.255
12/10/2017 02:24:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.40      0.07      0.12        55

avg / total       0.65      0.76      0.68       522

12/10/2017 02:24:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:13 [INFO] exp_shallowmodel: 
[[  1   2  52   4]
 [  1   0  11   0]
 [  3   1 390   2]
 [  2   0  49   4]]
12/10/2017 02:24:13 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 02:24:13 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:13 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:14 [INFO] exp_shallowmodel: train time: 1.527s
12/10/2017 02:24:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:14 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:24:14 [INFO] exp_shallowmodel: f1_score:   0.247
12/10/2017 02:24:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.50      0.07      0.13        55

avg / total       0.63      0.75      0.67       522

12/10/2017 02:24:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:14 [INFO] exp_shallowmodel: 
[[  0   0  57   2]
 [  0   0  12   0]
 [  5   1 388   2]
 [  1   0  50   4]]
12/10/2017 02:24:14 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 02:24:14 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:14 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:16 [INFO] exp_shallowmodel: train time: 1.586s
12/10/2017 02:24:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:16 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:24:16 [INFO] exp_shallowmodel: f1_score:   0.245
12/10/2017 02:24:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.25      0.05      0.09        55

avg / total       0.63      0.75      0.67       522

12/10/2017 02:24:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:16 [INFO] exp_shallowmodel: 
[[  1   0  55   3]
 [  0   0  12   0]
 [  2   1 387   6]
 [  4   0  48   3]]
12/10/2017 02:24:16 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 02:24:16 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:16 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:17 [INFO] exp_shallowmodel: train time: 1.530s
12/10/2017 02:24:17 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:17 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 02:24:17 [INFO] exp_shallowmodel: f1_score:   0.220
12/10/2017 02:24:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.75      0.97      0.85       396
          R       0.00      0.00      0.00        55

avg / total       0.58      0.74      0.65       522

12/10/2017 02:24:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:17 [INFO] exp_shallowmodel: 
[[  1   0  58   0]
 [  0   0  12   0]
 [  8   1 384   3]
 [  0   0  55   0]]
12/10/2017 02:24:17 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 02:24:17 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:17 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:19 [INFO] exp_shallowmodel: train time: 1.939s
12/10/2017 02:24:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:19 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:24:19 [INFO] exp_shallowmodel: f1_score:   0.271
12/10/2017 02:24:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.62      0.09      0.16        55

avg / total       0.69      0.76      0.68       522

12/10/2017 02:24:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:19 [INFO] exp_shallowmodel: 
[[  2   0  56   1]
 [  0   0  11   1]
 [  4   2 389   1]
 [  0   1  49   5]]
12/10/2017 02:24:19 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 02:24:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:19 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:21 [INFO] exp_shallowmodel: train time: 1.324s
12/10/2017 02:24:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:21 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:24:21 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 02:24:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.03      0.06        59
          C       1.00      0.08      0.15        12
          F       0.77      0.97      0.86       396
          R       0.27      0.05      0.09        55

avg / total       0.66      0.75      0.67       522

12/10/2017 02:24:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:21 [INFO] exp_shallowmodel: 
[[  2   0  53   4]
 [  0   1  11   0]
 [  6   0 386   4]
 [  2   0  50   3]]
12/10/2017 02:24:21 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 02:24:21 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:21 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:22 [INFO] exp_shallowmodel: train time: 1.320s
12/10/2017 02:24:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:22 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:24:22 [INFO] exp_shallowmodel: f1_score:   0.272
12/10/2017 02:24:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.38      0.11      0.17        55

avg / total       0.66      0.75      0.68       522

12/10/2017 02:24:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:22 [INFO] exp_shallowmodel: 
[[  2   0  55   2]
 [  0   0  12   0]
 [  3   0 385   8]
 [  2   0  47   6]]
12/10/2017 02:24:22 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 02:24:22 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:24:22 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:24 [INFO] exp_shallowmodel: train time: 1.576s
12/10/2017 02:24:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:24 [INFO] exp_shallowmodel: accuracy:   0.737
12/10/2017 02:24:24 [INFO] exp_shallowmodel: f1_score:   0.248
12/10/2017 02:24:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.06      0.11        64
          C       0.00      0.00      0.00        14
          F       0.75      0.98      0.85       402
          R       0.14      0.02      0.03        63

avg / total       0.65      0.74      0.65       543

12/10/2017 02:24:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:24 [INFO] exp_shallowmodel: 
[[  4   0  57   3]
 [  0   0  14   0]
 [  2   2 395   3]
 [  0   0  62   1]]
12/10/2017 02:24:24 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 02:24:24 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:24 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:25 [INFO] exp_shallowmodel: train time: 1.523s
12/10/2017 02:24:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:25 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:24:25 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 02:24:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.45      0.09      0.15        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:24:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:25 [INFO] exp_shallowmodel: 
[[  3   0  53   3]
 [  0   0  12   0]
 [  6   0 387   3]
 [  1   0  49   5]]
12/10/2017 02:24:25 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 02:24:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:25 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:27 [INFO] exp_shallowmodel: train time: 1.338s
12/10/2017 02:24:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:27 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:24:27 [INFO] exp_shallowmodel: f1_score:   0.259
12/10/2017 02:24:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.33      0.07      0.12        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:24:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:27 [INFO] exp_shallowmodel: 
[[  2   0  55   2]
 [  0   0  12   0]
 [  5   1 384   6]
 [  1   0  50   4]]
12/10/2017 02:24:27 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 02:24:27 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:27 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:28 [INFO] exp_shallowmodel: train time: 1.106s
12/10/2017 02:24:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:28 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:24:28 [INFO] exp_shallowmodel: f1_score:   0.272
12/10/2017 02:24:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.56      0.09      0.16        55

avg / total       0.69      0.76      0.68       522

12/10/2017 02:24:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:28 [INFO] exp_shallowmodel: 
[[  2   0  55   2]
 [  1   0  11   0]
 [  2   0 392   2]
 [  0   0  50   5]]
12/10/2017 02:24:28 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 02:24:28 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:28 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:29 [INFO] exp_shallowmodel: train time: 1.380s
12/10/2017 02:24:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:29 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:24:29 [INFO] exp_shallowmodel: f1_score:   0.247
12/10/2017 02:24:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.50      0.05      0.10        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:24:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:29 [INFO] exp_shallowmodel: 
[[  1   0  57   1]
 [  0   0  12   0]
 [  5   0 389   2]
 [  1   1  50   3]]
12/10/2017 02:24:29 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 02:24:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:29 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:31 [INFO] exp_shallowmodel: train time: 1.850s
12/10/2017 02:24:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:31 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:24:31 [INFO] exp_shallowmodel: f1_score:   0.274
12/10/2017 02:24:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.40      0.11      0.17        55

avg / total       0.66      0.75      0.68       522

12/10/2017 02:24:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:31 [INFO] exp_shallowmodel: 
[[  2   0  52   5]
 [  0   0  12   0]
 [  5   1 386   4]
 [  0   0  49   6]]
12/10/2017 02:24:31 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 02:24:31 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:31 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:33 [INFO] exp_shallowmodel: train time: 1.840s
12/10/2017 02:24:33 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:33 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:24:33 [INFO] exp_shallowmodel: f1_score:   0.245
12/10/2017 02:24:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.29      0.04      0.06        55

avg / total       0.64      0.75      0.66       522

12/10/2017 02:24:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:33 [INFO] exp_shallowmodel: 
[[  2   1  54   2]
 [  0   0  12   0]
 [  6   1 386   3]
 [  0   1  52   2]]
12/10/2017 02:24:33 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 02:24:33 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:33 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:35 [INFO] exp_shallowmodel: train time: 1.887s
12/10/2017 02:24:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:35 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:24:35 [INFO] exp_shallowmodel: f1_score:   0.246
12/10/2017 02:24:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.44      0.07      0.12        55

avg / total       0.63      0.75      0.66       522

12/10/2017 02:24:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:35 [INFO] exp_shallowmodel: 
[[  0   1  56   2]
 [  0   0  12   0]
 [  6   1 386   3]
 [  1   0  50   4]]
12/10/2017 02:24:35 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 02:24:35 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:35 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:37 [INFO] exp_shallowmodel: train time: 1.699s
12/10/2017 02:24:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:37 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:24:37 [INFO] exp_shallowmodel: f1_score:   0.262
12/10/2017 02:24:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.76      0.98      0.86       396
          R       0.50      0.05      0.10        55

avg / total       0.68      0.75      0.67       522

12/10/2017 02:24:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:37 [INFO] exp_shallowmodel: 
[[  3   0  56   0]
 [  0   0  11   1]
 [  5   2 387   2]
 [  0   0  52   3]]
12/10/2017 02:24:37 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 02:24:37 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:37 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:38 [INFO] exp_shallowmodel: train time: 1.609s
12/10/2017 02:24:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:38 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 02:24:38 [INFO] exp_shallowmodel: f1_score:   0.242
12/10/2017 02:24:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.76      0.96      0.85       396
          R       0.08      0.02      0.03        55

avg / total       0.62      0.74      0.66       522

12/10/2017 02:24:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:38 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  0   0  11   1]
 [  5   1 381   9]
 [  2   0  52   1]]
12/10/2017 02:24:38 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 02:24:38 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:24:38 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:39 [INFO] exp_shallowmodel: train time: 1.272s
12/10/2017 02:24:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:39 [INFO] exp_shallowmodel: accuracy:   0.735
12/10/2017 02:24:39 [INFO] exp_shallowmodel: f1_score:   0.265
12/10/2017 02:24:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.03      0.05        64
          C       0.00      0.00      0.00        14
          F       0.76      0.97      0.85       402
          R       0.43      0.10      0.16        63

avg / total       0.63      0.73      0.65       543

12/10/2017 02:24:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:39 [INFO] exp_shallowmodel: 
[[  2   0  60   2]
 [  0   0  13   1]
 [  5   1 391   5]
 [  4   0  53   6]]
12/10/2017 02:24:39 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 02:24:39 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:39 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:42 [INFO] exp_shallowmodel: train time: 2.184s
12/10/2017 02:24:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:42 [INFO] exp_shallowmodel: accuracy:   0.743
12/10/2017 02:24:42 [INFO] exp_shallowmodel: f1_score:   0.250
12/10/2017 02:24:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.25      0.07      0.11        55

avg / total       0.63      0.74      0.67       522

12/10/2017 02:24:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:42 [INFO] exp_shallowmodel: 
[[  1   0  53   5]
 [  0   0  11   1]
 [  6   1 383   6]
 [  1   0  50   4]]
12/10/2017 02:24:42 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 02:24:42 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:42 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:44 [INFO] exp_shallowmodel: train time: 1.992s
12/10/2017 02:24:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:44 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 02:24:44 [INFO] exp_shallowmodel: f1_score:   0.243
12/10/2017 02:24:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.76      0.97      0.85       396
          R       0.10      0.02      0.03        55

avg / total       0.62      0.74      0.66       522

12/10/2017 02:24:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:44 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  0   0  11   1]
 [  6   0 383   7]
 [  1   0  53   1]]
12/10/2017 02:24:44 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 02:24:44 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:44 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:45 [INFO] exp_shallowmodel: train time: 1.727s
12/10/2017 02:24:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:45 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:24:45 [INFO] exp_shallowmodel: f1_score:   0.265
12/10/2017 02:24:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.03      0.05        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.38      0.09      0.15        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:24:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:45 [INFO] exp_shallowmodel: 
[[  2   0  53   4]
 [  0   0  12   0]
 [  9   0 383   4]
 [  3   0  47   5]]
12/10/2017 02:24:45 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 02:24:45 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:45 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:47 [INFO] exp_shallowmodel: train time: 1.419s
12/10/2017 02:24:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:47 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:24:47 [INFO] exp_shallowmodel: f1_score:   0.253
12/10/2017 02:24:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.36      0.07      0.12        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:24:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:47 [INFO] exp_shallowmodel: 
[[  1   0  56   2]
 [  0   0  11   1]
 [  6   0 386   4]
 [  2   1  48   4]]
12/10/2017 02:24:47 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 02:24:47 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:47 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:48 [INFO] exp_shallowmodel: train time: 1.627s
12/10/2017 02:24:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:48 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:24:48 [INFO] exp_shallowmodel: f1_score:   0.241
12/10/2017 02:24:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.50      0.04      0.07        55

avg / total       0.65      0.76      0.67       522

12/10/2017 02:24:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:48 [INFO] exp_shallowmodel: 
[[  1   1  55   2]
 [  0   0  12   0]
 [  3   1 392   0]
 [  2   0  51   2]]
12/10/2017 02:24:48 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 02:24:48 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:48 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:50 [INFO] exp_shallowmodel: train time: 1.692s
12/10/2017 02:24:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:50 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:24:50 [INFO] exp_shallowmodel: f1_score:   0.264
12/10/2017 02:24:50 [INFO] exp_shallowmodel: classification report:
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:24:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.50      0.07      0.13        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:24:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:50 [INFO] exp_shallowmodel: 
[[  2   0  56   1]
 [  0   0  11   1]
 [  2   0 392   2]
 [  3   0  48   4]]
12/10/2017 02:24:50 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 02:24:50 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:50 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:52 [INFO] exp_shallowmodel: train time: 1.640s
12/10/2017 02:24:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:52 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:24:52 [INFO] exp_shallowmodel: f1_score:   0.246
12/10/2017 02:24:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.76      0.98      0.86       396
          R       0.38      0.05      0.10        55

avg / total       0.63      0.75      0.66       522

12/10/2017 02:24:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:52 [INFO] exp_shallowmodel: 
[[  1   0  57   1]
 [  1   0  11   0]
 [  5   0 387   4]
 [  1   0  51   3]]
12/10/2017 02:24:52 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 02:24:52 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:52 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:53 [INFO] exp_shallowmodel: train time: 1.375s
12/10/2017 02:24:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:53 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:24:53 [INFO] exp_shallowmodel: f1_score:   0.282
12/10/2017 02:24:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.50      0.11      0.18        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:24:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:53 [INFO] exp_shallowmodel: 
[[  3   0  54   2]
 [  0   0  12   0]
 [  5   1 386   4]
 [  2   0  47   6]]
12/10/2017 02:24:53 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 02:24:53 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:53 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:55 [INFO] exp_shallowmodel: train time: 2.163s
12/10/2017 02:24:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:55 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:24:55 [INFO] exp_shallowmodel: f1_score:   0.254
12/10/2017 02:24:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.33      0.02      0.03        55

avg / total       0.67      0.76      0.67       522

12/10/2017 02:24:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:55 [INFO] exp_shallowmodel: 
[[  4   2  52   1]
 [  0   0  11   1]
 [  5   0 391   0]
 [  1   0  53   1]]
12/10/2017 02:24:55 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 02:24:55 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:24:55 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:57 [INFO] exp_shallowmodel: train time: 1.492s
12/10/2017 02:24:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:57 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 02:24:57 [INFO] exp_shallowmodel: f1_score:   0.279
12/10/2017 02:24:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.03      0.05        64
          C       0.00      0.00      0.00        14
          F       0.76      0.97      0.85       402
          R       0.62      0.13      0.21        63

avg / total       0.65      0.74      0.66       543

12/10/2017 02:24:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:57 [INFO] exp_shallowmodel: 
[[  2   1  60   1]
 [  0   0  13   1]
 [  7   1 391   3]
 [  3   1  51   8]]
12/10/2017 02:24:57 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 02:24:57 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:57 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:58 [INFO] exp_shallowmodel: train time: 1.478s
12/10/2017 02:24:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:24:58 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:24:58 [INFO] exp_shallowmodel: f1_score:   0.247
12/10/2017 02:24:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.29      0.04      0.06        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:24:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:58 [INFO] exp_shallowmodel: 
[[  2   0  55   2]
 [  0   0  12   0]
 [  3   1 389   3]
 [  2   0  51   2]]
12/10/2017 02:24:58 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 02:24:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:24:58 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:24:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:01 [INFO] exp_shallowmodel: train time: 2.134s
12/10/2017 02:25:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:01 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:25:01 [INFO] exp_shallowmodel: f1_score:   0.263
12/10/2017 02:25:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.87       396
          R       0.57      0.07      0.13        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:25:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:01 [INFO] exp_shallowmodel: 
[[  2   2  55   0]
 [  0   0  11   1]
 [  5   0 389   2]
 [  2   1  48   4]]
12/10/2017 02:25:01 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 02:25:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:01 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:03 [INFO] exp_shallowmodel: train time: 2.011s
12/10/2017 02:25:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:03 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:25:03 [INFO] exp_shallowmodel: f1_score:   0.266
12/10/2017 02:25:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.45      0.09      0.15        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:25:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:03 [INFO] exp_shallowmodel: 
[[  2   1  53   3]
 [  0   0  12   0]
 [  9   1 383   3]
 [  2   0  48   5]]
12/10/2017 02:25:03 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 02:25:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:03 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:05 [INFO] exp_shallowmodel: train time: 1.851s
12/10/2017 02:25:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:05 [INFO] exp_shallowmodel: accuracy:   0.745
12/10/2017 02:25:05 [INFO] exp_shallowmodel: f1_score:   0.265
12/10/2017 02:25:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.96      0.86       396
          R       0.29      0.07      0.12        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:25:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:05 [INFO] exp_shallowmodel: 
[[  3   0  53   3]
 [  0   0  12   0]
 [  6   1 382   7]
 [  2   0  49   4]]
12/10/2017 02:25:05 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 02:25:05 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:05 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:06 [INFO] exp_shallowmodel: train time: 1.543s
12/10/2017 02:25:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:06 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:25:06 [INFO] exp_shallowmodel: f1_score:   0.255
12/10/2017 02:25:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.62      0.09      0.16        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:25:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:06 [INFO] exp_shallowmodel: 
[[  0   0  57   2]
 [  0   0  11   1]
 [  6   2 388   0]
 [  1   0  49   5]]
12/10/2017 02:25:06 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 02:25:06 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:06 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:08 [INFO] exp_shallowmodel: train time: 1.989s
12/10/2017 02:25:08 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:08 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:25:08 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 02:25:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.03      0.06        59
          C       0.33      0.08      0.13        12
          F       0.77      0.97      0.86       396
          R       0.29      0.07      0.12        55

avg / total       0.66      0.75      0.68       522

12/10/2017 02:25:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:08 [INFO] exp_shallowmodel: 
[[  2   2  52   3]
 [  0   1  10   1]
 [  5   0 385   6]
 [  0   0  51   4]]
12/10/2017 02:25:08 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 02:25:08 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:08 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:10 [INFO] exp_shallowmodel: train time: 1.474s
12/10/2017 02:25:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:10 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:25:10 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 02:25:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.58      0.13      0.21        55

avg / total       0.70      0.76      0.69       522

12/10/2017 02:25:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:10 [INFO] exp_shallowmodel: 
[[  4   0  52   3]
 [  0   0  11   1]
 [  6   1 388   1]
 [  0   0  48   7]]
12/10/2017 02:25:10 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 02:25:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:10 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:11 [INFO] exp_shallowmodel: train time: 1.359s
12/10/2017 02:25:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:11 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:25:11 [INFO] exp_shallowmodel: f1_score:   0.271
12/10/2017 02:25:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.43      0.05      0.10        55

avg / total       0.69      0.76      0.68       522

12/10/2017 02:25:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:11 [INFO] exp_shallowmodel: 
[[  4   0  55   0]
 [  0   0  11   1]
 [  1   1 391   3]
 [  3   0  49   3]]
12/10/2017 02:25:11 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 02:25:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:11 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:13 [INFO] exp_shallowmodel: train time: 1.623s
12/10/2017 02:25:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:13 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:25:13 [INFO] exp_shallowmodel: f1_score:   0.256
12/10/2017 02:25:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.86       396
          R       0.50      0.05      0.10        55

avg / total       0.67      0.76      0.67       522

12/10/2017 02:25:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:13 [INFO] exp_shallowmodel: 
[[  2   0  55   2]
 [  0   0  12   0]
 [  4   0 391   1]
 [  1   0  51   3]]
12/10/2017 02:25:13 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 02:25:13 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:25:13 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:14 [INFO] exp_shallowmodel: train time: 1.421s
12/10/2017 02:25:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:14 [INFO] exp_shallowmodel: accuracy:   0.740
12/10/2017 02:25:14 [INFO] exp_shallowmodel: f1_score:   0.249
12/10/2017 02:25:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.03      0.06        64
          C       0.00      0.00      0.00        14
          F       0.75      0.99      0.85       402
          R       0.33      0.05      0.08        63

avg / total       0.63      0.74      0.65       543

12/10/2017 02:25:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:14 [INFO] exp_shallowmodel: 
[[  2   0  59   3]
 [  1   0  13   0]
 [  2   0 397   3]
 [  2   0  58   3]]
12/10/2017 02:25:14 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 02:25:14 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:14 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:16 [INFO] exp_shallowmodel: train time: 1.556s
12/10/2017 02:25:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:16 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 02:25:16 [INFO] exp_shallowmodel: f1_score:   0.284
12/10/2017 02:25:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.05      0.08        59
          C       0.50      0.08      0.14        12
          F       0.77      0.96      0.85       396
          R       0.17      0.04      0.06        55

avg / total       0.64      0.74      0.66       522

12/10/2017 02:25:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:16 [INFO] exp_shallowmodel: 
[[  3   0  53   3]
 [  0   1  11   0]
 [ 10   0 379   7]
 [  1   1  51   2]]
12/10/2017 02:25:16 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 02:25:16 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:16 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:17 [INFO] exp_shallowmodel: train time: 1.274s
12/10/2017 02:25:17 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:17 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:25:17 [INFO] exp_shallowmodel: f1_score:   0.287
12/10/2017 02:25:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.75      0.11      0.19        55

avg / total       0.70      0.77      0.69       522

12/10/2017 02:25:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:17 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  0   0  11   1]
 [  4   1 391   0]
 [  3   0  46   6]]
12/10/2017 02:25:17 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 02:25:17 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:17 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:19 [INFO] exp_shallowmodel: train time: 1.668s
12/10/2017 02:25:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:19 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:25:19 [INFO] exp_shallowmodel: f1_score:   0.260
12/10/2017 02:25:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.44      0.07      0.12        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:25:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:19 [INFO] exp_shallowmodel: 
[[  2   0  56   1]
 [  0   0  12   0]
 [  6   0 386   4]
 [  1   0  50   4]]
12/10/2017 02:25:19 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 02:25:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:19 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:20 [INFO] exp_shallowmodel: train time: 1.365s
12/10/2017 02:25:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:20 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:25:20 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 02:25:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.56      0.09      0.16        55

avg / total       0.69      0.76      0.69       522

12/10/2017 02:25:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:20 [INFO] exp_shallowmodel: 
[[  5   0  53   1]
 [  0   0  12   0]
 [  7   0 386   3]
 [  0   0  50   5]]
12/10/2017 02:25:20 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 02:25:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:20 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:22 [INFO] exp_shallowmodel: train time: 1.544s
12/10/2017 02:25:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:22 [INFO] exp_shallowmodel: accuracy:   0.743
12/10/2017 02:25:22 [INFO] exp_shallowmodel: f1_score:   0.258
12/10/2017 02:25:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.96      0.86       396
          R       0.42      0.09      0.15        55

avg / total       0.64      0.74      0.67       522

12/10/2017 02:25:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:22 [INFO] exp_shallowmodel: 
[[  1   0  56   2]
 [  0   0  12   0]
 [  8   1 382   5]
 [  4   0  46   5]]
12/10/2017 02:25:22 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 02:25:22 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:22 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:23 [INFO] exp_shallowmodel: train time: 1.784s
12/10/2017 02:25:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:23 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:25:23 [INFO] exp_shallowmodel: f1_score:   0.313
12/10/2017 02:25:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.08      0.14        59
          C       1.00      0.08      0.15        12
          F       0.78      0.98      0.87       396
          R       0.43      0.05      0.10        55

avg / total       0.70      0.76      0.69       522

12/10/2017 02:25:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:23 [INFO] exp_shallowmodel: 
[[  5   0  52   2]
 [  1   1   9   1]
 [  7   0 388   1]
 [  1   0  51   3]]
12/10/2017 02:25:23 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 02:25:23 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:23 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:25 [INFO] exp_shallowmodel: train time: 1.821s
12/10/2017 02:25:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:25 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 02:25:25 [INFO] exp_shallowmodel: f1_score:   0.244
12/10/2017 02:25:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.76      0.97      0.85       396
          R       0.33      0.05      0.09        55

avg / total       0.63      0.74      0.66       522

12/10/2017 02:25:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:25 [INFO] exp_shallowmodel: 
[[  1   0  57   1]
 [  0   0  12   0]
 [  7   1 383   5]
 [  0   0  52   3]]
12/10/2017 02:25:25 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 02:25:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:25 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:27 [INFO] exp_shallowmodel: train time: 1.809s
12/10/2017 02:25:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:27 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:25:27 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 02:25:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.38      0.05      0.10        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:25:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:27 [INFO] exp_shallowmodel: 
[[  5   0  52   2]
 [  0   0  12   0]
 [  5   0 388   3]
 [  2   0  50   3]]
12/10/2017 02:25:27 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 02:25:27 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:25:27 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:29 [INFO] exp_shallowmodel: train time: 1.876s
12/10/2017 02:25:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:29 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:25:29 [INFO] exp_shallowmodel: f1_score:   0.261
12/10/2017 02:25:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.56      0.09      0.16        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:25:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:29 [INFO] exp_shallowmodel: 
[[  1   0  57   1]
 [  0   0  11   1]
 [  8   0 386   2]
 [  1   0  49   5]]
12/10/2017 02:25:29 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 02:25:29 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:25:29 [INFO] exp_shallowmodel: #(feature) = 150
12/10/2017 02:25:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:31 [INFO] exp_shallowmodel: train time: 1.715s
12/10/2017 02:25:31 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:25:31 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 02:25:31 [INFO] exp_shallowmodel: f1_score:   0.266
12/10/2017 02:25:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.03      0.06        64
          C       0.00      0.00      0.00        14
          F       0.75      0.98      0.85       402
          R       0.46      0.10      0.16        63

avg / total       0.65      0.74      0.65       543

12/10/2017 02:25:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:31 [INFO] exp_shallowmodel: 
[[  2   0  62   0]
 [  0   0  13   1]
 [  3   0 393   6]
 [  1   0  56   6]]
Done: 20171210-022532
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
