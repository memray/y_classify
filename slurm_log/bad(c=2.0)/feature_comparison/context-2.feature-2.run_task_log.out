/ihome/pbrusilosky/rum20/.conda/envs/py36/bin/python -m dialogue.classify.task_runner -selected_feature_set_id 2 -selected_context_id 2
No. of param settings = 1
[('deep_model', False), ('selected_context_id', 2), ('selected_feature_set_id', 2), ('similarity_feature', False)]
12/10/2017 02:14:03 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:03 [INFO] configuration: selected_context_id  :   2
12/10/2017 02:14:03 [INFO] configuration: selected_feature_set_id  :   2
12/10/2017 02:14:03 [INFO] configuration: similarity_feature  :   False
12/10/2017 02:14:03 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:03 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:03 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:03 [INFO] configuration: timemark  :   20171210-021403
12/10/2017 02:14:03 [INFO] configuration: context_set  :   last
12/10/2017 02:14:03 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:03 [INFO] configuration: utterance_range  :   ['current_user_utterance', 'last_system_utterance', 'current_user_utterance']
12/10/2017 02:14:03 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:03 [INFO] configuration: feature_set  :   2-lexical
12/10/2017 02:14:03 [INFO] configuration: feature_set_number  :   ['4']
12/10/2017 02:14:03 [INFO] configuration: experiment_name  :   20171210-021403.context=last.feature=2-lexical.similarity=false
12/10/2017 02:14:03 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021403.context=last.feature=2-lexical.similarity=false
12/10/2017 02:14:03 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021403.context=last.feature=2-lexical.similarity=false/output.log
12/10/2017 02:14:03 [INFO] configuration: valid_type  :   {'R', 'C', 'A', 'F'}
12/10/2017 02:14:03 [INFO] configuration: data_name  :   
12/10/2017 02:14:03 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:03 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:03 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:03 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:03 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:03 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:03 [INFO] configuration: #division  :   5
12/10/2017 02:14:03 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:03 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:03 [INFO] configuration: action_words  :   {'moder', 'play', 'light', 'snooze', 'telephon', 'watch', 'part', 'turn', 'reminds', 'findcare', 'cheap', 'reminder', 'else', 'room', 'music', 'temperature', 'reminders', 'moderate', 'help', 'start', 'remov', 'phone', 'centre', 'temperatur', 'remove', 'address', 'delet', 'volume', 'timer', 'add', 'any', 'stop', 'delete', 'snooz', 'time', 'tell', 'list', 'area', 'show', 'alarm', 'south', 'north', 'food', 'weather', 'price', 'item', 'findcar', 'ani', 'song', 'number', 'expens', 'clear', 'centr', 'shuffle', 'expensive', 'cast', 'items', 'volum', 'video', 'next', 'discard', 'skip', 'shuffl', 'els', 'matter', 'share', 'telephone', 'post', 'member', 'remind'}
12/10/2017 02:14:03 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:03 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:03 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:03 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:03 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:03 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:03 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:03 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:03 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:03 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:03 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:03 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:03 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:03 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:03 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:03 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:03 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:03 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:03 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 3, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:03 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:06 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:06 [INFO] task_runner: context=last, feature=2-lexical
12/10/2017 02:14:06 [INFO] task_runner: retained feature numbers=[4.1]
12/10/2017 02:14:06 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:06 [INFO] task_runner: #(feature)=4980
12/10/2017 02:14:06 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:07 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:07 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:14:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:23 [INFO] exp_shallowmodel: train time: 136.221s
12/10/2017 02:16:23 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:16:23 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 02:16:23 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 02:16:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.60      0.60       164
          F       0.67      0.74      0.70       268
          R       0.48      0.39      0.43       125

avg / total       0.59      0.61      0.60       571

12/10/2017 02:16:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:23 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  5  99  39  21]
 [  1  40 198  29]
 [  1  25  50  49]]
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:16:24 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:24 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:32 [INFO] exp_shallowmodel: train time: 128.320s
12/10/2017 02:18:32 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 02:18:32 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 02:18:32 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 02:18:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.60      0.57       164
          F       0.66      0.69      0.68       268
          R       0.40      0.34      0.37       125

avg / total       0.56      0.57      0.56       571

12/10/2017 02:18:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:32 [INFO] exp_shallowmodel: 
[[  0   1   7   6]
 [  1  99  35  29]
 [  4  52 185  27]
 [  1  29  53  42]]
12/10/2017 02:18:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:18:33 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:33 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:18:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:20:17 [INFO] exp_shallowmodel: train time: 103.801s
12/10/2017 02:20:17 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 02:20:17 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 02:20:17 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 02:20:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:20:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.61      0.60       164
          F       0.68      0.71      0.69       268
          R       0.35      0.30      0.32       125

avg / total       0.56      0.57      0.57       571

12/10/2017 02:20:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:20:17 [INFO] exp_shallowmodel: 
[[  0   3   4   7]
 [  2 100  35  27]
 [  6  35 191  36]
 [  6  30  52  37]]
12/10/2017 02:20:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:20:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:20:18 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:20:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:20:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:20:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:20:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:20:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:22:12 [INFO] exp_shallowmodel: train time: 114.119s
12/10/2017 02:22:12 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:22:12 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:22:12 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 02:22:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:22:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.65      0.61       164
          F       0.67      0.71      0.69       268
          R       0.40      0.32      0.36       125

avg / total       0.57      0.59      0.58       571

12/10/2017 02:22:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:22:12 [INFO] exp_shallowmodel: 
[[  0   2   7   5]
 [  2 106  37  19]
 [  2  42 189  35]
 [  3  33  49  40]]
12/10/2017 02:22:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:22:13 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:22:13 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:22:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:22:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:22:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:22:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:22:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:24:15 [INFO] exp_shallowmodel: train time: 122.144s
12/10/2017 02:24:15 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 02:24:15 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 02:24:15 [INFO] exp_shallowmodel: f1_score:   0.418
12/10/2017 02:24:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:24:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.60      0.59       164
          F       0.66      0.69      0.68       268
          R       0.43      0.38      0.41       125

avg / total       0.57      0.58      0.58       571

12/10/2017 02:24:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:24:15 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  3  99  41  21]
 [  4  40 185  39]
 [  1  30  46  48]]
12/10/2017 02:24:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:24:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:24:16 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:24:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:24:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:24:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:24:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:24:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:35 [INFO] exp_shallowmodel: train time: 139.142s
12/10/2017 02:26:35 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:26:35 [INFO] exp_shallowmodel: accuracy:   0.529
12/10/2017 02:26:35 [INFO] exp_shallowmodel: f1_score:   0.367
12/10/2017 02:26:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.51      0.52       164
          F       0.63      0.68      0.65       268
          R       0.32      0.29      0.30       125

avg / total       0.51      0.53      0.52       571

12/10/2017 02:26:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:35 [INFO] exp_shallowmodel: 
[[  0   3   9   2]
 [  0  84  48  32]
 [  3  39 182  44]
 [  2  36  51  36]]
12/10/2017 02:26:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:26:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:26:36 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:26:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:45 [INFO] exp_shallowmodel: train time: 129.907s
12/10/2017 02:28:45 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 02:28:45 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:28:45 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 02:28:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.63      0.61       164
          F       0.71      0.76      0.73       268
          R       0.38      0.32      0.35       125

avg / total       0.59      0.61      0.60       571

12/10/2017 02:28:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:45 [INFO] exp_shallowmodel: 
[[  0   2   6   6]
 [  1 103  31  29]
 [  2  32 204  30]
 [  2  35  48  40]]
12/10/2017 02:28:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:28:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:28:46 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:28:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:31:07 [INFO] exp_shallowmodel: train time: 140.710s
12/10/2017 02:31:07 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:31:07 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:31:07 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 02:31:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:31:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.07      0.08        14
          C       0.54      0.62      0.58       164
          F       0.70      0.69      0.69       268
          R       0.33      0.29      0.31       125

avg / total       0.56      0.57      0.56       571

12/10/2017 02:31:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:31:07 [INFO] exp_shallowmodel: 
[[  1   3   7   3]
 [  1 102  31  30]
 [  4  40 184  40]
 [  4  43  42  36]]
12/10/2017 02:31:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:31:08 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:31:08 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:31:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:31:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:31:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:31:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:31:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:23 [INFO] exp_shallowmodel: train time: 134.715s
12/10/2017 02:33:23 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 02:33:23 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 02:33:23 [INFO] exp_shallowmodel: f1_score:   0.449
12/10/2017 02:33:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.59      0.63      0.61       164
          F       0.69      0.72      0.71       268
          R       0.41      0.35      0.38       125

avg / total       0.59      0.60      0.59       571

12/10/2017 02:33:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:23 [INFO] exp_shallowmodel: 
[[  1   2   3   8]
 [  2 104  34  24]
 [  2  40 194  32]
 [  1  31  49  44]]
12/10/2017 02:33:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:33:24 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:33:24 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:33:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:35:39 [INFO] exp_shallowmodel: train time: 135.144s
12/10/2017 02:35:39 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:35:39 [INFO] exp_shallowmodel: accuracy:   0.575
12/10/2017 02:35:39 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 02:35:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:35:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.54      0.54      0.54       169
          F       0.64      0.75      0.69       271
          R       0.42      0.33      0.37       130

avg / total       0.55      0.58      0.56       586

12/10/2017 02:35:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:35:39 [INFO] exp_shallowmodel: 
[[  0   2  10   4]
 [  0  91  51  27]
 [  0  39 203  29]
 [  1  35  51  43]]
12/10/2017 02:35:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:35:40 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:35:40 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:35:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:35:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:35:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:35:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:35:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:37:57 [INFO] exp_shallowmodel: train time: 137.022s
12/10/2017 02:37:57 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:37:57 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 02:37:57 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:37:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:37:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.59      0.57       164
          F       0.64      0.69      0.67       268
          R       0.39      0.32      0.35       125

avg / total       0.55      0.56      0.55       571

12/10/2017 02:37:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:37:57 [INFO] exp_shallowmodel: 
[[  0   2   7   5]
 [  1  96  46  21]
 [  3  43 185  37]
 [  2  34  49  40]]
12/10/2017 02:37:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:37:58 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:37:58 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:37:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:37:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:37:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:37:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:37:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:40:20 [INFO] exp_shallowmodel: train time: 142.773s
12/10/2017 02:40:20 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:40:20 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:40:20 [INFO] exp_shallowmodel: f1_score:   0.449
12/10/2017 02:40:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:40:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.07      0.08        14
          C       0.57      0.63      0.60       164
          F       0.71      0.70      0.71       268
          R       0.43      0.39      0.41       125

avg / total       0.60      0.60      0.60       571

12/10/2017 02:40:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:40:20 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  1 104  32  27]
 [  6  41 188  33]
 [  4  33  39  49]]
12/10/2017 02:40:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:40:21 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:40:21 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:40:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:40:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:40:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:40:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:40:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:42:47 [INFO] exp_shallowmodel: train time: 145.518s
12/10/2017 02:42:47 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 02:42:47 [INFO] exp_shallowmodel: accuracy:   0.560
12/10/2017 02:42:47 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 02:42:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:42:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.56      0.55       164
          F       0.65      0.69      0.67       268
          R       0.40      0.35      0.38       125

avg / total       0.55      0.56      0.55       571

12/10/2017 02:42:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:42:47 [INFO] exp_shallowmodel: 
[[  0   5   4   5]
 [  3  92  45  24]
 [  2  46 184  36]
 [  0  30  51  44]]
12/10/2017 02:42:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:42:48 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:42:48 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:42:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:42:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:42:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:42:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:42:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:44:52 [INFO] exp_shallowmodel: train time: 124.336s
12/10/2017 02:44:52 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:44:52 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 02:44:52 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 02:44:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:44:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.61      0.59       164
          F       0.70      0.74      0.72       268
          R       0.39      0.33      0.36       125

avg / total       0.57      0.59      0.58       571

12/10/2017 02:44:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:44:52 [INFO] exp_shallowmodel: 
[[  0   3   3   8]
 [  1 100  38  25]
 [  1  38 198  31]
 [  3  36  45  41]]
12/10/2017 02:44:53 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:44:53 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:44:53 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:44:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:44:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:44:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:44:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:44:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:46:42 [INFO] exp_shallowmodel: train time: 109.177s
12/10/2017 02:46:42 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:46:42 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 02:46:42 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 02:46:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:46:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.53      0.57      0.55       164
          F       0.68      0.72      0.70       268
          R       0.33      0.28      0.30       125

avg / total       0.55      0.56      0.55       571

12/10/2017 02:46:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:46:42 [INFO] exp_shallowmodel: 
[[  1   3   7   3]
 [  3  93  37  31]
 [  1  38 192  37]
 [  3  40  47  35]]
12/10/2017 02:46:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:46:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:46:43 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:46:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:46:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:46:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:46:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:46:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:48:51 [INFO] exp_shallowmodel: train time: 128.310s
12/10/2017 02:48:51 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:48:51 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 02:48:51 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 02:48:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:48:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.62      0.58       164
          F       0.68      0.69      0.68       268
          R       0.40      0.34      0.37       125

avg / total       0.56      0.57      0.57       571

12/10/2017 02:48:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:48:51 [INFO] exp_shallowmodel: 
[[  0   1   4   9]
 [  2 101  40  21]
 [  2  47 184  35]
 [  1  37  44  43]]
12/10/2017 02:48:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:48:52 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:48:52 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:48:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:48:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:48:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:48:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:48:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:50:59 [INFO] exp_shallowmodel: train time: 127.300s
12/10/2017 02:50:59 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:50:59 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:50:59 [INFO] exp_shallowmodel: f1_score:   0.421
12/10/2017 02:50:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:50:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.67      0.63       164
          F       0.70      0.75      0.73       268
          R       0.41      0.28      0.33       125

avg / total       0.59      0.61      0.59       571

12/10/2017 02:50:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:50:59 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  2 110  29  23]
 [  5  38 202  23]
 [  3  37  50  35]]
12/10/2017 02:51:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:51:00 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:51:00 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:51:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:51:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:51:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:51:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:51:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:53:04 [INFO] exp_shallowmodel: train time: 123.414s
12/10/2017 02:53:04 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:53:04 [INFO] exp_shallowmodel: accuracy:   0.595
12/10/2017 02:53:04 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 02:53:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:53:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.63      0.61       164
          F       0.69      0.71      0.70       268
          R       0.39      0.36      0.38       125

avg / total       0.58      0.60      0.59       571

12/10/2017 02:53:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:53:04 [INFO] exp_shallowmodel: 
[[  0   2   5   7]
 [  1 104  29  30]
 [  2  43 191  32]
 [  2  27  51  45]]
12/10/2017 02:53:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 02:53:05 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:53:05 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:53:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:53:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:53:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:53:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:53:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:54:58 [INFO] exp_shallowmodel: train time: 112.984s
12/10/2017 02:54:58 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 02:54:58 [INFO] exp_shallowmodel: accuracy:   0.595
12/10/2017 02:54:58 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 02:54:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:54:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.62      0.61       164
          F       0.70      0.74      0.72       268
          R       0.36      0.32      0.34       125

avg / total       0.58      0.60      0.59       571

12/10/2017 02:54:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:54:58 [INFO] exp_shallowmodel: 
[[  0   2   7   5]
 [  0 102  32  30]
 [  2  31 198  37]
 [  3  36  46  40]]
12/10/2017 02:54:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 02:54:58 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:54:58 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:54:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:54:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:54:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:54:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:54:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:57:01 [INFO] exp_shallowmodel: train time: 122.972s
12/10/2017 02:57:01 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:57:01 [INFO] exp_shallowmodel: accuracy:   0.565
12/10/2017 02:57:01 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:57:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:57:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.58      0.60      0.59       169
          F       0.64      0.70      0.67       271
          R       0.38      0.30      0.33       130

avg / total       0.55      0.56      0.55       586

12/10/2017 02:57:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:57:01 [INFO] exp_shallowmodel: 
[[  0   2   6   8]
 [  2 101  45  21]
 [  7  38 191  35]
 [  2  32  57  39]]
12/10/2017 02:57:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 02:57:02 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:57:02 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:57:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:57:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:57:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:57:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:57:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:59:18 [INFO] exp_shallowmodel: train time: 135.418s
12/10/2017 02:59:18 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 02:59:18 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:59:18 [INFO] exp_shallowmodel: f1_score:   0.413
12/10/2017 02:59:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:59:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.62      0.58       164
          F       0.69      0.71      0.70       268
          R       0.41      0.34      0.37       125

avg / total       0.57      0.59      0.58       571

12/10/2017 02:59:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:59:18 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  1 101  34  28]
 [  0  46 191  31]
 [  2  36  44  43]]
12/10/2017 02:59:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 02:59:19 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:59:19 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 02:59:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:59:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:59:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:59:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:59:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:01:27 [INFO] exp_shallowmodel: train time: 128.096s
12/10/2017 03:01:27 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:01:27 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 03:01:27 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 03:01:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:01:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.07      0.09        14
          C       0.52      0.54      0.53       164
          F       0.68      0.73      0.70       268
          R       0.39      0.32      0.35       125

avg / total       0.55      0.57      0.56       571

12/10/2017 03:01:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:01:27 [INFO] exp_shallowmodel: 
[[  1   5   5   3]
 [  2  88  47  27]
 [  3  36 196  33]
 [  3  41  41  40]]
12/10/2017 03:01:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 03:01:28 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:01:28 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:01:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:01:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:01:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:01:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:01:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:03:36 [INFO] exp_shallowmodel: train time: 128.008s
12/10/2017 03:03:36 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:03:36 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 03:03:36 [INFO] exp_shallowmodel: f1_score:   0.435
12/10/2017 03:03:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:03:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.59      0.64      0.61       164
          F       0.66      0.69      0.68       268
          R       0.39      0.33      0.36       125

avg / total       0.57      0.58      0.58       571

12/10/2017 03:03:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:03:36 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  1 105  35  23]
 [  1  45 186  36]
 [  5  25  54  41]]
12/10/2017 03:03:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 03:03:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:03:36 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:03:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:03:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:03:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:03:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:03:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:05:42 [INFO] exp_shallowmodel: train time: 125.816s
12/10/2017 03:05:42 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:05:42 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 03:05:42 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 03:05:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:05:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.57      0.64      0.60       164
          F       0.68      0.69      0.69       268
          R       0.37      0.33      0.35       125

avg / total       0.57      0.58      0.57       571

12/10/2017 03:05:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:05:42 [INFO] exp_shallowmodel: 
[[  1   4   6   3]
 [  2 105  31  26]
 [  4  40 184  40]
 [  1  35  48  41]]
12/10/2017 03:05:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 03:05:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:05:43 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:05:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:05:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:05:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:05:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:05:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:07:27 [INFO] exp_shallowmodel: train time: 104.346s
12/10/2017 03:07:27 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:07:27 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 03:07:27 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 03:07:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:07:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.68      0.64       164
          F       0.69      0.71      0.70       268
          R       0.37      0.30      0.33       125

avg / total       0.58      0.59      0.58       571

12/10/2017 03:07:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:07:27 [INFO] exp_shallowmodel: 
[[  0   2   4   8]
 [  1 111  28  24]
 [  6  39 189  34]
 [  1  33  53  38]]
12/10/2017 03:07:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 03:07:28 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:07:28 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:07:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:07:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:07:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:07:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:07:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:09:32 [INFO] exp_shallowmodel: train time: 124.041s
12/10/2017 03:09:32 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:09:32 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 03:09:32 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 03:09:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:09:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.65      0.62       164
          F       0.66      0.70      0.68       268
          R       0.41      0.33      0.36       125

avg / total       0.57      0.59      0.58       571

12/10/2017 03:09:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:09:32 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  2 106  39  17]
 [  5  38 188  37]
 [  3  31  50  41]]
12/10/2017 03:09:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 03:09:33 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:09:33 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:09:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:09:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:09:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:09:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:09:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:11:58 [INFO] exp_shallowmodel: train time: 145.046s
12/10/2017 03:11:58 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:11:58 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 03:11:58 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 03:11:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:11:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.53      0.58      0.55       164
          F       0.66      0.70      0.68       268
          R       0.36      0.29      0.32       125

avg / total       0.54      0.56      0.55       571

12/10/2017 03:11:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:11:58 [INFO] exp_shallowmodel: 
[[  1   1   5   7]
 [  4  95  41  24]
 [  1  46 187  34]
 [  1  37  51  36]]
12/10/2017 03:11:59 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 03:11:59 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:11:59 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:11:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:11:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:11:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:11:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:11:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:14:01 [INFO] exp_shallowmodel: train time: 121.972s
12/10/2017 03:14:01 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:14:01 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 03:14:01 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 03:14:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:14:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.59      0.58       164
          F       0.68      0.72      0.70       268
          R       0.40      0.33      0.36       125

avg / total       0.57      0.58      0.57       571

12/10/2017 03:14:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:14:01 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  2  97  40  25]
 [  9  34 192  33]
 [  3  37  44  41]]
12/10/2017 03:14:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 03:14:02 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:14:02 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:14:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:14:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:14:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:14:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:14:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:16:19 [INFO] exp_shallowmodel: train time: 137.008s
12/10/2017 03:16:19 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:16:19 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 03:16:19 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 03:16:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:16:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.53      0.52      0.53       164
          F       0.68      0.75      0.72       268
          R       0.40      0.34      0.37       125

avg / total       0.56      0.58      0.57       571

12/10/2017 03:16:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:16:19 [INFO] exp_shallowmodel: 
[[  1   1   7   5]
 [  0  86  49  29]
 [  0  36 201  31]
 [  5  40  37  43]]
12/10/2017 03:16:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 03:16:20 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:16:20 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:16:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:16:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:16:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:16:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:16:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:18:37 [INFO] exp_shallowmodel: train time: 137.036s
12/10/2017 03:18:37 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:18:37 [INFO] exp_shallowmodel: accuracy:   0.575
12/10/2017 03:18:37 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 03:18:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:18:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.59      0.60      0.59       169
          F       0.65      0.71      0.68       271
          R       0.40      0.34      0.37       130

avg / total       0.56      0.58      0.57       586

12/10/2017 03:18:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:18:37 [INFO] exp_shallowmodel: 
[[  0   1  10   5]
 [  2 101  40  26]
 [  5  38 192  36]
 [  1  31  54  44]]
12/10/2017 03:18:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 03:18:38 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:18:38 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:18:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:18:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:18:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:18:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:18:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:21:07 [INFO] exp_shallowmodel: train time: 149.360s
12/10/2017 03:21:07 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:21:07 [INFO] exp_shallowmodel: accuracy:   0.545
12/10/2017 03:21:07 [INFO] exp_shallowmodel: f1_score:   0.379
12/10/2017 03:21:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:21:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.60      0.57       164
          F       0.67      0.67      0.67       268
          R       0.28      0.26      0.27       125

avg / total       0.54      0.54      0.54       571

12/10/2017 03:21:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:21:07 [INFO] exp_shallowmodel: 
[[  0   0   5   9]
 [  3  99  34  28]
 [  4  40 180  44]
 [  3  42  48  32]]
12/10/2017 03:21:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 03:21:08 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:21:08 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:21:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:21:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:21:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:21:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:21:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:23:47 [INFO] exp_shallowmodel: train time: 158.668s
12/10/2017 03:23:47 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:23:47 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 03:23:47 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 03:23:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:23:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.63      0.59       164
          F       0.65      0.67      0.66       268
          R       0.38      0.33      0.35       125

avg / total       0.55      0.57      0.56       571

12/10/2017 03:23:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:23:47 [INFO] exp_shallowmodel: 
[[  0   2   5   7]
 [  0 103  37  24]
 [  1  52 179  36]
 [  1  28  55  41]]
12/10/2017 03:23:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 03:23:48 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:23:48 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:23:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:23:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:23:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:23:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:23:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:26:19 [INFO] exp_shallowmodel: train time: 151.439s
12/10/2017 03:26:19 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 03:26:19 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 03:26:19 [INFO] exp_shallowmodel: f1_score:   0.406
12/10/2017 03:26:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:26:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.54      0.54       164
          F       0.70      0.72      0.71       268
          R       0.38      0.37      0.37       125

avg / total       0.57      0.57      0.57       571

12/10/2017 03:26:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:26:19 [INFO] exp_shallowmodel: 
[[  0   1   4   9]
 [  2  89  38  35]
 [  2  42 193  31]
 [  4  33  42  46]]
12/10/2017 03:26:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 03:26:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:26:20 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:26:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:26:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:26:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:26:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:26:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:28:31 [INFO] exp_shallowmodel: train time: 130.611s
12/10/2017 03:28:31 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:28:31 [INFO] exp_shallowmodel: accuracy:   0.627
12/10/2017 03:28:31 [INFO] exp_shallowmodel: f1_score:   0.440
12/10/2017 03:28:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:28:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.64      0.63       164
          F       0.72      0.78      0.75       268
          R       0.43      0.35      0.39       125

avg / total       0.61      0.63      0.62       571

12/10/2017 03:28:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:28:31 [INFO] exp_shallowmodel: 
[[  0   3   3   8]
 [  0 105  35  24]
 [  3  29 209  27]
 [  3  33  45  44]]
12/10/2017 03:28:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 03:28:32 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:28:32 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:28:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:28:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:28:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:28:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:28:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:30:32 [INFO] exp_shallowmodel: train time: 120.578s
12/10/2017 03:30:32 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:30:32 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 03:30:32 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 03:30:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:30:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.53      0.57      0.55       164
          F       0.70      0.74      0.72       268
          R       0.39      0.34      0.36       125

avg / total       0.57      0.59      0.58       571

12/10/2017 03:30:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:30:32 [INFO] exp_shallowmodel: 
[[  1   3   6   4]
 [  0  93  43  28]
 [  2  34 199  33]
 [  2  44  37  42]]
12/10/2017 03:30:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 03:30:33 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:30:33 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:30:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:30:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:30:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:30:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:30:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:32:40 [INFO] exp_shallowmodel: train time: 127.261s
12/10/2017 03:32:40 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:32:40 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 03:32:40 [INFO] exp_shallowmodel: f1_score:   0.418
12/10/2017 03:32:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:32:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.62      0.61       164
          F       0.68      0.73      0.70       268
          R       0.40      0.34      0.37       125

avg / total       0.58      0.59      0.58       571

12/10/2017 03:32:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:32:40 [INFO] exp_shallowmodel: 
[[  0   0   8   6]
 [  2 102  42  18]
 [  2  33 195  38]
 [  2  38  43  42]]
12/10/2017 03:32:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 03:32:41 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:32:41 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:32:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:32:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:32:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:32:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:32:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:34:41 [INFO] exp_shallowmodel: train time: 120.135s
12/10/2017 03:34:41 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:34:41 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 03:34:41 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 03:34:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:34:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.65      0.61       164
          F       0.66      0.71      0.68       268
          R       0.38      0.29      0.33       125

avg / total       0.56      0.58      0.57       571

12/10/2017 03:34:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:34:41 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  1 106  36  21]
 [  4  42 189  33]
 [  2  31  56  36]]
12/10/2017 03:34:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 03:34:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:34:42 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:34:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:34:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:34:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:34:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:34:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:36:51 [INFO] exp_shallowmodel: train time: 129.246s
12/10/2017 03:36:51 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:36:51 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 03:36:51 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 03:36:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:36:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.62      0.59       164
          F       0.67      0.70      0.68       268
          R       0.37      0.30      0.33       125

avg / total       0.56      0.57      0.56       571

12/10/2017 03:36:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:36:51 [INFO] exp_shallowmodel: 
[[  0   1   9   4]
 [  0 102  37  25]
 [  2  44 187  35]
 [  5  36  46  38]]
12/10/2017 03:36:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 03:36:52 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:36:52 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:36:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:36:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:36:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:36:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:36:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:39:10 [INFO] exp_shallowmodel: train time: 137.922s
12/10/2017 03:39:10 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:39:10 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 03:39:10 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 03:39:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:39:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.59      0.56       164
          F       0.67      0.71      0.69       268
          R       0.39      0.30      0.34       125

avg / total       0.55      0.57      0.56       571

12/10/2017 03:39:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:39:10 [INFO] exp_shallowmodel: 
[[  0   5   5   4]
 [  1  97  40  26]
 [  6  44 191  27]
 [  1  36  51  37]]
12/10/2017 03:39:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 03:39:11 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:39:11 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:39:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:39:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:39:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:39:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:39:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:41:14 [INFO] exp_shallowmodel: train time: 123.316s
12/10/2017 03:41:14 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:41:14 [INFO] exp_shallowmodel: accuracy:   0.565
12/10/2017 03:41:14 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 03:41:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:41:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.56      0.57      0.56       169
          F       0.65      0.71      0.68       271
          R       0.38      0.32      0.35       130

avg / total       0.55      0.56      0.55       586

12/10/2017 03:41:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:41:14 [INFO] exp_shallowmodel: 
[[  0   2   8   6]
 [  1  96  47  25]
 [  3  38 193  37]
 [  3  35  50  42]]
12/10/2017 03:41:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 03:41:15 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:41:15 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:41:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:41:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:41:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:41:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:41:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:42:56 [INFO] exp_shallowmodel: train time: 101.035s
12/10/2017 03:42:56 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:42:56 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 03:42:56 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 03:42:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:42:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.60      0.57       164
          F       0.67      0.70      0.69       268
          R       0.38      0.33      0.35       125

avg / total       0.56      0.57      0.56       571

12/10/2017 03:42:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:42:56 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  3  98  36  27]
 [  2  43 188  35]
 [  2  32  50  41]]
12/10/2017 03:42:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 03:42:57 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:42:57 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:42:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:42:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:42:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:42:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:42:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:45:24 [INFO] exp_shallowmodel: train time: 146.943s
12/10/2017 03:45:24 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:45:24 [INFO] exp_shallowmodel: accuracy:   0.541
12/10/2017 03:45:24 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 03:45:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:45:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.57      0.56       164
          F       0.63      0.66      0.65       268
          R       0.33      0.31      0.32       125

avg / total       0.53      0.54      0.53       571

12/10/2017 03:45:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:45:24 [INFO] exp_shallowmodel: 
[[  0   2   6   6]
 [  1  93  48  22]
 [  2  39 177  50]
 [  2  35  49  39]]
12/10/2017 03:45:25 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 03:45:25 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:45:25 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:45:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:45:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:45:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:45:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:45:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:47:36 [INFO] exp_shallowmodel: train time: 130.777s
12/10/2017 03:47:36 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:47:36 [INFO] exp_shallowmodel: accuracy:   0.590
12/10/2017 03:47:36 [INFO] exp_shallowmodel: f1_score:   0.436
12/10/2017 03:47:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:47:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.54      0.57      0.56       164
          F       0.70      0.74      0.72       268
          R       0.41      0.35      0.38       125

avg / total       0.58      0.59      0.58       571

12/10/2017 03:47:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:47:36 [INFO] exp_shallowmodel: 
[[  1   4   4   5]
 [  3  93  38  30]
 [  2  38 199  29]
 [  2  36  43  44]]
12/10/2017 03:47:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 03:47:37 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:47:37 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:47:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:47:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:47:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:47:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:47:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:49:53 [INFO] exp_shallowmodel: train time: 136.479s
12/10/2017 03:49:53 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:49:53 [INFO] exp_shallowmodel: accuracy:   0.548
12/10/2017 03:49:53 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 03:49:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:49:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.60      0.56       164
          F       0.65      0.66      0.66       268
          R       0.36      0.30      0.33       125

avg / total       0.54      0.55      0.54       571

12/10/2017 03:49:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:49:53 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  1  98  45  20]
 [  3  44 177  44]
 [  3  42  42  38]]
12/10/2017 03:49:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 03:49:54 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:49:54 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:49:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:49:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:49:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:49:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:49:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:51:59 [INFO] exp_shallowmodel: train time: 124.768s
12/10/2017 03:51:59 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:51:59 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 03:51:59 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 03:51:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:51:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.64      0.62       164
          F       0.70      0.74      0.72       268
          R       0.43      0.37      0.40       125

avg / total       0.60      0.61      0.60       571

12/10/2017 03:51:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:51:59 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  2 105  32  25]
 [  2  35 199  32]
 [  1  33  45  46]]
12/10/2017 03:52:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 03:52:00 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:52:00 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:52:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:52:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:52:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:52:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:52:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:53:54 [INFO] exp_shallowmodel: train time: 114.475s
12/10/2017 03:53:54 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:53:54 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 03:53:54 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 03:53:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:53:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.60      0.57       164
          F       0.67      0.72      0.69       268
          R       0.33      0.25      0.28       125

avg / total       0.54      0.56      0.55       571

12/10/2017 03:53:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:53:54 [INFO] exp_shallowmodel: 
[[  0   4   3   7]
 [  1  98  38  27]
 [  7  40 192  29]
 [  3  37  54  31]]
12/10/2017 03:53:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 03:53:55 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:53:55 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:53:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:53:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:53:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:53:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:53:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:56:04 [INFO] exp_shallowmodel: train time: 128.677s
12/10/2017 03:56:04 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:56:04 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 03:56:04 [INFO] exp_shallowmodel: f1_score:   0.421
12/10/2017 03:56:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:56:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.55      0.59      0.57       164
          F       0.67      0.73      0.70       268
          R       0.36      0.29      0.32       125

avg / total       0.56      0.57      0.56       571

12/10/2017 03:56:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:56:04 [INFO] exp_shallowmodel: 
[[  1   1   6   6]
 [  0  96  40  28]
 [  1  43 195  29]
 [  4  34  51  36]]
12/10/2017 03:56:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 03:56:05 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:56:05 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:56:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:56:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:56:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:56:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:56:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:58:01 [INFO] exp_shallowmodel: train time: 116.589s
12/10/2017 03:58:01 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 03:58:01 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 03:58:01 [INFO] exp_shallowmodel: f1_score:   0.431
12/10/2017 03:58:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:58:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.65      0.61       164
          F       0.69      0.70      0.70       268
          R       0.45      0.39      0.42       125

avg / total       0.59      0.60      0.59       571

12/10/2017 03:58:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:58:01 [INFO] exp_shallowmodel: 
[[  0   2   6   6]
 [  2 106  33  23]
 [  3  46 188  31]
 [  1  29  46  49]]
12/10/2017 03:58:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 03:58:02 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:58:02 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 03:58:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:58:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:58:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:58:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:58:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:00:09 [INFO] exp_shallowmodel: train time: 127.214s
12/10/2017 04:00:09 [INFO] exp_shallowmodel: test time:  0.004s
12/10/2017 04:00:09 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 04:00:09 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 04:00:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:00:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.63      0.61       164
          F       0.69      0.72      0.71       268
          R       0.43      0.35      0.39       125

avg / total       0.59      0.60      0.59       571

12/10/2017 04:00:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:00:09 [INFO] exp_shallowmodel: 
[[  0   2   5   7]
 [  1 104  34  25]
 [  4  44 194  26]
 [  5  29  47  44]]
12/10/2017 04:00:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 04:00:10 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 04:00:10 [INFO] exp_shallowmodel: #(feature) = 4980
12/10/2017 04:00:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:00:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:00:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:00:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:00:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:02:21 [INFO] exp_shallowmodel: train time: 131.205s
12/10/2017 04:02:21 [INFO] exp_shallowmodel: test time:  0.005s
12/10/2017 04:02:21 [INFO] exp_shallowmodel: accuracy:   0.582
12/10/2017 04:02:21 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 04:02:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:02:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.57      0.59      0.58       169
          F       0.66      0.71      0.68       271
          R       0.43      0.38      0.40       130

avg / total       0.56      0.58      0.57       586

12/10/2017 04:02:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:02:21 [INFO] exp_shallowmodel: 
[[  0   1   7   8]
 [  1  99  45  24]
 [  1  43 192  35]
 [  1  30  49  50]]
12/10/2017 04:02:25 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 04:02:25 [INFO] task_runner: context=last, feature=2-lexical
12/10/2017 04:02:25 [INFO] task_runner: retained feature numbers=[4.1]
12/10/2017 04:02:25 [INFO] task_runner: #(data)=5934
12/10/2017 04:02:25 [INFO] task_runner: #(feature)=7303
12/10/2017 04:02:25 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 04:02:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 04:02:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:02:26 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:02:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:02:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:02:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:02:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:02:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:04:11 [INFO] exp_shallowmodel: train time: 104.493s
12/10/2017 04:04:11 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:04:11 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 04:04:11 [INFO] exp_shallowmodel: f1_score:   0.429
12/10/2017 04:04:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:04:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.10      0.14        20
          C       0.52      0.55      0.54       169
          F       0.68      0.73      0.70       281
          R       0.36      0.31      0.33       122

avg / total       0.55      0.57      0.56       592

12/10/2017 04:04:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:04:11 [INFO] exp_shallowmodel: 
[[  2   0  13   5]
 [  1  93  42  33]
 [  1  47 204  29]
 [  4  38  42  38]]
12/10/2017 04:04:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 04:04:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:04:12 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:04:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:04:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:04:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:04:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:04:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:05:31 [INFO] exp_shallowmodel: train time: 79.159s
12/10/2017 04:05:31 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:05:31 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 04:05:31 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 04:05:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:05:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.53      0.57      0.55       169
          F       0.71      0.73      0.72       281
          R       0.36      0.31      0.33       122

avg / total       0.56      0.58      0.57       592

12/10/2017 04:05:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:05:31 [INFO] exp_shallowmodel: 
[[  1   4   8   7]
 [  4  96  38  31]
 [  4  41 206  30]
 [  6  39  39  38]]
12/10/2017 04:05:32 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 04:05:32 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:05:32 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:05:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:05:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:05:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:05:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:05:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:07:23 [INFO] exp_shallowmodel: train time: 110.962s
12/10/2017 04:07:23 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:07:23 [INFO] exp_shallowmodel: accuracy:   0.552
12/10/2017 04:07:23 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 04:07:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:07:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.05      0.07        20
          C       0.49      0.52      0.50       169
          F       0.68      0.72      0.70       281
          R       0.33      0.30      0.31       122

avg / total       0.54      0.55      0.54       592

12/10/2017 04:07:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:07:23 [INFO] exp_shallowmodel: 
[[  1   5  10   4]
 [  1  88  39  41]
 [  3  49 202  27]
 [  3  38  45  36]]
12/10/2017 04:07:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 04:07:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:07:25 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:07:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:07:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:07:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:07:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:07:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:09:18 [INFO] exp_shallowmodel: train time: 113.741s
12/10/2017 04:09:18 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:09:18 [INFO] exp_shallowmodel: accuracy:   0.586
12/10/2017 04:09:18 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 04:09:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:09:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.05      0.07        20
          C       0.57      0.61      0.59       169
          F       0.68      0.71      0.69       281
          R       0.40      0.35      0.38       122

avg / total       0.57      0.59      0.58       592

12/10/2017 04:09:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:09:18 [INFO] exp_shallowmodel: 
[[  1   2  11   6]
 [  1 103  40  25]
 [  3  45 200  33]
 [  3  32  44  43]]
12/10/2017 04:09:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 04:09:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:09:20 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:09:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:09:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:09:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:09:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:09:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:11:20 [INFO] exp_shallowmodel: train time: 120.584s
12/10/2017 04:11:20 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:11:20 [INFO] exp_shallowmodel: accuracy:   0.532
12/10/2017 04:11:20 [INFO] exp_shallowmodel: f1_score:   0.366
12/10/2017 04:11:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:11:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.50      0.48       169
          F       0.67      0.69      0.68       281
          R       0.31      0.30      0.30       122

avg / total       0.51      0.53      0.52       592

12/10/2017 04:11:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:11:20 [INFO] exp_shallowmodel: 
[[  0   8   6   6]
 [  2  84  47  36]
 [  0  48 195  38]
 [  1  42  43  36]]
12/10/2017 04:11:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 04:11:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:11:21 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:11:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:11:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:11:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:11:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:11:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:12:58 [INFO] exp_shallowmodel: train time: 96.878s
12/10/2017 04:12:58 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:12:58 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 04:12:58 [INFO] exp_shallowmodel: f1_score:   0.390
12/10/2017 04:12:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:12:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.51      0.51       169
          F       0.66      0.71      0.68       281
          R       0.40      0.34      0.37       122

avg / total       0.54      0.55      0.55       592

12/10/2017 04:12:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:12:58 [INFO] exp_shallowmodel: 
[[  0   5   9   6]
 [  1  87  51  30]
 [  7  49 199  26]
 [  4  34  42  42]]
12/10/2017 04:13:00 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 04:13:00 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:13:00 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:13:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:13:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:13:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:13:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:13:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:14:43 [INFO] exp_shallowmodel: train time: 103.224s
12/10/2017 04:14:43 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:14:43 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 04:14:43 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 04:14:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:14:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.51      0.57      0.54       169
          F       0.71      0.71      0.71       281
          R       0.34      0.30      0.32       122

avg / total       0.55      0.56      0.56       592

12/10/2017 04:14:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:14:43 [INFO] exp_shallowmodel: 
[[  1   4  11   4]
 [  5  96  32  36]
 [  2  47 200  32]
 [  4  42  39  37]]
12/10/2017 04:14:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 04:14:44 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:14:44 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:14:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:14:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:14:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:14:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:14:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:16:25 [INFO] exp_shallowmodel: train time: 100.554s
12/10/2017 04:16:25 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:16:25 [INFO] exp_shallowmodel: accuracy:   0.542
12/10/2017 04:16:25 [INFO] exp_shallowmodel: f1_score:   0.375
12/10/2017 04:16:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:16:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.53      0.50       169
          F       0.68      0.70      0.69       281
          R       0.33      0.29      0.31       122

avg / total       0.53      0.54      0.53       592

12/10/2017 04:16:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:16:25 [INFO] exp_shallowmodel: 
[[  0   8   6   6]
 [  2  90  46  31]
 [  3  49 196  33]
 [  6  42  39  35]]
12/10/2017 04:16:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 04:16:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:16:26 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:16:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:16:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:16:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:16:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:16:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:18:01 [INFO] exp_shallowmodel: train time: 95.531s
12/10/2017 04:18:01 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:18:01 [INFO] exp_shallowmodel: accuracy:   0.525
12/10/2017 04:18:01 [INFO] exp_shallowmodel: f1_score:   0.368
12/10/2017 04:18:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:18:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.47      0.48      0.47       169
          F       0.67      0.68      0.67       281
          R       0.33      0.33      0.33       122

avg / total       0.52      0.53      0.52       592

12/10/2017 04:18:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:18:01 [INFO] exp_shallowmodel: 
[[  0   5  10   5]
 [  4  81  49  35]
 [  3  46 190  42]
 [  5  41  36  40]]
12/10/2017 04:18:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 04:18:03 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:18:03 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:18:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:18:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:18:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:18:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:18:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:19:42 [INFO] exp_shallowmodel: train time: 98.969s
12/10/2017 04:19:42 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:19:42 [INFO] exp_shallowmodel: accuracy:   0.540
12/10/2017 04:19:42 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 04:19:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:19:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.07      0.11        28
          C       0.46      0.50      0.48       172
          F       0.67      0.72      0.70       283
          R       0.32      0.28      0.30       123

avg / total       0.52      0.54      0.53       606

12/10/2017 04:19:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:19:42 [INFO] exp_shallowmodel: 
[[  2   9   7  10]
 [  1  86  46  39]
 [  3  50 204  26]
 [  2  40  46  35]]
12/10/2017 04:19:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 04:19:43 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:19:43 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:19:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:19:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:19:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:19:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:19:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:21:42 [INFO] exp_shallowmodel: train time: 119.131s
12/10/2017 04:21:42 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:21:42 [INFO] exp_shallowmodel: accuracy:   0.586
12/10/2017 04:21:42 [INFO] exp_shallowmodel: f1_score:   0.436
12/10/2017 04:21:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:21:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.10      0.12        20
          C       0.56      0.56      0.56       169
          F       0.71      0.75      0.73       281
          R       0.35      0.32      0.33       122

avg / total       0.57      0.59      0.58       592

12/10/2017 04:21:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:21:42 [INFO] exp_shallowmodel: 
[[  2   4   7   7]
 [  3  94  36  36]
 [  4  35 212  30]
 [  3  36  44  39]]
12/10/2017 04:21:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 04:21:43 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:21:43 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:21:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:21:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:21:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:21:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:21:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:23:51 [INFO] exp_shallowmodel: train time: 127.624s
12/10/2017 04:23:51 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:23:51 [INFO] exp_shallowmodel: accuracy:   0.514
12/10/2017 04:23:51 [INFO] exp_shallowmodel: f1_score:   0.355
12/10/2017 04:23:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:23:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.49      0.47       169
          F       0.65      0.67      0.66       281
          R       0.31      0.28      0.29       122

avg / total       0.50      0.51      0.51       592

12/10/2017 04:23:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:23:51 [INFO] exp_shallowmodel: 
[[  0   6  10   4]
 [  1  82  46  40]
 [  5  56 188  32]
 [  6  38  44  34]]
12/10/2017 04:23:52 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 04:23:52 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:23:52 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:23:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:23:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:23:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:23:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:23:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:25:45 [INFO] exp_shallowmodel: train time: 112.614s
12/10/2017 04:25:45 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:25:45 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 04:25:45 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 04:25:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:25:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.05      0.07        20
          C       0.49      0.56      0.52       169
          F       0.69      0.70      0.69       281
          R       0.32      0.29      0.30       122

avg / total       0.54      0.55      0.54       592

12/10/2017 04:25:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:25:45 [INFO] exp_shallowmodel: 
[[  1   7   8   4]
 [  2  94  40  33]
 [  2  46 196  37]
 [  3  44  40  35]]
12/10/2017 04:25:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 04:25:46 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:25:46 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:25:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:25:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:25:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:25:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:25:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:27:40 [INFO] exp_shallowmodel: train time: 114.201s
12/10/2017 04:27:40 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:27:40 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 04:27:40 [INFO] exp_shallowmodel: f1_score:   0.452
12/10/2017 04:27:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:27:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.53      0.60      0.56       169
          F       0.70      0.71      0.70       281
          R       0.42      0.37      0.39       122

avg / total       0.58      0.59      0.58       592

12/10/2017 04:27:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:27:40 [INFO] exp_shallowmodel: 
[[  2   4  11   3]
 [  0 101  36  32]
 [  2  51 200  28]
 [  3  34  40  45]]
12/10/2017 04:27:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 04:27:41 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:27:41 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:27:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:27:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:27:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:27:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:27:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:29:24 [INFO] exp_shallowmodel: train time: 102.291s
12/10/2017 04:29:24 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:29:24 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 04:29:24 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 04:29:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:29:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.56      0.55       169
          F       0.72      0.75      0.73       281
          R       0.36      0.31      0.33       122

avg / total       0.57      0.58      0.57       592

12/10/2017 04:29:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:29:24 [INFO] exp_shallowmodel: 
[[  0   4  11   5]
 [  4  95  36  34]
 [  3  40 210  28]
 [  8  40  36  38]]
12/10/2017 04:29:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 04:29:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:29:25 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:29:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:29:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:29:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:29:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:29:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:31:24 [INFO] exp_shallowmodel: train time: 118.900s
12/10/2017 04:31:24 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:31:24 [INFO] exp_shallowmodel: accuracy:   0.561
12/10/2017 04:31:24 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 04:31:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:31:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.51      0.49       169
          F       0.73      0.72      0.72       281
          R       0.35      0.37      0.36       122

avg / total       0.55      0.56      0.56       592

12/10/2017 04:31:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:31:24 [INFO] exp_shallowmodel: 
[[  0   6   3  11]
 [  4  86  35  44]
 [  3  50 201  27]
 [  1  39  37  45]]
12/10/2017 04:31:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 04:31:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:31:25 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:31:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:31:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:31:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:31:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:31:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:33:16 [INFO] exp_shallowmodel: train time: 111.131s
12/10/2017 04:33:16 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:33:16 [INFO] exp_shallowmodel: accuracy:   0.549
12/10/2017 04:33:16 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 04:33:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:33:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.05      0.08        20
          C       0.48      0.49      0.48       169
          F       0.68      0.74      0.71       281
          R       0.32      0.28      0.30       122

avg / total       0.53      0.55      0.54       592

12/10/2017 04:33:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:33:16 [INFO] exp_shallowmodel: 
[[  1   5   7   7]
 [  1  82  49  37]
 [  1  43 208  29]
 [  3  41  44  34]]
12/10/2017 04:33:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 04:33:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:33:17 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:33:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:33:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:33:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:33:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:33:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:35:16 [INFO] exp_shallowmodel: train time: 118.151s
12/10/2017 04:35:16 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:35:16 [INFO] exp_shallowmodel: accuracy:   0.568
12/10/2017 04:35:16 [INFO] exp_shallowmodel: f1_score:   0.443
12/10/2017 04:35:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:35:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.15      0.19        20
          C       0.52      0.56      0.54       169
          F       0.70      0.70      0.70       281
          R       0.34      0.33      0.33       122

avg / total       0.56      0.57      0.56       592

12/10/2017 04:35:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:35:16 [INFO] exp_shallowmodel: 
[[  3   4   7   6]
 [  2  95  34  38]
 [  5  45 198  33]
 [  1  38  43  40]]
12/10/2017 04:35:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 04:35:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:35:17 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:35:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:35:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:35:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:35:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:35:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:37:26 [INFO] exp_shallowmodel: train time: 128.807s
12/10/2017 04:37:26 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:37:26 [INFO] exp_shallowmodel: accuracy:   0.547
12/10/2017 04:37:26 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 04:37:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:37:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.56      0.52       169
          F       0.69      0.68      0.68       281
          R       0.34      0.33      0.34       122

avg / total       0.54      0.55      0.54       592

12/10/2017 04:37:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:37:26 [INFO] exp_shallowmodel: 
[[  0   6  10   4]
 [  3  94  39  33]
 [  1  51 190  39]
 [  4  40  38  40]]
12/10/2017 04:37:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 04:37:27 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:37:27 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:37:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:37:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:37:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:37:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:37:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:39:13 [INFO] exp_shallowmodel: train time: 106.003s
12/10/2017 04:39:13 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:39:13 [INFO] exp_shallowmodel: accuracy:   0.538
12/10/2017 04:39:13 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 04:39:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:39:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.07      0.11        28
          C       0.52      0.51      0.52       172
          F       0.64      0.70      0.67       283
          R       0.31      0.31      0.31       123

avg / total       0.52      0.54      0.53       606

12/10/2017 04:39:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:39:13 [INFO] exp_shallowmodel: 
[[  2   9  11   6]
 [  0  88  53  31]
 [  4  35 198  46]
 [  2  37  46  38]]
12/10/2017 04:39:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 04:39:14 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:39:14 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:39:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:39:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:39:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:39:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:39:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:41:17 [INFO] exp_shallowmodel: train time: 122.654s
12/10/2017 04:41:17 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:41:17 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 04:41:17 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 04:41:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:41:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        20
          C       0.49      0.54      0.52       169
          F       0.72      0.73      0.72       281
          R       0.34      0.28      0.31       122

avg / total       0.55      0.56      0.56       592

12/10/2017 04:41:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:41:17 [INFO] exp_shallowmodel: 
[[  2   7   7   4]
 [  4  92  42  31]
 [  2  43 206  30]
 [  9  46  33  34]]
12/10/2017 04:41:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 04:41:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:41:18 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:41:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:41:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:41:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:41:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:41:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:42:55 [INFO] exp_shallowmodel: train time: 97.109s
12/10/2017 04:42:55 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:42:55 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 04:42:55 [INFO] exp_shallowmodel: f1_score:   0.442
12/10/2017 04:42:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:42:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.10      0.13        20
          C       0.52      0.60      0.56       169
          F       0.68      0.71      0.70       281
          R       0.44      0.34      0.38       122

avg / total       0.57      0.58      0.57       592

12/10/2017 04:42:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:42:55 [INFO] exp_shallowmodel: 
[[  2   5  10   3]
 [  2 102  43  22]
 [  4  49 200  28]
 [  3  39  39  41]]
12/10/2017 04:42:56 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 04:42:56 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:42:56 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:42:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:42:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:42:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:42:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:42:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:44:50 [INFO] exp_shallowmodel: train time: 113.557s
12/10/2017 04:44:50 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:44:50 [INFO] exp_shallowmodel: accuracy:   0.541
12/10/2017 04:44:50 [INFO] exp_shallowmodel: f1_score:   0.372
12/10/2017 04:44:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:44:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.50      0.50       169
          F       0.68      0.71      0.69       281
          R       0.30      0.30      0.30       122

avg / total       0.52      0.54      0.53       592

12/10/2017 04:44:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:44:50 [INFO] exp_shallowmodel: 
[[  0   4  10   6]
 [  2  84  39  44]
 [  2  43 200  36]
 [  2  37  47  36]]
12/10/2017 04:44:51 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 04:44:51 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:44:51 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:44:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:44:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:44:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:44:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:44:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:46:40 [INFO] exp_shallowmodel: train time: 108.950s
12/10/2017 04:46:40 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:46:40 [INFO] exp_shallowmodel: accuracy:   0.568
12/10/2017 04:46:40 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 04:46:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:46:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.57      0.55       169
          F       0.66      0.71      0.68       281
          R       0.38      0.33      0.35       122

avg / total       0.55      0.57      0.56       592

12/10/2017 04:46:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:46:40 [INFO] exp_shallowmodel: 
[[  0   5  10   5]
 [  1  97  43  28]
 [  2  49 199  31]
 [  3  30  49  40]]
12/10/2017 04:46:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 04:46:41 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:46:41 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:46:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:46:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:46:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:46:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:46:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:48:25 [INFO] exp_shallowmodel: train time: 103.846s
12/10/2017 04:48:25 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:48:25 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 04:48:25 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 04:48:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:48:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.49      0.50       169
          F       0.68      0.72      0.70       281
          R       0.33      0.33      0.33       122

avg / total       0.54      0.55      0.54       592

12/10/2017 04:48:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:48:25 [INFO] exp_shallowmodel: 
[[  0   2   8  10]
 [  0  83  45  41]
 [  4  44 203  30]
 [  6  35  41  40]]
12/10/2017 04:48:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 04:48:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:48:27 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:48:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:48:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:48:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:48:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:48:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:50:11 [INFO] exp_shallowmodel: train time: 104.703s
12/10/2017 04:50:11 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:50:11 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 04:50:11 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 04:50:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:50:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.53      0.52       169
          F       0.68      0.72      0.70       281
          R       0.37      0.34      0.36       122

avg / total       0.55      0.56      0.55       592

12/10/2017 04:50:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:50:11 [INFO] exp_shallowmodel: 
[[  0   5   8   7]
 [  1  89  44  35]
 [  4  46 202  29]
 [  4  34  42  42]]
12/10/2017 04:50:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 04:50:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:50:12 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:50:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:50:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:50:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:50:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:50:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:52:09 [INFO] exp_shallowmodel: train time: 116.696s
12/10/2017 04:52:09 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:52:09 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 04:52:09 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 04:52:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:52:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.10      0.13        20
          C       0.56      0.60      0.58       169
          F       0.68      0.72      0.70       281
          R       0.31      0.26      0.28       122

avg / total       0.55      0.57      0.56       592

12/10/2017 04:52:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:52:09 [INFO] exp_shallowmodel: 
[[  2   4   8   6]
 [  1 102  39  27]
 [  2  40 201  38]
 [  6  37  47  32]]
12/10/2017 04:52:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 04:52:10 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:52:10 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:52:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:52:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:52:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:52:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:52:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:53:49 [INFO] exp_shallowmodel: train time: 98.149s
12/10/2017 04:53:49 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:53:49 [INFO] exp_shallowmodel: accuracy:   0.547
12/10/2017 04:53:49 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 04:53:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:53:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        20
          C       0.46      0.49      0.47       169
          F       0.70      0.69      0.70       281
          R       0.36      0.36      0.36       122

avg / total       0.54      0.55      0.54       592

12/10/2017 04:53:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:53:49 [INFO] exp_shallowmodel: 
[[  2   4   5   9]
 [  0  83  45  41]
 [  2  55 195  29]
 [  3  40  35  44]]
12/10/2017 04:53:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 04:53:50 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:53:50 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:53:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:53:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:53:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:53:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:53:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:55:27 [INFO] exp_shallowmodel: train time: 97.083s
12/10/2017 04:55:27 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 04:55:27 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 04:55:27 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 04:55:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:55:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.54      0.53       169
          F       0.69      0.70      0.70       281
          R       0.35      0.36      0.36       122

avg / total       0.55      0.56      0.56       592

12/10/2017 04:55:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:55:27 [INFO] exp_shallowmodel: 
[[  0   1  11   8]
 [  3  91  38  37]
 [  3  45 198  35]
 [  3  35  40  44]]
12/10/2017 04:55:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 04:55:28 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:55:28 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:55:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:55:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:55:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:55:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:55:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:57:01 [INFO] exp_shallowmodel: train time: 92.490s
12/10/2017 04:57:01 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:57:01 [INFO] exp_shallowmodel: accuracy:   0.545
12/10/2017 04:57:01 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 04:57:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:57:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.05        28
          C       0.47      0.49      0.48       172
          F       0.70      0.75      0.72       283
          R       0.31      0.28      0.29       123

avg / total       0.52      0.54      0.53       606

12/10/2017 04:57:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:57:01 [INFO] exp_shallowmodel: 
[[  1  10   7  10]
 [  3  84  48  37]
 [  3  39 211  30]
 [  6  46  37  34]]
12/10/2017 04:57:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 04:57:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:57:02 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:57:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:57:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:57:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:57:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:57:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:59:02 [INFO] exp_shallowmodel: train time: 119.713s
12/10/2017 04:59:02 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 04:59:02 [INFO] exp_shallowmodel: accuracy:   0.593
12/10/2017 04:59:02 [INFO] exp_shallowmodel: f1_score:   0.430
12/10/2017 04:59:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:59:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.05      0.06        20
          C       0.54      0.56      0.55       169
          F       0.69      0.76      0.72       281
          R       0.42      0.34      0.38       122

avg / total       0.57      0.59      0.58       592

12/10/2017 04:59:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:59:02 [INFO] exp_shallowmodel: 
[[  1   8   6   5]
 [  4  95  43  27]
 [  3  40 213  25]
 [  3  32  45  42]]
12/10/2017 04:59:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 04:59:03 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:59:03 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 04:59:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:59:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:59:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:59:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:59:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:01:03 [INFO] exp_shallowmodel: train time: 120.375s
12/10/2017 05:01:03 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:01:03 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 05:01:03 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 05:01:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:01:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.50      0.51      0.51       169
          F       0.70      0.72      0.71       281
          R       0.41      0.39      0.40       122

avg / total       0.56      0.57      0.56       592

12/10/2017 05:01:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:01:03 [INFO] exp_shallowmodel: 
[[  1   6   5   8]
 [  4  86  47  32]
 [  3  46 202  30]
 [  5  33  36  48]]
12/10/2017 05:01:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 05:01:04 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:01:04 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:01:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:01:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:01:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:01:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:01:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:02:38 [INFO] exp_shallowmodel: train time: 93.310s
12/10/2017 05:02:38 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:02:38 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 05:02:38 [INFO] exp_shallowmodel: f1_score:   0.406
12/10/2017 05:02:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:02:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.05        20
          C       0.53      0.54      0.54       169
          F       0.67      0.69      0.68       281
          R       0.36      0.34      0.35       122

avg / total       0.55      0.56      0.55       592

12/10/2017 05:02:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:02:38 [INFO] exp_shallowmodel: 
[[  1   6   8   5]
 [  4  92  43  30]
 [  6  43 195  37]
 [  6  31  44  41]]
12/10/2017 05:02:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 05:02:39 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:02:39 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:02:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:02:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:02:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:02:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:02:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:04:17 [INFO] exp_shallowmodel: train time: 97.824s
12/10/2017 05:04:17 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:04:17 [INFO] exp_shallowmodel: accuracy:   0.561
12/10/2017 05:04:17 [INFO] exp_shallowmodel: f1_score:   0.395
12/10/2017 05:04:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:04:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.53      0.52       169
          F       0.69      0.71      0.70       281
          R       0.36      0.35      0.36       122

avg / total       0.55      0.56      0.55       592

12/10/2017 05:04:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:04:17 [INFO] exp_shallowmodel: 
[[  0   6   8   6]
 [  2  90  39  38]
 [  4  46 199  32]
 [  3  33  43  43]]
12/10/2017 05:04:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 05:04:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:04:18 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:04:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:04:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:04:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:04:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:04:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:06:05 [INFO] exp_shallowmodel: train time: 107.015s
12/10/2017 05:06:05 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:06:05 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 05:06:05 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 05:06:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:06:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.54      0.54       169
          F       0.66      0.71      0.69       281
          R       0.32      0.30      0.31       122

avg / total       0.53      0.56      0.54       592

12/10/2017 05:06:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:06:05 [INFO] exp_shallowmodel: 
[[  0   3  14   3]
 [  0  92  39  38]
 [  0  42 200  39]
 [  2  35  48  37]]
12/10/2017 05:06:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 05:06:06 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:06:06 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:06:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:06:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:06:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:06:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:06:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:07:47 [INFO] exp_shallowmodel: train time: 100.870s
12/10/2017 05:07:47 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:07:47 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 05:07:47 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 05:07:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:07:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.53      0.56      0.55       169
          F       0.71      0.75      0.73       281
          R       0.35      0.30      0.33       122

avg / total       0.56      0.58      0.57       592

12/10/2017 05:07:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:07:47 [INFO] exp_shallowmodel: 
[[  1   4   8   7]
 [  0  95  36  38]
 [  7  40 211  23]
 [  1  40  44  37]]
12/10/2017 05:07:49 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 05:07:49 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:07:49 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:07:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:07:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:07:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:07:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:07:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:09:27 [INFO] exp_shallowmodel: train time: 98.381s
12/10/2017 05:09:27 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:09:27 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 05:09:27 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 05:09:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:09:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.52      0.56      0.54       169
          F       0.69      0.73      0.71       281
          R       0.40      0.34      0.37       122

avg / total       0.56      0.58      0.57       592

12/10/2017 05:09:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:09:27 [INFO] exp_shallowmodel: 
[[  1   6   7   6]
 [  1  94  47  27]
 [  3  44 205  29]
 [  4  36  40  42]]
12/10/2017 05:09:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 05:09:28 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:09:28 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:09:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:09:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:09:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:09:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:09:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:11:07 [INFO] exp_shallowmodel: train time: 99.342s
12/10/2017 05:11:07 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:11:07 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 05:11:07 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 05:11:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:11:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        20
          C       0.53      0.59      0.56       169
          F       0.69      0.70      0.69       281
          R       0.38      0.32      0.35       122

avg / total       0.56      0.57      0.56       592

12/10/2017 05:11:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:11:08 [INFO] exp_shallowmodel: 
[[  2   5   9   4]
 [  4  99  40  26]
 [  4  47 197  33]
 [  6  36  41  39]]
12/10/2017 05:11:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 05:11:09 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:11:09 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:11:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:11:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:11:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:11:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:11:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:12:45 [INFO] exp_shallowmodel: train time: 96.330s
12/10/2017 05:12:45 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:12:45 [INFO] exp_shallowmodel: accuracy:   0.532
12/10/2017 05:12:45 [INFO] exp_shallowmodel: f1_score:   0.359
12/10/2017 05:12:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:12:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.47      0.46      0.46       169
          F       0.68      0.73      0.70       281
          R       0.28      0.26      0.27       122

avg / total       0.51      0.53      0.52       592

12/10/2017 05:12:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:12:45 [INFO] exp_shallowmodel: 
[[  0   5   8   7]
 [  0  78  51  40]
 [  1  38 205  37]
 [  5  46  39  32]]
12/10/2017 05:12:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 05:12:46 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 05:12:46 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:12:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:12:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:12:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:12:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:12:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:14:22 [INFO] exp_shallowmodel: train time: 95.196s
12/10/2017 05:14:22 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:14:22 [INFO] exp_shallowmodel: accuracy:   0.550
12/10/2017 05:14:22 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 05:14:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:14:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.04      0.05        28
          C       0.51      0.52      0.52       172
          F       0.69      0.74      0.71       283
          R       0.28      0.27      0.28       123

avg / total       0.53      0.55      0.54       606

12/10/2017 05:14:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:14:22 [INFO] exp_shallowmodel: 
[[  1   4  13  10]
 [  3  89  41  39]
 [  2  36 210  35]
 [  4  44  42  33]]
12/10/2017 05:14:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 05:14:23 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:14:23 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:14:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:14:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:14:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:14:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:14:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:16:13 [INFO] exp_shallowmodel: train time: 110.613s
12/10/2017 05:16:13 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:16:13 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 05:16:13 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 05:16:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:16:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.51      0.53      0.52       169
          F       0.72      0.72      0.72       281
          R       0.35      0.34      0.35       122

avg / total       0.56      0.56      0.56       592

12/10/2017 05:16:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:16:13 [INFO] exp_shallowmodel: 
[[  1   5   7   7]
 [  3  90  37  39]
 [  3  44 201  33]
 [  8  36  36  42]]
12/10/2017 05:16:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 05:16:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:16:15 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:16:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:16:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:16:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:16:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:16:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:17:57 [INFO] exp_shallowmodel: train time: 102.397s
12/10/2017 05:17:57 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:17:57 [INFO] exp_shallowmodel: accuracy:   0.561
12/10/2017 05:17:57 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 05:17:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:17:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.10      0.13        20
          C       0.48      0.53      0.50       169
          F       0.72      0.69      0.71       281
          R       0.36      0.38      0.37       122

avg / total       0.56      0.56      0.56       592

12/10/2017 05:17:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:17:57 [INFO] exp_shallowmodel: 
[[  2   5   3  10]
 [  3  89  37  40]
 [  2  53 195  31]
 [  3  37  36  46]]
12/10/2017 05:17:58 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 05:17:58 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:17:58 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:17:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:17:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:17:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:17:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:17:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:19:30 [INFO] exp_shallowmodel: train time: 91.613s
12/10/2017 05:19:30 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:19:30 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 05:19:30 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 05:19:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:19:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.50      0.50      0.50       169
          F       0.68      0.74      0.71       281
          R       0.34      0.30      0.32       122

avg / total       0.54      0.56      0.55       592

12/10/2017 05:19:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:19:30 [INFO] exp_shallowmodel: 
[[  1   6   8   5]
 [  4  85  48  32]
 [  2  40 207  32]
 [  5  40  41  36]]
12/10/2017 05:19:31 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 05:19:31 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:19:31 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:19:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:19:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:19:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:19:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:19:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:21:15 [INFO] exp_shallowmodel: train time: 104.179s
12/10/2017 05:21:15 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:21:15 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 05:21:15 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 05:21:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:21:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.59      0.56       169
          F       0.69      0.71      0.70       281
          R       0.39      0.37      0.38       122

avg / total       0.56      0.58      0.57       592

12/10/2017 05:21:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:21:15 [INFO] exp_shallowmodel: 
[[  0   3  12   5]
 [  3  99  38  29]
 [  2  45 199  35]
 [  3  36  38  45]]
12/10/2017 05:21:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 05:21:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:21:17 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:21:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:21:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:21:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:21:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:21:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:23:03 [INFO] exp_shallowmodel: train time: 106.682s
12/10/2017 05:23:03 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:23:03 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 05:23:03 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 05:23:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:23:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.47      0.54      0.50       169
          F       0.71      0.70      0.70       281
          R       0.36      0.31      0.33       122

avg / total       0.54      0.55      0.55       592

12/10/2017 05:23:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:23:03 [INFO] exp_shallowmodel: 
[[  0   9   6   5]
 [  7  91  39  32]
 [  0  53 197  31]
 [  6  41  37  38]]
12/10/2017 05:23:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 05:23:05 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:23:05 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:23:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:23:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:23:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:23:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:23:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:24:44 [INFO] exp_shallowmodel: train time: 99.677s
12/10/2017 05:24:44 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:24:44 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 05:24:44 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 05:24:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:24:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.10      0.14        20
          C       0.48      0.53      0.51       169
          F       0.66      0.69      0.67       281
          R       0.36      0.31      0.33       122

avg / total       0.53      0.55      0.54       592

12/10/2017 05:24:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:24:44 [INFO] exp_shallowmodel: 
[[  2   3   9   6]
 [  2  90  45  32]
 [  1  57 193  30]
 [  3  37  44  38]]
12/10/2017 05:24:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 05:24:45 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:24:45 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:24:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:24:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:24:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:24:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:24:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:26:25 [INFO] exp_shallowmodel: train time: 99.816s
12/10/2017 05:26:25 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:26:25 [INFO] exp_shallowmodel: accuracy:   0.546
12/10/2017 05:26:25 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 05:26:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:26:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.53      0.54       169
          F       0.63      0.70      0.66       281
          R       0.35      0.30      0.33       122

avg / total       0.53      0.55      0.54       592

12/10/2017 05:26:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:26:25 [INFO] exp_shallowmodel: 
[[  0   2  11   7]
 [  2  90  51  26]
 [  7  43 196  35]
 [  3  31  51  37]]
12/10/2017 05:26:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 05:26:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:26:26 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:26:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:26:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:26:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:26:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:26:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:28:24 [INFO] exp_shallowmodel: train time: 117.362s
12/10/2017 05:28:24 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:28:24 [INFO] exp_shallowmodel: accuracy:   0.552
12/10/2017 05:28:24 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 05:28:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:28:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.10      0.14        20
          C       0.49      0.51      0.50       169
          F       0.69      0.72      0.70       281
          R       0.32      0.30      0.31       122

avg / total       0.54      0.55      0.55       592

12/10/2017 05:28:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:28:24 [INFO] exp_shallowmodel: 
[[  2   4   9   5]
 [  3  87  42  37]
 [  1  43 202  35]
 [  2  43  41  36]]
12/10/2017 05:28:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 05:28:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:28:25 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:28:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:28:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:28:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:28:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:28:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:30:25 [INFO] exp_shallowmodel: train time: 120.371s
12/10/2017 05:30:25 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 05:30:25 [INFO] exp_shallowmodel: accuracy:   0.561
12/10/2017 05:30:25 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 05:30:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:30:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.05      0.07        20
          C       0.52      0.55      0.53       169
          F       0.69      0.69      0.69       281
          R       0.35      0.35      0.35       122

avg / total       0.55      0.56      0.56       592

12/10/2017 05:30:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:30:25 [INFO] exp_shallowmodel: 
[[  1   7   5   7]
 [  0  93  45  31]
 [  6  39 195  41]
 [  3  40  36  43]]
12/10/2017 05:30:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 05:30:27 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 05:30:27 [INFO] exp_shallowmodel: #(feature) = 7303
12/10/2017 05:30:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:30:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:30:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:30:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:30:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:31:54 [INFO] exp_shallowmodel: train time: 87.023s
12/10/2017 05:31:54 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:31:54 [INFO] exp_shallowmodel: accuracy:   0.543
12/10/2017 05:31:54 [INFO] exp_shallowmodel: f1_score:   0.379
12/10/2017 05:31:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:31:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.49      0.51      0.50       172
          F       0.67      0.71      0.69       283
          R       0.33      0.33      0.33       123

avg / total       0.52      0.54      0.53       606

12/10/2017 05:31:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:31:54 [INFO] exp_shallowmodel: 
[[  0  10  11   7]
 [  1  87  40  44]
 [  2  49 202  30]
 [  3  33  47  40]]
12/10/2017 05:31:59 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 05:31:59 [INFO] task_runner: context=last, feature=2-lexical
12/10/2017 05:31:59 [INFO] task_runner: retained feature numbers=[4.1]
12/10/2017 05:31:59 [INFO] task_runner: #(data)=3530
12/10/2017 05:31:59 [INFO] task_runner: #(feature)=19310
12/10/2017 05:31:59 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 05:32:01 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 05:32:01 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:32:01 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:32:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:32:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:32:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:32:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:32:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:32:22 [INFO] exp_shallowmodel: train time: 21.224s
12/10/2017 05:32:22 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:32:22 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 05:32:22 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 05:32:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:32:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.25      0.11      0.15        27
          F       0.77      0.92      0.84       250
          R       0.41      0.27      0.33        52

avg / total       0.64      0.70      0.66       352

12/10/2017 05:32:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:32:22 [INFO] exp_shallowmodel: 
[[  2   1  17   3]
 [  2   3  18   4]
 [  4   4 229  13]
 [  2   4  32  14]]
12/10/2017 05:32:24 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 05:32:24 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:32:24 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:32:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:32:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:32:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:32:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:32:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:32:44 [INFO] exp_shallowmodel: train time: 20.533s
12/10/2017 05:32:44 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:32:44 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 05:32:44 [INFO] exp_shallowmodel: f1_score:   0.344
12/10/2017 05:32:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:32:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.09      0.12        23
          C       0.22      0.07      0.11        27
          F       0.77      0.92      0.84       250
          R       0.37      0.25      0.30        52

avg / total       0.64      0.70      0.66       352

12/10/2017 05:32:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:32:44 [INFO] exp_shallowmodel: 
[[  2   1  17   3]
 [  1   2  18   6]
 [  2   4 231  13]
 [  4   2  33  13]]
12/10/2017 05:32:46 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 05:32:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:32:46 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:32:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:32:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:32:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:32:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:32:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:33:06 [INFO] exp_shallowmodel: train time: 19.958s
12/10/2017 05:33:06 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:33:06 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 05:33:06 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 05:33:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:33:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.07        23
          C       0.75      0.22      0.34        27
          F       0.76      0.92      0.83       250
          R       0.35      0.25      0.29        52

avg / total       0.66      0.71      0.66       352

12/10/2017 05:33:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:33:06 [INFO] exp_shallowmodel: 
[[  1   0  18   4]
 [  0   6  18   3]
 [  3   1 229  17]
 [  2   1  36  13]]
12/10/2017 05:33:08 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 05:33:08 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:33:08 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:33:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:33:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:33:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:33:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:33:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:33:28 [INFO] exp_shallowmodel: train time: 20.216s
12/10/2017 05:33:28 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:33:28 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 05:33:28 [INFO] exp_shallowmodel: f1_score:   0.328
12/10/2017 05:33:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:33:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.20      0.11      0.14        27
          F       0.77      0.90      0.83       250
          R       0.41      0.29      0.34        52

avg / total       0.62      0.69      0.65       352

12/10/2017 05:33:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:33:28 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  0   3  18   6]
 [  3   9 226  12]
 [  3   3  31  15]]
12/10/2017 05:33:30 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 05:33:30 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:33:30 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:33:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:33:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:33:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:33:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:33:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:33:50 [INFO] exp_shallowmodel: train time: 19.755s
12/10/2017 05:33:50 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:33:50 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 05:33:50 [INFO] exp_shallowmodel: f1_score:   0.378
12/10/2017 05:33:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:33:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        23
          C       0.57      0.30      0.39        27
          F       0.76      0.90      0.83       250
          R       0.29      0.19      0.23        52

avg / total       0.64      0.69      0.65       352

12/10/2017 05:33:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:33:50 [INFO] exp_shallowmodel: 
[[  1   0  17   5]
 [  0   8  17   2]
 [  5   3 225  17]
 [  3   3  36  10]]
12/10/2017 05:33:52 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 05:33:52 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:33:52 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:33:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:33:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:33:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:33:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:33:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:34:13 [INFO] exp_shallowmodel: train time: 20.842s
12/10/2017 05:34:13 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:34:13 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 05:34:13 [INFO] exp_shallowmodel: f1_score:   0.304
12/10/2017 05:34:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:34:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.06        23
          C       0.25      0.11      0.15        27
          F       0.76      0.91      0.83       250
          R       0.24      0.13      0.17        52

avg / total       0.60      0.68      0.63       352

12/10/2017 05:34:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:34:13 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   3  15   9]
 [  7   5 228  10]
 [  4   3  38   7]]
12/10/2017 05:34:15 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 05:34:15 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:34:15 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:34:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:34:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:34:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:34:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:34:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:34:36 [INFO] exp_shallowmodel: train time: 20.836s
12/10/2017 05:34:36 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:34:36 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 05:34:36 [INFO] exp_shallowmodel: f1_score:   0.431
12/10/2017 05:34:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:34:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.09      0.11        23
          C       0.59      0.37      0.45        27
          F       0.78      0.90      0.84       250
          R       0.40      0.27      0.32        52

avg / total       0.67      0.71      0.68       352

12/10/2017 05:34:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:34:36 [INFO] exp_shallowmodel: 
[[  2   2  16   3]
 [  1  10  13   3]
 [  6   4 225  15]
 [  4   1  33  14]]
12/10/2017 05:34:37 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 05:34:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:34:37 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:34:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:34:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:34:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:34:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:34:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:35:00 [INFO] exp_shallowmodel: train time: 22.476s
12/10/2017 05:35:00 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:35:00 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 05:35:00 [INFO] exp_shallowmodel: f1_score:   0.334
12/10/2017 05:35:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:35:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.13      0.16        23
          C       0.25      0.11      0.15        27
          F       0.76      0.90      0.83       250
          R       0.26      0.15      0.19        52

avg / total       0.61      0.68      0.64       352

12/10/2017 05:35:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:35:00 [INFO] exp_shallowmodel: 
[[  3   2  13   5]
 [  0   3  17   7]
 [  9   5 225  11]
 [  2   2  40   8]]
12/10/2017 05:35:02 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 05:35:02 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:35:02 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:35:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:35:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:35:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:35:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:35:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:35:23 [INFO] exp_shallowmodel: train time: 21.543s
12/10/2017 05:35:23 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:35:23 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 05:35:23 [INFO] exp_shallowmodel: f1_score:   0.375
12/10/2017 05:35:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:35:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.06        23
          C       0.47      0.30      0.36        27
          F       0.77      0.89      0.82       250
          R       0.33      0.21      0.26        52

avg / total       0.63      0.69      0.65       352

12/10/2017 05:35:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:35:23 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  1   8  15   3]
 [  5   7 222  16]
 [  5   2  34  11]]
12/10/2017 05:35:25 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 05:35:25 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 05:35:25 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:35:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:35:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:35:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:35:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:35:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:35:46 [INFO] exp_shallowmodel: train time: 21.023s
12/10/2017 05:35:46 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:35:46 [INFO] exp_shallowmodel: accuracy:   0.691
12/10/2017 05:35:46 [INFO] exp_shallowmodel: f1_score:   0.367
12/10/2017 05:35:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:35:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.12      0.18        25
          C       0.42      0.19      0.26        27
          F       0.74      0.93      0.82       251
          R       0.32      0.15      0.21        59

avg / total       0.62      0.69      0.64       362

12/10/2017 05:35:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:35:46 [INFO] exp_shallowmodel: 
[[  3   1  16   5]
 [  1   5  19   2]
 [  4   2 233  12]
 [  0   4  46   9]]
12/10/2017 05:35:48 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 05:35:48 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:35:48 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:35:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:35:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:35:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:35:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:35:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:36:09 [INFO] exp_shallowmodel: train time: 20.190s
12/10/2017 05:36:09 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:36:09 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 05:36:09 [INFO] exp_shallowmodel: f1_score:   0.361
12/10/2017 05:36:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:36:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.23      0.11      0.15        27
          F       0.78      0.90      0.84       250
          R       0.37      0.31      0.34        52

avg / total       0.64      0.70      0.66       352

12/10/2017 05:36:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:36:09 [INFO] exp_shallowmodel: 
[[  2   0  17   4]
 [  0   3  17   7]
 [  4   6 224  16]
 [  4   4  28  16]]
12/10/2017 05:36:10 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 05:36:10 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:36:10 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:36:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:36:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:36:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:36:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:36:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:36:31 [INFO] exp_shallowmodel: train time: 20.412s
12/10/2017 05:36:31 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:36:31 [INFO] exp_shallowmodel: accuracy:   0.653
12/10/2017 05:36:31 [INFO] exp_shallowmodel: f1_score:   0.266
12/10/2017 05:36:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:36:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.15      0.07      0.10        27
          F       0.76      0.88      0.82       250
          R       0.17      0.13      0.15        52

avg / total       0.58      0.65      0.61       352

12/10/2017 05:36:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:36:31 [INFO] exp_shallowmodel: 
[[  0   1  18   4]
 [  1   2  13  11]
 [  2   7 221  20]
 [  3   3  39   7]]
12/10/2017 05:36:33 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 05:36:33 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:36:33 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:36:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:36:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:36:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:36:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:36:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:36:54 [INFO] exp_shallowmodel: train time: 20.959s
12/10/2017 05:36:54 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:36:54 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 05:36:54 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 05:36:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:36:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.13      0.15        23
          C       0.37      0.26      0.30        27
          F       0.78      0.87      0.83       250
          R       0.31      0.23      0.26        52

avg / total       0.64      0.68      0.66       352

12/10/2017 05:36:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:36:54 [INFO] exp_shallowmodel: 
[[  3   0  15   5]
 [  0   7  15   5]
 [  7   8 218  17]
 [  6   4  30  12]]
12/10/2017 05:36:56 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 05:36:56 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:36:56 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:36:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:36:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:36:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:36:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:36:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:37:16 [INFO] exp_shallowmodel: train time: 20.130s
12/10/2017 05:37:16 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:37:16 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 05:37:16 [INFO] exp_shallowmodel: f1_score:   0.342
12/10/2017 05:37:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:37:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.17      0.21        23
          C       0.22      0.07      0.11        27
          F       0.78      0.92      0.84       250
          R       0.26      0.17      0.21        52

avg / total       0.63      0.69      0.65       352

12/10/2017 05:37:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:37:16 [INFO] exp_shallowmodel: 
[[  4   1  12   6]
 [  1   2  17   7]
 [  6   3 229  12]
 [  5   3  35   9]]
12/10/2017 05:37:18 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 05:37:18 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:37:18 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:37:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:37:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:37:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:37:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:37:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:37:39 [INFO] exp_shallowmodel: train time: 20.938s
12/10/2017 05:37:39 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:37:39 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 05:37:39 [INFO] exp_shallowmodel: f1_score:   0.359
12/10/2017 05:37:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:37:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        23
          C       0.30      0.11      0.16        27
          F       0.76      0.90      0.83       250
          R       0.47      0.33      0.39        52

avg / total       0.64      0.70      0.66       352

12/10/2017 05:37:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:37:39 [INFO] exp_shallowmodel: 
[[  1   0  18   4]
 [  1   3  21   2]
 [  6   5 226  13]
 [  1   2  32  17]]
12/10/2017 05:37:41 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 05:37:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:37:41 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:37:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:37:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:37:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:37:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:37:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:38:02 [INFO] exp_shallowmodel: train time: 21.760s
12/10/2017 05:38:02 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:38:02 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 05:38:02 [INFO] exp_shallowmodel: f1_score:   0.346
12/10/2017 05:38:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:38:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.09      0.13        23
          C       0.30      0.11      0.16        27
          F       0.76      0.90      0.82       250
          R       0.32      0.23      0.27        52

avg / total       0.63      0.69      0.64       352

12/10/2017 05:38:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:38:02 [INFO] exp_shallowmodel: 
[[  2   0  16   5]
 [  1   3  20   3]
 [  4   4 225  17]
 [  1   3  36  12]]
12/10/2017 05:38:04 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 05:38:04 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:38:04 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:38:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:38:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:38:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:38:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:38:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:38:25 [INFO] exp_shallowmodel: train time: 20.910s
12/10/2017 05:38:25 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:38:25 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 05:38:25 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 05:38:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:38:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.56      0.37      0.44        27
          F       0.78      0.89      0.83       250
          R       0.38      0.29      0.33        52

avg / total       0.65      0.70      0.67       352

12/10/2017 05:38:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:38:25 [INFO] exp_shallowmodel: 
[[  0   2  15   6]
 [  1  10  13   3]
 [  5   6 223  16]
 [  1   0  36  15]]
12/10/2017 05:38:27 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 05:38:27 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:38:27 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:38:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:38:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:38:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:38:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:38:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:38:48 [INFO] exp_shallowmodel: train time: 20.643s
12/10/2017 05:38:48 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:38:48 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 05:38:48 [INFO] exp_shallowmodel: f1_score:   0.372
12/10/2017 05:38:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:38:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.09      0.11        23
          C       0.43      0.22      0.29        27
          F       0.76      0.89      0.82       250
          R       0.33      0.21      0.26        52

avg / total       0.63      0.69      0.65       352

12/10/2017 05:38:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:38:48 [INFO] exp_shallowmodel: 
[[  2   1  15   5]
 [  2   6  15   4]
 [  8   6 223  13]
 [  0   1  40  11]]
12/10/2017 05:38:50 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 05:38:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:38:50 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:38:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:38:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:38:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:38:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:38:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:39:10 [INFO] exp_shallowmodel: train time: 20.464s
12/10/2017 05:39:10 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:39:10 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 05:39:10 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 05:39:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:39:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.23      0.11      0.15        27
          F       0.77      0.92      0.84       250
          R       0.36      0.23      0.28        52

avg / total       0.63      0.70      0.65       352

12/10/2017 05:39:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:39:10 [INFO] exp_shallowmodel: 
[[  1   1  16   5]
 [  1   3  18   5]
 [  3   5 231  11]
 [  0   4  36  12]]
12/10/2017 05:39:12 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 05:39:12 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 05:39:12 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:39:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:39:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:39:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:39:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:39:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:39:32 [INFO] exp_shallowmodel: train time: 19.631s
12/10/2017 05:39:32 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:39:32 [INFO] exp_shallowmodel: accuracy:   0.666
12/10/2017 05:39:32 [INFO] exp_shallowmodel: f1_score:   0.328
12/10/2017 05:39:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:39:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.08      0.11        25
          C       0.25      0.15      0.19        27
          F       0.74      0.90      0.81       251
          R       0.30      0.15      0.20        59

avg / total       0.59      0.67      0.62       362

12/10/2017 05:39:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:39:32 [INFO] exp_shallowmodel: 
[[  2   0  18   5]
 [  0   4  18   5]
 [  7   7 226  11]
 [  2   5  43   9]]
12/10/2017 05:39:34 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 05:39:34 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:39:34 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:39:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:39:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:39:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:39:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:39:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:39:55 [INFO] exp_shallowmodel: train time: 21.392s
12/10/2017 05:39:55 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:39:55 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 05:39:55 [INFO] exp_shallowmodel: f1_score:   0.373
12/10/2017 05:39:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:39:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.04      0.06        23
          C       0.44      0.26      0.33        27
          F       0.77      0.91      0.83       250
          R       0.38      0.21      0.27        52

avg / total       0.64      0.70      0.66       352

12/10/2017 05:39:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:39:55 [INFO] exp_shallowmodel: 
[[  1   0  18   4]
 [  0   7  17   3]
 [  7   4 228  11]
 [  2   5  34  11]]
12/10/2017 05:39:57 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 05:39:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:39:57 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:39:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:39:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:39:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:39:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:39:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:40:18 [INFO] exp_shallowmodel: train time: 20.609s
12/10/2017 05:40:18 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:40:18 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 05:40:18 [INFO] exp_shallowmodel: f1_score:   0.364
12/10/2017 05:40:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:40:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.13      0.18        23
          C       0.27      0.15      0.19        27
          F       0.76      0.90      0.82       250
          R       0.35      0.21      0.27        52

avg / total       0.63      0.69      0.65       352

12/10/2017 05:40:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:40:18 [INFO] exp_shallowmodel: 
[[  3   1  18   1]
 [  0   4  20   3]
 [  5   5 224  16]
 [  2   5  34  11]]
12/10/2017 05:40:20 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 05:40:20 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:40:20 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:40:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:40:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:40:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:40:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:40:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:40:40 [INFO] exp_shallowmodel: train time: 20.868s
12/10/2017 05:40:40 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:40:40 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 05:40:40 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 05:40:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:40:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.31      0.15      0.20        27
          F       0.77      0.93      0.84       250
          R       0.38      0.23      0.29        52

avg / total       0.62      0.70      0.65       352

12/10/2017 05:40:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:40:40 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  1   4  13   9]
 [  3   6 232   9]
 [  1   3  36  12]]
12/10/2017 05:40:42 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 05:40:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:40:42 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:40:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:40:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:40:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:40:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:40:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:41:03 [INFO] exp_shallowmodel: train time: 20.584s
12/10/2017 05:41:03 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:41:03 [INFO] exp_shallowmodel: accuracy:   0.668
12/10/2017 05:41:03 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 05:41:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:41:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.11      0.15        27
          F       0.76      0.89      0.82       250
          R       0.23      0.17      0.20        52

avg / total       0.59      0.67      0.62       352

12/10/2017 05:41:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:41:03 [INFO] exp_shallowmodel: 
[[  0   0  17   6]
 [  1   3  15   8]
 [  3   7 223  17]
 [  3   2  38   9]]
12/10/2017 05:41:05 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 05:41:05 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:41:05 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:41:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:41:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:41:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:41:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:41:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:41:26 [INFO] exp_shallowmodel: train time: 20.843s
12/10/2017 05:41:26 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:41:26 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 05:41:26 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 05:41:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:41:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.13      0.17        23
          C       0.44      0.15      0.22        27
          F       0.79      0.93      0.86       250
          R       0.42      0.29      0.34        52

avg / total       0.67      0.72      0.69       352

12/10/2017 05:41:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:41:26 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  2   4  15   6]
 [  3   2 233  12]
 [  4   2  31  15]]
12/10/2017 05:41:28 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 05:41:28 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:41:28 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:41:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:41:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:41:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:41:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:41:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:41:49 [INFO] exp_shallowmodel: train time: 21.362s
12/10/2017 05:41:49 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:41:49 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 05:41:49 [INFO] exp_shallowmodel: f1_score:   0.296
12/10/2017 05:41:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:41:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.18      0.07      0.11        27
          F       0.75      0.91      0.82       250
          R       0.33      0.21      0.26        52

avg / total       0.60      0.68      0.63       352

12/10/2017 05:41:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:41:49 [INFO] exp_shallowmodel: 
[[  0   0  17   6]
 [  0   2  23   2]
 [  2   7 227  14]
 [  3   2  36  11]]
12/10/2017 05:41:51 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 05:41:51 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:41:51 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:41:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:41:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:41:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:41:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:41:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:42:11 [INFO] exp_shallowmodel: train time: 19.845s
12/10/2017 05:42:11 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:42:11 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 05:42:11 [INFO] exp_shallowmodel: f1_score:   0.371
12/10/2017 05:42:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:42:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.09      0.11        23
          C       0.38      0.19      0.25        27
          F       0.78      0.90      0.83       250
          R       0.36      0.25      0.30        52

avg / total       0.64      0.69      0.66       352

12/10/2017 05:42:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:42:11 [INFO] exp_shallowmodel: 
[[  2   1  16   4]
 [  1   5  18   3]
 [  6   4 224  16]
 [  5   3  31  13]]
12/10/2017 05:42:13 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 05:42:13 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:42:13 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:42:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:42:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:42:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:42:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:42:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:42:33 [INFO] exp_shallowmodel: train time: 20.764s
12/10/2017 05:42:33 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:42:33 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 05:42:33 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 05:42:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:42:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.04      0.06        23
          C       0.38      0.11      0.17        27
          F       0.76      0.92      0.83       250
          R       0.26      0.17      0.21        52

avg / total       0.62      0.69      0.64       352

12/10/2017 05:42:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:42:33 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   3  16   8]
 [  5   2 229  14]
 [  4   2  37   9]]
12/10/2017 05:42:35 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 05:42:35 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:42:35 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:42:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:42:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:42:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:42:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:42:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:42:57 [INFO] exp_shallowmodel: train time: 21.135s
12/10/2017 05:42:57 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:42:57 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 05:42:57 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 05:42:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:42:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.07        23
          C       0.25      0.11      0.15        27
          F       0.77      0.92      0.84       250
          R       0.32      0.21      0.26        52

avg / total       0.62      0.70      0.65       352

12/10/2017 05:42:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:42:57 [INFO] exp_shallowmodel: 
[[  1   1  16   5]
 [  0   3  18   6]
 [  3   4 231  12]
 [  2   4  35  11]]
12/10/2017 05:42:58 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 05:42:58 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 05:42:58 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:42:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:42:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:42:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:42:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:42:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:43:20 [INFO] exp_shallowmodel: train time: 21.113s
12/10/2017 05:43:20 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:43:20 [INFO] exp_shallowmodel: accuracy:   0.671
12/10/2017 05:43:20 [INFO] exp_shallowmodel: f1_score:   0.335
12/10/2017 05:43:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:43:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        25
          C       0.25      0.15      0.19        27
          F       0.74      0.90      0.81       251
          R       0.39      0.22      0.28        59

avg / total       0.60      0.67      0.63       362

12/10/2017 05:43:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:43:20 [INFO] exp_shallowmodel: 
[[  1   1  19   4]
 [  1   4  18   4]
 [  7   7 225  12]
 [  0   4  42  13]]
12/10/2017 05:43:22 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 05:43:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:43:22 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:43:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:43:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:43:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:43:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:43:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:43:43 [INFO] exp_shallowmodel: train time: 21.495s
12/10/2017 05:43:43 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:43:43 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 05:43:43 [INFO] exp_shallowmodel: f1_score:   0.356
12/10/2017 05:43:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:43:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.09      0.11        23
          C       0.21      0.11      0.15        27
          F       0.77      0.90      0.83       250
          R       0.47      0.27      0.34        52

avg / total       0.64      0.70      0.66       352

12/10/2017 05:43:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:43:43 [INFO] exp_shallowmodel: 
[[  2   1  19   1]
 [  2   3  19   3]
 [  5   7 226  12]
 [  6   3  29  14]]
12/10/2017 05:43:45 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 05:43:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:43:45 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:43:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:43:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:43:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:43:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:43:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:44:05 [INFO] exp_shallowmodel: train time: 20.339s
12/10/2017 05:44:05 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:44:05 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 05:44:05 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 05:44:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:44:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.13      0.19        23
          C       0.33      0.22      0.27        27
          F       0.77      0.89      0.83       250
          R       0.37      0.27      0.31        52

avg / total       0.65      0.70      0.67       352

12/10/2017 05:44:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:44:05 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  0   6  17   4]
 [  3   7 223  17]
 [  2   4  32  14]]
12/10/2017 05:44:07 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 05:44:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:44:07 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:44:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:44:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:44:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:44:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:44:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:44:28 [INFO] exp_shallowmodel: train time: 20.428s
12/10/2017 05:44:28 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:44:28 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 05:44:28 [INFO] exp_shallowmodel: f1_score:   0.310
12/10/2017 05:44:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:44:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.31      0.15      0.20        27
          F       0.77      0.90      0.83       250
          R       0.26      0.17      0.21        52

avg / total       0.61      0.68      0.64       352

12/10/2017 05:44:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:44:28 [INFO] exp_shallowmodel: 
[[  0   2  17   4]
 [  1   4  14   8]
 [  9   2 225  14]
 [  3   5  35   9]]
12/10/2017 05:44:30 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 05:44:30 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:44:30 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:44:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:44:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:44:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:44:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:44:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:44:50 [INFO] exp_shallowmodel: train time: 20.621s
12/10/2017 05:44:50 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:44:50 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 05:44:50 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 05:44:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:44:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        23
          C       0.58      0.26      0.36        27
          F       0.76      0.91      0.83       250
          R       0.44      0.27      0.33        52

avg / total       0.66      0.71      0.67       352

12/10/2017 05:44:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:44:50 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   7  19   1]
 [  3   4 228  15]
 [  4   0  34  14]]
12/10/2017 05:44:52 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 05:44:52 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:44:52 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:44:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:44:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:44:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:44:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:44:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:45:12 [INFO] exp_shallowmodel: train time: 19.608s
12/10/2017 05:45:12 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:45:12 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 05:45:12 [INFO] exp_shallowmodel: f1_score:   0.376
12/10/2017 05:45:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:45:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.09      0.12        23
          C       0.30      0.11      0.16        27
          F       0.80      0.94      0.86       250
          R       0.42      0.31      0.36        52

avg / total       0.67      0.73      0.69       352

12/10/2017 05:45:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:45:12 [INFO] exp_shallowmodel: 
[[  2   0  12   9]
 [  3   3  18   3]
 [  2   3 235  10]
 [  2   4  30  16]]
12/10/2017 05:45:14 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 05:45:14 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:45:14 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:45:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:45:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:45:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:45:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:45:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:45:34 [INFO] exp_shallowmodel: train time: 20.046s
12/10/2017 05:45:34 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:45:34 [INFO] exp_shallowmodel: accuracy:   0.653
12/10/2017 05:45:34 [INFO] exp_shallowmodel: f1_score:   0.280
12/10/2017 05:45:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:45:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.04      0.07        23
          C       0.08      0.04      0.05        27
          F       0.75      0.88      0.81       250
          R       0.22      0.17      0.19        52

avg / total       0.58      0.65      0.61       352

12/10/2017 05:45:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:45:34 [INFO] exp_shallowmodel: 
[[  1   0  17   5]
 [  1   1  16   9]
 [  4   9 219  18]
 [  1   2  40   9]]
12/10/2017 05:45:36 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 05:45:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:45:36 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:45:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:45:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:45:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:45:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:45:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:45:56 [INFO] exp_shallowmodel: train time: 20.751s
12/10/2017 05:45:56 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:45:56 [INFO] exp_shallowmodel: accuracy:   0.662
12/10/2017 05:45:56 [INFO] exp_shallowmodel: f1_score:   0.334
12/10/2017 05:45:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:45:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.22      0.26        23
          C       0.33      0.15      0.21        27
          F       0.76      0.89      0.82       250
          R       0.06      0.04      0.05        52

avg / total       0.60      0.66      0.62       352

12/10/2017 05:45:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:45:56 [INFO] exp_shallowmodel: 
[[  5   1  13   4]
 [  2   4  11  10]
 [  6   5 222  17]
 [  2   2  46   2]]
12/10/2017 05:45:58 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 05:45:58 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:45:58 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:45:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:45:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:45:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:45:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:45:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:46:19 [INFO] exp_shallowmodel: train time: 21.021s
12/10/2017 05:46:19 [INFO] exp_shallowmodel: test time:  0.009s
12/10/2017 05:46:19 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 05:46:19 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 05:46:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:46:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.07      0.11        27
          F       0.75      0.91      0.82       250
          R       0.41      0.29      0.34        52

avg / total       0.61      0.69      0.64       352

12/10/2017 05:46:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:46:19 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  0   2  21   4]
 [  3   5 227  15]
 [  3   0  34  15]]
12/10/2017 05:46:21 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 05:46:21 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:46:21 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:46:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:46:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:46:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:46:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:46:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:46:42 [INFO] exp_shallowmodel: train time: 20.707s
12/10/2017 05:46:42 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:46:42 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 05:46:42 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 05:46:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:46:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.42      0.30      0.35        27
          F       0.78      0.90      0.83       250
          R       0.42      0.27      0.33        52

avg / total       0.66      0.71      0.68       352

12/10/2017 05:46:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:46:42 [INFO] exp_shallowmodel: 
[[  2   1  18   2]
 [  2   8  14   3]
 [  4   7 225  14]
 [  2   3  33  14]]
12/10/2017 05:46:44 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 05:46:44 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 05:46:44 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:46:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:46:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:46:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:46:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:46:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:47:04 [INFO] exp_shallowmodel: train time: 20.481s
12/10/2017 05:47:04 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:47:04 [INFO] exp_shallowmodel: accuracy:   0.666
12/10/2017 05:47:04 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 05:47:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:47:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        25
          C       0.25      0.15      0.19        27
          F       0.73      0.89      0.80       251
          R       0.39      0.20      0.27        59

avg / total       0.60      0.67      0.62       362

12/10/2017 05:47:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:47:04 [INFO] exp_shallowmodel: 
[[  1   1  21   2]
 [  0   4  17   6]
 [  7   9 224  11]
 [  1   2  44  12]]
12/10/2017 05:47:06 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 05:47:06 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:47:06 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:47:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:47:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:47:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:47:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:47:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:47:26 [INFO] exp_shallowmodel: train time: 19.552s
12/10/2017 05:47:26 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:47:26 [INFO] exp_shallowmodel: accuracy:   0.690
12/10/2017 05:47:26 [INFO] exp_shallowmodel: f1_score:   0.349
12/10/2017 05:47:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:47:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        23
          C       0.40      0.22      0.29        27
          F       0.76      0.91      0.83       250
          R       0.29      0.17      0.22        52

avg / total       0.62      0.69      0.65       352

12/10/2017 05:47:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:47:26 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  1   6  16   4]
 [  3   6 227  14]
 [  3   2  38   9]]
12/10/2017 05:47:28 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 05:47:28 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:47:28 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:47:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:47:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:47:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:47:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:47:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:47:48 [INFO] exp_shallowmodel: train time: 20.261s
12/10/2017 05:47:48 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:47:48 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 05:47:48 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 05:47:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:47:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.21      0.11      0.15        27
          F       0.77      0.90      0.83       250
          R       0.39      0.29      0.33        52

avg / total       0.63      0.70      0.65       352

12/10/2017 05:47:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:47:48 [INFO] exp_shallowmodel: 
[[  1   3  14   5]
 [  0   3  21   3]
 [  4   5 226  15]
 [  0   3  34  15]]
12/10/2017 05:47:50 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 05:47:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:47:50 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:47:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:47:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:47:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:47:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:47:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:48:10 [INFO] exp_shallowmodel: train time: 20.235s
12/10/2017 05:48:10 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:48:10 [INFO] exp_shallowmodel: accuracy:   0.685
12/10/2017 05:48:10 [INFO] exp_shallowmodel: f1_score:   0.375
12/10/2017 05:48:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:48:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.17      0.22        23
          C       0.38      0.11      0.17        27
          F       0.77      0.88      0.82       250
          R       0.30      0.27      0.28        52

avg / total       0.64      0.68      0.65       352

12/10/2017 05:48:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:48:10 [INFO] exp_shallowmodel: 
[[  4   1  13   5]
 [  0   3  18   6]
 [  6   2 220  22]
 [  3   2  33  14]]
12/10/2017 05:48:12 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 05:48:12 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:48:12 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:48:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:48:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:48:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:48:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:48:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:48:31 [INFO] exp_shallowmodel: train time: 19.420s
12/10/2017 05:48:31 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:48:31 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 05:48:31 [INFO] exp_shallowmodel: f1_score:   0.376
12/10/2017 05:48:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:48:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.09      0.12        23
          C       0.27      0.15      0.19        27
          F       0.78      0.90      0.83       250
          R       0.42      0.31      0.36        52

avg / total       0.65      0.70      0.67       352

12/10/2017 05:48:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:48:31 [INFO] exp_shallowmodel: 
[[  2   2  17   2]
 [  1   4  14   8]
 [  6   7 225  12]
 [  1   2  33  16]]
12/10/2017 05:48:33 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 05:48:33 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:48:33 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:48:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:48:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:48:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:48:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:48:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:48:53 [INFO] exp_shallowmodel: train time: 19.666s
12/10/2017 05:48:53 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:48:53 [INFO] exp_shallowmodel: accuracy:   0.668
12/10/2017 05:48:53 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 05:48:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:48:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.30      0.11      0.16        27
          F       0.77      0.88      0.82       250
          R       0.27      0.23      0.25        52

avg / total       0.61      0.67      0.63       352

12/10/2017 05:48:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:48:53 [INFO] exp_shallowmodel: 
[[  0   0  17   6]
 [  0   3  15   9]
 [  8   5 220  17]
 [  5   2  33  12]]
12/10/2017 05:48:55 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 05:48:55 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:48:55 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:48:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:48:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:48:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:48:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:48:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:49:15 [INFO] exp_shallowmodel: train time: 20.295s
12/10/2017 05:49:15 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:49:15 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 05:49:15 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 05:49:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:49:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.17      0.22        23
          C       0.42      0.19      0.26        27
          F       0.79      0.92      0.85       250
          R       0.37      0.25      0.30        52

avg / total       0.66      0.71      0.68       352

12/10/2017 05:49:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:49:15 [INFO] exp_shallowmodel: 
[[  4   1  15   3]
 [  2   5  13   7]
 [  5   4 229  12]
 [  3   2  34  13]]
12/10/2017 05:49:17 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 05:49:17 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:49:17 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:49:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:49:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:49:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:49:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:49:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:49:37 [INFO] exp_shallowmodel: train time: 20.101s
12/10/2017 05:49:37 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:49:37 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 05:49:37 [INFO] exp_shallowmodel: f1_score:   0.361
12/10/2017 05:49:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:49:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.09      0.13        23
          C       0.50      0.19      0.27        27
          F       0.75      0.91      0.82       250
          R       0.29      0.17      0.22        52

avg / total       0.63      0.69      0.65       352

12/10/2017 05:49:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:49:37 [INFO] exp_shallowmodel: 
[[  2   0  16   5]
 [  0   5  21   1]
 [  3   3 228  16]
 [  2   2  39   9]]
12/10/2017 05:49:39 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 05:49:39 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:49:39 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:49:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:49:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:49:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:49:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:49:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:49:59 [INFO] exp_shallowmodel: train time: 20.136s
12/10/2017 05:49:59 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:49:59 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 05:49:59 [INFO] exp_shallowmodel: f1_score:   0.357
12/10/2017 05:49:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:49:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.13      0.18        23
          C       0.23      0.11      0.15        27
          F       0.77      0.93      0.84       250
          R       0.38      0.19      0.26        52

avg / total       0.64      0.71      0.66       352

12/10/2017 05:49:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:49:59 [INFO] exp_shallowmodel: 
[[  3   1  17   2]
 [  4   3  17   3]
 [  1   5 233  11]
 [  3   4  35  10]]
12/10/2017 05:50:01 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 05:50:01 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:50:01 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:50:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:50:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:50:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:50:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:50:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:50:21 [INFO] exp_shallowmodel: train time: 20.123s
12/10/2017 05:50:21 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:50:21 [INFO] exp_shallowmodel: accuracy:   0.665
12/10/2017 05:50:21 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 05:50:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:50:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.04      0.06        23
          C       0.18      0.07      0.11        27
          F       0.73      0.90      0.81       250
          R       0.26      0.13      0.18        52

avg / total       0.58      0.66      0.61       352

12/10/2017 05:50:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:50:21 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  1   2  22   2]
 [  5   6 224  15]
 [  2   2  41   7]]
12/10/2017 05:50:23 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 05:50:23 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 05:50:23 [INFO] exp_shallowmodel: #(feature) = 19310
12/10/2017 05:50:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:50:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:50:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:50:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:50:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:50:43 [INFO] exp_shallowmodel: train time: 19.780s
12/10/2017 05:50:43 [INFO] exp_shallowmodel: test time:  0.010s
12/10/2017 05:50:43 [INFO] exp_shallowmodel: accuracy:   0.671
12/10/2017 05:50:43 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 05:50:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:50:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.20      0.11      0.14        27
          F       0.73      0.91      0.81       251
          R       0.41      0.20      0.27        59

avg / total       0.59      0.67      0.62       362

12/10/2017 05:50:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:50:43 [INFO] exp_shallowmodel: 
[[  0   0  21   4]
 [  1   3  19   4]
 [  5   9 228   9]
 [  0   3  44  12]]
12/10/2017 05:50:48 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 05:50:48 [INFO] task_runner: context=last, feature=2-lexical
12/10/2017 05:50:48 [INFO] task_runner: retained feature numbers=[4.1]
12/10/2017 05:50:48 [INFO] task_runner: #(data)=5241
12/10/2017 05:50:48 [INFO] task_runner: #(feature)=9446
12/10/2017 05:50:48 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 05:50:50 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 05:50:50 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:50:50 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:50:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:50:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:50:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:50:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:50:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:51:28 [INFO] exp_shallowmodel: train time: 38.122s
12/10/2017 05:51:28 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:51:28 [INFO] exp_shallowmodel: accuracy:   0.734
12/10/2017 05:51:28 [INFO] exp_shallowmodel: f1_score:   0.334
12/10/2017 05:51:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:51:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.22      0.26        59
          C       0.00      0.00      0.00        12
          F       0.80      0.91      0.85       396
          R       0.38      0.16      0.23        55

avg / total       0.68      0.73      0.70       522

12/10/2017 05:51:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:51:28 [INFO] exp_shallowmodel: 
[[ 13   0  43   3]
 [  1   0   9   2]
 [ 23   2 361  10]
 [  5   0  41   9]]
12/10/2017 05:51:29 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 05:51:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:51:29 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:51:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:51:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:51:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:51:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:51:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:52:11 [INFO] exp_shallowmodel: train time: 41.475s
12/10/2017 05:52:11 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:52:11 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 05:52:11 [INFO] exp_shallowmodel: f1_score:   0.349
12/10/2017 05:52:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:52:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.22      0.26        59
          C       0.00      0.00      0.00        12
          F       0.82      0.93      0.87       396
          R       0.39      0.20      0.27        55

avg / total       0.70      0.75      0.72       522

12/10/2017 05:52:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:52:11 [INFO] exp_shallowmodel: 
[[ 13   1  41   4]
 [  2   0   7   3]
 [ 15   4 367  10]
 [ 12   1  31  11]]
12/10/2017 05:52:12 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 05:52:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:52:12 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:52:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:52:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:52:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:52:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:52:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:52:50 [INFO] exp_shallowmodel: train time: 37.699s
12/10/2017 05:52:50 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:52:50 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 05:52:50 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 05:52:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:52:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.17      0.21        59
          C       0.00      0.00      0.00        12
          F       0.82      0.90      0.86       396
          R       0.26      0.18      0.22        55

avg / total       0.68      0.72      0.70       522

12/10/2017 05:52:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:52:50 [INFO] exp_shallowmodel: 
[[ 10   3  35  11]
 [  2   0  10   0]
 [ 16   6 357  17]
 [ 10   0  35  10]]
12/10/2017 05:52:51 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 05:52:51 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:52:51 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:52:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:52:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:52:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:52:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:52:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:53:26 [INFO] exp_shallowmodel: train time: 35.304s
12/10/2017 05:53:26 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:53:26 [INFO] exp_shallowmodel: accuracy:   0.732
12/10/2017 05:53:26 [INFO] exp_shallowmodel: f1_score:   0.335
12/10/2017 05:53:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:53:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.19      0.23        59
          C       0.00      0.00      0.00        12
          F       0.82      0.91      0.86       396
          R       0.29      0.22      0.25        55

avg / total       0.69      0.73      0.71       522

12/10/2017 05:53:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:53:26 [INFO] exp_shallowmodel: 
[[ 11   2  36  10]
 [  1   0   9   2]
 [ 17   2 359  18]
 [  8   2  33  12]]
12/10/2017 05:53:28 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 05:53:28 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:53:28 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:53:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:53:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:53:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:53:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:53:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:54:00 [INFO] exp_shallowmodel: train time: 32.632s
12/10/2017 05:54:00 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:54:00 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 05:54:00 [INFO] exp_shallowmodel: f1_score:   0.364
12/10/2017 05:54:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:54:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.24      0.27        59
          C       0.20      0.17      0.18        12
          F       0.81      0.91      0.86       396
          R       0.23      0.11      0.15        55

avg / total       0.68      0.73      0.70       522

12/10/2017 05:54:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:54:00 [INFO] exp_shallowmodel: 
[[ 14   3  36   6]
 [  0   2   8   2]
 [ 21   4 359  12]
 [ 10   1  38   6]]
12/10/2017 05:54:02 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 05:54:02 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:54:02 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:54:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:54:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:54:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:54:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:54:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:54:42 [INFO] exp_shallowmodel: train time: 39.870s
12/10/2017 05:54:42 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:54:42 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 05:54:42 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 05:54:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:54:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.25      0.30        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.39      0.22      0.28        55

avg / total       0.70      0.75      0.72       522

12/10/2017 05:54:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:54:42 [INFO] exp_shallowmodel: 
[[ 15   1  42   1]
 [  3   0   8   1]
 [ 13   2 364  17]
 [ 11   1  31  12]]
12/10/2017 05:54:43 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 05:54:43 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:54:43 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:54:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:54:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:54:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:54:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:54:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:55:24 [INFO] exp_shallowmodel: train time: 40.786s
12/10/2017 05:55:24 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:55:24 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 05:55:24 [INFO] exp_shallowmodel: f1_score:   0.371
12/10/2017 05:55:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:55:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.24      0.30        59
          C       0.14      0.08      0.11        12
          F       0.83      0.93      0.88       396
          R       0.25      0.16      0.20        55

avg / total       0.71      0.75      0.72       522

12/10/2017 05:55:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:55:24 [INFO] exp_shallowmodel: 
[[ 14   1  31  13]
 [  0   1   8   3]
 [ 11   5 369  11]
 [  8   0  38   9]]
12/10/2017 05:55:25 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 05:55:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:55:25 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:55:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:55:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:55:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:55:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:55:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:56:00 [INFO] exp_shallowmodel: train time: 34.686s
12/10/2017 05:56:00 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:56:00 [INFO] exp_shallowmodel: accuracy:   0.736
12/10/2017 05:56:00 [INFO] exp_shallowmodel: f1_score:   0.361
12/10/2017 05:56:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:56:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.10      0.13        59
          C       0.40      0.17      0.24        12
          F       0.81      0.93      0.86       396
          R       0.32      0.16      0.22        55

avg / total       0.68      0.74      0.70       522

12/10/2017 05:56:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:56:00 [INFO] exp_shallowmodel: 
[[  6   2  44   7]
 [  1   2   8   1]
 [ 17   1 367  11]
 [ 11   0  35   9]]
12/10/2017 05:56:01 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 05:56:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:56:01 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:56:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:56:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:56:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:56:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:56:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:56:40 [INFO] exp_shallowmodel: train time: 39.186s
12/10/2017 05:56:40 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:56:40 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 05:56:40 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 05:56:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:56:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.15      0.17        59
          C       0.25      0.08      0.12        12
          F       0.81      0.91      0.86       396
          R       0.32      0.18      0.23        55

avg / total       0.68      0.73      0.70       522

12/10/2017 05:56:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:56:40 [INFO] exp_shallowmodel: 
[[  9   1  41   8]
 [  1   1   9   1]
 [ 23   2 359  12]
 [ 13   0  32  10]]
12/10/2017 05:56:42 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 05:56:42 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 05:56:42 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:56:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:56:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:56:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:56:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:56:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:57:16 [INFO] exp_shallowmodel: train time: 34.070s
12/10/2017 05:57:16 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:57:16 [INFO] exp_shallowmodel: accuracy:   0.737
12/10/2017 05:57:16 [INFO] exp_shallowmodel: f1_score:   0.340
12/10/2017 05:57:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:57:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.20      0.25        64
          C       0.00      0.00      0.00        14
          F       0.79      0.94      0.86       402
          R       0.42      0.17      0.25        63

avg / total       0.68      0.74      0.69       543

12/10/2017 05:57:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:57:16 [INFO] exp_shallowmodel: 
[[ 13   1  44   6]
 [  2   0  11   1]
 [ 16   2 376   8]
 [  7   3  42  11]]
12/10/2017 05:57:17 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 05:57:17 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:57:17 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:57:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:57:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:57:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:57:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:57:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:57:58 [INFO] exp_shallowmodel: train time: 40.826s
12/10/2017 05:57:58 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:57:58 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 05:57:58 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 05:57:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:57:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.15      0.18        59
          C       0.00      0.00      0.00        12
          F       0.81      0.90      0.85       396
          R       0.24      0.15      0.18        55

avg / total       0.66      0.71      0.68       522

12/10/2017 05:57:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:57:58 [INFO] exp_shallowmodel: 
[[  9   1  40   9]
 [  2   0   8   2]
 [ 23   4 355  14]
 [  9   2  36   8]]
12/10/2017 05:57:59 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 05:57:59 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:57:59 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:57:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:57:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:57:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:57:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:57:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:58:36 [INFO] exp_shallowmodel: train time: 36.219s
12/10/2017 05:58:36 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:58:36 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 05:58:36 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 05:58:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:58:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.22      0.30        59
          C       0.14      0.08      0.11        12
          F       0.81      0.93      0.87       396
          R       0.42      0.25      0.32        55

avg / total       0.72      0.76      0.73       522

12/10/2017 05:58:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:58:36 [INFO] exp_shallowmodel: 
[[ 13   1  40   5]
 [  0   1  10   1]
 [ 10   3 370  13]
 [  5   2  34  14]]
12/10/2017 05:58:37 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 05:58:37 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:58:37 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:58:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:58:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:58:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:58:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:58:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:59:18 [INFO] exp_shallowmodel: train time: 40.751s
12/10/2017 05:59:18 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:59:18 [INFO] exp_shallowmodel: accuracy:   0.745
12/10/2017 05:59:18 [INFO] exp_shallowmodel: f1_score:   0.342
12/10/2017 05:59:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:59:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.22      0.27        59
          C       0.00      0.00      0.00        12
          F       0.81      0.92      0.87       396
          R       0.31      0.18      0.23        55

avg / total       0.69      0.75      0.71       522

12/10/2017 05:59:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:59:18 [INFO] exp_shallowmodel: 
[[ 13   2  39   5]
 [  0   0  11   1]
 [ 12   2 366  16]
 [ 11   0  34  10]]
12/10/2017 05:59:19 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 05:59:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:59:19 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 05:59:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:59:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:59:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:59:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:59:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:59:59 [INFO] exp_shallowmodel: train time: 40.001s
12/10/2017 05:59:59 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 05:59:59 [INFO] exp_shallowmodel: accuracy:   0.718
12/10/2017 05:59:59 [INFO] exp_shallowmodel: f1_score:   0.326
12/10/2017 05:59:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:59:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.14      0.16        59
          C       0.25      0.08      0.12        12
          F       0.80      0.91      0.85       396
          R       0.25      0.13      0.17        55

avg / total       0.66      0.72      0.68       522

12/10/2017 05:59:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:59:59 [INFO] exp_shallowmodel: 
[[  8   1  43   7]
 [  1   1   9   1]
 [ 22   2 359  13]
 [ 10   0  38   7]]
12/10/2017 06:00:01 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 06:00:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:00:01 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:00:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:00:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:00:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:00:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:00:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:00:38 [INFO] exp_shallowmodel: train time: 37.013s
12/10/2017 06:00:38 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:00:38 [INFO] exp_shallowmodel: accuracy:   0.739
12/10/2017 06:00:38 [INFO] exp_shallowmodel: f1_score:   0.341
12/10/2017 06:00:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:00:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.22      0.25        59
          C       0.00      0.00      0.00        12
          F       0.83      0.91      0.87       396
          R       0.31      0.20      0.24        55

avg / total       0.69      0.74      0.71       522

12/10/2017 06:00:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:00:38 [INFO] exp_shallowmodel: 
[[ 13   2  30  14]
 [  4   0   8   0]
 [ 21   2 362  11]
 [  5   1  38  11]]
12/10/2017 06:00:39 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 06:00:39 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:00:39 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:00:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:00:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:00:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:00:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:00:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:01:15 [INFO] exp_shallowmodel: train time: 35.784s
12/10/2017 06:01:15 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:01:15 [INFO] exp_shallowmodel: accuracy:   0.745
12/10/2017 06:01:15 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 06:01:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:01:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.22      0.27        59
          C       0.00      0.00      0.00        12
          F       0.81      0.93      0.87       396
          R       0.30      0.13      0.18        55

avg / total       0.69      0.75      0.71       522

12/10/2017 06:01:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:01:15 [INFO] exp_shallowmodel: 
[[ 13   2  40   4]
 [  1   0  10   1]
 [ 12   4 369  11]
 [ 10   1  37   7]]
12/10/2017 06:01:16 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 06:01:16 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:01:16 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:01:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:01:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:01:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:01:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:01:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:02:00 [INFO] exp_shallowmodel: train time: 43.508s
12/10/2017 06:02:00 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:02:00 [INFO] exp_shallowmodel: accuracy:   0.736
12/10/2017 06:02:00 [INFO] exp_shallowmodel: f1_score:   0.339
12/10/2017 06:02:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:02:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.25      0.28        59
          C       0.00      0.00      0.00        12
          F       0.82      0.91      0.86       396
          R       0.31      0.16      0.21        55

avg / total       0.69      0.74      0.71       522

12/10/2017 06:02:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:02:00 [INFO] exp_shallowmodel: 
[[ 15   1  36   7]
 [  2   0   9   1]
 [ 21   3 360  12]
 [ 10   1  35   9]]
12/10/2017 06:02:01 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 06:02:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:02:01 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:02:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:02:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:02:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:02:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:02:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:02:46 [INFO] exp_shallowmodel: train time: 44.795s
12/10/2017 06:02:46 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:02:46 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 06:02:46 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 06:02:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:02:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.08      0.11        59
          C       0.00      0.00      0.00        12
          F       0.80      0.92      0.86       396
          R       0.38      0.20      0.26        55

avg / total       0.66      0.73      0.69       522

12/10/2017 06:02:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:02:46 [INFO] exp_shallowmodel: 
[[  5   1  49   4]
 [  4   0   6   2]
 [ 18   3 363  12]
 [  8   1  35  11]]
12/10/2017 06:02:47 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 06:02:47 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:02:47 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:02:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:02:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:02:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:02:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:02:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:03:29 [INFO] exp_shallowmodel: train time: 41.611s
12/10/2017 06:03:29 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:03:29 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 06:03:29 [INFO] exp_shallowmodel: f1_score:   0.301
12/10/2017 06:03:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:03:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.22      0.24        59
          C       0.00      0.00      0.00        12
          F       0.81      0.90      0.85       396
          R       0.17      0.09      0.12        55

avg / total       0.66      0.71      0.68       522

12/10/2017 06:03:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:03:29 [INFO] exp_shallowmodel: 
[[ 13   0  38   8]
 [  1   0   9   2]
 [ 25   2 355  14]
 [ 12   0  38   5]]
12/10/2017 06:03:30 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 06:03:30 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:03:30 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:03:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:03:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:03:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:03:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:03:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:04:07 [INFO] exp_shallowmodel: train time: 37.324s
12/10/2017 06:04:07 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:04:07 [INFO] exp_shallowmodel: accuracy:   0.742
12/10/2017 06:04:07 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 06:04:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:04:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.22      0.26        64
          C       0.33      0.14      0.20        14
          F       0.82      0.93      0.87       402
          R       0.40      0.22      0.29        63

avg / total       0.70      0.74      0.71       543

12/10/2017 06:04:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:04:07 [INFO] exp_shallowmodel: 
[[ 14   1  40   9]
 [  4   2   8   0]
 [ 15   2 373  12]
 [ 12   1  36  14]]
12/10/2017 06:04:09 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 06:04:09 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:04:09 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:04:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:04:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:04:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:04:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:04:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:04:44 [INFO] exp_shallowmodel: train time: 35.441s
12/10/2017 06:04:44 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:04:44 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 06:04:44 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 06:04:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:04:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.17      0.21        59
          C       0.25      0.08      0.12        12
          F       0.82      0.92      0.87       396
          R       0.44      0.27      0.34        55

avg / total       0.70      0.75      0.72       522

12/10/2017 06:04:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:04:44 [INFO] exp_shallowmodel: 
[[ 10   3  37   9]
 [  0   1  10   1]
 [ 21   0 366   9]
 [  6   0  34  15]]
12/10/2017 06:04:46 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 06:04:46 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:04:46 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:04:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:04:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:04:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:04:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:04:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:05:25 [INFO] exp_shallowmodel: train time: 39.446s
12/10/2017 06:05:25 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:05:25 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 06:05:25 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 06:05:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:05:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.17      0.21        59
          C       0.00      0.00      0.00        12
          F       0.80      0.89      0.85       396
          R       0.23      0.16      0.19        55

avg / total       0.66      0.71      0.69       522

12/10/2017 06:05:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:05:25 [INFO] exp_shallowmodel: 
[[ 10   0  41   8]
 [  2   0   7   3]
 [ 20   2 354  20]
 [  4   3  39   9]]
12/10/2017 06:05:26 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 06:05:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:05:26 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:05:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:05:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:05:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:05:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:05:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:06:02 [INFO] exp_shallowmodel: train time: 35.976s
12/10/2017 06:06:02 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:06:02 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 06:06:02 [INFO] exp_shallowmodel: f1_score:   0.373
12/10/2017 06:06:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:06:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.25      0.30        59
          C       0.25      0.08      0.12        12
          F       0.81      0.91      0.86       396
          R       0.28      0.16      0.21        55

avg / total       0.69      0.74      0.71       522

12/10/2017 06:06:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:06:02 [INFO] exp_shallowmodel: 
[[ 15   0  36   8]
 [  1   1   9   1]
 [ 17   3 362  14]
 [  8   0  38   9]]
12/10/2017 06:06:04 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 06:06:04 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:06:04 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:06:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:06:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:06:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:06:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:06:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:06:43 [INFO] exp_shallowmodel: train time: 38.885s
12/10/2017 06:06:43 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:06:43 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 06:06:43 [INFO] exp_shallowmodel: f1_score:   0.352
12/10/2017 06:06:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:06:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.20      0.26        59
          C       0.00      0.00      0.00        12
          F       0.81      0.93      0.86       396
          R       0.40      0.22      0.28        55

avg / total       0.70      0.75      0.71       522

12/10/2017 06:06:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:06:43 [INFO] exp_shallowmodel: 
[[ 12   1  40   6]
 [  2   0  10   0]
 [ 15   1 368  12]
 [  4   1  38  12]]
12/10/2017 06:06:44 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 06:06:44 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:06:44 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:06:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:06:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:06:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:06:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:06:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:07:24 [INFO] exp_shallowmodel: train time: 39.613s
12/10/2017 06:07:24 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:07:24 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 06:07:24 [INFO] exp_shallowmodel: f1_score:   0.328
12/10/2017 06:07:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:07:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.17      0.21        59
          C       0.00      0.00      0.00        12
          F       0.80      0.92      0.86       396
          R       0.37      0.18      0.24        55

avg / total       0.68      0.74      0.70       522

12/10/2017 06:07:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:07:24 [INFO] exp_shallowmodel: 
[[ 10   1  43   5]
 [  3   0   8   1]
 [ 19   1 365  11]
 [  4   1  40  10]]
12/10/2017 06:07:25 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 06:07:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:07:25 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:07:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:07:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:07:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:07:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:07:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:08:01 [INFO] exp_shallowmodel: train time: 36.075s
12/10/2017 06:08:01 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:08:01 [INFO] exp_shallowmodel: accuracy:   0.718
12/10/2017 06:08:01 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 06:08:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:08:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.15      0.17        59
          C       0.00      0.00      0.00        12
          F       0.81      0.90      0.85       396
          R       0.34      0.20      0.25        55

avg / total       0.68      0.72      0.69       522

12/10/2017 06:08:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:08:01 [INFO] exp_shallowmodel: 
[[  9   1  41   8]
 [  2   0  10   0]
 [ 24   4 355  13]
 [ 13   1  30  11]]
12/10/2017 06:08:03 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 06:08:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:08:03 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:08:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:08:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:08:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:08:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:08:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:08:43 [INFO] exp_shallowmodel: train time: 40.079s
12/10/2017 06:08:43 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:08:43 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 06:08:43 [INFO] exp_shallowmodel: f1_score:   0.300
12/10/2017 06:08:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:08:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.20      0.24        59
          C       0.00      0.00      0.00        12
          F       0.79      0.89      0.84       396
          R       0.17      0.09      0.12        55

avg / total       0.65      0.71      0.68       522

12/10/2017 06:08:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:08:43 [INFO] exp_shallowmodel: 
[[ 12   0  42   5]
 [  0   0  11   1]
 [ 18   5 354  19]
 [ 10   0  40   5]]
12/10/2017 06:08:44 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 06:08:44 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:08:44 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:08:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:08:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:08:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:08:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:08:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:09:28 [INFO] exp_shallowmodel: train time: 43.913s
12/10/2017 06:09:28 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:09:28 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 06:09:28 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 06:09:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:09:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.20      0.24        59
          C       0.00      0.00      0.00        12
          F       0.82      0.91      0.86       396
          R       0.24      0.13      0.17        55

avg / total       0.68      0.73      0.70       522

12/10/2017 06:09:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:09:28 [INFO] exp_shallowmodel: 
[[ 12   2  42   3]
 [  1   0   9   2]
 [ 13   4 362  17]
 [ 16   1  31   7]]
12/10/2017 06:09:29 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 06:09:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:09:29 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:09:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:09:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:09:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:09:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:09:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:10:08 [INFO] exp_shallowmodel: train time: 38.482s
12/10/2017 06:10:08 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:10:08 [INFO] exp_shallowmodel: accuracy:   0.739
12/10/2017 06:10:08 [INFO] exp_shallowmodel: f1_score:   0.325
12/10/2017 06:10:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:10:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.15      0.19        59
          C       0.00      0.00      0.00        12
          F       0.80      0.93      0.86       396
          R       0.38      0.18      0.25        55

avg / total       0.68      0.74      0.70       522

12/10/2017 06:10:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:10:08 [INFO] exp_shallowmodel: 
[[  9   0  42   8]
 [  1   0  10   1]
 [ 17   5 367   7]
 [  8   0  37  10]]
12/10/2017 06:10:09 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 06:10:09 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:10:09 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:10:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:10:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:10:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:10:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:10:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:10:49 [INFO] exp_shallowmodel: train time: 40.306s
12/10/2017 06:10:49 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:10:49 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 06:10:49 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 06:10:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:10:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.19      0.21        64
          C       0.00      0.00      0.00        14
          F       0.81      0.91      0.86       402
          R       0.41      0.25      0.31        63

avg / total       0.68      0.73      0.70       543

12/10/2017 06:10:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:10:49 [INFO] exp_shallowmodel: 
[[ 12   1  43   8]
 [  6   0   7   1]
 [ 22   0 366  14]
 [ 13   0  34  16]]
12/10/2017 06:10:51 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 06:10:51 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:10:51 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:10:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:10:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:10:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:10:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:10:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:11:31 [INFO] exp_shallowmodel: train time: 40.330s
12/10/2017 06:11:31 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:11:31 [INFO] exp_shallowmodel: accuracy:   0.732
12/10/2017 06:11:31 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 06:11:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:11:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.14      0.17        59
          C       0.00      0.00      0.00        12
          F       0.81      0.92      0.86       396
          R       0.30      0.18      0.23        55

avg / total       0.67      0.73      0.70       522

12/10/2017 06:11:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:11:31 [INFO] exp_shallowmodel: 
[[  8   2  43   6]
 [  4   0   8   0]
 [ 12   3 364  17]
 [ 12   0  33  10]]
12/10/2017 06:11:33 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 06:11:33 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:11:33 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:11:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:11:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:11:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:11:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:11:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:12:09 [INFO] exp_shallowmodel: train time: 36.889s
12/10/2017 06:12:09 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:12:09 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 06:12:09 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 06:12:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:12:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.19      0.22        59
          C       0.00      0.00      0.00        12
          F       0.81      0.91      0.86       396
          R       0.27      0.16      0.20        55

avg / total       0.68      0.73      0.70       522

12/10/2017 06:12:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:12:09 [INFO] exp_shallowmodel: 
[[ 11   2  38   8]
 [  1   0   9   2]
 [ 20   1 361  14]
 [ 10   0  36   9]]
12/10/2017 06:12:11 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 06:12:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:12:11 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:12:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:12:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:12:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:12:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:12:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:12:49 [INFO] exp_shallowmodel: train time: 38.456s
12/10/2017 06:12:49 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:12:49 [INFO] exp_shallowmodel: accuracy:   0.743
12/10/2017 06:12:49 [INFO] exp_shallowmodel: f1_score:   0.358
12/10/2017 06:12:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:12:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.31      0.35        59
          C       0.00      0.00      0.00        12
          F       0.82      0.91      0.86       396
          R       0.29      0.18      0.22        55

avg / total       0.70      0.74      0.72       522

12/10/2017 06:12:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:12:49 [INFO] exp_shallowmodel: 
[[ 18   0  37   4]
 [  0   0   9   3]
 [ 17   2 360  17]
 [ 10   1  34  10]]
12/10/2017 06:12:51 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 06:12:51 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:12:51 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:12:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:12:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:12:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:12:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:12:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:13:35 [INFO] exp_shallowmodel: train time: 44.816s
12/10/2017 06:13:35 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:13:35 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 06:13:35 [INFO] exp_shallowmodel: f1_score:   0.363
12/10/2017 06:13:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:13:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.24      0.30        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.36      0.24      0.29        55

avg / total       0.70      0.75      0.72       522

12/10/2017 06:13:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:13:35 [INFO] exp_shallowmodel: 
[[ 14   1  36   8]
 [  2   0   7   3]
 [ 16   2 366  12]
 [  3   0  39  13]]
12/10/2017 06:13:37 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 06:13:37 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:13:37 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:13:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:13:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:13:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:13:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:13:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:14:19 [INFO] exp_shallowmodel: train time: 42.071s
12/10/2017 06:14:19 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:14:19 [INFO] exp_shallowmodel: accuracy:   0.728
12/10/2017 06:14:19 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 06:14:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:14:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.17      0.21        59
          C       0.17      0.08      0.11        12
          F       0.80      0.91      0.85       396
          R       0.26      0.13      0.17        55

avg / total       0.67      0.73      0.69       522

12/10/2017 06:14:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:14:19 [INFO] exp_shallowmodel: 
[[ 10   1  41   7]
 [  1   1   9   1]
 [ 20   2 362  12]
 [  6   2  40   7]]
12/10/2017 06:14:20 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 06:14:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:14:20 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:14:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:14:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:14:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:14:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:14:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:15:03 [INFO] exp_shallowmodel: train time: 42.786s
12/10/2017 06:15:03 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:15:03 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 06:15:03 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 06:15:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:15:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.15      0.18        59
          C       0.00      0.00      0.00        12
          F       0.81      0.90      0.86       396
          R       0.35      0.24      0.28        55

avg / total       0.68      0.73      0.70       522

12/10/2017 06:15:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:15:03 [INFO] exp_shallowmodel: 
[[  9   1  42   7]
 [  1   0  11   0]
 [ 21   1 357  17]
 [ 10   3  29  13]]
12/10/2017 06:15:04 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 06:15:04 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:15:04 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:15:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:15:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:15:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:15:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:15:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:15:34 [INFO] exp_shallowmodel: train time: 29.248s
12/10/2017 06:15:34 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:15:34 [INFO] exp_shallowmodel: accuracy:   0.741
12/10/2017 06:15:34 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 06:15:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:15:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.24      0.26        59
          C       0.22      0.17      0.19        12
          F       0.83      0.90      0.87       396
          R       0.38      0.24      0.29        55

avg / total       0.71      0.74      0.72       522

12/10/2017 06:15:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:15:34 [INFO] exp_shallowmodel: 
[[ 14   3  36   6]
 [  2   2   6   2]
 [ 22   3 358  13]
 [ 10   1  31  13]]
12/10/2017 06:15:35 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 06:15:35 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:15:35 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:15:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:15:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:15:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:15:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:15:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:16:12 [INFO] exp_shallowmodel: train time: 36.739s
12/10/2017 06:16:12 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:16:12 [INFO] exp_shallowmodel: accuracy:   0.718
12/10/2017 06:16:12 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 06:16:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:16:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.17      0.20        59
          C       0.00      0.00      0.00        12
          F       0.79      0.90      0.84       396
          R       0.33      0.16      0.22        55

avg / total       0.66      0.72      0.68       522

12/10/2017 06:16:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:16:12 [INFO] exp_shallowmodel: 
[[ 10   0  42   7]
 [  2   0   9   1]
 [ 27   3 356  10]
 [  3   0  43   9]]
12/10/2017 06:16:13 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 06:16:13 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:16:13 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:16:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:16:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:16:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:16:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:16:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:16:46 [INFO] exp_shallowmodel: train time: 32.649s
12/10/2017 06:16:46 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:16:46 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 06:16:46 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 06:16:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:16:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.08      0.10        59
          C       0.00      0.00      0.00        12
          F       0.81      0.91      0.86       396
          R       0.41      0.22      0.29        55

avg / total       0.67      0.72      0.69       522

12/10/2017 06:16:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:16:46 [INFO] exp_shallowmodel: 
[[  5   2  44   8]
 [  3   0   9   0]
 [ 22   4 361   9]
 [  8   1  34  12]]
12/10/2017 06:16:47 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 06:16:47 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:16:47 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:16:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:16:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:16:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:16:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:16:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:17:25 [INFO] exp_shallowmodel: train time: 37.782s
12/10/2017 06:17:25 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:17:25 [INFO] exp_shallowmodel: accuracy:   0.720
12/10/2017 06:17:25 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 06:17:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:17:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.23      0.26        64
          C       0.33      0.07      0.12        14
          F       0.80      0.90      0.85       402
          R       0.35      0.19      0.25        63

avg / total       0.67      0.72      0.69       543

12/10/2017 06:17:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:17:25 [INFO] exp_shallowmodel: 
[[ 15   0  43   6]
 [  3   1  10   0]
 [ 22   1 363  16]
 [ 10   1  40  12]]
12/10/2017 06:17:26 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 06:17:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:17:26 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:17:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:17:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:17:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:17:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:17:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:18:12 [INFO] exp_shallowmodel: train time: 46.001s
12/10/2017 06:18:12 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:18:12 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 06:18:12 [INFO] exp_shallowmodel: f1_score:   0.358
12/10/2017 06:18:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:18:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.19      0.22        59
          C       0.50      0.08      0.14        12
          F       0.81      0.90      0.85       396
          R       0.28      0.18      0.22        55

avg / total       0.68      0.73      0.70       522

12/10/2017 06:18:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:18:12 [INFO] exp_shallowmodel: 
[[ 11   1  37  10]
 [  1   1  10   0]
 [ 23   0 357  16]
 [  8   0  37  10]]
12/10/2017 06:18:14 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 06:18:14 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:18:14 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:18:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:18:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:18:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:18:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:18:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:18:50 [INFO] exp_shallowmodel: train time: 36.246s
12/10/2017 06:18:50 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:18:50 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 06:18:50 [INFO] exp_shallowmodel: f1_score:   0.378
12/10/2017 06:18:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:18:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.19      0.24        59
          C       0.33      0.08      0.13        12
          F       0.82      0.93      0.87       396
          R       0.34      0.22      0.27        55

avg / total       0.70      0.75      0.72       522

12/10/2017 06:18:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:18:50 [INFO] exp_shallowmodel: 
[[ 11   1  40   7]
 [  0   1   9   2]
 [ 12   0 370  14]
 [ 10   1  32  12]]
12/10/2017 06:18:51 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 06:18:51 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:18:51 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:18:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:18:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:18:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:18:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:18:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:19:30 [INFO] exp_shallowmodel: train time: 38.797s
12/10/2017 06:19:30 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:19:30 [INFO] exp_shallowmodel: accuracy:   0.743
12/10/2017 06:19:30 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 06:19:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:19:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.31      0.34        59
          C       0.25      0.08      0.12        12
          F       0.83      0.90      0.86       396
          R       0.28      0.20      0.23        55

avg / total       0.71      0.74      0.72       522

12/10/2017 06:19:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:19:30 [INFO] exp_shallowmodel: 
[[ 18   0  31  10]
 [  1   1  10   0]
 [ 17   3 358  18]
 [ 11   0  33  11]]
12/10/2017 06:19:32 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 06:19:32 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:19:32 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:19:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:19:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:19:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:19:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:19:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:20:16 [INFO] exp_shallowmodel: train time: 44.943s
12/10/2017 06:20:16 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:20:16 [INFO] exp_shallowmodel: accuracy:   0.732
12/10/2017 06:20:16 [INFO] exp_shallowmodel: f1_score:   0.352
12/10/2017 06:20:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:20:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.25      0.28        59
          C       0.00      0.00      0.00        12
          F       0.81      0.90      0.85       396
          R       0.39      0.22      0.28        55

avg / total       0.69      0.73      0.71       522

12/10/2017 06:20:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:20:16 [INFO] exp_shallowmodel: 
[[ 15   2  37   5]
 [  2   0   8   2]
 [ 27   2 355  12]
 [  6   0  37  12]]
12/10/2017 06:20:18 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 06:20:18 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:20:18 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:20:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:20:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:20:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:20:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:20:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:20:59 [INFO] exp_shallowmodel: train time: 41.564s
12/10/2017 06:20:59 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:20:59 [INFO] exp_shallowmodel: accuracy:   0.732
12/10/2017 06:20:59 [INFO] exp_shallowmodel: f1_score:   0.337
12/10/2017 06:20:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:20:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.24      0.29        59
          C       0.00      0.00      0.00        12
          F       0.80      0.91      0.85       396
          R       0.26      0.16      0.20        55

avg / total       0.68      0.73      0.70       522

12/10/2017 06:20:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:20:59 [INFO] exp_shallowmodel: 
[[ 14   0  37   8]
 [  2   0   8   2]
 [ 16   5 359  16]
 [  4   0  42   9]]
12/10/2017 06:21:01 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 06:21:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:21:01 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:21:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:21:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:21:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:21:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:21:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:21:34 [INFO] exp_shallowmodel: train time: 32.965s
12/10/2017 06:21:34 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:21:34 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 06:21:34 [INFO] exp_shallowmodel: f1_score:   0.370
12/10/2017 06:21:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:21:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.17      0.20        59
          C       0.33      0.17      0.22        12
          F       0.82      0.92      0.87       396
          R       0.26      0.15      0.19        55

avg / total       0.69      0.74      0.71       522

12/10/2017 06:21:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:21:34 [INFO] exp_shallowmodel: 
[[ 10   1  39   9]
 [  1   2   6   3]
 [ 17   3 365  11]
 [ 12   0  35   8]]
12/10/2017 06:21:35 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 06:21:35 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:21:35 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:21:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:21:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:21:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:21:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:21:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:22:07 [INFO] exp_shallowmodel: train time: 32.165s
12/10/2017 06:22:07 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:22:07 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 06:22:07 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 06:22:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:22:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.19      0.21        59
          C       0.00      0.00      0.00        12
          F       0.81      0.90      0.85       396
          R       0.35      0.20      0.26        55

avg / total       0.68      0.73      0.70       522

12/10/2017 06:22:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:22:07 [INFO] exp_shallowmodel: 
[[ 11   1  42   5]
 [  0   0  12   0]
 [ 23   1 357  15]
 [ 12   1  31  11]]
12/10/2017 06:22:09 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 06:22:09 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:22:09 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:22:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:22:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:22:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:22:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:22:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:22:49 [INFO] exp_shallowmodel: train time: 40.379s
12/10/2017 06:22:49 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:22:49 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 06:22:49 [INFO] exp_shallowmodel: f1_score:   0.305
12/10/2017 06:22:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:22:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.19      0.22        59
          C       0.00      0.00      0.00        12
          F       0.82      0.92      0.87       396
          R       0.18      0.11      0.13        55

avg / total       0.67      0.73      0.70       522

12/10/2017 06:22:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:22:49 [INFO] exp_shallowmodel: 
[[ 11   0  37  11]
 [  2   0   9   1]
 [ 15   1 364  16]
 [ 13   1  35   6]]
12/10/2017 06:22:50 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 06:22:50 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:22:50 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:22:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:22:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:22:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:22:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:22:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:23:32 [INFO] exp_shallowmodel: train time: 41.949s
12/10/2017 06:23:32 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:23:32 [INFO] exp_shallowmodel: accuracy:   0.743
12/10/2017 06:23:32 [INFO] exp_shallowmodel: f1_score:   0.354
12/10/2017 06:23:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:23:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.22      0.29        59
          C       0.20      0.08      0.12        12
          F       0.80      0.93      0.86       396
          R       0.23      0.11      0.15        55

avg / total       0.68      0.74      0.70       522

12/10/2017 06:23:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:23:32 [INFO] exp_shallowmodel: 
[[ 13   1  42   3]
 [  0   1  11   0]
 [  8   3 368  17]
 [  9   0  40   6]]
12/10/2017 06:23:34 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 06:23:34 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:23:34 [INFO] exp_shallowmodel: #(feature) = 9446
12/10/2017 06:23:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:23:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:23:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:23:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:23:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:24:15 [INFO] exp_shallowmodel: train time: 41.381s
12/10/2017 06:24:15 [INFO] exp_shallowmodel: test time:  0.007s
12/10/2017 06:24:15 [INFO] exp_shallowmodel: accuracy:   0.735
12/10/2017 06:24:15 [INFO] exp_shallowmodel: f1_score:   0.334
12/10/2017 06:24:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:24:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.19      0.23        64
          C       0.00      0.00      0.00        14
          F       0.80      0.94      0.86       402
          R       0.41      0.17      0.24        63

avg / total       0.67      0.73      0.69       543

12/10/2017 06:24:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:24:15 [INFO] exp_shallowmodel: 
[[ 12   1  49   2]
 [  4   0   9   1]
 [ 11   2 376  13]
 [ 14   2  36  11]]
Done: 20171210-062416
