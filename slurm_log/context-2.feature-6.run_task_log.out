/ihome/pbrusilosky/rum20/.conda/envs/py36/bin/python -m dialogue.classify.task_runner -selected_feature_set_id 6 -selected_context_id 2
No. of param settings = 1
[('deep_model', False), ('selected_context_id', 2), ('selected_feature_set_id', 6), ('similarity_feature', False)]
12/10/2017 02:14:33 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:33 [INFO] configuration: selected_context_id  :   2
12/10/2017 02:14:33 [INFO] configuration: selected_feature_set_id  :   6
12/10/2017 02:14:33 [INFO] configuration: similarity_feature  :   False
12/10/2017 02:14:33 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:33 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:33 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:33 [INFO] configuration: timemark  :   20171210-021433
12/10/2017 02:14:33 [INFO] configuration: context_set  :   last
12/10/2017 02:14:33 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:33 [INFO] configuration: utterance_range  :   ['current_user_utterance', 'last_system_utterance', 'current_user_utterance']
12/10/2017 02:14:33 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:33 [INFO] configuration: feature_set  :   6-w2v
12/10/2017 02:14:33 [INFO] configuration: feature_set_number  :   ['9']
12/10/2017 02:14:33 [INFO] configuration: experiment_name  :   20171210-021433.context=last.feature=6-w2v.similarity=false
12/10/2017 02:14:33 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021433.context=last.feature=6-w2v.similarity=false
12/10/2017 02:14:33 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021433.context=last.feature=6-w2v.similarity=false/output.log
12/10/2017 02:14:33 [INFO] configuration: valid_type  :   {'A', 'F', 'C', 'R'}
12/10/2017 02:14:33 [INFO] configuration: data_name  :   
12/10/2017 02:14:33 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:33 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:33 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:33 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:33 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:33 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:33 [INFO] configuration: #division  :   5
12/10/2017 02:14:33 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:33 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:33 [INFO] configuration: action_words  :   {'reminder', 'start', 'telephon', 'telephone', 'findcare', 'member', 'item', 'moderate', 'time', 'weather', 'tell', 'temperatur', 'clear', 'light', 'next', 'centr', 'phone', 'ani', 'findcar', 'skip', 'north', 'share', 'food', 'address', 'els', 'room', 'video', 'shuffl', 'alarm', 'cast', 'snooz', 'temperature', 'help', 'cheap', 'watch', 'price', 'centre', 'post', 'south', 'play', 'volume', 'music', 'delete', 'items', 'matter', 'reminders', 'show', 'delet', 'area', 'reminds', 'number', 'remov', 'add', 'expensive', 'any', 'expens', 'timer', 'else', 'snooze', 'shuffle', 'turn', 'song', 'list', 'part', 'remove', 'volum', 'discard', 'stop', 'moder', 'remind'}
12/10/2017 02:14:33 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:33 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:33 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:33 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:33 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:33 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:33 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:33 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:33 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:33 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:33 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:33 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:33 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:33 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:33 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:33 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:33 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:33 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:33 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 3, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:33 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:36 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:36 [INFO] task_runner: context=last, feature=6-w2v
12/10/2017 02:14:36 [INFO] task_runner: retained feature numbers=[9.1]
12/10/2017 02:14:36 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:36 [INFO] task_runner: #(feature)=900
12/10/2017 02:14:36 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:36 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:22 [INFO] exp_shallowmodel: train time: 105.921s
12/10/2017 02:16:22 [INFO] exp_shallowmodel: test time:  0.009s
12/10/2017 02:16:22 [INFO] exp_shallowmodel: accuracy:   0.637
12/10/2017 02:16:22 [INFO] exp_shallowmodel: f1_score:   0.475
12/10/2017 02:16:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.61      0.68      0.64       164
          F       0.73      0.76      0.74       268
          R       0.48      0.38      0.42       125

avg / total       0.62      0.64      0.63       571

12/10/2017 02:16:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:22 [INFO] exp_shallowmodel: 
[[  1   4   3   6]
 [  0 112  29  23]
 [  3  39 204  22]
 [  3  30  45  47]]
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:16:22 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:22 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:04 [INFO] exp_shallowmodel: train time: 102.285s
12/10/2017 02:18:04 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:18:04 [INFO] exp_shallowmodel: accuracy:   0.602
12/10/2017 02:18:04 [INFO] exp_shallowmodel: f1_score:   0.475
12/10/2017 02:18:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.14      0.19        14
          C       0.57      0.65      0.61       164
          F       0.68      0.71      0.70       268
          R       0.46      0.37      0.41       125

avg / total       0.59      0.60      0.59       571

12/10/2017 02:18:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:04 [INFO] exp_shallowmodel: 
[[  2   1   6   5]
 [  1 106  34  23]
 [  1  51 190  26]
 [  3  28  48  46]]
12/10/2017 02:18:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:18:05 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:05 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:18:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:19:43 [INFO] exp_shallowmodel: train time: 98.388s
12/10/2017 02:19:43 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:19:43 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 02:19:43 [INFO] exp_shallowmodel: f1_score:   0.458
12/10/2017 02:19:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:19:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.56      0.66      0.61       164
          F       0.73      0.73      0.73       268
          R       0.45      0.37      0.41       125

avg / total       0.61      0.61      0.61       571

12/10/2017 02:19:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:19:43 [INFO] exp_shallowmodel: 
[[  1   2   4   7]
 [  3 109  29  23]
 [  2  45 195  26]
 [  2  39  38  46]]
12/10/2017 02:19:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:19:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:19:43 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:19:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:19:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:19:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:19:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:19:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:37 [INFO] exp_shallowmodel: train time: 114.021s
12/10/2017 02:21:37 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:37 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 02:21:37 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 02:21:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.67      0.63       164
          F       0.68      0.75      0.71       268
          R       0.43      0.29      0.35       125

avg / total       0.59      0.61      0.59       571

12/10/2017 02:21:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:37 [INFO] exp_shallowmodel: 
[[  0   1   8   5]
 [  2 110  34  18]
 [  4  40 200  24]
 [  4  34  51  36]]
12/10/2017 02:21:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:21:37 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:21:37 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:21:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:20 [INFO] exp_shallowmodel: train time: 102.299s
12/10/2017 02:23:20 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:23:20 [INFO] exp_shallowmodel: accuracy:   0.604
12/10/2017 02:23:20 [INFO] exp_shallowmodel: f1_score:   0.452
12/10/2017 02:23:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.56      0.69      0.62       164
          F       0.69      0.70      0.70       268
          R       0.48      0.34      0.40       125

avg / total       0.59      0.60      0.59       571

12/10/2017 02:23:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:20 [INFO] exp_shallowmodel: 
[[  1   3   8   2]
 [  3 113  32  16]
 [  1  50 188  29]
 [  2  36  44  43]]
12/10/2017 02:23:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:23:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:23:20 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:23:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:08 [INFO] exp_shallowmodel: train time: 107.792s
12/10/2017 02:25:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:25:08 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 02:25:08 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 02:25:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.57      0.54       164
          F       0.67      0.70      0.68       268
          R       0.41      0.30      0.35       125

avg / total       0.55      0.56      0.55       571

12/10/2017 02:25:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:08 [INFO] exp_shallowmodel: 
[[  0   5   6   3]
 [  2  94  46  22]
 [  6  45 187  30]
 [  4  41  42  38]]
12/10/2017 02:25:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:25:08 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:25:08 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:25:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:26:47 [INFO] exp_shallowmodel: train time: 99.544s
12/10/2017 02:26:47 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:26:47 [INFO] exp_shallowmodel: accuracy:   0.651
12/10/2017 02:26:47 [INFO] exp_shallowmodel: f1_score:   0.455
12/10/2017 02:26:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:26:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.72      0.67       164
          F       0.73      0.80      0.76       268
          R       0.48      0.32      0.38       125

avg / total       0.63      0.65      0.64       571

12/10/2017 02:26:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:26:47 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  2 118  29  15]
 [  3  28 214  23]
 [  3  39  43  40]]
12/10/2017 02:26:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:26:47 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:26:47 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:26:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:26:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:26:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:26:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:26:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:28:28 [INFO] exp_shallowmodel: train time: 100.802s
12/10/2017 02:28:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:28:28 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 02:28:28 [INFO] exp_shallowmodel: f1_score:   0.437
12/10/2017 02:28:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:28:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.58      0.62      0.60       164
          F       0.68      0.74      0.71       268
          R       0.39      0.31      0.35       125

avg / total       0.58      0.59      0.58       571

12/10/2017 02:28:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:28:28 [INFO] exp_shallowmodel: 
[[  1   3   8   2]
 [  4 102  34  24]
 [  2  34 197  35]
 [  1  36  49  39]]
12/10/2017 02:28:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:28:28 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:28:28 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:28:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:28:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:28:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:28:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:28:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:30:20 [INFO] exp_shallowmodel: train time: 111.561s
12/10/2017 02:30:20 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:30:20 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 02:30:20 [INFO] exp_shallowmodel: f1_score:   0.449
12/10/2017 02:30:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:30:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.14      0.16        14
          C       0.54      0.70      0.60       164
          F       0.70      0.66      0.68       268
          R       0.40      0.30      0.35       125

avg / total       0.58      0.58      0.57       571

12/10/2017 02:30:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:30:20 [INFO] exp_shallowmodel: 
[[  2   1   6   5]
 [  1 114  27  22]
 [  3  58 178  29]
 [  5  40  42  38]]
12/10/2017 02:30:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:30:20 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:30:20 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:30:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:30:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:30:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:30:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:30:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:32:14 [INFO] exp_shallowmodel: train time: 114.072s
12/10/2017 02:32:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:32:14 [INFO] exp_shallowmodel: accuracy:   0.602
12/10/2017 02:32:14 [INFO] exp_shallowmodel: f1_score:   0.448
12/10/2017 02:32:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:32:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.06      0.06        16
          C       0.57      0.67      0.61       169
          F       0.70      0.71      0.70       271
          R       0.48      0.35      0.41       130

avg / total       0.60      0.60      0.60       586

12/10/2017 02:32:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:32:14 [INFO] exp_shallowmodel: 
[[  1   4   7   4]
 [  3 113  31  22]
 [  7  48 193  23]
 [  4  34  46  46]]
12/10/2017 02:32:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:32:14 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:32:14 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:32:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:32:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:32:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:32:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:32:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:33:55 [INFO] exp_shallowmodel: train time: 100.416s
12/10/2017 02:33:55 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:33:55 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 02:33:55 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:33:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:33:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.68      0.61       164
          F       0.70      0.68      0.69       268
          R       0.42      0.36      0.39       125

avg / total       0.58      0.59      0.59       571

12/10/2017 02:33:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:33:55 [INFO] exp_shallowmodel: 
[[  0   3   5   6]
 [  2 111  34  17]
 [  0  47 183  38]
 [  4  36  40  45]]
12/10/2017 02:33:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:33:55 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:33:55 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:33:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:33:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:33:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:33:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:33:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:35:32 [INFO] exp_shallowmodel: train time: 97.167s
12/10/2017 02:35:32 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:35:32 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 02:35:32 [INFO] exp_shallowmodel: f1_score:   0.458
12/10/2017 02:35:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:35:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.07      0.09        14
          C       0.58      0.65      0.61       164
          F       0.72      0.73      0.72       268
          R       0.45      0.38      0.41       125

avg / total       0.60      0.61      0.61       571

12/10/2017 02:35:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:35:32 [INFO] exp_shallowmodel: 
[[  1   1   8   4]
 [  3 107  25  29]
 [  1  47 195  25]
 [  4  31  43  47]]
12/10/2017 02:35:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:35:32 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:35:32 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:35:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:35:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:35:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:35:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:35:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:37:21 [INFO] exp_shallowmodel: train time: 108.410s
12/10/2017 02:37:21 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:37:21 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 02:37:21 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:37:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:37:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.51      0.58      0.54       164
          F       0.68      0.72      0.70       268
          R       0.40      0.31      0.35       125

avg / total       0.56      0.57      0.56       571

12/10/2017 02:37:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:37:21 [INFO] exp_shallowmodel: 
[[  1   2   7   4]
 [  0  95  41  28]
 [  2  47 192  27]
 [  2  41  43  39]]
12/10/2017 02:37:21 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:37:21 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:37:21 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:37:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:37:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:37:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:37:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:37:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:39:18 [INFO] exp_shallowmodel: train time: 117.358s
12/10/2017 02:39:18 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:39:18 [INFO] exp_shallowmodel: accuracy:   0.625
12/10/2017 02:39:18 [INFO] exp_shallowmodel: f1_score:   0.455
12/10/2017 02:39:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:39:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.71      0.65       164
          F       0.70      0.70      0.70       268
          R       0.55      0.42      0.47       125

avg / total       0.62      0.63      0.62       571

12/10/2017 02:39:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:39:18 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  2 117  32  13]
 [  4  51 188  25]
 [  4  26  43  52]]
12/10/2017 02:39:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:39:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:39:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:39:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:39:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:39:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:39:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:39:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:41:16 [INFO] exp_shallowmodel: train time: 117.828s
12/10/2017 02:41:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:41:16 [INFO] exp_shallowmodel: accuracy:   0.618
12/10/2017 02:41:16 [INFO] exp_shallowmodel: f1_score:   0.457
12/10/2017 02:41:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:41:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.07      0.08        14
          C       0.58      0.66      0.62       164
          F       0.72      0.75      0.73       268
          R       0.45      0.35      0.39       125

avg / total       0.61      0.62      0.61       571

12/10/2017 02:41:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:41:16 [INFO] exp_shallowmodel: 
[[  1   4   8   1]
 [  3 108  28  25]
 [  2  38 200  28]
 [  5  35  41  44]]
12/10/2017 02:41:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:41:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:41:16 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:41:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:41:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:41:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:41:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:41:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:43:07 [INFO] exp_shallowmodel: train time: 110.458s
12/10/2017 02:43:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:43:07 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 02:43:07 [INFO] exp_shallowmodel: f1_score:   0.479
12/10/2017 02:43:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:43:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.14      0.16        14
          C       0.56      0.66      0.61       164
          F       0.71      0.72      0.71       268
          R       0.51      0.38      0.44       125

avg / total       0.61      0.61      0.61       571

12/10/2017 02:43:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:43:07 [INFO] exp_shallowmodel: 
[[  2   1   7   4]
 [  4 109  34  17]
 [  4  46 192  26]
 [  1  38  38  48]]
12/10/2017 02:43:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:43:07 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:43:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:43:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:43:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:43:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:43:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:43:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:44:57 [INFO] exp_shallowmodel: train time: 110.320s
12/10/2017 02:44:57 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:44:57 [INFO] exp_shallowmodel: accuracy:   0.646
12/10/2017 02:44:57 [INFO] exp_shallowmodel: f1_score:   0.481
12/10/2017 02:44:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:44:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.63      0.73      0.68       164
          F       0.74      0.76      0.75       268
          R       0.45      0.35      0.39       125

avg / total       0.63      0.65      0.63       571

12/10/2017 02:44:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:44:57 [INFO] exp_shallowmodel: 
[[  1   1   6   6]
 [  3 120  18  23]
 [  1  38 204  25]
 [  0  32  49  44]]
12/10/2017 02:44:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:44:57 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:44:57 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:44:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:44:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:44:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:44:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:44:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:46:40 [INFO] exp_shallowmodel: train time: 102.763s
12/10/2017 02:46:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:46:40 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:46:40 [INFO] exp_shallowmodel: f1_score:   0.421
12/10/2017 02:46:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:46:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.62      0.60       164
          F       0.68      0.75      0.71       268
          R       0.45      0.32      0.37       125

avg / total       0.58      0.60      0.59       571

12/10/2017 02:46:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:46:40 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  2 102  36  24]
 [  2  44 200  22]
 [  8  27  50  40]]
12/10/2017 02:46:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 02:46:40 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:46:40 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:46:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:46:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:46:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:46:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:46:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:48:24 [INFO] exp_shallowmodel: train time: 103.494s
12/10/2017 02:48:24 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:48:24 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 02:48:24 [INFO] exp_shallowmodel: f1_score:   0.440
12/10/2017 02:48:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:48:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.07      0.07        14
          C       0.54      0.66      0.59       164
          F       0.73      0.77      0.75       268
          R       0.47      0.27      0.35       125

avg / total       0.60      0.61      0.60       571

12/10/2017 02:48:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:48:24 [INFO] exp_shallowmodel: 
[[  1   2   7   4]
 [  4 108  29  23]
 [  4  46 207  11]
 [  4  45  42  34]]
12/10/2017 02:48:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 02:48:24 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:48:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:48:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:48:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:48:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:48:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:48:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:50:02 [INFO] exp_shallowmodel: train time: 98.462s
12/10/2017 02:50:02 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:50:02 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:50:02 [INFO] exp_shallowmodel: f1_score:   0.421
12/10/2017 02:50:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:50:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.60      0.68      0.64       169
          F       0.68      0.73      0.71       271
          R       0.41      0.29      0.34       130

avg / total       0.58      0.60      0.59       586

12/10/2017 02:50:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:50:02 [INFO] exp_shallowmodel: 
[[  0   4   5   7]
 [  1 115  29  24]
 [  5  44 198  24]
 [  6  28  58  38]]
12/10/2017 02:50:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 02:50:02 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:50:02 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:50:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:50:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:50:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:50:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:50:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:51:45 [INFO] exp_shallowmodel: train time: 102.719s
12/10/2017 02:51:45 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:51:45 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 02:51:45 [INFO] exp_shallowmodel: f1_score:   0.438
12/10/2017 02:51:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:51:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.63      0.60       164
          F       0.70      0.74      0.72       268
          R       0.49      0.39      0.44       125

avg / total       0.60      0.61      0.61       571

12/10/2017 02:51:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:51:45 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  3 104  35  22]
 [  0  45 198  25]
 [  2  33  41  49]]
12/10/2017 02:51:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 02:51:45 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:51:45 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:51:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:51:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:51:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:51:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:51:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:53:33 [INFO] exp_shallowmodel: train time: 107.386s
12/10/2017 02:53:33 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:53:33 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 02:53:33 [INFO] exp_shallowmodel: f1_score:   0.461
12/10/2017 02:53:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:53:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.14      0.17        14
          C       0.53      0.58      0.56       164
          F       0.73      0.75      0.74       268
          R       0.40      0.35      0.38       125

avg / total       0.59      0.60      0.59       571

12/10/2017 02:53:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:53:33 [INFO] exp_shallowmodel: 
[[  2   3   5   4]
 [  0  95  32  37]
 [  4  40 200  24]
 [  3  40  38  44]]
12/10/2017 02:53:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 02:53:33 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:53:33 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:53:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:53:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:53:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:53:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:53:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:55:30 [INFO] exp_shallowmodel: train time: 117.184s
12/10/2017 02:55:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:55:30 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 02:55:30 [INFO] exp_shallowmodel: f1_score:   0.459
12/10/2017 02:55:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:55:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.14      0.15        14
          C       0.56      0.67      0.61       164
          F       0.72      0.71      0.72       268
          R       0.42      0.32      0.36       125

avg / total       0.59      0.60      0.59       571

12/10/2017 02:55:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:55:30 [INFO] exp_shallowmodel: 
[[  2   2   4   6]
 [  3 110  27  24]
 [  1  50 191  26]
 [  7  34  44  40]]
12/10/2017 02:55:30 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 02:55:30 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:55:30 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:55:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:55:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:55:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:55:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:55:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:57:26 [INFO] exp_shallowmodel: train time: 115.712s
12/10/2017 02:57:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:57:26 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 02:57:26 [INFO] exp_shallowmodel: f1_score:   0.437
12/10/2017 02:57:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:57:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.67      0.63       164
          F       0.71      0.75      0.73       268
          R       0.43      0.34      0.38       125

avg / total       0.60      0.62      0.61       571

12/10/2017 02:57:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:57:26 [INFO] exp_shallowmodel: 
[[  0   2   7   5]
 [  2 110  30  22]
 [  2  36 201  29]
 [  3  35  44  43]]
12/10/2017 02:57:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 02:57:26 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:57:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:57:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:57:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:57:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:57:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:57:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:59:15 [INFO] exp_shallowmodel: train time: 109.149s
12/10/2017 02:59:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:59:15 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:59:15 [INFO] exp_shallowmodel: f1_score:   0.448
12/10/2017 02:59:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:59:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.58      0.71      0.64       164
          F       0.70      0.68      0.69       268
          R       0.40      0.34      0.37       125

avg / total       0.59      0.60      0.59       571

12/10/2017 02:59:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:59:15 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  1 116  26  21]
 [  1  48 183  36]
 [  4  32  47  42]]
12/10/2017 02:59:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 02:59:15 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:59:15 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:59:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:59:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:59:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:59:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:59:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:00:56 [INFO] exp_shallowmodel: train time: 100.510s
12/10/2017 03:00:56 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:00:56 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 03:00:56 [INFO] exp_shallowmodel: f1_score:   0.429
12/10/2017 03:00:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:00:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.64      0.62       164
          F       0.67      0.72      0.69       268
          R       0.45      0.36      0.40       125

avg / total       0.59      0.60      0.59       571

12/10/2017 03:00:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:00:56 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  3 105  34  22]
 [  3  42 192  31]
 [  5  23  52  45]]
12/10/2017 03:00:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 03:00:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:00:56 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:00:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:00:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:00:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:00:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:00:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:02:44 [INFO] exp_shallowmodel: train time: 108.107s
12/10/2017 03:02:44 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:02:44 [INFO] exp_shallowmodel: accuracy:   0.637
12/10/2017 03:02:44 [INFO] exp_shallowmodel: f1_score:   0.490
12/10/2017 03:02:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:02:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.14      0.19        14
          C       0.59      0.71      0.64       164
          F       0.75      0.77      0.76       268
          R       0.44      0.32      0.37       125

avg / total       0.62      0.64      0.63       571

12/10/2017 03:02:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:02:44 [INFO] exp_shallowmodel: 
[[  2   2   4   6]
 [  0 116  26  22]
 [  1  38 206  23]
 [  4  41  40  40]]
12/10/2017 03:02:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 03:02:44 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:02:44 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:02:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:02:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:02:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:02:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:02:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:04:23 [INFO] exp_shallowmodel: train time: 98.579s
12/10/2017 03:04:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:04:23 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 03:04:23 [INFO] exp_shallowmodel: f1_score:   0.439
12/10/2017 03:04:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:04:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.72      0.64       164
          F       0.73      0.71      0.72       268
          R       0.46      0.34      0.39       125

avg / total       0.61      0.61      0.61       571

12/10/2017 03:04:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:04:23 [INFO] exp_shallowmodel: 
[[  0   5   3   6]
 [  3 118  25  18]
 [  7  45 190  26]
 [  4  37  41  43]]
12/10/2017 03:04:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 03:04:23 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:04:23 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:04:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:04:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:04:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:04:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:04:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:06:07 [INFO] exp_shallowmodel: train time: 103.965s
12/10/2017 03:06:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:06:07 [INFO] exp_shallowmodel: accuracy:   0.609
12/10/2017 03:06:07 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 03:06:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:06:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.66      0.61       164
          F       0.71      0.75      0.73       268
          R       0.44      0.30      0.36       125

avg / total       0.59      0.61      0.59       571

12/10/2017 03:06:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:06:07 [INFO] exp_shallowmodel: 
[[  0   1   7   6]
 [  2 109  34  19]
 [  1  43 201  23]
 [  2  43  42  38]]
12/10/2017 03:06:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 03:06:07 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:06:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:06:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:06:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:06:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:06:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:06:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:07:53 [INFO] exp_shallowmodel: train time: 105.674s
12/10/2017 03:07:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:07:53 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 03:07:53 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 03:07:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:07:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.59      0.66      0.62       169
          F       0.68      0.73      0.70       271
          R       0.47      0.36      0.41       130

avg / total       0.59      0.61      0.60       586

12/10/2017 03:07:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:07:53 [INFO] exp_shallowmodel: 
[[  0   3   8   5]
 [  0 112  37  20]
 [  3  43 197  28]
 [  3  32  48  47]]
12/10/2017 03:07:53 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 03:07:53 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:07:53 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:07:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:07:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:07:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:07:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:07:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:09:35 [INFO] exp_shallowmodel: train time: 102.249s
12/10/2017 03:09:35 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:09:35 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 03:09:35 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 03:09:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:09:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.72      0.62       164
          F       0.73      0.71      0.72       268
          R       0.38      0.27      0.32       125

avg / total       0.58      0.60      0.58       571

12/10/2017 03:09:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:09:35 [INFO] exp_shallowmodel: 
[[  0   3   4   7]
 [  1 118  25  20]
 [  2  47 190  29]
 [  1  49  41  34]]
12/10/2017 03:09:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 03:09:35 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:09:35 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:09:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:09:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:09:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:09:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:09:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:11:20 [INFO] exp_shallowmodel: train time: 104.647s
12/10/2017 03:11:20 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:11:20 [INFO] exp_shallowmodel: accuracy:   0.604
12/10/2017 03:11:20 [INFO] exp_shallowmodel: f1_score:   0.456
12/10/2017 03:11:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:11:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.55      0.70      0.62       164
          F       0.71      0.69      0.70       268
          R       0.46      0.36      0.40       125

avg / total       0.60      0.60      0.60       571

12/10/2017 03:11:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:11:20 [INFO] exp_shallowmodel: 
[[  1   1   6   6]
 [  1 114  25  24]
 [  1  59 185  23]
 [  2  32  46  45]]
12/10/2017 03:11:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 03:11:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:11:20 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:11:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:11:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:11:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:11:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:11:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:13:02 [INFO] exp_shallowmodel: train time: 102.452s
12/10/2017 03:13:02 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:13:02 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 03:13:02 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 03:13:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:13:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.59      0.57       164
          F       0.70      0.72      0.71       268
          R       0.38      0.32      0.35       125

avg / total       0.57      0.58      0.57       571

12/10/2017 03:13:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:13:02 [INFO] exp_shallowmodel: 
[[  0   2   6   6]
 [  4  97  30  33]
 [  1  47 194  26]
 [  6  31  48  40]]
12/10/2017 03:13:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 03:13:03 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:13:03 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:13:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:13:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:13:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:13:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:13:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:14:50 [INFO] exp_shallowmodel: train time: 106.983s
12/10/2017 03:14:50 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:14:50 [INFO] exp_shallowmodel: accuracy:   0.651
12/10/2017 03:14:50 [INFO] exp_shallowmodel: f1_score:   0.468
12/10/2017 03:14:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:14:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.70      0.65       164
          F       0.74      0.76      0.75       268
          R       0.55      0.42      0.47       125

avg / total       0.64      0.65      0.64       571

12/10/2017 03:14:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:14:50 [INFO] exp_shallowmodel: 
[[  0   5   6   3]
 [  1 115  28  20]
 [  3  40 205  20]
 [  4  32  37  52]]
12/10/2017 03:14:50 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 03:14:50 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:14:50 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:14:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:14:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:14:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:14:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:14:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:16:33 [INFO] exp_shallowmodel: train time: 103.572s
12/10/2017 03:16:33 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:16:33 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 03:16:33 [INFO] exp_shallowmodel: f1_score:   0.455
12/10/2017 03:16:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:16:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.56      0.69      0.62       164
          F       0.71      0.74      0.72       268
          R       0.50      0.32      0.39       125

avg / total       0.60      0.62      0.60       571

12/10/2017 03:16:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:16:33 [INFO] exp_shallowmodel: 
[[  1   4   8   1]
 [  2 113  34  15]
 [  2  44 198  24]
 [  3  42  40  40]]
12/10/2017 03:16:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 03:16:33 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:16:33 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:16:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:16:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:16:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:16:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:16:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:18:25 [INFO] exp_shallowmodel: train time: 111.993s
12/10/2017 03:18:25 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:18:25 [INFO] exp_shallowmodel: accuracy:   0.609
12/10/2017 03:18:25 [INFO] exp_shallowmodel: f1_score:   0.506
12/10/2017 03:18:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:18:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.29      0.32        14
          C       0.58      0.67      0.62       164
          F       0.68      0.72      0.70       268
          R       0.47      0.32      0.38       125

avg / total       0.60      0.61      0.60       571

12/10/2017 03:18:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:18:25 [INFO] exp_shallowmodel: 
[[  4   3   4   3]
 [  1 110  41  12]
 [  3  40 194  31]
 [  3  36  46  40]]
12/10/2017 03:18:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 03:18:26 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:18:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:18:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:18:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:18:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:18:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:18:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:20:17 [INFO] exp_shallowmodel: train time: 111.169s
12/10/2017 03:20:17 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:20:17 [INFO] exp_shallowmodel: accuracy:   0.609
12/10/2017 03:20:17 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 03:20:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:20:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.68      0.61       164
          F       0.71      0.71      0.71       268
          R       0.46      0.37      0.41       125

avg / total       0.60      0.61      0.60       571

12/10/2017 03:20:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:20:17 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  2 111  30  21]
 [  1  49 191  27]
 [  2  35  42  46]]
12/10/2017 03:20:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 03:20:17 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:20:17 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:20:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:20:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:20:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:20:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:20:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:22:10 [INFO] exp_shallowmodel: train time: 112.845s
12/10/2017 03:22:10 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:22:10 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 03:22:10 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 03:22:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:22:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.64      0.59       164
          F       0.68      0.70      0.69       268
          R       0.41      0.33      0.36       125

avg / total       0.57      0.58      0.57       571

12/10/2017 03:22:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:22:10 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  2 105  34  23]
 [  0  48 187  33]
 [  3  36  45  41]]
12/10/2017 03:22:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 03:22:10 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:22:10 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:22:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:22:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:22:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:22:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:22:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:23:56 [INFO] exp_shallowmodel: train time: 106.068s
12/10/2017 03:23:56 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:23:56 [INFO] exp_shallowmodel: accuracy:   0.602
12/10/2017 03:23:56 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 03:23:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:23:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.68      0.62       164
          F       0.69      0.72      0.70       268
          R       0.46      0.33      0.38       125

avg / total       0.59      0.60      0.59       571

12/10/2017 03:23:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:23:56 [INFO] exp_shallowmodel: 
[[  0   1   6   7]
 [  1 111  35  17]
 [  3  48 192  25]
 [  6  32  46  41]]
12/10/2017 03:23:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 03:23:56 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:23:56 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:23:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:23:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:23:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:23:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:23:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:25:49 [INFO] exp_shallowmodel: train time: 112.824s
12/10/2017 03:25:49 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:25:49 [INFO] exp_shallowmodel: accuracy:   0.585
12/10/2017 03:25:49 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 03:25:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:25:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.58      0.61      0.60       169
          F       0.67      0.72      0.70       271
          R       0.41      0.34      0.37       130

avg / total       0.57      0.59      0.58       586

12/10/2017 03:25:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:25:49 [INFO] exp_shallowmodel: 
[[  0   2   9   5]
 [  1 103  39  26]
 [  3  39 196  33]
 [  5  33  48  44]]
12/10/2017 03:25:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 03:25:49 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:25:49 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:25:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:25:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:25:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:25:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:25:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:27:33 [INFO] exp_shallowmodel: train time: 104.150s
12/10/2017 03:27:33 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:27:33 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 03:27:33 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 03:27:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:27:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.66      0.60       164
          F       0.71      0.72      0.71       268
          R       0.43      0.32      0.37       125

avg / total       0.59      0.60      0.59       571

12/10/2017 03:27:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:27:33 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  2 109  27  26]
 [  2  50 194  22]
 [  3  34  48  40]]
12/10/2017 03:27:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 03:27:33 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:27:33 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:27:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:27:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:27:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:27:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:27:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:29:18 [INFO] exp_shallowmodel: train time: 104.922s
12/10/2017 03:29:18 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:29:18 [INFO] exp_shallowmodel: accuracy:   0.585
12/10/2017 03:29:18 [INFO] exp_shallowmodel: f1_score:   0.439
12/10/2017 03:29:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:29:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.07      0.08        14
          C       0.53      0.59      0.56       164
          F       0.66      0.71      0.68       268
          R       0.50      0.38      0.43       125

avg / total       0.58      0.58      0.58       571

12/10/2017 03:29:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:29:18 [INFO] exp_shallowmodel: 
[[  1   1  11   1]
 [  2  96  46  20]
 [  4  48 190  26]
 [  3  35  40  47]]
12/10/2017 03:29:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 03:29:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:29:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:29:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:29:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:29:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:29:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:29:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:31:00 [INFO] exp_shallowmodel: train time: 101.618s
12/10/2017 03:31:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:31:00 [INFO] exp_shallowmodel: accuracy:   0.595
12/10/2017 03:31:00 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 03:31:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:31:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.59      0.58       164
          F       0.69      0.74      0.72       268
          R       0.41      0.37      0.39       125

avg / total       0.58      0.60      0.59       571

12/10/2017 03:31:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:31:00 [INFO] exp_shallowmodel: 
[[  0   2   4   8]
 [  1  96  40  27]
 [  4  36 198  30]
 [  4  32  43  46]]
12/10/2017 03:31:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 03:31:00 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:31:00 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:31:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:31:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:31:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:31:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:31:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:32:42 [INFO] exp_shallowmodel: train time: 102.000s
12/10/2017 03:32:42 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:32:42 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 03:32:42 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 03:32:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:32:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.63      0.57       164
          F       0.68      0.70      0.69       268
          R       0.38      0.25      0.30       125

avg / total       0.55      0.57      0.55       571

12/10/2017 03:32:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:32:42 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  1 104  35  24]
 [  3  54 188  23]
 [  6  40  48  31]]
12/10/2017 03:32:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 03:32:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:32:42 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:32:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:32:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:32:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:32:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:32:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:34:30 [INFO] exp_shallowmodel: train time: 108.139s
12/10/2017 03:34:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:34:30 [INFO] exp_shallowmodel: accuracy:   0.646
12/10/2017 03:34:30 [INFO] exp_shallowmodel: f1_score:   0.477
12/10/2017 03:34:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:34:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.62      0.70      0.66       164
          F       0.72      0.79      0.75       268
          R       0.51      0.34      0.41       125

avg / total       0.63      0.65      0.63       571

12/10/2017 03:34:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:34:30 [INFO] exp_shallowmodel: 
[[  1   2   8   3]
 [  0 114  33  17]
 [  1  34 211  22]
 [  5  34  43  43]]
12/10/2017 03:34:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 03:34:31 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:34:31 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:34:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:34:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:34:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:34:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:34:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:36:11 [INFO] exp_shallowmodel: train time: 100.200s
12/10/2017 03:36:11 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:36:11 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 03:36:11 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 03:36:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:36:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.69      0.64       164
          F       0.71      0.74      0.72       268
          R       0.41      0.33      0.37       125

avg / total       0.59      0.61      0.60       571

12/10/2017 03:36:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:36:11 [INFO] exp_shallowmodel: 
[[  0   5   2   7]
 [  1 113  30  20]
 [  1  39 197  31]
 [  2  32  50  41]]
12/10/2017 03:36:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 03:36:11 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:36:11 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:36:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:36:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:36:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:36:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:36:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:37:55 [INFO] exp_shallowmodel: train time: 103.677s
12/10/2017 03:37:55 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:37:55 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 03:37:55 [INFO] exp_shallowmodel: f1_score:   0.449
12/10/2017 03:37:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:37:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.14      0.17        14
          C       0.55      0.60      0.57       164
          F       0.69      0.77      0.73       268
          R       0.41      0.27      0.33       125

avg / total       0.58      0.60      0.58       571

12/10/2017 03:37:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:37:55 [INFO] exp_shallowmodel: 
[[  2   2   7   3]
 [  1  98  40  25]
 [  2  38 207  21]
 [  5  41  45  34]]
12/10/2017 03:37:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 03:37:55 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:37:55 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:37:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:37:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:37:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:37:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:37:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:39:36 [INFO] exp_shallowmodel: train time: 101.370s
12/10/2017 03:39:36 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:39:36 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 03:39:36 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 03:39:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:39:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.74      0.66       164
          F       0.71      0.71      0.71       268
          R       0.44      0.30      0.36       125

avg / total       0.60      0.61      0.60       571

12/10/2017 03:39:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:39:36 [INFO] exp_shallowmodel: 
[[  0   1   7   6]
 [  4 121  23  16]
 [  6  45 190  27]
 [  3  36  48  38]]
12/10/2017 03:39:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 03:39:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:39:36 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:39:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:39:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:39:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:39:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:39:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:41:33 [INFO] exp_shallowmodel: train time: 116.668s
12/10/2017 03:41:33 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:41:33 [INFO] exp_shallowmodel: accuracy:   0.618
12/10/2017 03:41:33 [INFO] exp_shallowmodel: f1_score:   0.466
12/10/2017 03:41:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:41:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.60      0.68      0.64       164
          F       0.72      0.71      0.72       268
          R       0.43      0.40      0.42       125

avg / total       0.61      0.62      0.61       571

12/10/2017 03:41:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:41:33 [INFO] exp_shallowmodel: 
[[  1   2   4   7]
 [  2 111  23  28]
 [  0  47 191  30]
 [  5  24  46  50]]
12/10/2017 03:41:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 03:41:33 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:41:33 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:41:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:41:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:41:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:41:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:41:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:43:15 [INFO] exp_shallowmodel: train time: 101.421s
12/10/2017 03:43:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:43:15 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 03:43:15 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 03:43:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:43:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.56      0.67      0.61       169
          F       0.70      0.69      0.69       271
          R       0.44      0.35      0.39       130

avg / total       0.58      0.59      0.58       586

12/10/2017 03:43:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:43:15 [INFO] exp_shallowmodel: 
[[  0   1   9   6]
 [  3 114  28  24]
 [  3  53 187  28]
 [  3  37  44  46]]
12/10/2017 03:43:18 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 03:43:18 [INFO] task_runner: context=last, feature=6-w2v
12/10/2017 03:43:18 [INFO] task_runner: retained feature numbers=[9.1]
12/10/2017 03:43:18 [INFO] task_runner: #(data)=5934
12/10/2017 03:43:18 [INFO] task_runner: #(feature)=900
12/10/2017 03:43:18 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 03:43:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 03:43:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:43:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:43:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:43:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:43:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:43:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:43:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:45:16 [INFO] exp_shallowmodel: train time: 117.114s
12/10/2017 03:45:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:45:16 [INFO] exp_shallowmodel: accuracy:   0.600
12/10/2017 03:45:16 [INFO] exp_shallowmodel: f1_score:   0.430
12/10/2017 03:45:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:45:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.05      0.06        20
          C       0.54      0.63      0.58       169
          F       0.74      0.75      0.75       281
          R       0.36      0.30      0.33       122

avg / total       0.58      0.60      0.59       592

12/10/2017 03:45:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:45:16 [INFO] exp_shallowmodel: 
[[  1   2   8   9]
 [  2 106  33  28]
 [  4  39 212  26]
 [  4  49  33  36]]
12/10/2017 03:45:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 03:45:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:45:16 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:45:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:45:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:45:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:45:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:45:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:47:16 [INFO] exp_shallowmodel: train time: 120.033s
12/10/2017 03:47:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:47:16 [INFO] exp_shallowmodel: accuracy:   0.591
12/10/2017 03:47:16 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 03:47:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:47:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.63      0.58       169
          F       0.70      0.74      0.72       281
          R       0.43      0.29      0.34       122

avg / total       0.57      0.59      0.58       592

12/10/2017 03:47:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:47:16 [INFO] exp_shallowmodel: 
[[  0   3   9   8]
 [  4 107  39  19]
 [  0  54 208  19]
 [  5  39  43  35]]
12/10/2017 03:47:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 03:47:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:47:16 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:47:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:47:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:47:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:47:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:47:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:49:18 [INFO] exp_shallowmodel: train time: 122.031s
12/10/2017 03:49:18 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:49:18 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 03:49:18 [INFO] exp_shallowmodel: f1_score:   0.421
12/10/2017 03:49:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:49:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.10      0.14        20
          C       0.47      0.59      0.52       169
          F       0.70      0.71      0.70       281
          R       0.38      0.27      0.32       122

avg / total       0.55      0.56      0.55       592

12/10/2017 03:49:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:49:18 [INFO] exp_shallowmodel: 
[[  2   7  10   1]
 [  5 100  35  29]
 [  0  59 199  23]
 [  2  47  40  33]]
12/10/2017 03:49:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 03:49:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:49:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:49:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:49:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:49:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:49:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:49:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:51:29 [INFO] exp_shallowmodel: train time: 130.737s
12/10/2017 03:51:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:51:29 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 03:51:29 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 03:51:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:51:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.63      0.57       169
          F       0.70      0.72      0.71       281
          R       0.35      0.25      0.30       122

avg / total       0.55      0.57      0.56       592

12/10/2017 03:51:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:51:29 [INFO] exp_shallowmodel: 
[[  0   5   6   9]
 [  1 106  41  21]
 [  1  51 202  27]
 [  8  42  41  31]]
12/10/2017 03:51:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 03:51:29 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:51:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:51:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:51:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:51:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:51:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:51:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:53:27 [INFO] exp_shallowmodel: train time: 117.743s
12/10/2017 03:53:27 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:53:27 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 03:53:27 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 03:53:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:53:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.53      0.53       169
          F       0.69      0.74      0.71       281
          R       0.35      0.32      0.34       122

avg / total       0.55      0.57      0.56       592

12/10/2017 03:53:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:53:27 [INFO] exp_shallowmodel: 
[[  0   2   8  10]
 [  4  89  46  30]
 [  4  39 207  31]
 [  3  40  40  39]]
12/10/2017 03:53:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 03:53:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:53:27 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:53:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:53:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:53:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:53:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:53:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:55:26 [INFO] exp_shallowmodel: train time: 119.433s
12/10/2017 03:55:26 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:55:26 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 03:55:26 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 03:55:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:55:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.60      0.56       169
          F       0.68      0.75      0.71       281
          R       0.38      0.25      0.30       122

avg / total       0.55      0.58      0.56       592

12/10/2017 03:55:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:55:26 [INFO] exp_shallowmodel: 
[[  0   5   7   8]
 [  2 101  46  20]
 [  2  48 210  21]
 [ 11  35  46  30]]
12/10/2017 03:55:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 03:55:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:55:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:55:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:55:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:55:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:55:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:55:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:57:20 [INFO] exp_shallowmodel: train time: 113.678s
12/10/2017 03:57:20 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 03:57:20 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 03:57:20 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 03:57:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:57:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.06        20
          C       0.48      0.54      0.51       169
          F       0.69      0.72      0.70       281
          R       0.37      0.29      0.32       122

avg / total       0.54      0.56      0.55       592

12/10/2017 03:57:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:57:20 [INFO] exp_shallowmodel: 
[[  1   6   6   7]
 [  3  91  44  31]
 [  7  50 202  22]
 [  5  41  41  35]]
12/10/2017 03:57:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 03:57:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:57:20 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:57:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:57:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:57:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:57:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:57:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:59:29 [INFO] exp_shallowmodel: train time: 128.365s
12/10/2017 03:59:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:59:29 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 03:59:29 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 03:59:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:59:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.10      0.11        20
          C       0.52      0.54      0.53       169
          F       0.69      0.75      0.72       281
          R       0.41      0.33      0.36       122

avg / total       0.57      0.58      0.57       592

12/10/2017 03:59:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:59:29 [INFO] exp_shallowmodel: 
[[  2   5   7   6]
 [  4  92  43  30]
 [  3  46 210  22]
 [  6  33  43  40]]
12/10/2017 03:59:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 03:59:29 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 03:59:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:59:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:59:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:59:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:59:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:59:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:01:30 [INFO] exp_shallowmodel: train time: 121.061s
12/10/2017 04:01:30 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:01:30 [INFO] exp_shallowmodel: accuracy:   0.568
12/10/2017 04:01:30 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 04:01:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:01:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.05      0.07        20
          C       0.49      0.60      0.54       169
          F       0.70      0.71      0.70       281
          R       0.38      0.27      0.32       122

avg / total       0.55      0.57      0.56       592

12/10/2017 04:01:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:01:30 [INFO] exp_shallowmodel: 
[[  1   4   8   7]
 [  3 102  37  27]
 [  1  60 200  20]
 [  3  44  42  33]]
12/10/2017 04:01:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 04:01:30 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:01:30 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:01:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:01:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:01:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:01:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:01:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:03:46 [INFO] exp_shallowmodel: train time: 135.979s
12/10/2017 04:03:46 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:03:46 [INFO] exp_shallowmodel: accuracy:   0.589
12/10/2017 04:03:46 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 04:03:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:03:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.07      0.10        28
          C       0.53      0.65      0.58       172
          F       0.72      0.75      0.74       283
          R       0.35      0.24      0.29       123

avg / total       0.56      0.59      0.57       606

12/10/2017 04:03:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:03:46 [INFO] exp_shallowmodel: 
[[  2   6   7  13]
 [  0 112  37  23]
 [  5  46 213  19]
 [  6  48  39  30]]
12/10/2017 04:03:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 04:03:46 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:03:46 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:03:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:03:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:03:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:03:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:03:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:05:55 [INFO] exp_shallowmodel: train time: 128.497s
12/10/2017 04:05:55 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:05:55 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 04:05:55 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 04:05:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:05:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.64      0.59       169
          F       0.75      0.75      0.75       281
          R       0.41      0.32      0.36       122

avg / total       0.59      0.61      0.60       592

12/10/2017 04:05:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:05:55 [INFO] exp_shallowmodel: 
[[  0   4   6  10]
 [  1 109  33  26]
 [  4  45 211  21]
 [  7  44  32  39]]
12/10/2017 04:05:55 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 04:05:55 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:05:55 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:05:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:05:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:05:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:05:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:05:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:07:50 [INFO] exp_shallowmodel: train time: 115.447s
12/10/2017 04:07:50 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:07:50 [INFO] exp_shallowmodel: accuracy:   0.549
12/10/2017 04:07:50 [INFO] exp_shallowmodel: f1_score:   0.406
12/10/2017 04:07:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:07:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.10      0.11        20
          C       0.49      0.49      0.49       169
          F       0.66      0.73      0.69       281
          R       0.37      0.30      0.33       122

avg / total       0.53      0.55      0.54       592

12/10/2017 04:07:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:07:50 [INFO] exp_shallowmodel: 
[[  2   6   5   7]
 [  4  83  56  26]
 [  4  44 204  29]
 [  5  37  44  36]]
12/10/2017 04:07:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 04:07:50 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:07:50 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:07:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:07:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:07:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:07:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:07:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:10:00 [INFO] exp_shallowmodel: train time: 129.428s
12/10/2017 04:10:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:10:00 [INFO] exp_shallowmodel: accuracy:   0.557
12/10/2017 04:10:00 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 04:10:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:10:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.06        20
          C       0.51      0.56      0.53       169
          F       0.68      0.74      0.71       281
          R       0.31      0.22      0.26       122

avg / total       0.54      0.56      0.54       592

12/10/2017 04:10:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:10:00 [INFO] exp_shallowmodel: 
[[  1   6   5   8]
 [  4  94  46  25]
 [  4  43 208  26]
 [  7  42  46  27]]
12/10/2017 04:10:00 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 04:10:00 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:10:00 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:10:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:10:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:10:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:10:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:10:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:12:03 [INFO] exp_shallowmodel: train time: 123.084s
12/10/2017 04:12:03 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:12:03 [INFO] exp_shallowmodel: accuracy:   0.584
12/10/2017 04:12:03 [INFO] exp_shallowmodel: f1_score:   0.406
12/10/2017 04:12:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:12:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.57      0.54       169
          F       0.70      0.75      0.72       281
          R       0.41      0.32      0.36       122

avg / total       0.56      0.58      0.57       592

12/10/2017 04:12:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:12:03 [INFO] exp_shallowmodel: 
[[  0   4   9   7]
 [  4  97  43  25]
 [  1  45 210  25]
 [  2  41  40  39]]
12/10/2017 04:12:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 04:12:03 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:12:03 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:12:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:12:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:12:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:12:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:12:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:14:05 [INFO] exp_shallowmodel: train time: 122.096s
12/10/2017 04:14:05 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:14:05 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 04:14:05 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 04:14:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:14:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.10      0.12        20
          C       0.48      0.51      0.50       169
          F       0.69      0.75      0.72       281
          R       0.39      0.30      0.33       122

avg / total       0.55      0.57      0.56       592

12/10/2017 04:14:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:14:05 [INFO] exp_shallowmodel: 
[[  2   4  10   4]
 [  2  87  44  36]
 [  4  48 212  17]
 [  5  41  40  36]]
12/10/2017 04:14:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 04:14:05 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:14:05 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:14:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:14:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:14:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:14:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:14:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:16:08 [INFO] exp_shallowmodel: train time: 123.024s
12/10/2017 04:16:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:16:08 [INFO] exp_shallowmodel: accuracy:   0.557
12/10/2017 04:16:08 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 04:16:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:16:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.54      0.52       169
          F       0.67      0.72      0.69       281
          R       0.38      0.30      0.33       122

avg / total       0.54      0.56      0.55       592

12/10/2017 04:16:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:16:08 [INFO] exp_shallowmodel: 
[[  0   6   7   7]
 [  2  91  52  24]
 [  8  41 203  29]
 [  1  42  43  36]]
12/10/2017 04:16:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 04:16:09 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:16:09 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:16:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:16:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:16:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:16:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:16:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:18:13 [INFO] exp_shallowmodel: train time: 123.978s
12/10/2017 04:18:13 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:18:13 [INFO] exp_shallowmodel: accuracy:   0.591
12/10/2017 04:18:13 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 04:18:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:18:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.62      0.56       169
          F       0.71      0.75      0.73       281
          R       0.41      0.28      0.33       122

avg / total       0.57      0.59      0.58       592

12/10/2017 04:18:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:18:13 [INFO] exp_shallowmodel: 
[[  0   3   7  10]
 [  2 104  39  24]
 [  5  49 212  15]
 [  3  44  41  34]]
12/10/2017 04:18:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 04:18:13 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:18:13 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:18:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:18:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:18:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:18:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:18:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:20:11 [INFO] exp_shallowmodel: train time: 118.620s
12/10/2017 04:20:11 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:20:11 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 04:20:11 [INFO] exp_shallowmodel: f1_score:   0.440
12/10/2017 04:20:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:20:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.10      0.13        20
          C       0.54      0.67      0.60       169
          F       0.71      0.70      0.71       281
          R       0.37      0.28      0.32       122

avg / total       0.57      0.59      0.58       592

12/10/2017 04:20:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:20:11 [INFO] exp_shallowmodel: 
[[  2   3   5  10]
 [  2 114  32  21]
 [  3  53 198  27]
 [  3  41  44  34]]
12/10/2017 04:20:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 04:20:11 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:20:11 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:20:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:20:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:20:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:20:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:20:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:22:07 [INFO] exp_shallowmodel: train time: 115.235s
12/10/2017 04:22:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:22:07 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 04:22:07 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 04:22:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:22:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.60      0.56       169
          F       0.68      0.73      0.70       281
          R       0.36      0.26      0.30       122

avg / total       0.55      0.57      0.55       592

12/10/2017 04:22:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:22:07 [INFO] exp_shallowmodel: 
[[  0   5   8   7]
 [  1 101  37  30]
 [  2  55 204  20]
 [  6  33  51  32]]
12/10/2017 04:22:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 04:22:07 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:22:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:22:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:22:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:22:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:22:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:22:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:24:27 [INFO] exp_shallowmodel: train time: 140.004s
12/10/2017 04:24:27 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:24:27 [INFO] exp_shallowmodel: accuracy:   0.586
12/10/2017 04:24:27 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 04:24:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:24:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        28
          C       0.50      0.64      0.56       172
          F       0.72      0.75      0.73       283
          R       0.39      0.26      0.31       123

avg / total       0.57      0.59      0.57       606

12/10/2017 04:24:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:24:27 [INFO] exp_shallowmodel: 
[[  2   9   7  10]
 [  4 110  38  20]
 [  3  49 211  20]
 [  5  50  36  32]]
12/10/2017 04:24:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 04:24:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:24:27 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:24:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:24:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:24:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:24:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:24:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:26:27 [INFO] exp_shallowmodel: train time: 120.093s
12/10/2017 04:26:27 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:26:27 [INFO] exp_shallowmodel: accuracy:   0.595
12/10/2017 04:26:27 [INFO] exp_shallowmodel: f1_score:   0.454
12/10/2017 04:26:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:26:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.20      0.22        20
          C       0.50      0.68      0.58       169
          F       0.75      0.73      0.74       281
          R       0.40      0.22      0.28       122

avg / total       0.59      0.59      0.58       592

12/10/2017 04:26:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:26:27 [INFO] exp_shallowmodel: 
[[  4   3   7   6]
 [  3 115  31  20]
 [  2  58 206  15]
 [  8  55  32  27]]
12/10/2017 04:26:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 04:26:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:26:27 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:26:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:26:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:26:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:26:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:26:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:28:21 [INFO] exp_shallowmodel: train time: 113.931s
12/10/2017 04:28:21 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:28:21 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 04:28:21 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 04:28:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:28:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.62      0.54       169
          F       0.71      0.71      0.71       281
          R       0.43      0.30      0.35       122

avg / total       0.56      0.57      0.56       592

12/10/2017 04:28:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:28:21 [INFO] exp_shallowmodel: 
[[  0   6   7   7]
 [  5 104  40  20]
 [  3  58 199  21]
 [  5  45  36  36]]
12/10/2017 04:28:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 04:28:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:28:21 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:28:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:28:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:28:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:28:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:28:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:30:22 [INFO] exp_shallowmodel: train time: 120.922s
12/10/2017 04:30:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:30:22 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 04:30:22 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 04:30:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:30:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.59      0.55       169
          F       0.67      0.75      0.71       281
          R       0.41      0.25      0.31       122

avg / total       0.55      0.57      0.56       592

12/10/2017 04:30:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:30:22 [INFO] exp_shallowmodel: 
[[  0   6  12   2]
 [  6  99  44  20]
 [  3  47 210  21]
 [  8  38  46  30]]
12/10/2017 04:30:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 04:30:22 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:30:22 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:30:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:30:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:30:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:30:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:30:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:32:21 [INFO] exp_shallowmodel: train time: 118.356s
12/10/2017 04:32:21 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:32:21 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 04:32:21 [INFO] exp_shallowmodel: f1_score:   0.439
12/10/2017 04:32:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:32:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.55      0.60      0.57       169
          F       0.69      0.76      0.72       281
          R       0.43      0.34      0.38       122

avg / total       0.58      0.60      0.59       592

12/10/2017 04:32:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:32:21 [INFO] exp_shallowmodel: 
[[  1   5   8   6]
 [  2 101  41  25]
 [  0  44 213  24]
 [  1  34  46  41]]
12/10/2017 04:32:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 04:32:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:32:21 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:32:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:32:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:32:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:32:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:32:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:34:19 [INFO] exp_shallowmodel: train time: 118.484s
12/10/2017 04:34:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:34:19 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 04:34:19 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 04:34:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:34:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.05      0.07        20
          C       0.50      0.62      0.55       169
          F       0.71      0.71      0.71       281
          R       0.36      0.28      0.31       122

avg / total       0.56      0.57      0.56       592

12/10/2017 04:34:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:34:19 [INFO] exp_shallowmodel: 
[[  1   2   8   9]
 [  1 104  37  27]
 [  5  52 199  25]
 [  3  50  35  34]]
12/10/2017 04:34:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 04:34:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:34:20 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:34:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:34:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:34:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:34:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:34:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:36:24 [INFO] exp_shallowmodel: train time: 124.085s
12/10/2017 04:36:24 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:36:24 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 04:36:24 [INFO] exp_shallowmodel: f1_score:   0.379
12/10/2017 04:36:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:36:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.57      0.52       169
          F       0.70      0.73      0.71       281
          R       0.32      0.25      0.28       122

avg / total       0.54      0.56      0.55       592

12/10/2017 04:36:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:36:24 [INFO] exp_shallowmodel: 
[[  0   5   7   8]
 [  1  97  40  31]
 [  3  49 204  25]
 [  3  50  39  30]]
12/10/2017 04:36:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 04:36:24 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:36:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:36:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:36:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:36:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:36:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:36:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:38:27 [INFO] exp_shallowmodel: train time: 123.394s
12/10/2017 04:38:27 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:38:27 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 04:38:27 [INFO] exp_shallowmodel: f1_score:   0.460
12/10/2017 04:38:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:38:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.10      0.10        20
          C       0.58      0.65      0.61       169
          F       0.72      0.74      0.73       281
          R       0.45      0.35      0.40       122

avg / total       0.60      0.61      0.61       592

12/10/2017 04:38:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:38:27 [INFO] exp_shallowmodel: 
[[  2   5   9   4]
 [  4 110  32  23]
 [  4  45 207  25]
 [  9  31  39  43]]
12/10/2017 04:38:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 04:38:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:38:27 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:38:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:38:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:38:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:38:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:38:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:40:25 [INFO] exp_shallowmodel: train time: 117.820s
12/10/2017 04:40:25 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:40:25 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 04:40:25 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 04:40:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:40:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.05      0.06        20
          C       0.51      0.56      0.53       169
          F       0.70      0.73      0.71       281
          R       0.33      0.28      0.30       122

avg / total       0.55      0.57      0.56       592

12/10/2017 04:40:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:40:25 [INFO] exp_shallowmodel: 
[[  1   7   4   8]
 [  5  94  41  29]
 [  1  43 206  31]
 [  4  39  45  34]]
12/10/2017 04:40:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 04:40:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:40:25 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:40:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:40:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:40:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:40:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:40:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:42:30 [INFO] exp_shallowmodel: train time: 124.661s
12/10/2017 04:42:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:42:30 [INFO] exp_shallowmodel: accuracy:   0.596
12/10/2017 04:42:30 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 04:42:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:42:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.66      0.59       169
          F       0.74      0.72      0.73       281
          R       0.39      0.34      0.36       122

avg / total       0.58      0.60      0.59       592

12/10/2017 04:42:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:42:30 [INFO] exp_shallowmodel: 
[[  0   5   8   7]
 [  2 111  27  29]
 [  2  51 201  27]
 [  3  43  35  41]]
12/10/2017 04:42:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 04:42:30 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:42:30 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:42:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:42:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:42:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:42:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:42:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:44:35 [INFO] exp_shallowmodel: train time: 124.674s
12/10/2017 04:44:35 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:44:35 [INFO] exp_shallowmodel: accuracy:   0.589
12/10/2017 04:44:35 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 04:44:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:44:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        28
          C       0.55      0.60      0.57       172
          F       0.71      0.76      0.74       283
          R       0.34      0.29      0.32       123

avg / total       0.57      0.59      0.58       606

12/10/2017 04:44:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:44:35 [INFO] exp_shallowmodel: 
[[  2   5   7  14]
 [  3 103  39  27]
 [  2  37 216  28]
 [  3  43  41  36]]
12/10/2017 04:44:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 04:44:35 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:44:35 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:44:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:44:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:44:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:44:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:44:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:46:38 [INFO] exp_shallowmodel: train time: 122.512s
12/10/2017 04:46:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:46:38 [INFO] exp_shallowmodel: accuracy:   0.600
12/10/2017 04:46:38 [INFO] exp_shallowmodel: f1_score:   0.438
12/10/2017 04:46:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:46:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.10      0.12        20
          C       0.53      0.62      0.57       169
          F       0.71      0.77      0.74       281
          R       0.43      0.26      0.33       122

avg / total       0.58      0.60      0.58       592

12/10/2017 04:46:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:46:38 [INFO] exp_shallowmodel: 
[[  2   6   5   7]
 [  5 105  40  19]
 [  3  46 216  16]
 [  4  42  44  32]]
12/10/2017 04:46:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 04:46:38 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:46:38 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:46:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:46:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:46:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:46:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:46:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:48:37 [INFO] exp_shallowmodel: train time: 119.389s
12/10/2017 04:48:37 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:48:37 [INFO] exp_shallowmodel: accuracy:   0.586
12/10/2017 04:48:37 [INFO] exp_shallowmodel: f1_score:   0.443
12/10/2017 04:48:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:48:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.15      0.16        20
          C       0.53      0.57      0.55       169
          F       0.72      0.75      0.73       281
          R       0.37      0.30      0.33       122

avg / total       0.57      0.59      0.58       592

12/10/2017 04:48:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:48:37 [INFO] exp_shallowmodel: 
[[  3   4   4   9]
 [  3  96  41  29]
 [  4  42 212  23]
 [  7  40  39  36]]
12/10/2017 04:48:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 04:48:37 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:48:37 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:48:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:48:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:48:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:48:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:48:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:50:38 [INFO] exp_shallowmodel: train time: 120.440s
12/10/2017 04:50:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:50:38 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 04:50:38 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 04:50:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:50:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.05      0.08        20
          C       0.51      0.57      0.53       169
          F       0.71      0.70      0.71       281
          R       0.35      0.34      0.35       122

avg / total       0.56      0.57      0.56       592

12/10/2017 04:50:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:50:38 [INFO] exp_shallowmodel: 
[[  1   2   9   8]
 [  0  96  35  38]
 [  2  50 198  31]
 [  3  42  35  42]]
12/10/2017 04:50:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 04:50:38 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:50:38 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:50:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:50:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:50:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:50:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:50:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:52:41 [INFO] exp_shallowmodel: train time: 123.434s
12/10/2017 04:52:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:52:41 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 04:52:41 [INFO] exp_shallowmodel: f1_score:   0.437
12/10/2017 04:52:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:52:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.16      0.15      0.15        20
          C       0.50      0.64      0.56       169
          F       0.71      0.66      0.69       281
          R       0.40      0.30      0.34       122

avg / total       0.57      0.57      0.56       592

12/10/2017 04:52:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:52:41 [INFO] exp_shallowmodel: 
[[  3   3   8   6]
 [  4 109  33  23]
 [  4  64 186  27]
 [  8  42  35  37]]
12/10/2017 04:52:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 04:52:41 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:52:41 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:52:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:52:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:52:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:52:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:52:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:54:49 [INFO] exp_shallowmodel: train time: 128.036s
12/10/2017 04:54:49 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:54:49 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 04:54:49 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 04:54:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:54:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.50      0.63      0.55       169
          F       0.71      0.70      0.71       281
          R       0.37      0.26      0.31       122

avg / total       0.56      0.57      0.56       592

12/10/2017 04:54:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:54:49 [INFO] exp_shallowmodel: 
[[  1   8   5   6]
 [  2 106  34  27]
 [  4  58 198  21]
 [  8  41  41  32]]
12/10/2017 04:54:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 04:54:50 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:54:50 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:54:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:54:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:54:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:54:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:54:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:56:49 [INFO] exp_shallowmodel: train time: 119.707s
12/10/2017 04:56:49 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:56:49 [INFO] exp_shallowmodel: accuracy:   0.586
12/10/2017 04:56:49 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 04:56:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:56:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.62      0.56       169
          F       0.72      0.74      0.73       281
          R       0.35      0.28      0.31       122

avg / total       0.56      0.59      0.57       592

12/10/2017 04:56:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:56:49 [INFO] exp_shallowmodel: 
[[  0   5   7   8]
 [  0 104  35  30]
 [  3  45 209  24]
 [  2  48  38  34]]
12/10/2017 04:56:49 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 04:56:49 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:56:49 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:56:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:56:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:56:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:56:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:56:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:58:56 [INFO] exp_shallowmodel: train time: 126.105s
12/10/2017 04:58:56 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:58:56 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 04:58:56 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 04:58:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:58:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.05      0.06        20
          C       0.49      0.60      0.54       169
          F       0.69      0.75      0.72       281
          R       0.38      0.22      0.28       122

avg / total       0.55      0.57      0.55       592

12/10/2017 04:58:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:58:56 [INFO] exp_shallowmodel: 
[[  1   6   7   6]
 [  4 101  47  17]
 [  2  47 210  22]
 [  4  52  39  27]]
12/10/2017 04:58:56 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 04:58:56 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:58:56 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:58:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:58:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:58:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:58:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:58:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:01:02 [INFO] exp_shallowmodel: train time: 125.945s
12/10/2017 05:01:02 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:01:02 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 05:01:02 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 05:01:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:01:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.62      0.56       169
          F       0.73      0.74      0.73       281
          R       0.40      0.30      0.34       122

avg / total       0.58      0.59      0.58       592

12/10/2017 05:01:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:01:02 [INFO] exp_shallowmodel: 
[[  0   2   8  10]
 [  5 104  33  27]
 [  3  52 207  19]
 [  6  42  37  37]]
12/10/2017 05:01:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 05:01:02 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:01:02 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:01:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:01:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:01:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:01:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:01:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:03:03 [INFO] exp_shallowmodel: train time: 120.710s
12/10/2017 05:03:03 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:03:03 [INFO] exp_shallowmodel: accuracy:   0.556
12/10/2017 05:03:03 [INFO] exp_shallowmodel: f1_score:   0.378
12/10/2017 05:03:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:03:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.51      0.50       169
          F       0.69      0.74      0.71       281
          R       0.33      0.27      0.30       122

avg / total       0.53      0.56      0.54       592

12/10/2017 05:03:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:03:03 [INFO] exp_shallowmodel: 
[[  0   7   5   8]
 [  4  87  43  35]
 [  2  45 209  25]
 [  4  38  47  33]]
12/10/2017 05:03:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 05:03:03 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 05:03:03 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:03:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:03:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:03:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:03:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:03:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:05:08 [INFO] exp_shallowmodel: train time: 124.930s
12/10/2017 05:05:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:05:08 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 05:05:08 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 05:05:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:05:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.50      0.58      0.54       172
          F       0.71      0.71      0.71       283
          R       0.38      0.37      0.37       123

avg / total       0.55      0.57      0.56       606

12/10/2017 05:05:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:05:08 [INFO] exp_shallowmodel: 
[[  0   3  13  12]
 [  3  99  34  36]
 [  1  56 201  25]
 [  4  39  35  45]]
12/10/2017 05:05:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 05:05:08 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:05:08 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:05:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:05:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:05:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:05:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:05:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:07:10 [INFO] exp_shallowmodel: train time: 121.914s
12/10/2017 05:07:10 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:07:10 [INFO] exp_shallowmodel: accuracy:   0.596
12/10/2017 05:07:10 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 05:07:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:07:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.53      0.57      0.55       169
          F       0.70      0.76      0.73       281
          R       0.46      0.34      0.39       122

avg / total       0.58      0.60      0.58       592

12/10/2017 05:07:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:07:10 [INFO] exp_shallowmodel: 
[[  1   4   8   7]
 [  5  97  47  20]
 [  0  45 214  22]
 [  6  37  38  41]]
12/10/2017 05:07:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 05:07:10 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:07:10 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:07:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:07:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:07:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:07:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:07:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:09:08 [INFO] exp_shallowmodel: train time: 117.716s
12/10/2017 05:09:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:09:08 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 05:09:08 [INFO] exp_shallowmodel: f1_score:   0.388
12/10/2017 05:09:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:09:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.56      0.54       169
          F       0.68      0.74      0.71       281
          R       0.34      0.27      0.30       122

avg / total       0.54      0.57      0.55       592

12/10/2017 05:09:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:09:08 [INFO] exp_shallowmodel: 
[[  0   4   4  12]
 [  5  94  44  26]
 [  4  43 208  26]
 [  1  36  52  33]]
12/10/2017 05:09:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 05:09:08 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:09:08 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:09:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:09:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:09:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:09:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:09:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:11:14 [INFO] exp_shallowmodel: train time: 126.515s
12/10/2017 05:11:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:11:14 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 05:11:14 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 05:11:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:11:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.62      0.55       169
          F       0.72      0.71      0.72       281
          R       0.37      0.27      0.31       122

avg / total       0.56      0.57      0.56       592

12/10/2017 05:11:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:11:14 [INFO] exp_shallowmodel: 
[[  0   9   7   4]
 [  1 105  36  27]
 [  5  51 200  25]
 [  6  49  34  33]]
12/10/2017 05:11:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 05:11:14 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:11:14 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:11:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:11:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:11:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:11:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:11:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:13:07 [INFO] exp_shallowmodel: train time: 113.106s
12/10/2017 05:13:08 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:13:08 [INFO] exp_shallowmodel: accuracy:   0.549
12/10/2017 05:13:08 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 05:13:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:13:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.49      0.62      0.55       169
          F       0.70      0.67      0.69       281
          R       0.32      0.25      0.28       122

avg / total       0.54      0.55      0.54       592

12/10/2017 05:13:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:13:08 [INFO] exp_shallowmodel: 
[[  1   5   7   7]
 [  4 105  35  25]
 [  6  55 189  31]
 [  3  51  38  30]]
12/10/2017 05:13:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 05:13:08 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:13:08 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:13:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:13:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:13:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:13:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:13:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:15:17 [INFO] exp_shallowmodel: train time: 129.671s
12/10/2017 05:15:17 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:15:17 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 05:15:17 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 05:15:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:15:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.51      0.49       169
          F       0.73      0.76      0.74       281
          R       0.34      0.27      0.30       122

avg / total       0.55      0.56      0.55       592

12/10/2017 05:15:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:15:17 [INFO] exp_shallowmodel: 
[[  0   4   7   9]
 [  6  87  37  39]
 [  4  49 213  15]
 [  5  48  36  33]]
12/10/2017 05:15:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 05:15:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:15:17 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:15:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:15:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:15:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:15:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:15:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:17:14 [INFO] exp_shallowmodel: train time: 116.754s
12/10/2017 05:17:14 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:17:14 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 05:17:14 [INFO] exp_shallowmodel: f1_score:   0.447
12/10/2017 05:17:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:17:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.20      0.22        20
          C       0.52      0.60      0.56       169
          F       0.69      0.70      0.70       281
          R       0.37      0.28      0.32       122

avg / total       0.56      0.57      0.56       592

12/10/2017 05:17:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:17:14 [INFO] exp_shallowmodel: 
[[  4   5   8   3]
 [  2 102  36  29]
 [  3  53 198  27]
 [  8  36  44  34]]
12/10/2017 05:17:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 05:17:14 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:17:14 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:17:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:17:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:17:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:17:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:17:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:19:24 [INFO] exp_shallowmodel: train time: 129.809s
12/10/2017 05:19:24 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:19:24 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 05:19:24 [INFO] exp_shallowmodel: f1_score:   0.418
12/10/2017 05:19:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:19:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.54      0.55      0.55       169
          F       0.71      0.76      0.73       281
          R       0.36      0.31      0.33       122

avg / total       0.57      0.58      0.57       592

12/10/2017 05:19:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:19:24 [INFO] exp_shallowmodel: 
[[  1   3  11   5]
 [  2  93  37  37]
 [  2  39 213  27]
 [  8  36  40  38]]
12/10/2017 05:19:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 05:19:24 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:19:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:19:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:19:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:19:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:19:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:19:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:21:25 [INFO] exp_shallowmodel: train time: 120.182s
12/10/2017 05:21:25 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:21:25 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 05:21:25 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 05:21:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:21:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.05      0.06        20
          C       0.52      0.60      0.55       169
          F       0.70      0.73      0.72       281
          R       0.31      0.22      0.26       122

avg / total       0.55      0.57      0.55       592

12/10/2017 05:21:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:21:25 [INFO] exp_shallowmodel: 
[[  1   3   6  10]
 [  5 101  35  28]
 [  3  49 206  23]
 [  7  42  46  27]]
12/10/2017 05:21:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 05:21:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:21:25 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:21:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:21:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:21:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:21:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:21:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:23:44 [INFO] exp_shallowmodel: train time: 139.141s
12/10/2017 05:23:44 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:23:44 [INFO] exp_shallowmodel: accuracy:   0.593
12/10/2017 05:23:44 [INFO] exp_shallowmodel: f1_score:   0.443
12/10/2017 05:23:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:23:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.10      0.14        20
          C       0.49      0.57      0.53       169
          F       0.73      0.76      0.74       281
          R       0.41      0.32      0.36       122

avg / total       0.58      0.59      0.58       592

12/10/2017 05:23:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:23:44 [INFO] exp_shallowmodel: 
[[  2   8   4   6]
 [  1  96  41  31]
 [  3  45 214  19]
 [  3  45  35  39]]
12/10/2017 05:23:44 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 05:23:44 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 05:23:44 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:23:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:23:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:23:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:23:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:23:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:25:45 [INFO] exp_shallowmodel: train time: 120.778s
12/10/2017 05:25:45 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:25:45 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 05:25:45 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 05:25:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:25:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        28
          C       0.48      0.64      0.55       172
          F       0.68      0.71      0.70       283
          R       0.32      0.20      0.24       123

avg / total       0.53      0.55      0.53       606

12/10/2017 05:25:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:25:45 [INFO] exp_shallowmodel: 
[[  1  10   9   8]
 [  3 110  38  21]
 [  4  57 201  21]
 [  0  52  47  24]]
12/10/2017 05:25:50 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 05:25:50 [INFO] task_runner: context=last, feature=6-w2v
12/10/2017 05:25:50 [INFO] task_runner: retained feature numbers=[9.1]
12/10/2017 05:25:50 [INFO] task_runner: #(data)=3530
12/10/2017 05:25:50 [INFO] task_runner: #(feature)=900
12/10/2017 05:25:50 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 05:25:50 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 05:25:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:25:50 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:25:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:25:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:25:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:25:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:25:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:26:23 [INFO] exp_shallowmodel: train time: 33.291s
12/10/2017 05:26:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:26:23 [INFO] exp_shallowmodel: accuracy:   0.628
12/10/2017 05:26:23 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 05:26:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:26:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.04      0.05        23
          C       0.30      0.22      0.26        27
          F       0.76      0.82      0.79       250
          R       0.20      0.17      0.19        52

avg / total       0.59      0.63      0.61       352

12/10/2017 05:26:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:26:23 [INFO] exp_shallowmodel: 
[[  1   1  12   9]
 [  1   6  16   4]
 [ 13  10 205  22]
 [  2   3  38   9]]
12/10/2017 05:26:24 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 05:26:24 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:26:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:26:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:26:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:26:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:26:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:26:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:26:56 [INFO] exp_shallowmodel: train time: 31.978s
12/10/2017 05:26:56 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:26:56 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 05:26:56 [INFO] exp_shallowmodel: f1_score:   0.335
12/10/2017 05:26:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:26:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.13      0.13        23
          C       0.22      0.19      0.20        27
          F       0.77      0.80      0.78       250
          R       0.23      0.21      0.22        52

avg / total       0.61      0.62      0.61       352

12/10/2017 05:26:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:26:56 [INFO] exp_shallowmodel: 
[[  3   1  12   7]
 [  4   5  15   3]
 [ 11  13 200  26]
 [  4   4  33  11]]
12/10/2017 05:26:56 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 05:26:56 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:26:56 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:26:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:26:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:26:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:26:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:26:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:27:29 [INFO] exp_shallowmodel: train time: 33.345s
12/10/2017 05:27:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:27:29 [INFO] exp_shallowmodel: accuracy:   0.651
12/10/2017 05:27:29 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 05:27:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:27:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.17      0.17        23
          C       0.11      0.07      0.09        27
          F       0.79      0.84      0.81       250
          R       0.29      0.23      0.26        52

avg / total       0.62      0.65      0.63       352

12/10/2017 05:27:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:27:29 [INFO] exp_shallowmodel: 
[[  4   2  13   4]
 [  3   2  17   5]
 [  9   9 211  21]
 [  8   5  27  12]]
12/10/2017 05:27:29 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 05:27:29 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:27:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:27:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:27:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:27:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:27:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:27:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:28:02 [INFO] exp_shallowmodel: train time: 32.567s
12/10/2017 05:28:02 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:28:02 [INFO] exp_shallowmodel: accuracy:   0.645
12/10/2017 05:28:02 [INFO] exp_shallowmodel: f1_score:   0.372
12/10/2017 05:28:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:28:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.17      0.22        23
          C       0.24      0.22      0.23        27
          F       0.76      0.82      0.79       250
          R       0.29      0.23      0.26        52

avg / total       0.62      0.64      0.63       352

12/10/2017 05:28:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:28:02 [INFO] exp_shallowmodel: 
[[  4   1  14   4]
 [  1   6  18   2]
 [  7  14 205  24]
 [  2   4  34  12]]
12/10/2017 05:28:02 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 05:28:02 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:28:02 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:28:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:28:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:28:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:28:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:28:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:28:35 [INFO] exp_shallowmodel: train time: 32.863s
12/10/2017 05:28:35 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:28:35 [INFO] exp_shallowmodel: accuracy:   0.577
12/10/2017 05:28:35 [INFO] exp_shallowmodel: f1_score:   0.271
12/10/2017 05:28:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:28:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.09      0.10        23
          C       0.10      0.07      0.09        27
          F       0.73      0.76      0.74       250
          R       0.16      0.15      0.16        52

avg / total       0.55      0.58      0.56       352

12/10/2017 05:28:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:28:35 [INFO] exp_shallowmodel: 
[[  2   5  14   2]
 [  0   2  22   3]
 [ 12   9 191  38]
 [  4   4  36   8]]
12/10/2017 05:28:35 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 05:28:35 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:28:35 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:28:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:28:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:28:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:28:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:28:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:29:07 [INFO] exp_shallowmodel: train time: 32.757s
12/10/2017 05:29:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:29:07 [INFO] exp_shallowmodel: accuracy:   0.648
12/10/2017 05:29:07 [INFO] exp_shallowmodel: f1_score:   0.370
12/10/2017 05:29:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:29:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.17      0.21        23
          C       0.23      0.22      0.23        27
          F       0.78      0.82      0.80       250
          R       0.26      0.23      0.24        52

avg / total       0.63      0.65      0.64       352

12/10/2017 05:29:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:29:07 [INFO] exp_shallowmodel: 
[[  4   4  10   5]
 [  0   6  17   4]
 [  9   9 206  26]
 [  2   7  31  12]]
12/10/2017 05:29:07 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 05:29:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:29:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:29:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:29:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:29:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:29:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:29:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:29:41 [INFO] exp_shallowmodel: train time: 33.087s
12/10/2017 05:29:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:29:41 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 05:29:41 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 05:29:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:29:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.04      0.05        23
          C       0.26      0.30      0.28        27
          F       0.77      0.81      0.79       250
          R       0.16      0.12      0.13        52

avg / total       0.59      0.62      0.60       352

12/10/2017 05:29:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:29:41 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  1   8  14   4]
 [ 10  13 203  24]
 [  6   9  31   6]]
12/10/2017 05:29:41 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 05:29:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:29:41 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:29:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:29:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:29:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:29:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:29:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:30:11 [INFO] exp_shallowmodel: train time: 30.758s
12/10/2017 05:30:11 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:30:11 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 05:30:11 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 05:30:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:30:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.09      0.10        23
          C       0.19      0.19      0.19        27
          F       0.76      0.78      0.77       250
          R       0.18      0.17      0.18        52

avg / total       0.59      0.60      0.59       352

12/10/2017 05:30:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:30:11 [INFO] exp_shallowmodel: 
[[  2   2  11   8]
 [  1   5  15   6]
 [ 12  17 194  27]
 [  4   3  36   9]]
12/10/2017 05:30:11 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 05:30:11 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:30:11 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:30:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:30:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:30:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:30:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:30:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:30:45 [INFO] exp_shallowmodel: train time: 33.104s
12/10/2017 05:30:45 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:30:45 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 05:30:45 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 05:30:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:30:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.09      0.10        23
          C       0.25      0.26      0.25        27
          F       0.74      0.78      0.76       250
          R       0.12      0.10      0.11        52

avg / total       0.57      0.60      0.58       352

12/10/2017 05:30:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:30:45 [INFO] exp_shallowmodel: 
[[  2   1  15   5]
 [  1   7  15   4]
 [  7  18 196  29]
 [  7   2  38   5]]
12/10/2017 05:30:45 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 05:30:45 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 05:30:45 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:30:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:30:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:30:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:30:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:30:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:31:18 [INFO] exp_shallowmodel: train time: 33.337s
12/10/2017 05:31:18 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:31:18 [INFO] exp_shallowmodel: accuracy:   0.591
12/10/2017 05:31:18 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 05:31:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:31:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.08      0.11        25
          C       0.14      0.15      0.15        27
          F       0.73      0.79      0.76       251
          R       0.21      0.17      0.19        59

avg / total       0.56      0.59      0.57       362

12/10/2017 05:31:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:31:18 [INFO] exp_shallowmodel: 
[[  2   4  14   5]
 [  0   4  20   3]
 [ 10  13 198  30]
 [  1   7  41  10]]
12/10/2017 05:31:18 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 05:31:18 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:31:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:31:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:31:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:31:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:31:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:31:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:31:50 [INFO] exp_shallowmodel: train time: 32.338s
12/10/2017 05:31:50 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:31:50 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 05:31:50 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 05:31:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:31:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.23      0.19      0.20        27
          F       0.75      0.81      0.78       250
          R       0.22      0.19      0.21        52

avg / total       0.59      0.62      0.60       352

12/10/2017 05:31:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:31:50 [INFO] exp_shallowmodel: 
[[  0   2  16   5]
 [  0   5  14   8]
 [ 12  13 203  22]
 [  4   2  36  10]]
12/10/2017 05:31:50 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 05:31:50 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:31:50 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:31:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:31:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:31:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:31:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:31:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:32:22 [INFO] exp_shallowmodel: train time: 31.028s
12/10/2017 05:32:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:32:22 [INFO] exp_shallowmodel: accuracy:   0.631
12/10/2017 05:32:22 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 05:32:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:32:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.09      0.11        23
          C       0.21      0.15      0.17        27
          F       0.76      0.83      0.79       250
          R       0.19      0.17      0.18        52

avg / total       0.59      0.63      0.61       352

12/10/2017 05:32:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:32:22 [INFO] exp_shallowmodel: 
[[  2   2  16   3]
 [  2   4  16   5]
 [  6   7 207  30]
 [  2   6  35   9]]
12/10/2017 05:32:22 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 05:32:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:32:22 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:32:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:32:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:32:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:32:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:32:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:32:57 [INFO] exp_shallowmodel: train time: 35.221s
12/10/2017 05:32:57 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:32:57 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 05:32:57 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 05:32:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:32:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.13      0.16        23
          C       0.12      0.15      0.14        27
          F       0.76      0.78      0.77       250
          R       0.18      0.17      0.18        52

avg / total       0.59      0.60      0.59       352

12/10/2017 05:32:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:32:57 [INFO] exp_shallowmodel: 
[[  3   2   9   9]
 [  1   4  17   5]
 [  7  21 195  27]
 [  3   5  35   9]]
12/10/2017 05:32:57 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 05:32:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:32:57 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:32:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:32:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:32:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:32:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:32:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:33:31 [INFO] exp_shallowmodel: train time: 33.622s
12/10/2017 05:33:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:33:31 [INFO] exp_shallowmodel: accuracy:   0.645
12/10/2017 05:33:31 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 05:33:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:33:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.17      0.16        23
          C       0.20      0.07      0.11        27
          F       0.78      0.85      0.81       250
          R       0.21      0.17      0.19        52

avg / total       0.61      0.64      0.62       352

12/10/2017 05:33:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:33:31 [INFO] exp_shallowmodel: 
[[  4   0  15   4]
 [  4   2  14   7]
 [ 10   5 212  23]
 [  8   3  32   9]]
12/10/2017 05:33:31 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 05:33:31 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:33:31 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:33:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:33:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:33:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:33:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:33:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:34:05 [INFO] exp_shallowmodel: train time: 34.491s
12/10/2017 05:34:05 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:34:05 [INFO] exp_shallowmodel: accuracy:   0.642
12/10/2017 05:34:05 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 05:34:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:34:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.09      0.10        23
          C       0.16      0.11      0.13        27
          F       0.78      0.85      0.81       250
          R       0.22      0.17      0.19        52

avg / total       0.60      0.64      0.62       352

12/10/2017 05:34:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:34:05 [INFO] exp_shallowmodel: 
[[  2   1  14   6]
 [  3   3  16   5]
 [  9   8 212  21]
 [  5   7  31   9]]
12/10/2017 05:34:05 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 05:34:05 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:34:05 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:34:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:34:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:34:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:34:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:34:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:34:39 [INFO] exp_shallowmodel: train time: 34.257s
12/10/2017 05:34:39 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:34:39 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 05:34:39 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 05:34:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:34:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.13      0.15        23
          C       0.24      0.19      0.21        27
          F       0.75      0.79      0.77       250
          R       0.21      0.21      0.21        52

avg / total       0.60      0.62      0.61       352

12/10/2017 05:34:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:34:39 [INFO] exp_shallowmodel: 
[[  3   2  12   6]
 [  1   5  15   6]
 [ 10  13 198  29]
 [  2   1  38  11]]
12/10/2017 05:34:39 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 05:34:39 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:34:39 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:34:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:34:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:34:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:34:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:34:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:35:12 [INFO] exp_shallowmodel: train time: 32.132s
12/10/2017 05:35:12 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:35:12 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 05:35:12 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 05:35:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:35:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.04      0.05        23
          C       0.26      0.22      0.24        27
          F       0.76      0.79      0.78       250
          R       0.13      0.13      0.13        52

avg / total       0.59      0.60      0.59       352

12/10/2017 05:35:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:35:12 [INFO] exp_shallowmodel: 
[[  1   2  11   9]
 [  0   6  17   4]
 [ 13   8 197  32]
 [  5   7  33   7]]
12/10/2017 05:35:12 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 05:35:12 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:35:12 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:35:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:35:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:35:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:35:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:35:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:35:44 [INFO] exp_shallowmodel: train time: 32.723s
12/10/2017 05:35:44 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:35:44 [INFO] exp_shallowmodel: accuracy:   0.631
12/10/2017 05:35:44 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 05:35:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:35:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.29      0.26      0.27        27
          F       0.76      0.81      0.79       250
          R       0.29      0.23      0.26        52

avg / total       0.60      0.63      0.62       352

12/10/2017 05:35:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:35:44 [INFO] exp_shallowmodel: 
[[  0   1  16   6]
 [  2   7  17   1]
 [ 12  12 203  23]
 [  5   4  31  12]]
12/10/2017 05:35:45 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 05:35:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:35:45 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:35:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:35:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:35:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:35:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:35:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:36:19 [INFO] exp_shallowmodel: train time: 34.091s
12/10/2017 05:36:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:36:19 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 05:36:19 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 05:36:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:36:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.13      0.13        23
          C       0.27      0.15      0.19        27
          F       0.76      0.80      0.78       250
          R       0.21      0.21      0.21        52

avg / total       0.60      0.62      0.61       352

12/10/2017 05:36:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:36:19 [INFO] exp_shallowmodel: 
[[  3   1  13   6]
 [  4   4  16   3]
 [ 14   5 199  32]
 [  2   5  34  11]]
12/10/2017 05:36:19 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 05:36:19 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 05:36:19 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:36:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:36:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:36:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:36:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:36:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:36:51 [INFO] exp_shallowmodel: train time: 32.333s
12/10/2017 05:36:51 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:36:51 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 05:36:51 [INFO] exp_shallowmodel: f1_score:   0.310
12/10/2017 05:36:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:36:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.12      0.13        25
          C       0.20      0.11      0.14        27
          F       0.74      0.79      0.76       251
          R       0.21      0.20      0.21        59

avg / total       0.57      0.60      0.58       362

12/10/2017 05:36:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:36:51 [INFO] exp_shallowmodel: 
[[  3   1  14   7]
 [  0   3  20   4]
 [ 10   8 198  35]
 [  8   3  36  12]]
12/10/2017 05:36:51 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 05:36:51 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:36:51 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:36:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:36:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:36:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:36:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:36:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:37:23 [INFO] exp_shallowmodel: train time: 31.890s
12/10/2017 05:37:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:37:23 [INFO] exp_shallowmodel: accuracy:   0.614
12/10/2017 05:37:23 [INFO] exp_shallowmodel: f1_score:   0.313
12/10/2017 05:37:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:37:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.13      0.15        23
          C       0.14      0.11      0.12        27
          F       0.75      0.80      0.78       250
          R       0.20      0.19      0.20        52

avg / total       0.59      0.61      0.60       352

12/10/2017 05:37:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:37:23 [INFO] exp_shallowmodel: 
[[  3   2  14   4]
 [  2   3  19   3]
 [  9   9 200  32]
 [  2   8  32  10]]
12/10/2017 05:37:23 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 05:37:23 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:37:23 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:37:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:37:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:37:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:37:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:37:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:37:54 [INFO] exp_shallowmodel: train time: 30.825s
12/10/2017 05:37:54 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:37:54 [INFO] exp_shallowmodel: accuracy:   0.631
12/10/2017 05:37:54 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 05:37:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:37:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.09      0.10        23
          C       0.28      0.19      0.22        27
          F       0.74      0.83      0.78       250
          R       0.19      0.13      0.16        52

avg / total       0.58      0.63      0.60       352

12/10/2017 05:37:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:37:54 [INFO] exp_shallowmodel: 
[[  2   1  16   4]
 [  0   5  19   3]
 [ 12   8 208  22]
 [  2   4  39   7]]
12/10/2017 05:37:54 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 05:37:54 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:37:54 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:37:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:37:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:37:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:37:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:37:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:38:24 [INFO] exp_shallowmodel: train time: 29.733s
12/10/2017 05:38:24 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:38:24 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 05:38:24 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 05:38:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:38:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.13      0.14        23
          C       0.11      0.11      0.11        27
          F       0.77      0.80      0.78       250
          R       0.25      0.21      0.23        52

avg / total       0.60      0.62      0.61       352

12/10/2017 05:38:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:38:24 [INFO] exp_shallowmodel: 
[[  3   1  12   7]
 [  2   3  18   4]
 [ 10  18 200  22]
 [  5   5  31  11]]
12/10/2017 05:38:24 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 05:38:24 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:38:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:38:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:38:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:38:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:38:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:38:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:38:55 [INFO] exp_shallowmodel: train time: 30.949s
12/10/2017 05:38:55 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:38:55 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 05:38:55 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 05:38:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:38:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.22      0.22        23
          C       0.04      0.04      0.04        27
          F       0.76      0.79      0.77       250
          R       0.26      0.23      0.24        52

avg / total       0.59      0.61      0.60       352

12/10/2017 05:38:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:38:55 [INFO] exp_shallowmodel: 
[[  5   0  13   5]
 [  5   1  17   4]
 [ 12  16 197  25]
 [  1   6  33  12]]
12/10/2017 05:38:55 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 05:38:55 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:38:55 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:38:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:38:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:38:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:38:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:38:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:39:25 [INFO] exp_shallowmodel: train time: 30.464s
12/10/2017 05:39:25 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:39:25 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 05:39:25 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 05:39:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:39:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.13      0.14        23
          C       0.20      0.15      0.17        27
          F       0.78      0.84      0.81       250
          R       0.14      0.12      0.13        52

avg / total       0.60      0.63      0.61       352

12/10/2017 05:39:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:39:25 [INFO] exp_shallowmodel: 
[[  3   4  10   6]
 [  3   4  14   6]
 [  9   7 210  24]
 [  5   5  36   6]]
12/10/2017 05:39:25 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 05:39:25 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:39:25 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:39:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:39:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:39:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:39:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:39:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:39:54 [INFO] exp_shallowmodel: train time: 28.749s
12/10/2017 05:39:54 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:39:54 [INFO] exp_shallowmodel: accuracy:   0.636
12/10/2017 05:39:54 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 05:39:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:39:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.17      0.20        23
          C       0.08      0.04      0.05        27
          F       0.76      0.83      0.79       250
          R       0.25      0.23      0.24        52

avg / total       0.59      0.64      0.61       352

12/10/2017 05:39:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:39:54 [INFO] exp_shallowmodel: 
[[  4   0  15   4]
 [  2   1  19   5]
 [  8   8 207  27]
 [  3   4  33  12]]
12/10/2017 05:39:54 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 05:39:54 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:39:54 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:39:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:39:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:39:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:39:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:39:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:40:28 [INFO] exp_shallowmodel: train time: 33.879s
12/10/2017 05:40:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:40:28 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 05:40:28 [INFO] exp_shallowmodel: f1_score:   0.344
12/10/2017 05:40:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:40:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.09      0.09        23
          C       0.26      0.22      0.24        27
          F       0.76      0.77      0.76       250
          R       0.27      0.29      0.28        52

avg / total       0.61      0.61      0.61       352

12/10/2017 05:40:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:40:28 [INFO] exp_shallowmodel: 
[[  2   2  16   3]
 [  3   6  15   3]
 [ 12  12 192  34]
 [  5   3  29  15]]
12/10/2017 05:40:28 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 05:40:28 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:40:28 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:40:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:40:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:40:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:40:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:40:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:41:03 [INFO] exp_shallowmodel: train time: 35.215s
12/10/2017 05:41:03 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:41:03 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 05:41:03 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 05:41:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:41:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.13      0.12        23
          C       0.15      0.11      0.13        27
          F       0.76      0.74      0.75       250
          R       0.18      0.21      0.19        52

avg / total       0.58      0.57      0.58       352

12/10/2017 05:41:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:41:03 [INFO] exp_shallowmodel: 
[[  3   2  13   5]
 [  4   3  13   7]
 [ 14  13 185  38]
 [  5   2  34  11]]
12/10/2017 05:41:03 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 05:41:03 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:41:03 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:41:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:41:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:41:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:41:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:41:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:41:40 [INFO] exp_shallowmodel: train time: 36.503s
12/10/2017 05:41:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:41:40 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 05:41:40 [INFO] exp_shallowmodel: f1_score:   0.322
12/10/2017 05:41:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:41:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.09      0.09        23
          C       0.35      0.30      0.32        27
          F       0.75      0.80      0.77       250
          R       0.12      0.10      0.11        52

avg / total       0.58      0.61      0.59       352

12/10/2017 05:41:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:41:40 [INFO] exp_shallowmodel: 
[[  2   1  13   7]
 [  1   8  15   3]
 [ 14  10 199  27]
 [  5   4  38   5]]
12/10/2017 05:41:40 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 05:41:40 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 05:41:40 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:41:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:41:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:41:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:41:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:41:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:42:14 [INFO] exp_shallowmodel: train time: 33.475s
12/10/2017 05:42:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:42:14 [INFO] exp_shallowmodel: accuracy:   0.602
12/10/2017 05:42:14 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 05:42:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:42:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.30      0.33      0.32        27
          F       0.75      0.79      0.77       251
          R       0.20      0.17      0.19        59

avg / total       0.58      0.60      0.59       362

12/10/2017 05:42:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:42:14 [INFO] exp_shallowmodel: 
[[  0   3  14   8]
 [  1   9  14   3]
 [ 13  11 199  28]
 [  4   7  38  10]]
12/10/2017 05:42:14 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 05:42:14 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:42:14 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:42:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:42:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:42:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:42:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:42:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:42:48 [INFO] exp_shallowmodel: train time: 34.687s
12/10/2017 05:42:48 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:42:48 [INFO] exp_shallowmodel: accuracy:   0.645
12/10/2017 05:42:48 [INFO] exp_shallowmodel: f1_score:   0.389
12/10/2017 05:42:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:42:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.22      0.20        23
          C       0.27      0.30      0.28        27
          F       0.79      0.80      0.80       250
          R       0.32      0.25      0.28        52

avg / total       0.64      0.64      0.64       352

12/10/2017 05:42:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:42:48 [INFO] exp_shallowmodel: 
[[  5   2  12   4]
 [  1   8  17   1]
 [ 15  11 201  23]
 [  7   9  23  13]]
12/10/2017 05:42:48 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 05:42:48 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:42:48 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:42:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:42:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:42:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:42:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:42:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:43:20 [INFO] exp_shallowmodel: train time: 31.778s
12/10/2017 05:43:20 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:43:20 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 05:43:20 [INFO] exp_shallowmodel: f1_score:   0.246
12/10/2017 05:43:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:43:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.13      0.07      0.10        27
          F       0.73      0.80      0.77       250
          R       0.13      0.12      0.12        52

avg / total       0.55      0.59      0.57       352

12/10/2017 05:43:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:43:20 [INFO] exp_shallowmodel: 
[[  0   3  14   6]
 [  2   2  22   1]
 [  9   7 201  33]
 [  5   3  38   6]]
12/10/2017 05:43:20 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 05:43:20 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:43:20 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:43:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:43:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:43:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:43:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:43:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:43:53 [INFO] exp_shallowmodel: train time: 32.892s
12/10/2017 05:43:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:43:53 [INFO] exp_shallowmodel: accuracy:   0.651
12/10/2017 05:43:53 [INFO] exp_shallowmodel: f1_score:   0.370
12/10/2017 05:43:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:43:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.13      0.15        23
          C       0.47      0.26      0.33        27
          F       0.77      0.84      0.80       250
          R       0.20      0.19      0.20        52

avg / total       0.63      0.65      0.64       352

12/10/2017 05:43:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:43:53 [INFO] exp_shallowmodel: 
[[  3   1  13   6]
 [  0   7  13   7]
 [ 12   3 209  26]
 [  3   4  35  10]]
12/10/2017 05:43:53 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 05:43:53 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:43:53 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:43:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:43:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:43:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:43:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:43:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:44:26 [INFO] exp_shallowmodel: train time: 32.664s
12/10/2017 05:44:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:44:26 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 05:44:26 [INFO] exp_shallowmodel: f1_score:   0.334
12/10/2017 05:44:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:44:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.17      0.18        23
          C       0.24      0.15      0.18        27
          F       0.77      0.80      0.79       250
          R       0.19      0.19      0.19        52

avg / total       0.61      0.62      0.61       352

12/10/2017 05:44:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:44:26 [INFO] exp_shallowmodel: 
[[  4   0  13   6]
 [  1   4  11  11]
 [ 13  10 200  27]
 [  4   3  35  10]]
12/10/2017 05:44:26 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 05:44:26 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:44:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:44:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:44:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:44:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:44:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:44:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:44:57 [INFO] exp_shallowmodel: train time: 31.486s
12/10/2017 05:44:57 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:44:57 [INFO] exp_shallowmodel: accuracy:   0.602
12/10/2017 05:44:57 [INFO] exp_shallowmodel: f1_score:   0.265
12/10/2017 05:44:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:44:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.06        23
          C       0.03      0.04      0.04        27
          F       0.75      0.80      0.77       250
          R       0.22      0.17      0.19        52

avg / total       0.57      0.60      0.59       352

12/10/2017 05:44:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:44:57 [INFO] exp_shallowmodel: 
[[  1   3  16   3]
 [  2   1  16   8]
 [ 10  18 201  21]
 [  0   7  36   9]]
12/10/2017 05:44:57 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 05:44:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:44:57 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:44:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:44:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:44:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:44:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:44:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:45:31 [INFO] exp_shallowmodel: train time: 33.042s
12/10/2017 05:45:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:45:31 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 05:45:31 [INFO] exp_shallowmodel: f1_score:   0.324
12/10/2017 05:45:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:45:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.04      0.05        23
          C       0.25      0.26      0.25        27
          F       0.75      0.78      0.76       250
          R       0.26      0.21      0.23        52

avg / total       0.59      0.61      0.60       352

12/10/2017 05:45:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:45:31 [INFO] exp_shallowmodel: 
[[  1   2  14   6]
 [  0   7  17   3]
 [ 15  17 195  23]
 [  4   2  35  11]]
12/10/2017 05:45:31 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 05:45:31 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:45:31 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:45:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:45:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:45:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:45:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:45:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:45:59 [INFO] exp_shallowmodel: train time: 28.192s
12/10/2017 05:45:59 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:45:59 [INFO] exp_shallowmodel: accuracy:   0.602
12/10/2017 05:45:59 [INFO] exp_shallowmodel: f1_score:   0.326
12/10/2017 05:45:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:45:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.13      0.15        23
          C       0.28      0.26      0.27        27
          F       0.76      0.78      0.77       250
          R       0.12      0.12      0.12        52

avg / total       0.59      0.60      0.59       352

12/10/2017 05:45:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:45:59 [INFO] exp_shallowmodel: 
[[  3   3  13   4]
 [  2   7  14   4]
 [  8  10 196  36]
 [  5   5  36   6]]
12/10/2017 05:45:59 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 05:45:59 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:45:59 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:45:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:45:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:45:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:45:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:45:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:46:33 [INFO] exp_shallowmodel: train time: 33.927s
12/10/2017 05:46:33 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:46:33 [INFO] exp_shallowmodel: accuracy:   0.605
12/10/2017 05:46:33 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 05:46:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:46:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.09      0.10        23
          C       0.10      0.07      0.08        27
          F       0.73      0.80      0.76       250
          R       0.24      0.19      0.22        52

avg / total       0.57      0.61      0.58       352

12/10/2017 05:46:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:46:33 [INFO] exp_shallowmodel: 
[[  2   3  14   4]
 [  2   2  22   1]
 [ 11  14 199  26]
 [  1   2  39  10]]
12/10/2017 05:46:33 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 05:46:33 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:46:33 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:46:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:46:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:46:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:46:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:46:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:47:05 [INFO] exp_shallowmodel: train time: 31.780s
12/10/2017 05:47:05 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:47:05 [INFO] exp_shallowmodel: accuracy:   0.645
12/10/2017 05:47:05 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 05:47:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:47:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.17      0.19        23
          C       0.35      0.33      0.34        27
          F       0.79      0.80      0.80       250
          R       0.25      0.25      0.25        52

avg / total       0.64      0.64      0.64       352

12/10/2017 05:47:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:47:05 [INFO] exp_shallowmodel: 
[[  4   2  10   7]
 [  3   9  13   2]
 [  9  10 201  30]
 [  3   5  31  13]]
12/10/2017 05:47:05 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 05:47:05 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 05:47:05 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:47:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:47:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:47:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:47:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:47:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:47:37 [INFO] exp_shallowmodel: train time: 31.876s
12/10/2017 05:47:37 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:47:37 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 05:47:37 [INFO] exp_shallowmodel: f1_score:   0.281
12/10/2017 05:47:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:47:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.08      0.09        25
          C       0.05      0.04      0.04        27
          F       0.75      0.80      0.78       251
          R       0.23      0.20      0.22        59

avg / total       0.57      0.60      0.58       362

12/10/2017 05:47:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:47:37 [INFO] exp_shallowmodel: 
[[  2   0  19   4]
 [  3   1  15   8]
 [  9  12 202  28]
 [  5   8  34  12]]
12/10/2017 05:47:37 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 05:47:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:47:37 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:47:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:47:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:47:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:47:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:47:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:48:09 [INFO] exp_shallowmodel: train time: 32.203s
12/10/2017 05:48:09 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:48:09 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 05:48:09 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 05:48:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:48:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.04      0.05        23
          C       0.27      0.26      0.26        27
          F       0.76      0.79      0.78       250
          R       0.12      0.12      0.12        52

avg / total       0.58      0.60      0.59       352

12/10/2017 05:48:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:48:09 [INFO] exp_shallowmodel: 
[[  1   4  15   3]
 [  2   7  14   4]
 [  7  11 197  35]
 [ 10   4  32   6]]
12/10/2017 05:48:09 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 05:48:09 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:48:09 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:48:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:48:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:48:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:48:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:48:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:48:44 [INFO] exp_shallowmodel: train time: 34.876s
12/10/2017 05:48:44 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:48:44 [INFO] exp_shallowmodel: accuracy:   0.605
12/10/2017 05:48:44 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 05:48:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:48:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.04      0.05        23
          C       0.12      0.11      0.11        27
          F       0.76      0.79      0.77       250
          R       0.23      0.23      0.23        52

avg / total       0.59      0.61      0.59       352

12/10/2017 05:48:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:48:44 [INFO] exp_shallowmodel: 
[[  1   2  14   6]
 [  1   3  20   3]
 [ 10  12 197  31]
 [  2   9  29  12]]
12/10/2017 05:48:44 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 05:48:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:48:44 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:48:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:48:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:48:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:48:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:48:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:49:19 [INFO] exp_shallowmodel: train time: 34.613s
12/10/2017 05:49:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:49:19 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 05:49:19 [INFO] exp_shallowmodel: f1_score:   0.286
12/10/2017 05:49:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:49:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.09      0.08        23
          C       0.14      0.11      0.12        27
          F       0.76      0.81      0.78       250
          R       0.17      0.13      0.15        52

avg / total       0.58      0.61      0.59       352

12/10/2017 05:49:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:49:19 [INFO] exp_shallowmodel: 
[[  2   2  13   6]
 [  2   3  17   5]
 [ 13  13 202  22]
 [  8   4  33   7]]
12/10/2017 05:49:19 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 05:49:19 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:49:19 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:49:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:49:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:49:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:49:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:49:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:49:53 [INFO] exp_shallowmodel: train time: 33.959s
12/10/2017 05:49:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:49:53 [INFO] exp_shallowmodel: accuracy:   0.631
12/10/2017 05:49:53 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 05:49:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:49:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.13      0.14        23
          C       0.24      0.19      0.21        27
          F       0.77      0.82      0.79       250
          R       0.21      0.19      0.20        52

avg / total       0.61      0.63      0.62       352

12/10/2017 05:49:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:49:53 [INFO] exp_shallowmodel: 
[[  3   1  11   8]
 [  5   5  13   4]
 [  8  13 204  25]
 [  4   2  36  10]]
12/10/2017 05:49:53 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 05:49:53 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:49:53 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:49:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:49:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:49:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:49:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:49:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:50:25 [INFO] exp_shallowmodel: train time: 32.454s
12/10/2017 05:50:25 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:50:25 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 05:50:25 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 05:50:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:50:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.09      0.10        23
          C       0.31      0.19      0.23        27
          F       0.76      0.83      0.79       250
          R       0.20      0.17      0.19        52

avg / total       0.60      0.63      0.61       352

12/10/2017 05:50:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:50:25 [INFO] exp_shallowmodel: 
[[  2   1  13   7]
 [  1   5  16   5]
 [ 10   9 207  24]
 [  4   1  38   9]]
12/10/2017 05:50:25 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 05:50:25 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:50:25 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:50:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:50:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:50:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:50:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:50:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:50:57 [INFO] exp_shallowmodel: train time: 31.493s
12/10/2017 05:50:57 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:50:57 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 05:50:57 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 05:50:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:50:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.17      0.16        23
          C       0.13      0.15      0.14        27
          F       0.78      0.76      0.77       250
          R       0.16      0.15      0.16        52

avg / total       0.60      0.59      0.59       352

12/10/2017 05:50:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:50:57 [INFO] exp_shallowmodel: 
[[  4   3  10   6]
 [  2   4  14   7]
 [ 15  16 191  28]
 [  7   7  30   8]]
12/10/2017 05:50:57 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 05:50:57 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:50:57 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:50:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:50:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:50:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:50:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:50:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:51:28 [INFO] exp_shallowmodel: train time: 31.217s
12/10/2017 05:51:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:51:28 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 05:51:28 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 05:51:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:51:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.13      0.13        23
          C       0.22      0.19      0.20        27
          F       0.74      0.81      0.77       250
          R       0.22      0.13      0.17        52

avg / total       0.58      0.62      0.60       352

12/10/2017 05:51:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:51:28 [INFO] exp_shallowmodel: 
[[  3   0  17   3]
 [  1   5  19   2]
 [ 14  14 202  20]
 [  5   4  36   7]]
12/10/2017 05:51:28 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 05:51:28 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:51:28 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:51:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:51:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:51:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:51:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:51:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:52:00 [INFO] exp_shallowmodel: train time: 31.892s
12/10/2017 05:52:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:52:00 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 05:52:00 [INFO] exp_shallowmodel: f1_score:   0.328
12/10/2017 05:52:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:52:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.09      0.09        23
          C       0.23      0.19      0.20        27
          F       0.78      0.83      0.80       250
          R       0.24      0.19      0.22        52

avg / total       0.61      0.64      0.62       352

12/10/2017 05:52:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:52:00 [INFO] exp_shallowmodel: 
[[  2   2  15   4]
 [  1   5  16   5]
 [ 11   9 208  22]
 [  7   6  29  10]]
12/10/2017 05:52:00 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 05:52:00 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 05:52:00 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:52:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:52:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:52:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:52:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:52:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:52:33 [INFO] exp_shallowmodel: train time: 32.745s
12/10/2017 05:52:33 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:52:33 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 05:52:33 [INFO] exp_shallowmodel: f1_score:   0.286
12/10/2017 05:52:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:52:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.06        23
          C       0.14      0.11      0.12        27
          F       0.76      0.82      0.79       250
          R       0.18      0.17      0.18        52

avg / total       0.58      0.62      0.60       352

12/10/2017 05:52:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:52:33 [INFO] exp_shallowmodel: 
[[  1   2  15   5]
 [  1   3  18   5]
 [  6  10 204  30]
 [  5   7  31   9]]
12/10/2017 05:52:33 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 05:52:33 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 05:52:33 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:52:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:52:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:52:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:52:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:52:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:53:04 [INFO] exp_shallowmodel: train time: 31.634s
12/10/2017 05:53:04 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:53:04 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 05:53:04 [INFO] exp_shallowmodel: f1_score:   0.304
12/10/2017 05:53:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:53:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.04      0.05        25
          C       0.20      0.15      0.17        27
          F       0.74      0.83      0.78       251
          R       0.25      0.19      0.21        59

avg / total       0.57      0.62      0.59       362

12/10/2017 05:53:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:53:04 [INFO] exp_shallowmodel: 
[[  1   0  20   4]
 [  2   4  16   5]
 [  9   9 209  24]
 [  2   7  39  11]]
12/10/2017 05:53:11 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 05:53:11 [INFO] task_runner: context=last, feature=6-w2v
12/10/2017 05:53:11 [INFO] task_runner: retained feature numbers=[9.1]
12/10/2017 05:53:11 [INFO] task_runner: #(data)=5241
12/10/2017 05:53:11 [INFO] task_runner: #(feature)=900
12/10/2017 05:53:11 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 05:53:11 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 05:53:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:53:11 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:53:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:53:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:53:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:53:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:53:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:54:06 [INFO] exp_shallowmodel: train time: 55.078s
12/10/2017 05:54:06 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:54:06 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 05:54:06 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 05:54:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:54:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.32      0.32        59
          C       0.10      0.08      0.09        12
          F       0.83      0.85      0.84       396
          R       0.32      0.27      0.29        55

avg / total       0.70      0.71      0.70       522

12/10/2017 05:54:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:54:06 [INFO] exp_shallowmodel: 
[[ 19   0  34   6]
 [  5   1   4   2]
 [ 29   8 335  24]
 [  7   1  32  15]]
12/10/2017 05:54:06 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 05:54:06 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:54:06 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:54:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:54:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:54:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:54:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:54:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:55:00 [INFO] exp_shallowmodel: train time: 53.773s
12/10/2017 05:55:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:55:00 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 05:55:00 [INFO] exp_shallowmodel: f1_score:   0.343
12/10/2017 05:55:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:55:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.27      0.28        59
          C       0.00      0.00      0.00        12
          F       0.83      0.89      0.86       396
          R       0.28      0.20      0.23        55

avg / total       0.69      0.73      0.71       522

12/10/2017 05:55:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:55:00 [INFO] exp_shallowmodel: 
[[ 16   1  32  10]
 [  1   0   7   4]
 [ 29   1 352  14]
 [  9   1  34  11]]
12/10/2017 05:55:00 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 05:55:00 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:55:00 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:55:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:55:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:55:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:55:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:55:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:55:59 [INFO] exp_shallowmodel: train time: 59.046s
12/10/2017 05:55:59 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:55:59 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 05:55:59 [INFO] exp_shallowmodel: f1_score:   0.305
12/10/2017 05:55:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:55:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.22      0.22        59
          C       0.00      0.00      0.00        12
          F       0.81      0.86      0.84       396
          R       0.23      0.13      0.16        55

avg / total       0.66      0.69      0.68       522

12/10/2017 05:55:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:55:59 [INFO] exp_shallowmodel: 
[[ 13   3  37   6]
 [  4   0   7   1]
 [ 33   5 342  16]
 [ 11   2  35   7]]
12/10/2017 05:55:59 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 05:55:59 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:55:59 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:55:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:55:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:55:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:55:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:55:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:56:53 [INFO] exp_shallowmodel: train time: 54.517s
12/10/2017 05:56:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:56:54 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 05:56:54 [INFO] exp_shallowmodel: f1_score:   0.308
12/10/2017 05:56:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:56:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.20      0.21        59
          C       0.00      0.00      0.00        12
          F       0.82      0.83      0.82       396
          R       0.19      0.20      0.19        55

avg / total       0.66      0.68      0.67       522

12/10/2017 05:56:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:56:54 [INFO] exp_shallowmodel: 
[[ 12   1  33  13]
 [  1   0   8   3]
 [ 32   3 330  31]
 [ 10   1  33  11]]
12/10/2017 05:56:54 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 05:56:54 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:56:54 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:56:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:56:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:56:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:56:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:56:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:57:48 [INFO] exp_shallowmodel: train time: 54.837s
12/10/2017 05:57:48 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:57:48 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 05:57:48 [INFO] exp_shallowmodel: f1_score:   0.390
12/10/2017 05:57:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:57:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.24      0.24        59
          C       0.33      0.17      0.22        12
          F       0.83      0.84      0.83       396
          R       0.26      0.27      0.27        55

avg / total       0.69      0.69      0.69       522

12/10/2017 05:57:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:57:48 [INFO] exp_shallowmodel: 
[[ 14   0  33  12]
 [  1   2   7   2]
 [ 32   4 331  29]
 [ 10   0  30  15]]
12/10/2017 05:57:49 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 05:57:49 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:57:49 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:57:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:57:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:57:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:57:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:57:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:58:45 [INFO] exp_shallowmodel: train time: 56.421s
12/10/2017 05:58:45 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:58:45 [INFO] exp_shallowmodel: accuracy:   0.674
12/10/2017 05:58:45 [INFO] exp_shallowmodel: f1_score:   0.333
12/10/2017 05:58:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:58:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.27      0.26        59
          C       0.00      0.00      0.00        12
          F       0.82      0.81      0.82       396
          R       0.25      0.25      0.25        55

avg / total       0.68      0.67      0.67       522

12/10/2017 05:58:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:58:45 [INFO] exp_shallowmodel: 
[[ 16   2  32   9]
 [  3   0   8   1]
 [ 36   6 322  32]
 [  7   2  32  14]]
12/10/2017 05:58:45 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 05:58:45 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:58:45 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:58:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:58:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:58:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:58:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:58:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:59:40 [INFO] exp_shallowmodel: train time: 55.200s
12/10/2017 05:59:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:59:40 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 05:59:40 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 05:59:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:59:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.22      0.25        59
          C       0.14      0.08      0.11        12
          F       0.81      0.90      0.85       396
          R       0.31      0.18      0.23        55

avg / total       0.68      0.73      0.70       522

12/10/2017 05:59:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:59:40 [INFO] exp_shallowmodel: 
[[ 13   2  39   5]
 [  2   1   8   1]
 [ 22   3 355  16]
 [  6   1  38  10]]
12/10/2017 05:59:40 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 05:59:40 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 05:59:40 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:59:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:59:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:59:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:59:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:59:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:00:33 [INFO] exp_shallowmodel: train time: 52.260s
12/10/2017 06:00:33 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:00:33 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 06:00:33 [INFO] exp_shallowmodel: f1_score:   0.375
12/10/2017 06:00:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:00:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.19      0.20        59
          C       0.25      0.17      0.20        12
          F       0.81      0.86      0.83       396
          R       0.32      0.24      0.27        55

avg / total       0.68      0.70      0.69       522

12/10/2017 06:00:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:00:33 [INFO] exp_shallowmodel: 
[[ 11   1  40   7]
 [  1   2   7   2]
 [ 32   5 340  19]
 [  9   0  33  13]]
12/10/2017 06:00:33 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 06:00:33 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:00:33 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:00:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:00:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:00:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:00:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:00:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:01:27 [INFO] exp_shallowmodel: train time: 54.432s
12/10/2017 06:01:27 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:01:27 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 06:01:27 [INFO] exp_shallowmodel: f1_score:   0.343
12/10/2017 06:01:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:01:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.22      0.23        59
          C       0.08      0.08      0.08        12
          F       0.81      0.85      0.83       396
          R       0.27      0.20      0.23        55

avg / total       0.67      0.69      0.68       522

12/10/2017 06:01:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:01:27 [INFO] exp_shallowmodel: 
[[ 13   3  36   7]
 [  2   1   8   1]
 [ 31   6 337  22]
 [  7   3  34  11]]
12/10/2017 06:01:27 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 06:01:27 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:01:27 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:01:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:01:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:01:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:01:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:01:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:02:24 [INFO] exp_shallowmodel: train time: 56.341s
12/10/2017 06:02:24 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:02:24 [INFO] exp_shallowmodel: accuracy:   0.700
12/10/2017 06:02:24 [INFO] exp_shallowmodel: f1_score:   0.359
12/10/2017 06:02:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:02:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.33      0.34        64
          C       0.10      0.07      0.08        14
          F       0.81      0.87      0.84       402
          R       0.21      0.14      0.17        63

avg / total       0.67      0.70      0.68       543

12/10/2017 06:02:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:02:24 [INFO] exp_shallowmodel: 
[[ 21   1  37   5]
 [  3   1   5   5]
 [ 24   5 349  24]
 [ 10   3  41   9]]
12/10/2017 06:02:24 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 06:02:24 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:02:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:02:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:02:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:02:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:02:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:02:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:03:20 [INFO] exp_shallowmodel: train time: 56.253s
12/10/2017 06:03:20 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:03:20 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 06:03:20 [INFO] exp_shallowmodel: f1_score:   0.309
12/10/2017 06:03:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:03:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.22      0.22        59
          C       0.00      0.00      0.00        12
          F       0.81      0.85      0.83       396
          R       0.21      0.16      0.18        55

avg / total       0.66      0.69      0.67       522

12/10/2017 06:03:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:03:20 [INFO] exp_shallowmodel: 
[[ 13   0  37   9]
 [  2   0   7   3]
 [ 35   3 336  22]
 [  9   4  33   9]]
12/10/2017 06:03:20 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 06:03:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:03:20 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:03:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:03:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:03:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:03:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:03:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:04:17 [INFO] exp_shallowmodel: train time: 57.036s
12/10/2017 06:04:17 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:04:17 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 06:04:17 [INFO] exp_shallowmodel: f1_score:   0.323
12/10/2017 06:04:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:04:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.19      0.20        59
          C       0.00      0.00      0.00        12
          F       0.82      0.88      0.85       396
          R       0.30      0.20      0.24        55

avg / total       0.68      0.71      0.69       522

12/10/2017 06:04:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:04:17 [INFO] exp_shallowmodel: 
[[ 11   5  37   6]
 [  4   0   6   2]
 [ 24   7 347  18]
 [ 10   1  33  11]]
12/10/2017 06:04:17 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 06:04:17 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:04:17 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:04:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:04:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:04:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:04:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:04:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:05:09 [INFO] exp_shallowmodel: train time: 51.981s
12/10/2017 06:05:09 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:05:09 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 06:05:09 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 06:05:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:05:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.25      0.26        59
          C       0.12      0.08      0.10        12
          F       0.83      0.86      0.84       396
          R       0.29      0.25      0.27        55

avg / total       0.69      0.71      0.70       522

12/10/2017 06:05:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:05:09 [INFO] exp_shallowmodel: 
[[ 15   2  34   8]
 [  3   1   6   2]
 [ 31   1 340  24]
 [  7   4  30  14]]
12/10/2017 06:05:09 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 06:05:09 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:05:09 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:05:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:05:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:05:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:05:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:05:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:06:06 [INFO] exp_shallowmodel: train time: 56.710s
12/10/2017 06:06:06 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:06:06 [INFO] exp_shallowmodel: accuracy:   0.667
12/10/2017 06:06:06 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 06:06:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:06:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.17      0.18        59
          C       0.00      0.00      0.00        12
          F       0.80      0.82      0.81       396
          R       0.23      0.24      0.23        55

avg / total       0.65      0.67      0.66       522

12/10/2017 06:06:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:06:06 [INFO] exp_shallowmodel: 
[[ 10   1  37  11]
 [  1   0   9   2]
 [ 36   5 325  30]
 [  7   1  34  13]]
12/10/2017 06:06:06 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 06:06:06 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:06:06 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:06:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:06:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:06:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:06:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:06:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:07:02 [INFO] exp_shallowmodel: train time: 55.413s
12/10/2017 06:07:02 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:07:02 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 06:07:02 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 06:07:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:07:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.14      0.14        59
          C       0.08      0.08      0.08        12
          F       0.82      0.87      0.84       396
          R       0.33      0.24      0.27        55

avg / total       0.68      0.70      0.69       522

12/10/2017 06:07:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:07:02 [INFO] exp_shallowmodel: 
[[  8   5  40   6]
 [  3   1   6   2]
 [ 30   4 343  19]
 [ 12   2  28  13]]
12/10/2017 06:07:02 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 06:07:02 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:07:02 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:07:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:07:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:07:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:07:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:07:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:07:56 [INFO] exp_shallowmodel: train time: 54.513s
12/10/2017 06:07:56 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:07:56 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 06:07:56 [INFO] exp_shallowmodel: f1_score:   0.371
12/10/2017 06:07:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:07:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.32      0.35        59
          C       0.12      0.08      0.10        12
          F       0.82      0.88      0.85       396
          R       0.23      0.16      0.19        55

avg / total       0.69      0.72      0.71       522

12/10/2017 06:07:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:07:56 [INFO] exp_shallowmodel: 
[[ 19   2  31   7]
 [  2   1   8   1]
 [ 21   4 348  23]
 [  9   1  36   9]]
12/10/2017 06:07:56 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 06:07:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:07:56 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:07:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:07:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:07:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:07:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:07:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:08:54 [INFO] exp_shallowmodel: train time: 57.624s
12/10/2017 06:08:54 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:08:54 [INFO] exp_shallowmodel: accuracy:   0.672
12/10/2017 06:08:54 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 06:08:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:08:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.17      0.18        59
          C       0.00      0.00      0.00        12
          F       0.79      0.84      0.82       396
          R       0.20      0.15      0.17        55

avg / total       0.64      0.67      0.66       522

12/10/2017 06:08:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:08:54 [INFO] exp_shallowmodel: 
[[ 10   2  39   8]
 [  1   0  10   1]
 [ 33   7 333  23]
 [  8   1  38   8]]
12/10/2017 06:08:54 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 06:08:54 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:08:54 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:08:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:08:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:08:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:08:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:08:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:09:44 [INFO] exp_shallowmodel: train time: 49.759s
12/10/2017 06:09:44 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:09:44 [INFO] exp_shallowmodel: accuracy:   0.695
12/10/2017 06:09:44 [INFO] exp_shallowmodel: f1_score:   0.343
12/10/2017 06:09:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:09:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.17      0.18        59
          C       0.14      0.08      0.11        12
          F       0.82      0.86      0.84       396
          R       0.26      0.24      0.25        55

avg / total       0.67      0.70      0.68       522

12/10/2017 06:09:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:09:44 [INFO] exp_shallowmodel: 
[[ 10   1  38  10]
 [  1   1   8   2]
 [ 30   2 339  25]
 [  9   3  30  13]]
12/10/2017 06:09:44 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 06:09:44 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:09:44 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:09:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:09:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:09:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:09:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:09:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:10:37 [INFO] exp_shallowmodel: train time: 52.785s
12/10/2017 06:10:37 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:10:37 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 06:10:37 [INFO] exp_shallowmodel: f1_score:   0.352
12/10/2017 06:10:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:10:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.27      0.29        59
          C       0.00      0.00      0.00        12
          F       0.82      0.85      0.84       396
          R       0.29      0.27      0.28        55

avg / total       0.69      0.71      0.70       522

12/10/2017 06:10:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:10:37 [INFO] exp_shallowmodel: 
[[ 16   2  34   7]
 [  1   0   8   3]
 [ 29   3 338  26]
 [  6   1  33  15]]
12/10/2017 06:10:37 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 06:10:37 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:10:37 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:10:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:10:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:10:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:10:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:10:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:11:32 [INFO] exp_shallowmodel: train time: 54.918s
12/10/2017 06:11:32 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:11:32 [INFO] exp_shallowmodel: accuracy:   0.674
12/10/2017 06:11:32 [INFO] exp_shallowmodel: f1_score:   0.350
12/10/2017 06:11:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:11:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.16      0.19        64
          C       0.25      0.14      0.18        14
          F       0.79      0.85      0.82       402
          R       0.21      0.21      0.21        63

avg / total       0.64      0.67      0.66       543

12/10/2017 06:11:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:11:32 [INFO] exp_shallowmodel: 
[[ 10   1  40  13]
 [  2   2   8   2]
 [ 25   3 341  33]
 [  4   2  44  13]]
12/10/2017 06:11:32 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 06:11:32 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:11:32 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:11:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:11:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:11:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:11:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:11:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:12:29 [INFO] exp_shallowmodel: train time: 56.557s
12/10/2017 06:12:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:12:29 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 06:12:29 [INFO] exp_shallowmodel: f1_score:   0.353
12/10/2017 06:12:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:12:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.25      0.27        59
          C       0.12      0.08      0.10        12
          F       0.82      0.88      0.85       396
          R       0.24      0.16      0.20        55

avg / total       0.68      0.71      0.70       522

12/10/2017 06:12:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:12:29 [INFO] exp_shallowmodel: 
[[ 15   2  33   9]
 [  0   1   9   2]
 [ 28   3 348  17]
 [  9   2  35   9]]
12/10/2017 06:12:29 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 06:12:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:12:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:12:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:12:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:12:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:12:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:12:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:13:21 [INFO] exp_shallowmodel: train time: 52.308s
12/10/2017 06:13:21 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:13:21 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 06:13:21 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 06:13:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:13:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.29      0.26        59
          C       0.20      0.08      0.12        12
          F       0.81      0.84      0.83       396
          R       0.14      0.09      0.11        55

avg / total       0.66      0.68      0.67       522

12/10/2017 06:13:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:13:21 [INFO] exp_shallowmodel: 
[[ 17   0  35   7]
 [  4   1   4   3]
 [ 38   3 333  22]
 [ 11   1  38   5]]
12/10/2017 06:13:21 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 06:13:21 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:13:21 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:13:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:13:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:13:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:13:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:13:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:14:12 [INFO] exp_shallowmodel: train time: 51.028s
12/10/2017 06:14:12 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:14:12 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 06:14:12 [INFO] exp_shallowmodel: f1_score:   0.380
12/10/2017 06:14:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:14:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.29      0.30        59
          C       0.20      0.17      0.18        12
          F       0.82      0.86      0.84       396
          R       0.22      0.18      0.20        55

avg / total       0.69      0.70      0.70       522

12/10/2017 06:14:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:14:12 [INFO] exp_shallowmodel: 
[[ 17   1  30  11]
 [  2   2   8   0]
 [ 26   6 339  25]
 [ 10   1  34  10]]
12/10/2017 06:14:12 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 06:14:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:14:12 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:14:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:14:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:14:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:14:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:14:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:15:07 [INFO] exp_shallowmodel: train time: 54.654s
12/10/2017 06:15:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:15:07 [INFO] exp_shallowmodel: accuracy:   0.734
12/10/2017 06:15:07 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 06:15:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:15:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.31      0.30        59
          C       0.17      0.08      0.11        12
          F       0.85      0.87      0.86       396
          R       0.41      0.38      0.40        55

avg / total       0.73      0.73      0.73       522

12/10/2017 06:15:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:15:07 [INFO] exp_shallowmodel: 
[[ 18   1  27  13]
 [  3   1   8   0]
 [ 33   3 343  17]
 [  8   1  25  21]]
12/10/2017 06:15:07 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 06:15:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:15:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:15:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:15:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:15:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:15:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:15:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:16:02 [INFO] exp_shallowmodel: train time: 55.352s
12/10/2017 06:16:02 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:16:02 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 06:16:02 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 06:16:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:16:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.17      0.20        59
          C       0.11      0.08      0.10        12
          F       0.81      0.90      0.85       396
          R       0.31      0.18      0.23        55

avg / total       0.68      0.72      0.69       522

12/10/2017 06:16:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:16:02 [INFO] exp_shallowmodel: 
[[ 10   2  44   3]
 [  3   1   6   2]
 [ 18   5 356  17]
 [  8   1  36  10]]
12/10/2017 06:16:03 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 06:16:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:16:03 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:16:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:16:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:16:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:16:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:16:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:16:58 [INFO] exp_shallowmodel: train time: 55.384s
12/10/2017 06:16:58 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:16:58 [INFO] exp_shallowmodel: accuracy:   0.697
12/10/2017 06:16:58 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 06:16:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:16:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.17      0.18        59
          C       0.09      0.08      0.09        12
          F       0.82      0.86      0.84       396
          R       0.33      0.25      0.29        55

avg / total       0.68      0.70      0.69       522

12/10/2017 06:16:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:16:58 [INFO] exp_shallowmodel: 
[[ 10   3  39   7]
 [  4   1   7   0]
 [ 33   2 339  22]
 [  7   5  29  14]]
12/10/2017 06:16:58 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 06:16:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:16:58 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:16:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:16:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:16:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:16:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:16:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:17:48 [INFO] exp_shallowmodel: train time: 50.245s
12/10/2017 06:17:48 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:17:48 [INFO] exp_shallowmodel: accuracy:   0.672
12/10/2017 06:17:48 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 06:17:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:17:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.22      0.23        59
          C       0.00      0.00      0.00        12
          F       0.81      0.82      0.82       396
          R       0.22      0.24      0.23        55

avg / total       0.67      0.67      0.67       522

12/10/2017 06:17:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:17:48 [INFO] exp_shallowmodel: 
[[ 13   1  33  12]
 [  1   0  10   1]
 [ 32   6 325  33]
 [  9   2  31  13]]
12/10/2017 06:17:48 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 06:17:48 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:17:48 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:17:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:17:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:17:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:17:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:17:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:18:47 [INFO] exp_shallowmodel: train time: 58.242s
12/10/2017 06:18:47 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:18:47 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 06:18:47 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 06:18:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:18:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.22      0.23        59
          C       0.00      0.00      0.00        12
          F       0.82      0.87      0.84       396
          R       0.29      0.22      0.25        55

avg / total       0.68      0.70      0.69       522

12/10/2017 06:18:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:18:47 [INFO] exp_shallowmodel: 
[[ 13   2  35   9]
 [  2   0   8   2]
 [ 29   6 343  18]
 [ 12   1  30  12]]
12/10/2017 06:18:47 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 06:18:47 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:18:47 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:18:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:18:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:18:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:18:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:18:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:19:48 [INFO] exp_shallowmodel: train time: 60.849s
12/10/2017 06:19:48 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:19:48 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 06:19:48 [INFO] exp_shallowmodel: f1_score:   0.361
12/10/2017 06:19:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:19:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.25      0.26        59
          C       0.11      0.08      0.10        12
          F       0.82      0.86      0.84       396
          R       0.28      0.22      0.24        55

avg / total       0.69      0.71      0.70       522

12/10/2017 06:19:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:19:48 [INFO] exp_shallowmodel: 
[[ 15   2  35   7]
 [  3   1   8   0]
 [ 26   5 341  24]
 [ 12   1  30  12]]
12/10/2017 06:19:48 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 06:19:48 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:19:48 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:19:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:19:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:19:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:19:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:19:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:20:46 [INFO] exp_shallowmodel: train time: 58.129s
12/10/2017 06:20:46 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:20:46 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 06:20:46 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 06:20:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:20:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.25      0.25        64
          C       0.00      0.00      0.00        14
          F       0.83      0.88      0.86       402
          R       0.33      0.24      0.28        63

avg / total       0.68      0.71      0.70       543

12/10/2017 06:20:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:20:46 [INFO] exp_shallowmodel: 
[[ 16   3  32  13]
 [  5   0   8   1]
 [ 27   4 355  16]
 [ 14   2  32  15]]
12/10/2017 06:20:46 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 06:20:46 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:20:46 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:20:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:20:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:20:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:20:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:20:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:21:46 [INFO] exp_shallowmodel: train time: 60.292s
12/10/2017 06:21:46 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:21:46 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 06:21:46 [INFO] exp_shallowmodel: f1_score:   0.321
12/10/2017 06:21:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:21:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.25      0.28        59
          C       0.00      0.00      0.00        12
          F       0.82      0.85      0.84       396
          R       0.17      0.16      0.17        55

avg / total       0.68      0.69      0.69       522

12/10/2017 06:21:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:21:46 [INFO] exp_shallowmodel: 
[[ 15   2  26  16]
 [  3   0   6   3]
 [ 27   7 338  24]
 [  5   1  40   9]]
12/10/2017 06:21:46 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 06:21:46 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:21:46 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:21:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:21:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:21:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:21:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:21:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:22:38 [INFO] exp_shallowmodel: train time: 51.442s
12/10/2017 06:22:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:22:38 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 06:22:38 [INFO] exp_shallowmodel: f1_score:   0.308
12/10/2017 06:22:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:22:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.14      0.15        59
          C       0.00      0.00      0.00        12
          F       0.80      0.85      0.83       396
          R       0.27      0.24      0.25        55

avg / total       0.66      0.69      0.67       522

12/10/2017 06:22:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:22:38 [INFO] exp_shallowmodel: 
[[  8   4  36  11]
 [  2   0   9   1]
 [ 31   4 337  24]
 [  4   1  37  13]]
12/10/2017 06:22:38 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 06:22:38 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:22:38 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:22:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:22:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:22:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:22:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:22:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:23:34 [INFO] exp_shallowmodel: train time: 55.786s
12/10/2017 06:23:34 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:23:34 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 06:23:34 [INFO] exp_shallowmodel: f1_score:   0.344
12/10/2017 06:23:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:23:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.24      0.24        59
          C       0.12      0.17      0.14        12
          F       0.82      0.86      0.84       396
          R       0.18      0.13      0.15        55

avg / total       0.68      0.69      0.68       522

12/10/2017 06:23:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:23:34 [INFO] exp_shallowmodel: 
[[ 14   5  30  10]
 [  2   2   6   2]
 [ 31   7 339  19]
 [ 10   2  36   7]]
12/10/2017 06:23:34 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 06:23:34 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:23:34 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:23:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:23:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:23:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:23:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:23:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:24:29 [INFO] exp_shallowmodel: train time: 55.094s
12/10/2017 06:24:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:24:29 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 06:24:29 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 06:24:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:24:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.24      0.26        59
          C       0.00      0.00      0.00        12
          F       0.82      0.87      0.84       396
          R       0.26      0.20      0.22        55

avg / total       0.68      0.71      0.69       522

12/10/2017 06:24:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:24:29 [INFO] exp_shallowmodel: 
[[ 14   1  35   9]
 [  1   0   8   3]
 [ 26   5 345  20]
 [  7   2  35  11]]
12/10/2017 06:24:29 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 06:24:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:24:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:24:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:24:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:24:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:24:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:24:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:25:23 [INFO] exp_shallowmodel: train time: 53.513s
12/10/2017 06:25:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:25:23 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 06:25:23 [INFO] exp_shallowmodel: f1_score:   0.339
12/10/2017 06:25:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:25:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.22      0.23        59
          C       0.10      0.08      0.09        12
          F       0.82      0.85      0.84       396
          R       0.22      0.18      0.20        55

avg / total       0.68      0.69      0.68       522

12/10/2017 06:25:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:25:23 [INFO] exp_shallowmodel: 
[[ 13   1  34  11]
 [  1   1   8   2]
 [ 28   7 338  23]
 [ 13   1  31  10]]
12/10/2017 06:25:23 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 06:25:23 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:25:23 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:25:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:25:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:25:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:25:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:25:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:26:26 [INFO] exp_shallowmodel: train time: 63.616s
12/10/2017 06:26:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:26:26 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 06:26:26 [INFO] exp_shallowmodel: f1_score:   0.312
12/10/2017 06:26:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:26:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.12      0.13        59
          C       0.14      0.08      0.11        12
          F       0.82      0.85      0.83       396
          R       0.19      0.18      0.19        55

avg / total       0.66      0.68      0.67       522

12/10/2017 06:26:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:26:26 [INFO] exp_shallowmodel: 
[[  7   1  39  12]
 [  2   1   6   3]
 [ 30   3 335  28]
 [ 13   2  30  10]]
12/10/2017 06:26:26 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 06:26:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:26:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:26:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:26:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:26:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:26:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:26:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:27:27 [INFO] exp_shallowmodel: train time: 60.877s
12/10/2017 06:27:27 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:27:27 [INFO] exp_shallowmodel: accuracy:   0.736
12/10/2017 06:27:27 [INFO] exp_shallowmodel: f1_score:   0.425
12/10/2017 06:27:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:27:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.27      0.30        59
          C       0.30      0.25      0.27        12
          F       0.84      0.89      0.86       396
          R       0.31      0.24      0.27        55

avg / total       0.71      0.74      0.72       522

12/10/2017 06:27:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:27:27 [INFO] exp_shallowmodel: 
[[ 16   3  31   9]
 [  2   3   5   2]
 [ 24   2 352  18]
 [  7   2  33  13]]
12/10/2017 06:27:27 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 06:27:27 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:27:27 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:27:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:27:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:27:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:27:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:27:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:28:23 [INFO] exp_shallowmodel: train time: 55.530s
12/10/2017 06:28:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:28:23 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 06:28:23 [INFO] exp_shallowmodel: f1_score:   0.351
12/10/2017 06:28:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:28:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.25      0.28        59
          C       0.00      0.00      0.00        12
          F       0.82      0.87      0.84       396
          R       0.29      0.27      0.28        55

avg / total       0.69      0.71      0.70       522

12/10/2017 06:28:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:28:23 [INFO] exp_shallowmodel: 
[[ 15   2  31  11]
 [  2   0  10   0]
 [ 26   2 343  25]
 [  7   1  32  15]]
12/10/2017 06:28:23 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 06:28:23 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:28:23 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:28:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:28:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:28:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:28:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:28:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:29:17 [INFO] exp_shallowmodel: train time: 53.939s
12/10/2017 06:29:17 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 06:29:17 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 06:29:17 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 06:29:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:29:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.34      0.36        59
          C       0.00      0.00      0.00        12
          F       0.85      0.88      0.86       396
          R       0.33      0.29      0.31        55

avg / total       0.72      0.74      0.73       522

12/10/2017 06:29:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:29:17 [INFO] exp_shallowmodel: 
[[ 20   2  28   9]
 [  4   0   7   1]
 [ 18   6 349  23]
 [  9   1  29  16]]
12/10/2017 06:29:17 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 06:29:17 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:29:17 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:29:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:29:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:29:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:29:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:29:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:30:19 [INFO] exp_shallowmodel: train time: 61.680s
12/10/2017 06:30:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:30:19 [INFO] exp_shallowmodel: accuracy:   0.672
12/10/2017 06:30:19 [INFO] exp_shallowmodel: f1_score:   0.352
12/10/2017 06:30:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:30:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.20      0.20        64
          C       0.10      0.07      0.08        14
          F       0.79      0.83      0.81       402
          R       0.36      0.27      0.31        63

avg / total       0.65      0.67      0.66       543

12/10/2017 06:30:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:30:19 [INFO] exp_shallowmodel: 
[[ 13   0  44   7]
 [  5   1   7   1]
 [ 38   8 334  22]
 [  7   1  38  17]]
12/10/2017 06:30:19 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 06:30:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:30:19 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:30:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:30:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:30:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:30:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:30:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:31:10 [INFO] exp_shallowmodel: train time: 51.019s
12/10/2017 06:31:10 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:31:10 [INFO] exp_shallowmodel: accuracy:   0.676
12/10/2017 06:31:10 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 06:31:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:31:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.24      0.25        59
          C       0.12      0.08      0.10        12
          F       0.80      0.83      0.82       396
          R       0.20      0.18      0.19        55

avg / total       0.66      0.68      0.67       522

12/10/2017 06:31:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:31:10 [INFO] exp_shallowmodel: 
[[ 14   2  34   9]
 [  2   1   7   2]
 [ 34   4 328  30]
 [  5   1  39  10]]
12/10/2017 06:31:10 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 06:31:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:31:10 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:31:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:31:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:31:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:31:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:31:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:32:01 [INFO] exp_shallowmodel: train time: 51.258s
12/10/2017 06:32:01 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:32:01 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 06:32:01 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 06:32:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:32:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.19      0.21        59
          C       0.20      0.17      0.18        12
          F       0.82      0.88      0.85       396
          R       0.29      0.20      0.24        55

avg / total       0.68      0.72      0.70       522

12/10/2017 06:32:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:32:01 [INFO] exp_shallowmodel: 
[[ 11   2  36  10]
 [  0   2   8   2]
 [ 27   4 350  15]
 [  9   2  33  11]]
12/10/2017 06:32:01 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 06:32:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:32:01 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:32:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:32:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:32:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:32:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:32:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:32:56 [INFO] exp_shallowmodel: train time: 54.649s
12/10/2017 06:32:56 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:32:56 [INFO] exp_shallowmodel: accuracy:   0.745
12/10/2017 06:32:56 [INFO] exp_shallowmodel: f1_score:   0.379
12/10/2017 06:32:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:32:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.29      0.32        59
          C       0.00      0.00      0.00        12
          F       0.83      0.90      0.86       396
          R       0.38      0.29      0.33        55

avg / total       0.71      0.75      0.73       522

12/10/2017 06:32:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:32:56 [INFO] exp_shallowmodel: 
[[ 17   0  34   8]
 [  1   0   9   2]
 [ 20   4 356  16]
 [  8   2  29  16]]
12/10/2017 06:32:56 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 06:32:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:32:56 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:32:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:32:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:32:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:32:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:32:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:33:50 [INFO] exp_shallowmodel: train time: 54.190s
12/10/2017 06:33:50 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:33:50 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 06:33:50 [INFO] exp_shallowmodel: f1_score:   0.335
12/10/2017 06:33:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:33:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.22      0.23        59
          C       0.14      0.08      0.11        12
          F       0.81      0.88      0.84       396
          R       0.21      0.13      0.16        55

avg / total       0.67      0.71      0.69       522

12/10/2017 06:33:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:33:50 [INFO] exp_shallowmodel: 
[[ 13   2  39   5]
 [  4   1   7   0]
 [ 24   3 348  21]
 [ 12   1  35   7]]
12/10/2017 06:33:51 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 06:33:51 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:33:51 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:33:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:33:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:33:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:33:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:33:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:34:43 [INFO] exp_shallowmodel: train time: 52.866s
12/10/2017 06:34:43 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:34:43 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 06:34:43 [INFO] exp_shallowmodel: f1_score:   0.372
12/10/2017 06:34:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:34:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.32      0.32        59
          C       0.11      0.08      0.10        12
          F       0.82      0.84      0.83       396
          R       0.26      0.22      0.24        55

avg / total       0.69      0.70      0.69       522

12/10/2017 06:34:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:34:43 [INFO] exp_shallowmodel: 
[[ 19   4  33   3]
 [  2   1   6   3]
 [ 31   3 334  28]
 [  6   1  36  12]]
12/10/2017 06:34:44 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 06:34:44 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:34:44 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:34:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:34:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:34:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:34:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:34:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:35:38 [INFO] exp_shallowmodel: train time: 54.704s
12/10/2017 06:35:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:35:38 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 06:35:38 [INFO] exp_shallowmodel: f1_score:   0.365
12/10/2017 06:35:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:35:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.20      0.22        59
          C       0.08      0.08      0.08        12
          F       0.83      0.87      0.85       396
          R       0.32      0.29      0.30        55

avg / total       0.70      0.71      0.70       522

12/10/2017 06:35:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:35:38 [INFO] exp_shallowmodel: 
[[ 12   1  34  12]
 [  3   1   3   5]
 [ 26  10 343  17]
 [  8   0  31  16]]
12/10/2017 06:35:38 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 06:35:38 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:35:38 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:35:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:35:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:35:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:35:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:35:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:36:35 [INFO] exp_shallowmodel: train time: 56.781s
12/10/2017 06:36:35 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:36:35 [INFO] exp_shallowmodel: accuracy:   0.695
12/10/2017 06:36:35 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 06:36:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:36:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.24      0.25        59
          C       0.00      0.00      0.00        12
          F       0.80      0.86      0.83       396
          R       0.24      0.15      0.18        55

avg / total       0.66      0.70      0.68       522

12/10/2017 06:36:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:36:35 [INFO] exp_shallowmodel: 
[[ 14   0  39   6]
 [  2   0  10   0]
 [ 29   6 341  20]
 [  9   2  36   8]]
12/10/2017 06:36:35 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 06:36:35 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:36:35 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:36:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:36:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:36:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:36:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:36:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:37:36 [INFO] exp_shallowmodel: train time: 61.169s
12/10/2017 06:37:36 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:37:36 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 06:37:36 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 06:37:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:37:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.17      0.19        59
          C       0.00      0.00      0.00        12
          F       0.82      0.88      0.85       396
          R       0.20      0.15      0.17        55

avg / total       0.67      0.70      0.69       522

12/10/2017 06:37:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:37:36 [INFO] exp_shallowmodel: 
[[ 10   4  34  11]
 [  1   0  10   1]
 [ 23   3 350  20]
 [ 13   2  32   8]]
12/10/2017 06:37:37 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 06:37:37 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:37:37 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:37:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:37:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:37:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:37:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:37:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:38:34 [INFO] exp_shallowmodel: train time: 57.389s
12/10/2017 06:38:34 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:38:34 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 06:38:34 [INFO] exp_shallowmodel: f1_score:   0.353
12/10/2017 06:38:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:38:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.22      0.25        59
          C       0.10      0.08      0.09        12
          F       0.81      0.84      0.82       396
          R       0.25      0.25      0.25        55

avg / total       0.67      0.69      0.68       522

12/10/2017 06:38:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:38:34 [INFO] exp_shallowmodel: 
[[ 13   1  35  10]
 [  3   1   8   0]
 [ 27   6 331  32]
 [  4   2  35  14]]
12/10/2017 06:38:34 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 06:38:34 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 06:38:34 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:38:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:38:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:38:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:38:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:38:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:39:30 [INFO] exp_shallowmodel: train time: 56.257s
12/10/2017 06:39:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:39:30 [INFO] exp_shallowmodel: accuracy:   0.694
12/10/2017 06:39:30 [INFO] exp_shallowmodel: f1_score:   0.356
12/10/2017 06:39:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:39:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.22      0.24        64
          C       0.08      0.07      0.08        14
          F       0.81      0.86      0.83       402
          R       0.33      0.24      0.28        63

avg / total       0.67      0.69      0.68       543

12/10/2017 06:39:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:39:30 [INFO] exp_shallowmodel: 
[[ 14   2  41   7]
 [  3   1   7   3]
 [ 27   8 347  20]
 [ 11   1  36  15]]
Done: 20171210-063932
