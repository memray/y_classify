/ihome/pbrusilosky/rum20/.conda/envs/py36/bin/python -m dialogue.classify.task_runner -selected_feature_set_id 7 -selected_context_id 2
No. of param settings = 1
[('deep_model', False), ('selected_context_id', 2), ('selected_feature_set_id', 7), ('similarity_feature', False)]
12/10/2017 02:14:33 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:33 [INFO] configuration: selected_context_id  :   2
12/10/2017 02:14:33 [INFO] configuration: selected_feature_set_id  :   7
12/10/2017 02:14:33 [INFO] configuration: similarity_feature  :   False
12/10/2017 02:14:33 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:33 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:33 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:33 [INFO] configuration: timemark  :   20171210-021433
12/10/2017 02:14:33 [INFO] configuration: context_set  :   last
12/10/2017 02:14:33 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:33 [INFO] configuration: utterance_range  :   ['current_user_utterance', 'last_system_utterance', 'current_user_utterance']
12/10/2017 02:14:33 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:33 [INFO] configuration: feature_set  :   7-d2v
12/10/2017 02:14:33 [INFO] configuration: feature_set_number  :   ['10']
12/10/2017 02:14:33 [INFO] configuration: experiment_name  :   20171210-021433.context=last.feature=7-d2v.similarity=false
12/10/2017 02:14:33 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021433.context=last.feature=7-d2v.similarity=false
12/10/2017 02:14:33 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021433.context=last.feature=7-d2v.similarity=false/output.log
12/10/2017 02:14:33 [INFO] configuration: valid_type  :   {'C', 'F', 'R', 'A'}
12/10/2017 02:14:33 [INFO] configuration: data_name  :   
12/10/2017 02:14:33 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:33 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:33 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:33 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:33 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:33 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:33 [INFO] configuration: #division  :   5
12/10/2017 02:14:33 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:33 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:33 [INFO] configuration: action_words  :   {'else', 'reminders', 'cheap', 'area', 'shuffl', 'temperatur', 'findcar', 'volum', 'number', 'reminder', 'remove', 'temperature', 'member', 'next', 'expensive', 'volume', 'watch', 'phone', 'price', 'els', 'post', 'findcare', 'expens', 'items', 'remov', 'remind', 'food', 'address', 'show', 'light', 'delete', 'start', 'discard', 'matter', 'add', 'skip', 'time', 'snooze', 'snooz', 'timer', 'song', 'centr', 'delet', 'music', 'telephon', 'clear', 'item', 'shuffle', 'weather', 'north', 'telephone', 'part', 'tell', 'centre', 'help', 'list', 'video', 'any', 'alarm', 'play', 'room', 'reminds', 'cast', 'ani', 'turn', 'share', 'moderate', 'south', 'moder', 'stop'}
12/10/2017 02:14:33 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:33 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:33 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:33 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:33 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:33 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:33 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:33 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:33 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:33 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:33 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:33 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:33 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:33 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:33 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:33 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:33 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:33 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:33 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 3, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:33 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:36 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:36 [INFO] task_runner: context=last, feature=7-d2v
12/10/2017 02:14:36 [INFO] task_runner: retained feature numbers=[10.1]
12/10/2017 02:14:36 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:36 [INFO] task_runner: #(feature)=900
12/10/2017 02:14:36 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:36 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:51 [INFO] exp_shallowmodel: train time: 135.288s
12/10/2017 02:16:51 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 02:16:51 [INFO] exp_shallowmodel: accuracy:   0.618
12/10/2017 02:16:51 [INFO] exp_shallowmodel: f1_score:   0.471
12/10/2017 02:16:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.60      0.67      0.64       164
          F       0.70      0.71      0.70       268
          R       0.47      0.42      0.45       125

avg / total       0.61      0.62      0.61       571

12/10/2017 02:16:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:51 [INFO] exp_shallowmodel: 
[[  1   1   7   5]
 [  1 110  33  20]
 [  2  42 189  35]
 [  2  29  41  53]]
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:16:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:16:51 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:18:56 [INFO] exp_shallowmodel: train time: 124.674s
12/10/2017 02:18:56 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:18:56 [INFO] exp_shallowmodel: accuracy:   0.609
12/10/2017 02:18:56 [INFO] exp_shallowmodel: f1_score:   0.465
12/10/2017 02:18:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:18:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.59      0.70      0.64       164
          F       0.67      0.69      0.68       268
          R       0.48      0.38      0.42       125

avg / total       0.60      0.61      0.60       571

12/10/2017 02:18:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:18:56 [INFO] exp_shallowmodel: 
[[  1   2   8   3]
 [  0 114  33  17]
 [  0  52 186  30]
 [  2  24  52  47]]
12/10/2017 02:18:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:18:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:18:56 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:18:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:18:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:18:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:18:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:18:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:21:07 [INFO] exp_shallowmodel: train time: 130.967s
12/10/2017 02:21:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:21:07 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 02:21:07 [INFO] exp_shallowmodel: f1_score:   0.437
12/10/2017 02:21:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:21:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.67      0.62       164
          F       0.72      0.75      0.73       268
          R       0.44      0.35      0.39       125

avg / total       0.60      0.62      0.61       571

12/10/2017 02:21:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:21:07 [INFO] exp_shallowmodel: 
[[  0   3   5   6]
 [  0 110  33  21]
 [  3  36 200  29]
 [  1  40  40  44]]
12/10/2017 02:21:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:21:07 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:21:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:21:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:21:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:21:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:21:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:21:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:23:26 [INFO] exp_shallowmodel: train time: 138.645s
12/10/2017 02:23:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:23:26 [INFO] exp_shallowmodel: accuracy:   0.585
12/10/2017 02:23:26 [INFO] exp_shallowmodel: f1_score:   0.441
12/10/2017 02:23:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:23:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.53      0.62      0.57       164
          F       0.67      0.69      0.68       268
          R       0.48      0.37      0.42       125

avg / total       0.58      0.58      0.58       571

12/10/2017 02:23:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:23:26 [INFO] exp_shallowmodel: 
[[  1   3   5   5]
 [  5 102  44  13]
 [  0  52 185  31]
 [  2  35  42  46]]
12/10/2017 02:23:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:23:26 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:23:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:23:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:23:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:23:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:23:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:23:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:25:41 [INFO] exp_shallowmodel: train time: 134.384s
12/10/2017 02:25:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:25:41 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:25:41 [INFO] exp_shallowmodel: f1_score:   0.431
12/10/2017 02:25:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:25:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.73      0.64       164
          F       0.69      0.70      0.70       268
          R       0.47      0.33      0.39       125

avg / total       0.59      0.61      0.60       571

12/10/2017 02:25:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:25:41 [INFO] exp_shallowmodel: 
[[  0   1  10   3]
 [  2 119  27  16]
 [  3  51 187  27]
 [  2  36  46  41]]
12/10/2017 02:25:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:25:41 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:25:41 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:25:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:25:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:25:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:25:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:25:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:27:55 [INFO] exp_shallowmodel: train time: 134.057s
12/10/2017 02:27:55 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:27:55 [INFO] exp_shallowmodel: accuracy:   0.504
12/10/2017 02:27:55 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 02:27:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:27:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.53      0.51       164
          F       0.63      0.65      0.64       268
          R       0.26      0.22      0.23       125

avg / total       0.49      0.50      0.50       571

12/10/2017 02:27:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:27:55 [INFO] exp_shallowmodel: 
[[  0   5   7   2]
 [  2  87  43  32]
 [  5  45 174  44]
 [  4  42  52  27]]
12/10/2017 02:27:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:27:55 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:27:55 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:27:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:27:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:27:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:27:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:27:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:29:59 [INFO] exp_shallowmodel: train time: 124.397s
12/10/2017 02:29:59 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:29:59 [INFO] exp_shallowmodel: accuracy:   0.664
12/10/2017 02:29:59 [INFO] exp_shallowmodel: f1_score:   0.476
12/10/2017 02:29:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:29:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.64      0.74      0.69       164
          F       0.73      0.77      0.75       268
          R       0.56      0.40      0.47       125

avg / total       0.65      0.66      0.65       571

12/10/2017 02:29:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:29:59 [INFO] exp_shallowmodel: 
[[  0   1   8   5]
 [  1 122  29  12]
 [  4  35 207  22]
 [  2  33  40  50]]
12/10/2017 02:29:59 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:29:59 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:29:59 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:29:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:29:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:29:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:29:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:29:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:32:04 [INFO] exp_shallowmodel: train time: 125.060s
12/10/2017 02:32:04 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:32:04 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 02:32:04 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:32:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:32:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.66      0.60       164
          F       0.64      0.71      0.67       268
          R       0.40      0.25      0.31       125

avg / total       0.55      0.57      0.56       571

12/10/2017 02:32:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:32:04 [INFO] exp_shallowmodel: 
[[  0   7   7   0]
 [  2 108  39  15]
 [  3  45 189  31]
 [  1  34  59  31]]
12/10/2017 02:32:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:32:05 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:32:05 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:32:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:32:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:32:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:32:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:32:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:34:05 [INFO] exp_shallowmodel: train time: 119.970s
12/10/2017 02:34:05 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:34:05 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 02:34:05 [INFO] exp_shallowmodel: f1_score:   0.457
12/10/2017 02:34:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:34:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.07      0.10        14
          C       0.61      0.68      0.64       164
          F       0.70      0.74      0.72       268
          R       0.42      0.34      0.37       125

avg / total       0.60      0.61      0.60       571

12/10/2017 02:34:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:34:05 [INFO] exp_shallowmodel: 
[[  1   5   6   2]
 [  2 111  28  23]
 [  1  37 197  33]
 [  3  30  50  42]]
12/10/2017 02:34:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:34:05 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:34:05 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:34:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:34:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:34:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:34:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:34:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:36:10 [INFO] exp_shallowmodel: train time: 125.186s
12/10/2017 02:36:10 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:36:10 [INFO] exp_shallowmodel: accuracy:   0.568
12/10/2017 02:36:10 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 02:36:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:36:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.54      0.62      0.57       169
          F       0.67      0.68      0.68       271
          R       0.40      0.34      0.37       130

avg / total       0.55      0.57      0.56       586

12/10/2017 02:36:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:36:10 [INFO] exp_shallowmodel: 
[[  0   3   7   6]
 [  1 104  35  29]
 [  6  48 185  32]
 [  0  38  48  44]]
12/10/2017 02:36:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:36:10 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:36:10 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:36:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:36:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:36:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:36:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:36:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:38:11 [INFO] exp_shallowmodel: train time: 121.238s
12/10/2017 02:38:11 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:38:11 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:38:11 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 02:38:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:38:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.68      0.61       164
          F       0.67      0.67      0.67       268
          R       0.46      0.35      0.40       125

avg / total       0.57      0.59      0.58       571

12/10/2017 02:38:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:38:11 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  1 111  39  13]
 [  4  51 180  33]
 [  0  36  45  44]]
12/10/2017 02:38:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:38:11 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:38:11 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:38:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:38:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:38:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:38:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:38:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:40:13 [INFO] exp_shallowmodel: train time: 121.357s
12/10/2017 02:40:13 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:40:13 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:40:13 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 02:40:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:40:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.67      0.61       164
          F       0.66      0.70      0.68       268
          R       0.44      0.30      0.36       125

avg / total       0.57      0.59      0.57       571

12/10/2017 02:40:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:40:13 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 110  37  17]
 [  4  48 187  29]
 [  0  36  51  38]]
12/10/2017 02:40:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:40:13 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:40:13 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:40:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:40:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:40:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:40:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:40:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:42:19 [INFO] exp_shallowmodel: train time: 126.582s
12/10/2017 02:42:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:42:19 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 02:42:19 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:42:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:42:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.54      0.59      0.57       164
          F       0.67      0.69      0.68       268
          R       0.37      0.33      0.35       125

avg / total       0.55      0.57      0.56       571

12/10/2017 02:42:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:42:19 [INFO] exp_shallowmodel: 
[[  1   2   7   4]
 [  0  97  34  33]
 [  3  47 184  34]
 [  1  32  51  41]]
12/10/2017 02:42:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:42:20 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:42:20 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:42:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:42:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:42:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:42:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:42:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:44:17 [INFO] exp_shallowmodel: train time: 117.848s
12/10/2017 02:44:17 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:44:17 [INFO] exp_shallowmodel: accuracy:   0.632
12/10/2017 02:44:17 [INFO] exp_shallowmodel: f1_score:   0.448
12/10/2017 02:44:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:44:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.68      0.64       164
          F       0.71      0.76      0.73       268
          R       0.49      0.37      0.42       125

avg / total       0.61      0.63      0.62       571

12/10/2017 02:44:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:44:17 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  0 111  35  18]
 [  3  35 204  26]
 [  1  36  42  46]]
12/10/2017 02:44:18 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:44:18 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:44:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:44:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:44:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:44:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:44:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:44:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:46:23 [INFO] exp_shallowmodel: train time: 125.132s
12/10/2017 02:46:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:46:23 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 02:46:23 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 02:46:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:46:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.53      0.61      0.57       164
          F       0.65      0.64      0.65       268
          R       0.40      0.37      0.38       125

avg / total       0.55      0.56      0.55       571

12/10/2017 02:46:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:46:23 [INFO] exp_shallowmodel: 
[[  1   5   6   2]
 [  2 100  39  23]
 [  1  51 172  44]
 [  1  32  46  46]]
12/10/2017 02:46:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:46:23 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:46:23 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:46:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:46:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:46:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:46:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:46:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:48:24 [INFO] exp_shallowmodel: train time: 120.789s
12/10/2017 02:48:24 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:48:24 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 02:48:24 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 02:48:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:48:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.66      0.60       164
          F       0.68      0.72      0.70       268
          R       0.38      0.28      0.32       125

avg / total       0.56      0.59      0.57       571

12/10/2017 02:48:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:48:24 [INFO] exp_shallowmodel: 
[[  0   3   5   6]
 [  1 108  34  21]
 [  2  45 192  29]
 [  2  38  50  35]]
12/10/2017 02:48:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:48:24 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:48:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:48:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:48:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:48:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:48:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:48:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:50:26 [INFO] exp_shallowmodel: train time: 122.600s
12/10/2017 02:50:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:50:26 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 02:50:26 [INFO] exp_shallowmodel: f1_score:   0.443
12/10/2017 02:50:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:50:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.60      0.67      0.63       164
          F       0.67      0.70      0.68       268
          R       0.39      0.32      0.35       125

avg / total       0.58      0.59      0.58       571

12/10/2017 02:50:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:50:26 [INFO] exp_shallowmodel: 
[[  1   2   8   3]
 [  2 110  34  18]
 [  1  39 187  41]
 [  1  32  52  40]]
12/10/2017 02:50:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:50:27 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:50:27 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:50:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:50:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:50:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:50:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:50:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:52:42 [INFO] exp_shallowmodel: train time: 134.952s
12/10/2017 02:52:42 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:52:42 [INFO] exp_shallowmodel: accuracy:   0.553
12/10/2017 02:52:42 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 02:52:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:52:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.57      0.57       164
          F       0.63      0.68      0.65       268
          R       0.37      0.32      0.34       125

avg / total       0.54      0.55      0.55       571

12/10/2017 02:52:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:52:42 [INFO] exp_shallowmodel: 
[[  0   3   4   7]
 [  1  94  52  17]
 [  3  40 182  43]
 [  5  30  50  40]]
12/10/2017 02:52:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 02:52:42 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:52:42 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:52:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:52:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:52:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:52:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:52:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:55:22 [INFO] exp_shallowmodel: train time: 160.556s
12/10/2017 02:55:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:55:22 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 02:55:22 [INFO] exp_shallowmodel: f1_score:   0.458
12/10/2017 02:55:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:55:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.57      0.70      0.63       164
          F       0.72      0.73      0.72       268
          R       0.46      0.33      0.38       125

avg / total       0.60      0.62      0.60       571

12/10/2017 02:55:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:55:22 [INFO] exp_shallowmodel: 
[[  1   1   8   4]
 [  0 115  30  19]
 [  3  44 195  26]
 [  2  43  39  41]]
12/10/2017 02:55:22 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 02:55:22 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:55:22 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:55:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:55:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:55:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:55:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:55:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:57:37 [INFO] exp_shallowmodel: train time: 135.074s
12/10/2017 02:57:37 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:57:37 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:57:37 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 02:57:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:57:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.62      0.67      0.64       169
          F       0.67      0.76      0.71       271
          R       0.42      0.28      0.34       130

avg / total       0.58      0.61      0.59       586

12/10/2017 02:57:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:57:37 [INFO] exp_shallowmodel: 
[[  0   2   7   7]
 [  1 114  35  19]
 [  3  37 205  26]
 [  2  32  59  37]]
12/10/2017 02:57:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 02:57:38 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:57:38 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:57:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:57:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:57:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:57:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:57:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:59:38 [INFO] exp_shallowmodel: train time: 120.583s
12/10/2017 02:59:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 02:59:38 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 02:59:38 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 02:59:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:59:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.56      0.55       164
          F       0.65      0.70      0.67       268
          R       0.40      0.34      0.37       125

avg / total       0.55      0.56      0.56       571

12/10/2017 02:59:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:59:38 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  1  92  42  29]
 [  4  45 187  32]
 [  2  29  51  43]]
12/10/2017 02:59:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 02:59:38 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:59:38 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 02:59:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:59:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:59:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:59:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:59:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:01:40 [INFO] exp_shallowmodel: train time: 121.620s
12/10/2017 03:01:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:01:40 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 03:01:40 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 03:01:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:01:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.55      0.58      0.56       164
          F       0.69      0.73      0.71       268
          R       0.34      0.30      0.31       125

avg / total       0.56      0.57      0.57       571

12/10/2017 03:01:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:01:40 [INFO] exp_shallowmodel: 
[[  1   5   5   3]
 [  1  95  37  31]
 [  2  32 195  39]
 [  2  41  45  37]]
12/10/2017 03:01:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 03:01:40 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:01:40 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:01:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:01:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:01:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:01:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:01:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:03:46 [INFO] exp_shallowmodel: train time: 125.823s
12/10/2017 03:03:46 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:03:46 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 03:03:46 [INFO] exp_shallowmodel: f1_score:   0.483
12/10/2017 03:03:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:03:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.14      0.24        14
          C       0.58      0.71      0.64       164
          F       0.67      0.73      0.70       268
          R       0.47      0.29      0.36       125

avg / total       0.60      0.61      0.60       571

12/10/2017 03:03:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:03:46 [INFO] exp_shallowmodel: 
[[  2   3   4   5]
 [  0 117  34  13]
 [  0  50 195  23]
 [  1  30  58  36]]
12/10/2017 03:03:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 03:03:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:03:46 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:03:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:03:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:03:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:03:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:03:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:05:49 [INFO] exp_shallowmodel: train time: 122.733s
12/10/2017 03:05:49 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:05:49 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 03:05:49 [INFO] exp_shallowmodel: f1_score:   0.395
12/10/2017 03:05:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:05:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.66      0.59       164
          F       0.68      0.69      0.69       268
          R       0.37      0.26      0.30       125

avg / total       0.55      0.57      0.56       571

12/10/2017 03:05:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:05:49 [INFO] exp_shallowmodel: 
[[  0   1   9   4]
 [  1 109  31  23]
 [  1  53 186  28]
 [  3  41  49  32]]
12/10/2017 03:05:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 03:05:49 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:05:49 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:05:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:05:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:05:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:05:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:05:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:07:54 [INFO] exp_shallowmodel: train time: 125.221s
12/10/2017 03:07:54 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:07:54 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 03:07:54 [INFO] exp_shallowmodel: f1_score:   0.431
12/10/2017 03:07:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:07:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.07      0.11        14
          C       0.53      0.59      0.56       164
          F       0.67      0.68      0.68       268
          R       0.41      0.36      0.38       125

avg / total       0.56      0.57      0.56       571

12/10/2017 03:07:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:07:54 [INFO] exp_shallowmodel: 
[[  1   7   4   2]
 [  1  97  39  27]
 [  1  48 183  36]
 [  2  30  48  45]]
12/10/2017 03:07:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 03:07:54 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:07:54 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:07:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:07:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:07:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:07:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:07:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:10:04 [INFO] exp_shallowmodel: train time: 129.336s
12/10/2017 03:10:04 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:10:04 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 03:10:04 [INFO] exp_shallowmodel: f1_score:   0.445
12/10/2017 03:10:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:10:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.66      0.64       164
          F       0.70      0.74      0.72       268
          R       0.45      0.39      0.42       125

avg / total       0.61      0.62      0.61       571

12/10/2017 03:10:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:10:04 [INFO] exp_shallowmodel: 
[[  0   4   9   1]
 [  2 109  26  27]
 [  3  37 197  31]
 [  0  26  50  49]]
12/10/2017 03:10:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 03:10:04 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:10:04 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:10:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:10:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:10:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:10:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:10:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:12:08 [INFO] exp_shallowmodel: train time: 124.415s
12/10/2017 03:12:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:12:08 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 03:12:08 [INFO] exp_shallowmodel: f1_score:   0.431
12/10/2017 03:12:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:12:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.67      0.62       164
          F       0.71      0.74      0.72       268
          R       0.44      0.34      0.38       125

avg / total       0.59      0.61      0.60       571

12/10/2017 03:12:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:12:08 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 110  32  22]
 [  2  40 198  28]
 [  3  39  41  42]]
12/10/2017 03:12:08 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 03:12:08 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:12:08 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:12:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:12:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:12:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:12:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:12:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:14:13 [INFO] exp_shallowmodel: train time: 124.802s
12/10/2017 03:14:13 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:14:13 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 03:14:13 [INFO] exp_shallowmodel: f1_score:   0.435
12/10/2017 03:14:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:14:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.73      0.66       164
          F       0.70      0.74      0.72       268
          R       0.46      0.30      0.37       125

avg / total       0.60      0.62      0.61       571

12/10/2017 03:14:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:14:13 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  2 119  36   7]
 [  3  35 197  33]
 [  4  40  43  38]]
12/10/2017 03:14:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 03:14:13 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:14:13 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:14:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:14:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:14:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:14:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:14:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:16:22 [INFO] exp_shallowmodel: train time: 128.317s
12/10/2017 03:16:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:16:22 [INFO] exp_shallowmodel: accuracy:   0.609
12/10/2017 03:16:22 [INFO] exp_shallowmodel: f1_score:   0.438
12/10/2017 03:16:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:16:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.64      0.61       164
          F       0.70      0.72      0.71       268
          R       0.47      0.41      0.44       125

avg / total       0.60      0.61      0.60       571

12/10/2017 03:16:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:16:22 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  3 105  34  22]
 [  2  43 192  31]
 [  1  32  41  51]]
12/10/2017 03:16:22 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 03:16:22 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:16:22 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:16:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:16:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:16:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:16:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:16:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:18:23 [INFO] exp_shallowmodel: train time: 121.542s
12/10/2017 03:18:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:18:23 [INFO] exp_shallowmodel: accuracy:   0.587
12/10/2017 03:18:23 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 03:18:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:18:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.60      0.68      0.64       169
          F       0.66      0.70      0.68       271
          R       0.39      0.31      0.34       130

avg / total       0.56      0.59      0.57       586

12/10/2017 03:18:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:18:23 [INFO] exp_shallowmodel: 
[[  0   2   7   7]
 [  0 115  32  22]
 [  3  45 189  34]
 [  0  31  59  40]]
12/10/2017 03:18:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 03:18:23 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:18:23 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:18:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:18:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:18:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:18:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:18:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:20:28 [INFO] exp_shallowmodel: train time: 124.529s
12/10/2017 03:20:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:20:28 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 03:20:28 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 03:20:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:20:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.69      0.61       164
          F       0.68      0.68      0.68       268
          R       0.42      0.30      0.35       125

avg / total       0.57      0.58      0.57       571

12/10/2017 03:20:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:20:28 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  1 113  32  18]
 [  1  55 183  29]
 [  3  36  49  37]]
12/10/2017 03:20:28 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 03:20:28 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:20:28 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:20:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:20:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:20:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:20:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:20:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:22:41 [INFO] exp_shallowmodel: train time: 132.761s
12/10/2017 03:22:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:22:41 [INFO] exp_shallowmodel: accuracy:   0.604
12/10/2017 03:22:41 [INFO] exp_shallowmodel: f1_score:   0.455
12/10/2017 03:22:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:22:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.59      0.68      0.63       164
          F       0.68      0.71      0.70       268
          R       0.42      0.34      0.37       125

avg / total       0.59      0.60      0.59       571

12/10/2017 03:22:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:22:41 [INFO] exp_shallowmodel: 
[[  1   2   8   3]
 [  1 111  30  22]
 [  0  44 191  33]
 [  1  30  52  42]]
12/10/2017 03:22:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 03:22:41 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:22:41 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:22:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:22:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:22:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:22:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:22:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:24:45 [INFO] exp_shallowmodel: train time: 124.242s
12/10/2017 03:24:45 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:24:45 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 03:24:45 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 03:24:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:24:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.65      0.62       164
          F       0.67      0.69      0.68       268
          R       0.38      0.34      0.36       125

avg / total       0.57      0.58      0.57       571

12/10/2017 03:24:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:24:45 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  1 107  31  25]
 [  2  43 184  39]
 [  2  29  52  42]]
12/10/2017 03:24:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 03:24:45 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:24:45 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:24:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:24:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:24:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:24:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:24:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:27:01 [INFO] exp_shallowmodel: train time: 135.532s
12/10/2017 03:27:01 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:27:01 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 03:27:01 [INFO] exp_shallowmodel: f1_score:   0.445
12/10/2017 03:27:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:27:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.65      0.62       164
          F       0.70      0.79      0.74       268
          R       0.51      0.36      0.42       125

avg / total       0.61      0.63      0.62       571

12/10/2017 03:27:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:27:01 [INFO] exp_shallowmodel: 
[[  0   4   8   2]
 [  0 106  36  22]
 [  0  38 211  19]
 [  3  32  45  45]]
12/10/2017 03:27:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 03:27:01 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:27:01 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:27:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:27:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:27:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:27:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:27:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:29:12 [INFO] exp_shallowmodel: train time: 131.257s
12/10/2017 03:29:12 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:29:12 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 03:29:12 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 03:29:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:29:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.68      0.63       164
          F       0.69      0.76      0.73       268
          R       0.45      0.29      0.35       125

avg / total       0.59      0.62      0.60       571

12/10/2017 03:29:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:29:12 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  3 111  39  11]
 [  0  33 205  30]
 [  1  44  44  36]]
12/10/2017 03:29:12 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 03:29:12 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:29:12 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:29:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:29:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:29:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:29:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:29:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:31:24 [INFO] exp_shallowmodel: train time: 131.846s
12/10/2017 03:31:24 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:31:24 [INFO] exp_shallowmodel: accuracy:   0.597
12/10/2017 03:31:24 [INFO] exp_shallowmodel: f1_score:   0.439
12/10/2017 03:31:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:31:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.07      0.09        14
          C       0.59      0.70      0.64       164
          F       0.67      0.71      0.69       268
          R       0.42      0.28      0.33       125

avg / total       0.58      0.60      0.58       571

12/10/2017 03:31:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:31:24 [INFO] exp_shallowmodel: 
[[  1   3   7   3]
 [  3 115  37   9]
 [  2  39 190  37]
 [  2  38  50  35]]
12/10/2017 03:31:24 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 03:31:24 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:31:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:31:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:31:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:31:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:31:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:31:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:33:38 [INFO] exp_shallowmodel: train time: 133.595s
12/10/2017 03:33:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:33:38 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 03:33:38 [INFO] exp_shallowmodel: f1_score:   0.444
12/10/2017 03:33:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:33:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.63      0.61       164
          F       0.71      0.74      0.72       268
          R       0.48      0.41      0.44       125

avg / total       0.61      0.62      0.61       571

12/10/2017 03:33:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:33:38 [INFO] exp_shallowmodel: 
[[  0   5   3   6]
 [  1 104  39  20]
 [  4  36 199  29]
 [  2  31  41  51]]
12/10/2017 03:33:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 03:33:38 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:33:38 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:33:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:33:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:33:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:33:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:33:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:35:39 [INFO] exp_shallowmodel: train time: 120.910s
12/10/2017 03:35:39 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:35:39 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 03:35:39 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 03:35:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:35:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.60      0.57       164
          F       0.67      0.71      0.69       268
          R       0.42      0.32      0.36       125

avg / total       0.56      0.58      0.56       571

12/10/2017 03:35:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:35:39 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  1  99  41  23]
 [  3  45 190  30]
 [  1  39  45  40]]
12/10/2017 03:35:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 03:35:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:35:39 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:35:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:35:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:35:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:35:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:35:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:37:42 [INFO] exp_shallowmodel: train time: 123.202s
12/10/2017 03:37:42 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:37:42 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 03:37:42 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 03:37:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:37:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.67      0.61       164
          F       0.69      0.69      0.69       268
          R       0.37      0.30      0.33       125

avg / total       0.57      0.58      0.57       571

12/10/2017 03:37:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:37:42 [INFO] exp_shallowmodel: 
[[  0   2   5   7]
 [  0 110  26  28]
 [  5  48 185  30]
 [  1  34  52  38]]
12/10/2017 03:37:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 03:37:43 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:37:43 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:37:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:37:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:37:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:37:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:37:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:39:46 [INFO] exp_shallowmodel: train time: 123.013s
12/10/2017 03:39:46 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:39:46 [INFO] exp_shallowmodel: accuracy:   0.568
12/10/2017 03:39:46 [INFO] exp_shallowmodel: f1_score:   0.406
12/10/2017 03:39:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:39:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.56      0.58      0.57       169
          F       0.64      0.69      0.66       271
          R       0.42      0.36      0.39       130

avg / total       0.55      0.57      0.56       586

12/10/2017 03:39:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:39:46 [INFO] exp_shallowmodel: 
[[  0   4   6   6]
 [  1  98  47  23]
 [  2  45 188  36]
 [  1  28  54  47]]
12/10/2017 03:39:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 03:39:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:39:46 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:39:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:39:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:39:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:39:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:39:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:41:51 [INFO] exp_shallowmodel: train time: 125.297s
12/10/2017 03:41:51 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:41:51 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 03:41:51 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 03:41:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:41:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.67      0.61       164
          F       0.70      0.73      0.71       268
          R       0.47      0.35      0.40       125

avg / total       0.59      0.61      0.60       571

12/10/2017 03:41:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:41:51 [INFO] exp_shallowmodel: 
[[  0   5   5   4]
 [  0 110  32  22]
 [  2  48 195  23]
 [  1  32  48  44]]
12/10/2017 03:41:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 03:41:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:41:51 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:41:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:41:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:41:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:41:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:41:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:44:16 [INFO] exp_shallowmodel: train time: 144.768s
12/10/2017 03:44:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:44:16 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 03:44:16 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 03:44:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:44:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.54      0.54       164
          F       0.65      0.74      0.69       268
          R       0.48      0.37      0.42       125

avg / total       0.56      0.58      0.57       571

12/10/2017 03:44:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:44:16 [INFO] exp_shallowmodel: 
[[  0   6   8   0]
 [  2  89  57  16]
 [  3  35 197  33]
 [  1  35  43  46]]
12/10/2017 03:44:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 03:44:16 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:44:16 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:44:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:44:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:44:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:44:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:44:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:46:35 [INFO] exp_shallowmodel: train time: 138.527s
12/10/2017 03:46:35 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:46:35 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 03:46:35 [INFO] exp_shallowmodel: f1_score:   0.459
12/10/2017 03:46:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:46:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.60      0.59      0.60       164
          F       0.68      0.75      0.71       268
          R       0.47      0.39      0.43       125

avg / total       0.60      0.61      0.60       571

12/10/2017 03:46:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:46:35 [INFO] exp_shallowmodel: 
[[  1   1  10   2]
 [  1  97  43  23]
 [  1  35 202  30]
 [  3  29  44  49]]
12/10/2017 03:46:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 03:46:35 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:46:35 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:46:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:46:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:46:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:46:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:46:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:48:51 [INFO] exp_shallowmodel: train time: 136.107s
12/10/2017 03:48:51 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:48:51 [INFO] exp_shallowmodel: accuracy:   0.580
12/10/2017 03:48:51 [INFO] exp_shallowmodel: f1_score:   0.418
12/10/2017 03:48:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:48:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.07      0.08        14
          C       0.54      0.60      0.57       164
          F       0.67      0.74      0.70       268
          R       0.40      0.26      0.32       125

avg / total       0.56      0.58      0.57       571

12/10/2017 03:48:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:48:51 [INFO] exp_shallowmodel: 
[[  1   2   7   4]
 [  3  99  42  20]
 [  3  42 198  25]
 [  5  39  48  33]]
12/10/2017 03:48:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 03:48:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:48:51 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:48:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:48:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:48:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:48:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:48:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:51:09 [INFO] exp_shallowmodel: train time: 138.143s
12/10/2017 03:51:09 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:51:09 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 03:51:09 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 03:51:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:51:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.70      0.64       164
          F       0.67      0.69      0.68       268
          R       0.42      0.30      0.35       125

avg / total       0.57      0.59      0.58       571

12/10/2017 03:51:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:51:09 [INFO] exp_shallowmodel: 
[[  0   5   7   2]
 [  0 115  34  15]
 [  2  44 186  36]
 [  2  33  52  38]]
12/10/2017 03:51:09 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 03:51:09 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:51:09 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:51:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:51:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:51:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:51:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:51:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:53:14 [INFO] exp_shallowmodel: train time: 124.715s
12/10/2017 03:53:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:53:14 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 03:53:14 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 03:53:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:53:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.68      0.61       164
          F       0.70      0.69      0.70       268
          R       0.38      0.30      0.34       125

avg / total       0.57      0.59      0.58       571

12/10/2017 03:53:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:53:14 [INFO] exp_shallowmodel: 
[[  0   5   4   5]
 [  1 112  26  25]
 [  1  48 186  33]
 [  1  38  48  38]]
12/10/2017 03:53:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 03:53:14 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:53:14 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:53:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:53:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:53:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:53:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:53:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:55:06 [INFO] exp_shallowmodel: train time: 111.880s
12/10/2017 03:55:06 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:55:06 [INFO] exp_shallowmodel: accuracy:   0.594
12/10/2017 03:55:06 [INFO] exp_shallowmodel: f1_score:   0.418
12/10/2017 03:55:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:55:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.68      0.61       164
          F       0.69      0.71      0.70       268
          R       0.45      0.31      0.37       125

avg / total       0.58      0.59      0.58       571

12/10/2017 03:55:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:55:06 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  2 111  32  19]
 [  6  47 189  26]
 [  1  39  46  39]]
12/10/2017 03:55:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 03:55:06 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:55:06 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:55:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:55:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:55:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:55:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:55:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:57:10 [INFO] exp_shallowmodel: train time: 123.542s
12/10/2017 03:57:10 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:57:10 [INFO] exp_shallowmodel: accuracy:   0.601
12/10/2017 03:57:10 [INFO] exp_shallowmodel: f1_score:   0.464
12/10/2017 03:57:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:57:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.14      0.20        14
          C       0.59      0.67      0.63       164
          F       0.68      0.73      0.71       268
          R       0.39      0.28      0.33       125

avg / total       0.58      0.60      0.59       571

12/10/2017 03:57:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:57:10 [INFO] exp_shallowmodel: 
[[  2   1   5   6]
 [  2 110  33  19]
 [  1  41 196  30]
 [  1  36  53  35]]
12/10/2017 03:57:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 03:57:10 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 03:57:10 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:57:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:57:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:57:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:57:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:57:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 03:59:14 [INFO] exp_shallowmodel: train time: 124.012s
12/10/2017 03:59:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 03:59:14 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 03:59:14 [INFO] exp_shallowmodel: f1_score:   0.468
12/10/2017 03:59:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 03:59:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.07      0.10        14
          C       0.61      0.70      0.65       164
          F       0.72      0.72      0.72       268
          R       0.43      0.38      0.40       125

avg / total       0.61      0.62      0.61       571

12/10/2017 03:59:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 03:59:14 [INFO] exp_shallowmodel: 
[[  1   2   5   6]
 [  2 114  26  22]
 [  1  39 193  35]
 [  2  31  45  47]]
12/10/2017 03:59:14 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 03:59:14 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 03:59:14 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 03:59:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 03:59:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 03:59:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 03:59:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 03:59:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:01:22 [INFO] exp_shallowmodel: train time: 127.948s
12/10/2017 04:01:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:01:22 [INFO] exp_shallowmodel: accuracy:   0.582
12/10/2017 04:01:22 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 04:01:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:01:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.59      0.66      0.62       169
          F       0.68      0.68      0.68       271
          R       0.37      0.35      0.36       130

avg / total       0.57      0.58      0.58       586

12/10/2017 04:01:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:01:22 [INFO] exp_shallowmodel: 
[[  0   3   8   5]
 [  1 111  29  28]
 [  2  41 184  44]
 [  3  33  48  46]]
12/10/2017 04:01:26 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 04:01:26 [INFO] task_runner: context=last, feature=7-d2v
12/10/2017 04:01:26 [INFO] task_runner: retained feature numbers=[10.1]
12/10/2017 04:01:26 [INFO] task_runner: #(data)=5934
12/10/2017 04:01:26 [INFO] task_runner: #(feature)=900
12/10/2017 04:01:26 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 04:01:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 04:01:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:01:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:01:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:01:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:01:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:01:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:01:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:03:57 [INFO] exp_shallowmodel: train time: 150.781s
12/10/2017 04:03:57 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:03:57 [INFO] exp_shallowmodel: accuracy:   0.549
12/10/2017 04:03:57 [INFO] exp_shallowmodel: f1_score:   0.385
12/10/2017 04:03:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:03:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.48      0.51      0.49       169
          F       0.67      0.74      0.71       281
          R       0.33      0.25      0.28       122

avg / total       0.53      0.55      0.54       592

12/10/2017 04:03:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:03:57 [INFO] exp_shallowmodel: 
[[  1   4   9   6]
 [  3  86  48  32]
 [  4  46 208  23]
 [  5  43  44  30]]
12/10/2017 04:03:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 04:03:57 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:03:57 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:03:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:03:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:03:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:03:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:03:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:06:17 [INFO] exp_shallowmodel: train time: 140.193s
12/10/2017 04:06:17 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:06:17 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 04:06:17 [INFO] exp_shallowmodel: f1_score:   0.425
12/10/2017 04:06:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:06:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.10      0.10        20
          C       0.54      0.57      0.55       169
          F       0.71      0.75      0.73       281
          R       0.37      0.28      0.32       122

avg / total       0.57      0.58      0.57       592

12/10/2017 04:06:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:06:17 [INFO] exp_shallowmodel: 
[[  2   2  11   5]
 [  5  97  35  32]
 [  5  43 211  22]
 [  8  39  41  34]]
12/10/2017 04:06:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 04:06:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:06:17 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:06:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:06:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:06:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:06:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:06:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:08:38 [INFO] exp_shallowmodel: train time: 140.372s
12/10/2017 04:08:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:08:38 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 04:08:38 [INFO] exp_shallowmodel: f1_score:   0.453
12/10/2017 04:08:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:08:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.10      0.12        20
          C       0.52      0.62      0.57       169
          F       0.74      0.75      0.75       281
          R       0.45      0.34      0.38       122

avg / total       0.60      0.61      0.60       592

12/10/2017 04:08:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:08:38 [INFO] exp_shallowmodel: 
[[  2   5   8   5]
 [  5 104  33  27]
 [  2  49 212  18]
 [  5  41  35  41]]
12/10/2017 04:08:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 04:08:38 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:08:38 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:08:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:08:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:08:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:08:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:08:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:10:57 [INFO] exp_shallowmodel: train time: 139.284s
12/10/2017 04:10:57 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:10:57 [INFO] exp_shallowmodel: accuracy:   0.581
12/10/2017 04:10:57 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 04:10:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:10:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.52      0.56      0.54       169
          F       0.67      0.75      0.71       281
          R       0.43      0.31      0.36       122

avg / total       0.56      0.58      0.57       592

12/10/2017 04:10:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:10:57 [INFO] exp_shallowmodel: 
[[  1   4   7   8]
 [  3  95  50  21]
 [  1  48 210  22]
 [  4  34  46  38]]
12/10/2017 04:10:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 04:10:57 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:10:57 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:10:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:10:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:10:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:10:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:10:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:13:25 [INFO] exp_shallowmodel: train time: 148.119s
12/10/2017 04:13:25 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:13:25 [INFO] exp_shallowmodel: accuracy:   0.549
12/10/2017 04:13:25 [INFO] exp_shallowmodel: f1_score:   0.390
12/10/2017 04:13:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:13:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.48      0.54      0.51       169
          F       0.68      0.72      0.70       281
          R       0.32      0.25      0.28       122

avg / total       0.53      0.55      0.54       592

12/10/2017 04:13:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:13:25 [INFO] exp_shallowmodel: 
[[  1   5   8   6]
 [  4  92  44  29]
 [  2  48 201  30]
 [  5  45  41  31]]
12/10/2017 04:13:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 04:13:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:13:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:13:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:13:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:13:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:13:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:13:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:15:47 [INFO] exp_shallowmodel: train time: 141.937s
12/10/2017 04:15:47 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:15:47 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 04:15:47 [INFO] exp_shallowmodel: f1_score:   0.427
12/10/2017 04:15:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:15:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        20
          C       0.53      0.63      0.57       169
          F       0.68      0.72      0.70       281
          R       0.41      0.27      0.33       122

avg / total       0.56      0.58      0.57       592

12/10/2017 04:15:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:15:47 [INFO] exp_shallowmodel: 
[[  2   5   9   4]
 [  5 106  38  20]
 [  5  52 201  23]
 [  4  38  47  33]]
12/10/2017 04:15:48 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 04:15:48 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:15:48 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:15:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:15:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:15:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:15:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:15:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:18:05 [INFO] exp_shallowmodel: train time: 137.627s
12/10/2017 04:18:05 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:18:05 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 04:18:05 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 04:18:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:18:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.50      0.51      0.50       169
          F       0.68      0.77      0.72       281
          R       0.34      0.25      0.29       122

avg / total       0.54      0.56      0.55       592

12/10/2017 04:18:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:18:05 [INFO] exp_shallowmodel: 
[[  1   3   7   9]
 [  4  86  51  28]
 [  7  36 215  23]
 [  3  47  41  31]]
12/10/2017 04:18:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 04:18:05 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:18:05 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:18:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:18:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:18:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:18:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:18:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:20:29 [INFO] exp_shallowmodel: train time: 143.594s
12/10/2017 04:20:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:20:29 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 04:20:29 [INFO] exp_shallowmodel: f1_score:   0.383
12/10/2017 04:20:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:20:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.54      0.52       169
          F       0.67      0.74      0.70       281
          R       0.36      0.27      0.31       122

avg / total       0.54      0.56      0.55       592

12/10/2017 04:20:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:20:29 [INFO] exp_shallowmodel: 
[[  0   3   9   8]
 [  5  91  46  27]
 [  1  50 207  23]
 [  5  37  47  33]]
12/10/2017 04:20:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 04:20:29 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:20:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:20:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:20:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:20:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:20:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:20:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:22:53 [INFO] exp_shallowmodel: train time: 143.959s
12/10/2017 04:22:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:22:53 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 04:22:53 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 04:22:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:22:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.05      0.07        20
          C       0.53      0.57      0.55       169
          F       0.71      0.75      0.73       281
          R       0.36      0.30      0.33       122

avg / total       0.57      0.58      0.57       592

12/10/2017 04:22:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:22:53 [INFO] exp_shallowmodel: 
[[  1   4   9   6]
 [  1  97  37  34]
 [  1  44 210  26]
 [  6  39  40  37]]
12/10/2017 04:22:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 04:22:53 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:22:53 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:22:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:22:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:22:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:22:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:22:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:25:27 [INFO] exp_shallowmodel: train time: 154.191s
12/10/2017 04:25:27 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:25:27 [INFO] exp_shallowmodel: accuracy:   0.566
12/10/2017 04:25:27 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 04:25:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:25:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.04      0.06        28
          C       0.48      0.58      0.53       172
          F       0.72      0.75      0.73       283
          R       0.33      0.26      0.29       123

avg / total       0.54      0.57      0.55       606

12/10/2017 04:25:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:25:27 [INFO] exp_shallowmodel: 
[[  1  11   9   7]
 [  1  99  38  34]
 [  3  44 211  25]
 [  3  51  37  32]]
12/10/2017 04:25:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 04:25:28 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:25:28 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:25:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:25:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:25:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:25:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:25:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:27:52 [INFO] exp_shallowmodel: train time: 144.265s
12/10/2017 04:27:52 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:27:52 [INFO] exp_shallowmodel: accuracy:   0.586
12/10/2017 04:27:52 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 04:27:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:27:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.51      0.58      0.54       169
          F       0.74      0.71      0.73       281
          R       0.42      0.39      0.41       122

avg / total       0.58      0.59      0.58       592

12/10/2017 04:27:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:27:52 [INFO] exp_shallowmodel: 
[[  1   6   6   7]
 [  2  98  33  36]
 [  6  51 200  24]
 [  4  39  31  48]]
12/10/2017 04:27:52 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 04:27:52 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:27:52 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:27:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:27:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:27:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:27:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:27:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:30:17 [INFO] exp_shallowmodel: train time: 145.457s
12/10/2017 04:30:17 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:30:17 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 04:30:17 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 04:30:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:30:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.48      0.51      0.50       169
          F       0.69      0.77      0.73       281
          R       0.40      0.28      0.33       122

avg / total       0.55      0.57      0.56       592

12/10/2017 04:30:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:30:17 [INFO] exp_shallowmodel: 
[[  1   7   5   7]
 [  2  87  52  28]
 [  1  47 217  16]
 [  8  39  41  34]]
12/10/2017 04:30:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 04:30:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:30:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:30:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:30:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:30:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:30:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:30:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:32:34 [INFO] exp_shallowmodel: train time: 136.772s
12/10/2017 04:32:34 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:32:34 [INFO] exp_shallowmodel: accuracy:   0.532
12/10/2017 04:32:34 [INFO] exp_shallowmodel: f1_score:   0.359
12/10/2017 04:32:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:32:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.56      0.50       169
          F       0.67      0.69      0.68       281
          R       0.31      0.21      0.25       122

avg / total       0.51      0.53      0.52       592

12/10/2017 04:32:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:32:34 [INFO] exp_shallowmodel: 
[[  0   6   9   5]
 [  1  95  42  31]
 [  2  64 194  21]
 [  6  45  45  26]]
12/10/2017 04:32:35 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 04:32:35 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:32:35 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:32:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:32:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:32:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:32:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:32:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:35:08 [INFO] exp_shallowmodel: train time: 153.747s
12/10/2017 04:35:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:35:08 [INFO] exp_shallowmodel: accuracy:   0.600
12/10/2017 04:35:08 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 04:35:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:35:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.10      0.11        20
          C       0.54      0.61      0.58       169
          F       0.70      0.78      0.74       281
          R       0.43      0.25      0.31       122

avg / total       0.58      0.60      0.58       592

12/10/2017 04:35:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:35:08 [INFO] exp_shallowmodel: 
[[  2   3   9   6]
 [  5 103  44  17]
 [  6  38 220  17]
 [  5  45  42  30]]
12/10/2017 04:35:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 04:35:08 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:35:08 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:35:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:35:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:35:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:35:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:35:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:37:36 [INFO] exp_shallowmodel: train time: 147.357s
12/10/2017 04:37:36 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:37:36 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 04:37:36 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 04:37:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:37:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.52      0.62      0.56       169
          F       0.69      0.74      0.71       281
          R       0.39      0.25      0.30       122

avg / total       0.56      0.58      0.56       592

12/10/2017 04:37:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:37:36 [INFO] exp_shallowmodel: 
[[  1   3  10   6]
 [  6 105  38  20]
 [  4  50 207  20]
 [  2  45  45  30]]
12/10/2017 04:37:36 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 04:37:36 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:37:36 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:37:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:37:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:37:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:37:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:37:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:39:54 [INFO] exp_shallowmodel: train time: 137.910s
12/10/2017 04:39:54 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:39:54 [INFO] exp_shallowmodel: accuracy:   0.547
12/10/2017 04:39:54 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 04:39:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:39:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.51      0.51       169
          F       0.66      0.74      0.70       281
          R       0.32      0.24      0.27       122

avg / total       0.52      0.55      0.53       592

12/10/2017 04:39:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:39:54 [INFO] exp_shallowmodel: 
[[  0   5   7   8]
 [  3  86  53  27]
 [  5  39 209  28]
 [  4  40  49  29]]
12/10/2017 04:39:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 04:39:54 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:39:54 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:39:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:39:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:39:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:39:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:39:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:42:16 [INFO] exp_shallowmodel: train time: 142.270s
12/10/2017 04:42:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:42:16 [INFO] exp_shallowmodel: accuracy:   0.571
12/10/2017 04:42:16 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 04:42:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:42:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        20
          C       0.52      0.54      0.53       169
          F       0.69      0.75      0.72       281
          R       0.36      0.28      0.31       122

avg / total       0.55      0.57      0.56       592

12/10/2017 04:42:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:42:16 [INFO] exp_shallowmodel: 
[[  2   4   5   9]
 [  8  92  43  26]
 [  0  45 210  26]
 [  6  36  46  34]]
12/10/2017 04:42:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 04:42:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:42:16 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:42:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:42:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:42:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:42:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:42:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:44:41 [INFO] exp_shallowmodel: train time: 145.038s
12/10/2017 04:44:41 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 04:44:41 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 04:44:41 [INFO] exp_shallowmodel: f1_score:   0.457
12/10/2017 04:44:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:44:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.25      0.29        20
          C       0.52      0.57      0.54       169
          F       0.68      0.71      0.70       281
          R       0.33      0.26      0.29       122

avg / total       0.55      0.56      0.56       592

12/10/2017 04:44:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:44:41 [INFO] exp_shallowmodel: 
[[  5   3   6   6]
 [  2  97  38  32]
 [  5  49 200  27]
 [  2  39  49  32]]
12/10/2017 04:44:42 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 04:44:42 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:44:42 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:44:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:44:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:44:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:44:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:44:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:47:19 [INFO] exp_shallowmodel: train time: 157.315s
12/10/2017 04:47:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:47:19 [INFO] exp_shallowmodel: accuracy:   0.573
12/10/2017 04:47:19 [INFO] exp_shallowmodel: f1_score:   0.386
12/10/2017 04:47:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:47:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.57      0.55       169
          F       0.67      0.77      0.71       281
          R       0.35      0.23      0.28       122

avg / total       0.54      0.57      0.55       592

12/10/2017 04:47:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:47:19 [INFO] exp_shallowmodel: 
[[  0   7   9   4]
 [  1  96  43  29]
 [  3  45 215  18]
 [  8  31  55  28]]
12/10/2017 04:47:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 04:47:19 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 04:47:19 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:47:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:47:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:47:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:47:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:47:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:49:52 [INFO] exp_shallowmodel: train time: 152.736s
12/10/2017 04:49:52 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:49:52 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 04:49:52 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 04:49:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:49:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.04      0.05        28
          C       0.48      0.51      0.50       172
          F       0.70      0.74      0.72       283
          R       0.36      0.33      0.34       123

avg / total       0.54      0.56      0.55       606

12/10/2017 04:49:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:49:52 [INFO] exp_shallowmodel: 
[[  1  10   9   8]
 [  4  88  47  33]
 [  3  39 210  31]
 [  3  45  35  40]]
12/10/2017 04:49:52 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 04:49:52 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:49:52 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:49:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:49:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:49:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:49:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:49:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:52:12 [INFO] exp_shallowmodel: train time: 139.895s
12/10/2017 04:52:12 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:52:12 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 04:52:12 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 04:52:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:52:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.10      0.10        20
          C       0.49      0.53      0.51       169
          F       0.70      0.75      0.72       281
          R       0.39      0.27      0.32       122

avg / total       0.55      0.57      0.56       592

12/10/2017 04:52:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:52:12 [INFO] exp_shallowmodel: 
[[  2   5  10   3]
 [  8  90  42  29]
 [  3  47 212  19]
 [  6  43  40  33]]
12/10/2017 04:52:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 04:52:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:52:12 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:52:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:52:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:52:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:52:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:52:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:54:39 [INFO] exp_shallowmodel: train time: 146.792s
12/10/2017 04:54:39 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:54:39 [INFO] exp_shallowmodel: accuracy:   0.568
12/10/2017 04:54:39 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 04:54:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:54:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.49      0.60      0.54       169
          F       0.70      0.70      0.70       281
          R       0.40      0.30      0.34       122

avg / total       0.56      0.57      0.56       592

12/10/2017 04:54:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:54:39 [INFO] exp_shallowmodel: 
[[  1   4   9   6]
 [  4 101  40  24]
 [  4  54 198  25]
 [  3  47  36  36]]
12/10/2017 04:54:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 04:54:39 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:54:39 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:54:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:54:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:54:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:54:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:54:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:57:01 [INFO] exp_shallowmodel: train time: 141.927s
12/10/2017 04:57:01 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:57:01 [INFO] exp_shallowmodel: accuracy:   0.551
12/10/2017 04:57:01 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 04:57:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:57:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.10      0.10        20
          C       0.48      0.56      0.52       169
          F       0.68      0.70      0.69       281
          R       0.36      0.26      0.30       122

avg / total       0.54      0.55      0.54       592

12/10/2017 04:57:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:57:01 [INFO] exp_shallowmodel: 
[[  2   6   8   4]
 [  2  95  41  31]
 [  7  56 197  21]
 [  8  40  42  32]]
12/10/2017 04:57:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 04:57:01 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:57:01 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:57:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:57:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:57:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:57:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:57:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 04:59:26 [INFO] exp_shallowmodel: train time: 144.982s
12/10/2017 04:59:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 04:59:26 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 04:59:26 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 04:59:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 04:59:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.55      0.52       169
          F       0.68      0.73      0.70       281
          R       0.35      0.28      0.31       122

avg / total       0.54      0.56      0.55       592

12/10/2017 04:59:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 04:59:26 [INFO] exp_shallowmodel: 
[[  0   3  12   5]
 [  1  93  42  33]
 [  1  52 204  24]
 [  5  39  44  34]]
12/10/2017 04:59:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 04:59:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 04:59:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 04:59:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 04:59:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 04:59:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 04:59:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 04:59:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:01:52 [INFO] exp_shallowmodel: train time: 145.959s
12/10/2017 05:01:52 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:01:52 [INFO] exp_shallowmodel: accuracy:   0.583
12/10/2017 05:01:52 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 05:01:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:01:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.05      0.06        20
          C       0.51      0.62      0.56       169
          F       0.72      0.72      0.72       281
          R       0.40      0.30      0.34       122

avg / total       0.57      0.58      0.57       592

12/10/2017 05:01:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:01:52 [INFO] exp_shallowmodel: 
[[  1   4   7   8]
 [  1 105  38  25]
 [  7  49 203  22]
 [  4  47  35  36]]
12/10/2017 05:01:52 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 05:01:52 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:01:52 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:01:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:01:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:01:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:01:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:01:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:04:15 [INFO] exp_shallowmodel: train time: 143.068s
12/10/2017 05:04:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:04:15 [INFO] exp_shallowmodel: accuracy:   0.569
12/10/2017 05:04:15 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 05:04:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:04:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.05      0.06        20
          C       0.50      0.60      0.55       169
          F       0.68      0.73      0.70       281
          R       0.38      0.25      0.30       122

avg / total       0.55      0.57      0.55       592

12/10/2017 05:04:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:04:15 [INFO] exp_shallowmodel: 
[[  1   6  10   3]
 [  4 102  40  23]
 [  3  50 204  24]
 [  3  45  44  30]]
12/10/2017 05:04:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 05:04:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:04:15 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:04:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:04:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:04:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:04:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:04:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:06:50 [INFO] exp_shallowmodel: train time: 154.376s
12/10/2017 05:06:50 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:06:50 [INFO] exp_shallowmodel: accuracy:   0.576
12/10/2017 05:06:50 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 05:06:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:06:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.58      0.56      0.57       169
          F       0.69      0.73      0.71       281
          R       0.36      0.35      0.36       122

avg / total       0.57      0.58      0.57       592

12/10/2017 05:06:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:06:50 [INFO] exp_shallowmodel: 
[[  0   5   6   9]
 [  2  94  40  33]
 [  6  37 204  34]
 [  8  26  45  43]]
12/10/2017 05:06:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 05:06:50 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:06:50 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:06:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:06:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:06:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:06:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:06:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:09:27 [INFO] exp_shallowmodel: train time: 156.819s
12/10/2017 05:09:27 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:09:27 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 05:09:27 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 05:09:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:09:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.05      0.07        20
          C       0.53      0.51      0.52       169
          F       0.67      0.81      0.73       281
          R       0.35      0.24      0.28       122

avg / total       0.55      0.58      0.56       592

12/10/2017 05:09:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:09:27 [INFO] exp_shallowmodel: 
[[  1   5   3  11]
 [  1  86  59  23]
 [  1  33 227  20]
 [  4  37  52  29]]
12/10/2017 05:09:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 05:09:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:09:27 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:09:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:09:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:09:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:09:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:09:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:11:45 [INFO] exp_shallowmodel: train time: 137.593s
12/10/2017 05:11:45 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:11:45 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 05:11:45 [INFO] exp_shallowmodel: f1_score:   0.459
12/10/2017 05:11:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:11:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.05      0.07        20
          C       0.59      0.59      0.59       169
          F       0.73      0.78      0.75       281
          R       0.45      0.41      0.43       122

avg / total       0.61      0.62      0.61       592

12/10/2017 05:11:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:11:45 [INFO] exp_shallowmodel: 
[[  1   5   7   7]
 [  4 100  35  30]
 [  1  37 218  25]
 [  4  28  40  50]]
12/10/2017 05:11:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 05:11:45 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 05:11:45 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:11:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:11:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:11:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:11:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:11:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:13:53 [INFO] exp_shallowmodel: train time: 128.625s
12/10/2017 05:13:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:13:53 [INFO] exp_shallowmodel: accuracy:   0.568
12/10/2017 05:13:53 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 05:13:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:13:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.14      0.17        28
          C       0.53      0.55      0.54       172
          F       0.67      0.75      0.71       283
          R       0.37      0.28      0.32       123

avg / total       0.55      0.57      0.56       606

12/10/2017 05:13:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:13:53 [INFO] exp_shallowmodel: 
[[  4   8   8   8]
 [  2  94  51  25]
 [  7  39 212  25]
 [  7  38  44  34]]
12/10/2017 05:13:53 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 05:13:53 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:13:53 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:13:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:13:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:13:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:13:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:13:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:16:23 [INFO] exp_shallowmodel: train time: 149.321s
12/10/2017 05:16:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:16:23 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 05:16:23 [INFO] exp_shallowmodel: f1_score:   0.446
12/10/2017 05:16:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:16:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.05      0.06        20
          C       0.54      0.60      0.57       169
          F       0.73      0.75      0.74       281
          R       0.46      0.38      0.41       122

avg / total       0.60      0.61      0.60       592

12/10/2017 05:16:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:16:23 [INFO] exp_shallowmodel: 
[[  1   7   8   4]
 [  6 102  30  31]
 [  3  47 211  20]
 [  1  33  42  46]]
12/10/2017 05:16:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 05:16:23 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:16:23 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:16:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:16:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:16:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:16:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:16:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:18:46 [INFO] exp_shallowmodel: train time: 142.710s
12/10/2017 05:18:46 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:18:46 [INFO] exp_shallowmodel: accuracy:   0.584
12/10/2017 05:18:46 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 05:18:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:18:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.56      0.55       169
          F       0.71      0.75      0.73       281
          R       0.38      0.34      0.35       122

avg / total       0.57      0.58      0.58       592

12/10/2017 05:18:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:18:46 [INFO] exp_shallowmodel: 
[[  0   5   5  10]
 [  2  94  40  33]
 [  2  43 211  25]
 [  9  31  41  41]]
12/10/2017 05:18:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 05:18:46 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:18:46 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:18:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:18:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:18:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:18:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:18:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:21:18 [INFO] exp_shallowmodel: train time: 151.996s
12/10/2017 05:21:18 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:21:18 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 05:21:18 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 05:21:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:21:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.10      0.12        20
          C       0.53      0.60      0.56       169
          F       0.69      0.71      0.70       281
          R       0.39      0.32      0.35       122

avg / total       0.57      0.58      0.57       592

12/10/2017 05:21:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:21:18 [INFO] exp_shallowmodel: 
[[  2   4   9   5]
 [  4 101  36  28]
 [  1  52 200  28]
 [  6  34  43  39]]
12/10/2017 05:21:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 05:21:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:21:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:21:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:21:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:21:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:21:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:21:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:23:50 [INFO] exp_shallowmodel: train time: 152.427s
12/10/2017 05:23:50 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:23:50 [INFO] exp_shallowmodel: accuracy:   0.574
12/10/2017 05:23:50 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 05:23:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:23:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.10      0.13        20
          C       0.53      0.57      0.55       169
          F       0.68      0.77      0.72       281
          R       0.31      0.22      0.26       122

avg / total       0.55      0.57      0.56       592

12/10/2017 05:23:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:23:50 [INFO] exp_shallowmodel: 
[[  2   6   7   5]
 [  1  96  43  29]
 [  3  38 215  25]
 [  5  41  49  27]]
12/10/2017 05:23:51 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 05:23:51 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:23:51 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:23:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:23:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:23:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:23:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:23:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:26:00 [INFO] exp_shallowmodel: train time: 129.987s
12/10/2017 05:26:00 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:26:01 [INFO] exp_shallowmodel: accuracy:   0.547
12/10/2017 05:26:01 [INFO] exp_shallowmodel: f1_score:   0.371
12/10/2017 05:26:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:26:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.50      0.50       169
          F       0.66      0.74      0.70       281
          R       0.32      0.25      0.28       122

avg / total       0.52      0.55      0.53       592

12/10/2017 05:26:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:26:01 [INFO] exp_shallowmodel: 
[[  0   3  15   2]
 [  2  85  44  38]
 [  5  41 208  27]
 [  4  41  46  31]]
12/10/2017 05:26:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 05:26:01 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:26:01 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:26:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:26:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:26:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:26:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:26:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:28:21 [INFO] exp_shallowmodel: train time: 140.003s
12/10/2017 05:28:21 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:28:21 [INFO] exp_shallowmodel: accuracy:   0.562
12/10/2017 05:28:21 [INFO] exp_shallowmodel: f1_score:   0.387
12/10/2017 05:28:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:28:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.51      0.52       169
          F       0.68      0.75      0.71       281
          R       0.34      0.30      0.32       122

avg / total       0.54      0.56      0.55       592

12/10/2017 05:28:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:28:21 [INFO] exp_shallowmodel: 
[[  0   2   6  12]
 [  3  87  47  32]
 [  5  41 210  25]
 [  3  38  45  36]]
12/10/2017 05:28:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 05:28:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:28:21 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:28:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:28:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:28:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:28:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:28:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:30:51 [INFO] exp_shallowmodel: train time: 149.936s
12/10/2017 05:30:51 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:30:51 [INFO] exp_shallowmodel: accuracy:   0.554
12/10/2017 05:30:51 [INFO] exp_shallowmodel: f1_score:   0.381
12/10/2017 05:30:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:30:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.54      0.53       169
          F       0.67      0.73      0.70       281
          R       0.35      0.26      0.30       122

avg / total       0.53      0.55      0.54       592

12/10/2017 05:30:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:30:51 [INFO] exp_shallowmodel: 
[[  0   3  11   6]
 [  2  92  49  26]
 [  4  46 204  27]
 [  9  39  42  32]]
12/10/2017 05:30:51 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 05:30:51 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:30:51 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:30:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:30:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:30:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:30:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:30:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:33:15 [INFO] exp_shallowmodel: train time: 143.678s
12/10/2017 05:33:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:33:15 [INFO] exp_shallowmodel: accuracy:   0.568
12/10/2017 05:33:15 [INFO] exp_shallowmodel: f1_score:   0.444
12/10/2017 05:33:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:33:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.15      0.21        20
          C       0.49      0.51      0.50       169
          F       0.67      0.73      0.70       281
          R       0.41      0.34      0.37       122

avg / total       0.55      0.57      0.56       592

12/10/2017 05:33:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:33:15 [INFO] exp_shallowmodel: 
[[  3   3   7   7]
 [  1  86  54  28]
 [  3  47 206  25]
 [  2  40  39  41]]
12/10/2017 05:33:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 05:33:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:33:15 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:33:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:33:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:33:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:33:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:33:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:35:40 [INFO] exp_shallowmodel: train time: 145.044s
12/10/2017 05:35:40 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:35:40 [INFO] exp_shallowmodel: accuracy:   0.559
12/10/2017 05:35:40 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 05:35:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:35:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        20
          C       0.49      0.52      0.50       169
          F       0.70      0.75      0.72       281
          R       0.33      0.25      0.29       122

avg / total       0.54      0.56      0.55       592

12/10/2017 05:35:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:35:40 [INFO] exp_shallowmodel: 
[[  2   7   6   5]
 [  5  88  40  36]
 [  2  48 210  21]
 [  8  38  45  31]]
12/10/2017 05:35:40 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 05:35:40 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 05:35:40 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:35:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:35:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:35:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:35:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:35:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:38:11 [INFO] exp_shallowmodel: train time: 151.196s
12/10/2017 05:38:11 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:38:11 [INFO] exp_shallowmodel: accuracy:   0.564
12/10/2017 05:38:11 [INFO] exp_shallowmodel: f1_score:   0.399
12/10/2017 05:38:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:38:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.04      0.05        28
          C       0.47      0.56      0.51       172
          F       0.71      0.75      0.73       283
          R       0.39      0.26      0.31       123

avg / total       0.54      0.56      0.55       606

12/10/2017 05:38:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:38:11 [INFO] exp_shallowmodel: 
[[  1   5  12  10]
 [  3  97  46  26]
 [  2  54 212  15]
 [  9  52  30  32]]
12/10/2017 05:38:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 05:38:11 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:38:11 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:38:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:38:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:38:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:38:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:38:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:40:43 [INFO] exp_shallowmodel: train time: 151.836s
12/10/2017 05:40:43 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:40:43 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 05:40:43 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 05:40:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:40:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.56      0.54       169
          F       0.69      0.74      0.71       281
          R       0.40      0.32      0.35       122

avg / total       0.56      0.58      0.57       592

12/10/2017 05:40:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:40:43 [INFO] exp_shallowmodel: 
[[  0   2   9   9]
 [  5  95  45  24]
 [  2  45 208  26]
 [  3  39  41  39]]
12/10/2017 05:40:43 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 05:40:43 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:40:43 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:40:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:40:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:40:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:40:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:40:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:43:12 [INFO] exp_shallowmodel: train time: 148.931s
12/10/2017 05:43:12 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:43:12 [INFO] exp_shallowmodel: accuracy:   0.588
12/10/2017 05:43:12 [INFO] exp_shallowmodel: f1_score:   0.428
12/10/2017 05:43:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:43:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.10      0.12        20
          C       0.54      0.57      0.55       169
          F       0.72      0.78      0.75       281
          R       0.33      0.26      0.29       122

avg / total       0.57      0.59      0.58       592

12/10/2017 05:43:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:43:12 [INFO] exp_shallowmodel: 
[[  2   4   6   8]
 [  2  96  37  34]
 [  4  35 218  24]
 [  5  42  43  32]]
12/10/2017 05:43:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 05:43:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:43:12 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:43:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:43:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:43:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:43:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:43:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:45:47 [INFO] exp_shallowmodel: train time: 154.348s
12/10/2017 05:45:47 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:45:47 [INFO] exp_shallowmodel: accuracy:   0.579
12/10/2017 05:45:47 [INFO] exp_shallowmodel: f1_score:   0.425
12/10/2017 05:45:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:45:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.10      0.11        20
          C       0.51      0.57      0.54       169
          F       0.69      0.75      0.72       281
          R       0.42      0.28      0.34       122

avg / total       0.56      0.58      0.57       592

12/10/2017 05:45:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:45:47 [INFO] exp_shallowmodel: 
[[  2  10   5   3]
 [  3  96  49  21]
 [  6  42 211  22]
 [  6  40  42  34]]
12/10/2017 05:45:47 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 05:45:47 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:45:47 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:45:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:45:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:45:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:45:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:45:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:48:15 [INFO] exp_shallowmodel: train time: 147.737s
12/10/2017 05:48:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:48:15 [INFO] exp_shallowmodel: accuracy:   0.596
12/10/2017 05:48:15 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 05:48:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:48:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.55      0.62      0.58       169
          F       0.72      0.78      0.75       281
          R       0.34      0.23      0.27       122

avg / total       0.57      0.60      0.58       592

12/10/2017 05:48:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:48:15 [INFO] exp_shallowmodel: 
[[  1   4   8   7]
 [  3 105  37  24]
 [  2  37 219  23]
 [  8  46  40  28]]
12/10/2017 05:48:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 05:48:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:48:15 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:48:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:48:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:48:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:48:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:48:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:50:39 [INFO] exp_shallowmodel: train time: 144.172s
12/10/2017 05:50:39 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:50:39 [INFO] exp_shallowmodel: accuracy:   0.542
12/10/2017 05:50:39 [INFO] exp_shallowmodel: f1_score:   0.369
12/10/2017 05:50:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:50:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.05      0.06        20
          C       0.43      0.46      0.44       169
          F       0.68      0.78      0.73       281
          R       0.31      0.20      0.25       122

avg / total       0.51      0.54      0.52       592

12/10/2017 05:50:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:50:39 [INFO] exp_shallowmodel: 
[[  1   7   7   5]
 [  4  77  52  36]
 [  4  44 218  15]
 [  5  50  42  25]]
12/10/2017 05:50:39 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 05:50:39 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:50:39 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:50:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:50:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:50:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:50:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:50:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:53:07 [INFO] exp_shallowmodel: train time: 147.634s
12/10/2017 05:53:07 [INFO] exp_shallowmodel: test time:  0.002s
12/10/2017 05:53:07 [INFO] exp_shallowmodel: accuracy:   0.547
12/10/2017 05:53:07 [INFO] exp_shallowmodel: f1_score:   0.395
12/10/2017 05:53:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:53:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.10      0.12        20
          C       0.48      0.55      0.52       169
          F       0.67      0.72      0.70       281
          R       0.31      0.21      0.25       122

avg / total       0.53      0.55      0.53       592

12/10/2017 05:53:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:53:07 [INFO] exp_shallowmodel: 
[[  2   7   6   5]
 [  2  93  48  26]
 [  4  47 203  27]
 [  6  45  45  26]]
12/10/2017 05:53:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 05:53:07 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:53:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:53:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:53:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:53:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:53:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:53:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:55:33 [INFO] exp_shallowmodel: train time: 146.302s
12/10/2017 05:55:33 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:55:33 [INFO] exp_shallowmodel: accuracy:   0.535
12/10/2017 05:55:33 [INFO] exp_shallowmodel: f1_score:   0.356
12/10/2017 05:55:33 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:55:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.49      0.47       169
          F       0.67      0.74      0.70       281
          R       0.30      0.21      0.25       122

avg / total       0.51      0.54      0.52       592

12/10/2017 05:55:33 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:55:33 [INFO] exp_shallowmodel: 
[[  0   5  11   4]
 [  3  83  50  33]
 [  2  48 208  23]
 [  8  47  41  26]]
12/10/2017 05:55:33 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 05:55:33 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:55:33 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:55:33 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:55:33 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:55:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:55:33 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:55:33 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 05:57:57 [INFO] exp_shallowmodel: train time: 143.550s
12/10/2017 05:57:57 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 05:57:57 [INFO] exp_shallowmodel: accuracy:   0.544
12/10/2017 05:57:57 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 05:57:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 05:57:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.10      0.12        20
          C       0.51      0.47      0.49       169
          F       0.64      0.70      0.67       281
          R       0.38      0.34      0.36       122

avg / total       0.53      0.54      0.54       592

12/10/2017 05:57:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 05:57:57 [INFO] exp_shallowmodel: 
[[  2   2   8   8]
 [  4  80  48  37]
 [  4  54 198  25]
 [  4  22  54  42]]
12/10/2017 05:57:57 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 05:57:57 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 05:57:57 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 05:57:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 05:57:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 05:57:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 05:57:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 05:57:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:00:14 [INFO] exp_shallowmodel: train time: 137.031s
12/10/2017 06:00:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:00:14 [INFO] exp_shallowmodel: accuracy:   0.591
12/10/2017 06:00:14 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 06:00:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:00:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.54      0.54       169
          F       0.69      0.76      0.73       281
          R       0.43      0.36      0.39       122

avg / total       0.57      0.59      0.58       592

12/10/2017 06:00:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:00:14 [INFO] exp_shallowmodel: 
[[  0   7   7   6]
 [  2  92  44  31]
 [  5  41 214  21]
 [  2  33  43  44]]
12/10/2017 06:00:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 06:00:14 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 06:00:14 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:00:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:00:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:00:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:00:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:00:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:02:41 [INFO] exp_shallowmodel: train time: 147.103s
12/10/2017 06:02:41 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:02:41 [INFO] exp_shallowmodel: accuracy:   0.578
12/10/2017 06:02:41 [INFO] exp_shallowmodel: f1_score:   0.395
12/10/2017 06:02:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:02:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.52      0.58      0.55       172
          F       0.69      0.77      0.73       283
          R       0.36      0.26      0.30       123

avg / total       0.54      0.58      0.56       606

12/10/2017 06:02:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:02:41 [INFO] exp_shallowmodel: 
[[  0   7  11  10]
 [  2 100  41  29]
 [  4  44 218  17]
 [  3  41  47  32]]
12/10/2017 06:02:46 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 06:02:46 [INFO] task_runner: context=last, feature=7-d2v
12/10/2017 06:02:46 [INFO] task_runner: retained feature numbers=[10.1]
12/10/2017 06:02:46 [INFO] task_runner: #(data)=3530
12/10/2017 06:02:46 [INFO] task_runner: #(feature)=900
12/10/2017 06:02:46 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 06:02:46 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 06:02:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:02:46 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:02:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:02:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:02:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:02:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:02:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:03:37 [INFO] exp_shallowmodel: train time: 50.592s
12/10/2017 06:03:37 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:03:37 [INFO] exp_shallowmodel: accuracy:   0.653
12/10/2017 06:03:37 [INFO] exp_shallowmodel: f1_score:   0.334
12/10/2017 06:03:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:03:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.24      0.19      0.21        27
          F       0.80      0.83      0.81       250
          R       0.30      0.33      0.31        52

avg / total       0.63      0.65      0.64       352

12/10/2017 06:03:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:03:37 [INFO] exp_shallowmodel: 
[[  0   4  16   3]
 [  1   5  13   8]
 [  9   5 208  28]
 [  4   7  24  17]]
12/10/2017 06:03:37 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 06:03:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:03:37 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:03:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:03:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:03:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:03:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:03:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:04:28 [INFO] exp_shallowmodel: train time: 51.402s
12/10/2017 06:04:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:04:28 [INFO] exp_shallowmodel: accuracy:   0.659
12/10/2017 06:04:28 [INFO] exp_shallowmodel: f1_score:   0.346
12/10/2017 06:04:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:04:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.09      0.10        23
          C       0.27      0.22      0.24        27
          F       0.77      0.86      0.81       250
          R       0.29      0.19      0.23        52

avg / total       0.62      0.66      0.64       352

12/10/2017 06:04:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:04:28 [INFO] exp_shallowmodel: 
[[  2   3  13   5]
 [  2   6  13   6]
 [ 12  11 214  13]
 [  3   2  37  10]]
12/10/2017 06:04:29 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 06:04:29 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:04:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:04:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:04:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:04:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:04:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:04:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:05:20 [INFO] exp_shallowmodel: train time: 51.046s
12/10/2017 06:05:20 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:05:20 [INFO] exp_shallowmodel: accuracy:   0.625
12/10/2017 06:05:20 [INFO] exp_shallowmodel: f1_score:   0.349
12/10/2017 06:05:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:05:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.13      0.11        23
          C       0.35      0.30      0.32        27
          F       0.77      0.80      0.79       250
          R       0.21      0.15      0.18        52

avg / total       0.61      0.62      0.62       352

12/10/2017 06:05:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:05:20 [INFO] exp_shallowmodel: 
[[  3   2  15   3]
 [  3   8  11   5]
 [ 17  10 201  22]
 [  8   3  33   8]]
12/10/2017 06:05:20 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 06:05:20 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:05:20 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:05:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:05:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:05:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:05:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:05:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:06:06 [INFO] exp_shallowmodel: train time: 46.518s
12/10/2017 06:06:06 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:06:06 [INFO] exp_shallowmodel: accuracy:   0.651
12/10/2017 06:06:06 [INFO] exp_shallowmodel: f1_score:   0.359
12/10/2017 06:06:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:06:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.09      0.10        23
          C       0.26      0.19      0.22        27
          F       0.76      0.82      0.79       250
          R       0.35      0.31      0.33        52

avg / total       0.62      0.65      0.63       352

12/10/2017 06:06:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:06:06 [INFO] exp_shallowmodel: 
[[  2   0  16   5]
 [  2   5  19   1]
 [ 10  10 206  24]
 [  3   4  29  16]]
12/10/2017 06:06:06 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 06:06:06 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:06:06 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:06:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:06:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:06:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:06:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:06:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:07:00 [INFO] exp_shallowmodel: train time: 53.302s
12/10/2017 06:07:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:07:00 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 06:07:00 [INFO] exp_shallowmodel: f1_score:   0.333
12/10/2017 06:07:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:07:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.17      0.18        23
          C       0.29      0.19      0.23        27
          F       0.76      0.81      0.79       250
          R       0.15      0.13      0.14        52

avg / total       0.60      0.62      0.61       352

12/10/2017 06:07:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:07:00 [INFO] exp_shallowmodel: 
[[  4   2  11   6]
 [  1   5  17   4]
 [  9   9 203  29]
 [  8   1  36   7]]
12/10/2017 06:07:00 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 06:07:00 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:07:00 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:07:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:07:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:07:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:07:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:07:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:07:52 [INFO] exp_shallowmodel: train time: 51.966s
12/10/2017 06:07:52 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:07:52 [INFO] exp_shallowmodel: accuracy:   0.636
12/10/2017 06:07:52 [INFO] exp_shallowmodel: f1_score:   0.278
12/10/2017 06:07:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:07:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.04      0.05        23
          C       0.20      0.07      0.11        27
          F       0.75      0.86      0.80       250
          R       0.21      0.13      0.16        52

avg / total       0.58      0.64      0.60       352

12/10/2017 06:07:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:07:52 [INFO] exp_shallowmodel: 
[[  1   2  17   3]
 [  0   2  18   7]
 [ 15   4 214  17]
 [  5   2  38   7]]
12/10/2017 06:07:52 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 06:07:52 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:07:52 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:07:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:07:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:07:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:07:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:07:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:08:43 [INFO] exp_shallowmodel: train time: 51.025s
12/10/2017 06:08:43 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:08:43 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 06:08:43 [INFO] exp_shallowmodel: f1_score:   0.355
12/10/2017 06:08:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:08:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.19      0.17      0.18        23
          C       0.29      0.26      0.27        27
          F       0.77      0.82      0.79       250
          R       0.19      0.15      0.17        52

avg / total       0.61      0.63      0.62       352

12/10/2017 06:08:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:08:43 [INFO] exp_shallowmodel: 
[[  4   1  16   2]
 [  3   7  10   7]
 [  9  11 204  26]
 [  5   5  34   8]]
12/10/2017 06:08:43 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 06:08:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:08:43 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:08:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:08:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:08:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:08:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:08:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:09:35 [INFO] exp_shallowmodel: train time: 51.904s
12/10/2017 06:09:35 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:09:35 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 06:09:35 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 06:09:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:09:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.09      0.11        23
          C       0.06      0.04      0.04        27
          F       0.75      0.84      0.79       250
          R       0.31      0.25      0.28        52

avg / total       0.59      0.64      0.61       352

12/10/2017 06:09:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:09:35 [INFO] exp_shallowmodel: 
[[  2   2  18   1]
 [  2   1  20   4]
 [  6  11 209  24]
 [  3   4  32  13]]
12/10/2017 06:09:35 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 06:09:35 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:09:35 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:09:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:09:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:09:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:09:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:09:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:10:30 [INFO] exp_shallowmodel: train time: 55.691s
12/10/2017 06:10:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:10:30 [INFO] exp_shallowmodel: accuracy:   0.651
12/10/2017 06:10:30 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 06:10:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:10:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.09      0.10        23
          C       0.30      0.22      0.26        27
          F       0.75      0.86      0.80       250
          R       0.21      0.12      0.15        52

avg / total       0.59      0.65      0.62       352

12/10/2017 06:10:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:10:30 [INFO] exp_shallowmodel: 
[[  2   1  16   4]
 [  1   6  16   4]
 [ 11   9 215  15]
 [  2   4  40   6]]
12/10/2017 06:10:30 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 06:10:30 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:10:30 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:10:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:10:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:10:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:10:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:10:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:11:24 [INFO] exp_shallowmodel: train time: 53.350s
12/10/2017 06:11:24 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:11:24 [INFO] exp_shallowmodel: accuracy:   0.641
12/10/2017 06:11:24 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 06:11:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:11:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.28      0.26      0.27        27
          F       0.75      0.86      0.80       251
          R       0.25      0.15      0.19        59

avg / total       0.58      0.64      0.61       362

12/10/2017 06:11:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:11:24 [INFO] exp_shallowmodel: 
[[  0   0  14  11]
 [  2   7  17   1]
 [  8  12 216  15]
 [  4   6  40   9]]
12/10/2017 06:11:24 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 06:11:24 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:11:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:11:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:11:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:11:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:11:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:11:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:12:18 [INFO] exp_shallowmodel: train time: 54.271s
12/10/2017 06:12:18 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:12:18 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 06:12:18 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 06:12:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:12:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.04      0.05        23
          C       0.21      0.15      0.17        27
          F       0.76      0.82      0.79       250
          R       0.25      0.25      0.25        52

avg / total       0.60      0.63      0.62       352

12/10/2017 06:12:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:12:18 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  5   4  14   4]
 [  7   8 205  30]
 [  1   6  32  13]]
12/10/2017 06:12:18 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 06:12:18 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:12:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:12:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:12:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:12:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:12:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:12:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:13:07 [INFO] exp_shallowmodel: train time: 49.104s
12/10/2017 06:13:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:13:07 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 06:13:07 [INFO] exp_shallowmodel: f1_score:   0.300
12/10/2017 06:13:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:13:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.08      0.04      0.06        23
          C       0.29      0.30      0.29        27
          F       0.75      0.83      0.79       250
          R       0.09      0.06      0.07        52

avg / total       0.57      0.62      0.59       352

12/10/2017 06:13:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:13:07 [INFO] exp_shallowmodel: 
[[  1   2  17   3]
 [  1   8  15   3]
 [  9   9 207  25]
 [  2   9  38   3]]
12/10/2017 06:13:07 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 06:13:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:13:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:13:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:13:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:13:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:13:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:13:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:14:00 [INFO] exp_shallowmodel: train time: 52.606s
12/10/2017 06:14:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:14:00 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 06:14:00 [INFO] exp_shallowmodel: f1_score:   0.341
12/10/2017 06:14:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:14:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.13      0.18        23
          C       0.17      0.15      0.16        27
          F       0.78      0.82      0.80       250
          R       0.23      0.23      0.23        52

avg / total       0.62      0.64      0.63       352

12/10/2017 06:14:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:14:00 [INFO] exp_shallowmodel: 
[[  3   1  14   5]
 [  1   4  12  10]
 [  5  13 206  26]
 [  2   6  32  12]]
12/10/2017 06:14:00 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 06:14:00 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:14:00 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:14:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:14:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:14:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:14:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:14:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:14:52 [INFO] exp_shallowmodel: train time: 52.088s
12/10/2017 06:14:52 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:14:52 [INFO] exp_shallowmodel: accuracy:   0.659
12/10/2017 06:14:52 [INFO] exp_shallowmodel: f1_score:   0.358
12/10/2017 06:14:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:14:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.16      0.13      0.14        23
          C       0.28      0.26      0.27        27
          F       0.78      0.85      0.82       250
          R       0.25      0.17      0.20        52

avg / total       0.62      0.66      0.64       352

12/10/2017 06:14:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:14:52 [INFO] exp_shallowmodel: 
[[  3   0  15   5]
 [  2   7  14   4]
 [  8  11 213  18]
 [  6   7  30   9]]
12/10/2017 06:14:52 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 06:14:52 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:14:52 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:14:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:14:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:14:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:14:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:14:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:15:46 [INFO] exp_shallowmodel: train time: 53.681s
12/10/2017 06:15:46 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:15:46 [INFO] exp_shallowmodel: accuracy:   0.659
12/10/2017 06:15:46 [INFO] exp_shallowmodel: f1_score:   0.340
12/10/2017 06:15:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:15:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.04      0.04        23
          C       0.24      0.15      0.18        27
          F       0.78      0.85      0.81       250
          R       0.36      0.29      0.32        52

avg / total       0.63      0.66      0.64       352

12/10/2017 06:15:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:15:46 [INFO] exp_shallowmodel: 
[[  1   0  17   5]
 [  3   4  15   5]
 [ 13   8 212  17]
 [  5   5  27  15]]
12/10/2017 06:15:46 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 06:15:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:15:46 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:15:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:15:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:15:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:15:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:15:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:16:34 [INFO] exp_shallowmodel: train time: 47.663s
12/10/2017 06:16:34 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:16:34 [INFO] exp_shallowmodel: accuracy:   0.645
12/10/2017 06:16:34 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 06:16:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:16:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.04      0.05        23
          C       0.33      0.22      0.27        27
          F       0.77      0.84      0.80       250
          R       0.24      0.21      0.22        52

avg / total       0.61      0.64      0.62       352

12/10/2017 06:16:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:16:34 [INFO] exp_shallowmodel: 
[[  1   0  17   5]
 [  3   6  13   5]
 [  9   7 209  25]
 [  2   5  34  11]]
12/10/2017 06:16:34 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 06:16:34 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:16:34 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:16:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:16:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:16:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:16:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:16:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:17:30 [INFO] exp_shallowmodel: train time: 56.586s
12/10/2017 06:17:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:17:30 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 06:17:30 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 06:17:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:17:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.04      0.05        23
          C       0.20      0.15      0.17        27
          F       0.75      0.81      0.78       250
          R       0.24      0.21      0.22        52

avg / total       0.59      0.62      0.60       352

12/10/2017 06:17:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:17:30 [INFO] exp_shallowmodel: 
[[  1   3  16   3]
 [  1   4  19   3]
 [  9  10 202  29]
 [  6   3  32  11]]
12/10/2017 06:17:30 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 06:17:30 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:17:30 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:17:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:17:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:17:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:17:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:17:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:18:22 [INFO] exp_shallowmodel: train time: 51.819s
12/10/2017 06:18:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:18:22 [INFO] exp_shallowmodel: accuracy:   0.665
12/10/2017 06:18:22 [INFO] exp_shallowmodel: f1_score:   0.358
12/10/2017 06:18:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:18:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.04      0.05        23
          C       0.27      0.26      0.26        27
          F       0.79      0.85      0.82       250
          R       0.34      0.27      0.30        52

avg / total       0.64      0.66      0.65       352

12/10/2017 06:18:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:18:22 [INFO] exp_shallowmodel: 
[[  1   5  13   4]
 [  2   7  15   3]
 [  9   9 212  20]
 [  5   5  28  14]]
12/10/2017 06:18:22 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 06:18:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:18:22 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:18:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:18:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:18:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:18:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:18:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:19:14 [INFO] exp_shallowmodel: train time: 51.844s
12/10/2017 06:19:14 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:19:14 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 06:19:14 [INFO] exp_shallowmodel: f1_score:   0.313
12/10/2017 06:19:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:19:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.09      0.09        23
          C       0.19      0.15      0.17        27
          F       0.75      0.81      0.78       250
          R       0.24      0.19      0.22        52

avg / total       0.59      0.62      0.60       352

12/10/2017 06:19:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:19:14 [INFO] exp_shallowmodel: 
[[  2   0  17   4]
 [  0   4  14   9]
 [ 17  13 202  18]
 [  1   4  37  10]]
12/10/2017 06:19:14 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 06:19:14 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:19:14 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:19:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:19:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:19:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:19:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:19:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:20:07 [INFO] exp_shallowmodel: train time: 53.033s
12/10/2017 06:20:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:20:07 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 06:20:07 [INFO] exp_shallowmodel: f1_score:   0.331
12/10/2017 06:20:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:20:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.16      0.17        25
          C       0.20      0.11      0.14        27
          F       0.73      0.81      0.77       251
          R       0.29      0.22      0.25        59

avg / total       0.58      0.62      0.59       362

12/10/2017 06:20:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:20:07 [INFO] exp_shallowmodel: 
[[  4   1  16   4]
 [  4   3  19   1]
 [ 11  10 203  27]
 [  4   1  41  13]]
12/10/2017 06:20:07 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 06:20:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:20:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:20:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:20:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:20:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:20:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:20:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:20:58 [INFO] exp_shallowmodel: train time: 50.436s
12/10/2017 06:20:58 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:20:58 [INFO] exp_shallowmodel: accuracy:   0.659
12/10/2017 06:20:58 [INFO] exp_shallowmodel: f1_score:   0.334
12/10/2017 06:20:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:20:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.09      0.09        23
          C       0.21      0.11      0.15        27
          F       0.77      0.86      0.81       250
          R       0.33      0.25      0.29        52

avg / total       0.62      0.66      0.63       352

12/10/2017 06:20:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:20:58 [INFO] exp_shallowmodel: 
[[  2   1  15   5]
 [  3   3  15   6]
 [ 11  10 214  15]
 [  4   0  35  13]]
12/10/2017 06:20:58 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 06:20:58 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:20:58 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:20:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:20:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:20:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:20:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:20:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:21:48 [INFO] exp_shallowmodel: train time: 49.673s
12/10/2017 06:21:48 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:21:48 [INFO] exp_shallowmodel: accuracy:   0.628
12/10/2017 06:21:48 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 06:21:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:21:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.09      0.10        23
          C       0.25      0.22      0.24        27
          F       0.76      0.83      0.79       250
          R       0.16      0.12      0.13        52

avg / total       0.59      0.63      0.61       352

12/10/2017 06:21:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:21:48 [INFO] exp_shallowmodel: 
[[  2   2  17   2]
 [  3   6  10   8]
 [ 11  10 207  22]
 [  3   6  37   6]]
12/10/2017 06:21:48 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 06:21:48 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:21:48 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:21:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:21:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:21:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:21:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:21:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:22:42 [INFO] exp_shallowmodel: train time: 54.113s
12/10/2017 06:22:42 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:22:42 [INFO] exp_shallowmodel: accuracy:   0.625
12/10/2017 06:22:42 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 06:22:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:22:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.05      0.04      0.05        23
          C       0.21      0.22      0.22        27
          F       0.78      0.81      0.80       250
          R       0.23      0.19      0.21        52

avg / total       0.61      0.62      0.62       352

12/10/2017 06:22:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:22:42 [INFO] exp_shallowmodel: 
[[  1   1  17   4]
 [  4   6  11   6]
 [  9  15 203  23]
 [  7   6  29  10]]
12/10/2017 06:22:42 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 06:22:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:22:42 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:22:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:22:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:22:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:22:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:22:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:23:34 [INFO] exp_shallowmodel: train time: 52.100s
12/10/2017 06:23:34 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:23:34 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 06:23:34 [INFO] exp_shallowmodel: f1_score:   0.346
12/10/2017 06:23:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:23:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.13      0.14        23
          C       0.38      0.22      0.28        27
          F       0.74      0.83      0.78       250
          R       0.23      0.15      0.18        52

avg / total       0.60      0.64      0.61       352

12/10/2017 06:23:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:23:34 [INFO] exp_shallowmodel: 
[[  3   0  15   5]
 [  1   6  17   3]
 [ 16   7 208  19]
 [  0   3  41   8]]
12/10/2017 06:23:34 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 06:23:34 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:23:34 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:23:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:23:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:23:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:23:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:23:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:24:23 [INFO] exp_shallowmodel: train time: 48.830s
12/10/2017 06:24:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:24:23 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 06:24:23 [INFO] exp_shallowmodel: f1_score:   0.318
12/10/2017 06:24:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:24:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.21      0.26      0.23        27
          F       0.79      0.82      0.80       250
          R       0.27      0.21      0.24        52

avg / total       0.62      0.63      0.62       352

12/10/2017 06:24:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:24:23 [INFO] exp_shallowmodel: 
[[  0   3  14   6]
 [  3   7  13   4]
 [ 10  15 205  20]
 [  5   8  28  11]]
12/10/2017 06:24:23 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 06:24:23 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:24:23 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:24:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:24:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:24:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:24:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:24:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:25:15 [INFO] exp_shallowmodel: train time: 51.582s
12/10/2017 06:25:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:25:15 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 06:25:15 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 06:25:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:25:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.13      0.15        23
          C       0.20      0.11      0.14        27
          F       0.76      0.85      0.80       250
          R       0.15      0.12      0.13        52

avg / total       0.59      0.64      0.61       352

12/10/2017 06:25:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:25:15 [INFO] exp_shallowmodel: 
[[  3   0  15   5]
 [  1   3  16   7]
 [ 10   5 213  22]
 [  3   7  36   6]]
12/10/2017 06:25:15 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 06:25:15 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:25:15 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:25:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:25:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:25:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:25:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:25:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:26:08 [INFO] exp_shallowmodel: train time: 53.348s
12/10/2017 06:26:08 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:26:08 [INFO] exp_shallowmodel: accuracy:   0.631
12/10/2017 06:26:08 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 06:26:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:26:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.13      0.15        23
          C       0.00      0.00      0.00        27
          F       0.77      0.84      0.80       250
          R       0.20      0.19      0.20        52

avg / total       0.59      0.63      0.61       352

12/10/2017 06:26:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:26:08 [INFO] exp_shallowmodel: 
[[  3   1  14   5]
 [  2   0  14  11]
 [  7  11 209  23]
 [  5   4  33  10]]
12/10/2017 06:26:08 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 06:26:08 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:26:08 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:26:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:26:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:26:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:26:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:26:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:27:00 [INFO] exp_shallowmodel: train time: 51.873s
12/10/2017 06:27:00 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:27:00 [INFO] exp_shallowmodel: accuracy:   0.614
12/10/2017 06:27:00 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 06:27:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:27:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.13      0.14        23
          C       0.28      0.30      0.29        27
          F       0.77      0.78      0.78       250
          R       0.19      0.17      0.18        52

avg / total       0.60      0.61      0.61       352

12/10/2017 06:27:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:27:00 [INFO] exp_shallowmodel: 
[[  3   1  16   3]
 [  5   8  10   4]
 [  7  15 196  32]
 [  5   5  33   9]]
12/10/2017 06:27:00 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 06:27:00 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:27:00 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:27:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:27:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:27:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:27:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:27:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:27:53 [INFO] exp_shallowmodel: train time: 53.117s
12/10/2017 06:27:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:27:53 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 06:27:53 [INFO] exp_shallowmodel: f1_score:   0.329
12/10/2017 06:27:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:27:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.09      0.09        23
          C       0.44      0.30      0.36        27
          F       0.75      0.82      0.78       250
          R       0.10      0.08      0.09        52

avg / total       0.59      0.62      0.60       352

12/10/2017 06:27:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:27:53 [INFO] exp_shallowmodel: 
[[  2   1  16   4]
 [  0   8  14   5]
 [ 12   6 205  27]
 [  7   3  38   4]]
12/10/2017 06:27:53 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 06:27:53 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:27:53 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:27:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:27:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:27:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:27:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:27:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:28:44 [INFO] exp_shallowmodel: train time: 50.383s
12/10/2017 06:28:44 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:28:44 [INFO] exp_shallowmodel: accuracy:   0.652
12/10/2017 06:28:44 [INFO] exp_shallowmodel: f1_score:   0.372
12/10/2017 06:28:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:28:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.08      0.10        25
          C       0.27      0.22      0.24        27
          F       0.74      0.84      0.79       251
          R       0.44      0.31      0.36        59

avg / total       0.62      0.65      0.63       362

12/10/2017 06:28:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:28:44 [INFO] exp_shallowmodel: 
[[  2   2  18   3]
 [  1   6  17   3]
 [ 12  12 210  17]
 [  2   2  37  18]]
12/10/2017 06:28:44 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 06:28:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:28:44 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:28:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:28:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:28:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:28:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:28:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:29:34 [INFO] exp_shallowmodel: train time: 50.059s
12/10/2017 06:29:34 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:29:34 [INFO] exp_shallowmodel: accuracy:   0.631
12/10/2017 06:29:34 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 06:29:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:29:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.14      0.11      0.12        27
          F       0.79      0.82      0.80       250
          R       0.25      0.27      0.26        52

avg / total       0.61      0.63      0.62       352

12/10/2017 06:29:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:29:34 [INFO] exp_shallowmodel: 
[[  0   2  14   7]
 [  5   3  14   5]
 [  7   9 205  29]
 [  4   7  27  14]]
12/10/2017 06:29:34 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 06:29:34 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:29:34 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:29:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:29:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:29:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:29:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:29:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:30:22 [INFO] exp_shallowmodel: train time: 48.362s
12/10/2017 06:30:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:30:22 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 06:30:22 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 06:30:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:30:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.14      0.13      0.13        23
          C       0.14      0.11      0.12        27
          F       0.75      0.83      0.79       250
          R       0.27      0.17      0.21        52

avg / total       0.60      0.63      0.61       352

12/10/2017 06:30:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:30:22 [INFO] exp_shallowmodel: 
[[  3   1  17   2]
 [  2   3  21   1]
 [ 11  10 208  21]
 [  6   7  30   9]]
12/10/2017 06:30:22 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 06:30:22 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:30:22 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:30:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:30:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:30:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:30:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:30:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:31:15 [INFO] exp_shallowmodel: train time: 52.457s
12/10/2017 06:31:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:31:15 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 06:31:15 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 06:31:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:31:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.29      0.15      0.20        27
          F       0.73      0.83      0.78       250
          R       0.15      0.12      0.13        52

avg / total       0.56      0.62      0.59       352

12/10/2017 06:31:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:31:15 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  2   4  18   3]
 [  8   8 208  26]
 [  3   2  41   6]]
12/10/2017 06:31:15 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 06:31:15 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:31:15 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:31:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:31:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:31:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:31:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:31:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:32:07 [INFO] exp_shallowmodel: train time: 52.007s
12/10/2017 06:32:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:32:07 [INFO] exp_shallowmodel: accuracy:   0.679
12/10/2017 06:32:07 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 06:32:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:32:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.09      0.10        23
          C       0.50      0.41      0.45        27
          F       0.77      0.86      0.81       250
          R       0.33      0.21      0.26        52

avg / total       0.64      0.68      0.66       352

12/10/2017 06:32:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:32:07 [INFO] exp_shallowmodel: 
[[  2   1  14   6]
 [  2  11  13   1]
 [ 11   9 215  15]
 [  4   1  36  11]]
12/10/2017 06:32:07 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 06:32:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:32:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:32:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:32:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:32:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:32:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:32:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:32:58 [INFO] exp_shallowmodel: train time: 51.114s
12/10/2017 06:32:58 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:32:58 [INFO] exp_shallowmodel: accuracy:   0.665
12/10/2017 06:32:58 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 06:32:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:32:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.28      0.26      0.27        27
          F       0.78      0.86      0.82       250
          R       0.29      0.23      0.26        52

avg / total       0.62      0.66      0.64       352

12/10/2017 06:32:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:32:58 [INFO] exp_shallowmodel: 
[[  0   2  16   5]
 [  2   7  13   5]
 [  5  11 215  19]
 [  3   5  32  12]]
12/10/2017 06:32:58 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 06:32:58 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:32:58 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:32:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:32:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:32:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:32:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:32:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:33:53 [INFO] exp_shallowmodel: train time: 55.033s
12/10/2017 06:33:53 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:33:53 [INFO] exp_shallowmodel: accuracy:   0.628
12/10/2017 06:33:53 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 06:33:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:33:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.09      0.11        23
          C       0.25      0.26      0.25        27
          F       0.75      0.80      0.78       250
          R       0.27      0.23      0.25        52

avg / total       0.60      0.63      0.61       352

12/10/2017 06:33:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:33:53 [INFO] exp_shallowmodel: 
[[  2   5  14   2]
 [  0   7  17   3]
 [  8  14 200  28]
 [  3   2  35  12]]
12/10/2017 06:33:53 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 06:33:53 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:33:53 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:33:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:33:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:33:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:33:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:33:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:34:42 [INFO] exp_shallowmodel: train time: 48.616s
12/10/2017 06:34:42 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:34:42 [INFO] exp_shallowmodel: accuracy:   0.656
12/10/2017 06:34:42 [INFO] exp_shallowmodel: f1_score:   0.327
12/10/2017 06:34:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:34:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.04      0.06        23
          C       0.40      0.22      0.29        27
          F       0.75      0.87      0.81       250
          R       0.18      0.13      0.16        52

avg / total       0.60      0.66      0.62       352

12/10/2017 06:34:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:34:42 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  1   6  14   6]
 [  6   5 217  22]
 [  2   4  39   7]]
12/10/2017 06:34:42 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 06:34:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:34:42 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:34:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:34:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:34:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:34:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:34:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:35:35 [INFO] exp_shallowmodel: train time: 52.775s
12/10/2017 06:35:35 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:35:35 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 06:35:35 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 06:35:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:35:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.09      0.10        23
          C       0.17      0.15      0.16        27
          F       0.76      0.81      0.78       250
          R       0.23      0.19      0.21        52

avg / total       0.59      0.62      0.61       352

12/10/2017 06:35:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:35:35 [INFO] exp_shallowmodel: 
[[  2   3  16   2]
 [  1   4  16   6]
 [ 10  12 202  26]
 [  5   5  32  10]]
12/10/2017 06:35:35 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 06:35:35 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:35:35 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:35:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:35:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:35:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:35:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:35:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:36:27 [INFO] exp_shallowmodel: train time: 51.905s
12/10/2017 06:36:27 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:36:27 [INFO] exp_shallowmodel: accuracy:   0.645
12/10/2017 06:36:27 [INFO] exp_shallowmodel: f1_score:   0.341
12/10/2017 06:36:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:36:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.09      0.10        23
          C       0.25      0.15      0.19        27
          F       0.76      0.83      0.79       250
          R       0.31      0.27      0.29        52

avg / total       0.61      0.64      0.63       352

12/10/2017 06:36:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:36:27 [INFO] exp_shallowmodel: 
[[  2   1  16   4]
 [  4   4  14   5]
 [ 11  10 207  22]
 [  2   1  35  14]]
12/10/2017 06:36:27 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 06:36:27 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:36:27 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:36:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:36:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:36:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:36:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:36:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:37:17 [INFO] exp_shallowmodel: train time: 50.082s
12/10/2017 06:37:17 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:37:17 [INFO] exp_shallowmodel: accuracy:   0.605
12/10/2017 06:37:17 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 06:37:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:37:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.12      0.08      0.10        25
          C       0.17      0.15      0.16        27
          F       0.76      0.79      0.78       251
          R       0.23      0.25      0.24        59

avg / total       0.59      0.60      0.60       362

12/10/2017 06:37:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:37:17 [INFO] exp_shallowmodel: 
[[  2   2  18   3]
 [  3   4   9  11]
 [  8  10 198  35]
 [  3   7  34  15]]
12/10/2017 06:37:17 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 06:37:17 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:37:17 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:37:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:37:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:37:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:37:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:37:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:38:10 [INFO] exp_shallowmodel: train time: 52.745s
12/10/2017 06:38:10 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:38:10 [INFO] exp_shallowmodel: accuracy:   0.673
12/10/2017 06:38:10 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 06:38:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:38:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.13      0.15        23
          C       0.35      0.41      0.38        27
          F       0.79      0.84      0.82       250
          R       0.32      0.23      0.27        52

avg / total       0.65      0.67      0.66       352

12/10/2017 06:38:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:38:10 [INFO] exp_shallowmodel: 
[[  3   2  15   3]
 [  2  11  12   2]
 [  7  12 211  20]
 [  5   6  29  12]]
12/10/2017 06:38:10 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 06:38:10 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:38:10 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:38:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:38:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:38:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:38:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:38:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:39:01 [INFO] exp_shallowmodel: train time: 51.170s
12/10/2017 06:39:01 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:39:01 [INFO] exp_shallowmodel: accuracy:   0.631
12/10/2017 06:39:01 [INFO] exp_shallowmodel: f1_score:   0.333
12/10/2017 06:39:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:39:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.04      0.04      0.04        23
          C       0.33      0.22      0.27        27
          F       0.77      0.82      0.79       250
          R       0.26      0.21      0.23        52

avg / total       0.61      0.63      0.62       352

12/10/2017 06:39:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:39:01 [INFO] exp_shallowmodel: 
[[  1   3  14   5]
 [  3   6  14   4]
 [ 17   6 204  23]
 [  6   3  32  11]]
12/10/2017 06:39:01 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 06:39:01 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:39:01 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:39:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:39:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:39:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:39:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:39:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:39:52 [INFO] exp_shallowmodel: train time: 51.401s
12/10/2017 06:39:52 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:39:52 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 06:39:52 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 06:39:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:39:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.22      0.27        27
          F       0.77      0.84      0.81       250
          R       0.20      0.17      0.18        52

avg / total       0.60      0.64      0.62       352

12/10/2017 06:39:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:39:52 [INFO] exp_shallowmodel: 
[[  0   2  15   6]
 [  2   6  14   5]
 [  8   6 210  26]
 [  7   4  32   9]]
12/10/2017 06:39:52 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 06:39:52 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:39:52 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:39:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:39:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:39:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:39:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:39:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:40:43 [INFO] exp_shallowmodel: train time: 50.139s
12/10/2017 06:40:43 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:40:43 [INFO] exp_shallowmodel: accuracy:   0.605
12/10/2017 06:40:43 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 06:40:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:40:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.22      0.22      0.22        27
          F       0.75      0.77      0.76       250
          R       0.27      0.27      0.27        52

avg / total       0.59      0.61      0.60       352

12/10/2017 06:40:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:40:43 [INFO] exp_shallowmodel: 
[[  0   2  17   4]
 [  1   6  17   3]
 [ 12  14 193  31]
 [  4   5  29  14]]
12/10/2017 06:40:43 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 06:40:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:40:43 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:40:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:40:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:40:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:40:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:40:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:41:30 [INFO] exp_shallowmodel: train time: 47.250s
12/10/2017 06:41:30 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:41:30 [INFO] exp_shallowmodel: accuracy:   0.682
12/10/2017 06:41:30 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 06:41:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:41:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.17      0.19        23
          C       0.44      0.30      0.36        27
          F       0.79      0.86      0.82       250
          R       0.30      0.23      0.26        52

avg / total       0.65      0.68      0.66       352

12/10/2017 06:41:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:41:30 [INFO] exp_shallowmodel: 
[[  4   0  14   5]
 [  1   8  13   5]
 [ 10   6 216  18]
 [  4   4  32  12]]
12/10/2017 06:41:30 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 06:41:30 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:41:30 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:41:30 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:41:30 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:41:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:41:30 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:41:30 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:42:18 [INFO] exp_shallowmodel: train time: 48.050s
12/10/2017 06:42:18 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:42:18 [INFO] exp_shallowmodel: accuracy:   0.636
12/10/2017 06:42:18 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 06:42:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:42:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.04      0.05        23
          C       0.23      0.19      0.20        27
          F       0.77      0.83      0.80       250
          R       0.23      0.19      0.21        52

avg / total       0.60      0.64      0.62       352

12/10/2017 06:42:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:42:18 [INFO] exp_shallowmodel: 
[[  1   3  14   5]
 [  3   5  12   7]
 [ 12   9 208  21]
 [  0   5  37  10]]
12/10/2017 06:42:18 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 06:42:18 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:42:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:42:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:42:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:42:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:42:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:42:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:43:07 [INFO] exp_shallowmodel: train time: 48.939s
12/10/2017 06:43:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:43:07 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 06:43:07 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 06:43:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:43:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.07      0.04      0.05        23
          C       0.28      0.33      0.31        27
          F       0.77      0.81      0.79       250
          R       0.26      0.21      0.23        52

avg / total       0.61      0.63      0.62       352

12/10/2017 06:43:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:43:07 [INFO] exp_shallowmodel: 
[[  1   3  16   3]
 [  2   9  11   5]
 [ 11  14 202  23]
 [  1   6  34  11]]
12/10/2017 06:43:07 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 06:43:07 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:43:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:43:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:43:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:43:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:43:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:43:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:43:56 [INFO] exp_shallowmodel: train time: 49.324s
12/10/2017 06:43:56 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:43:56 [INFO] exp_shallowmodel: accuracy:   0.662
12/10/2017 06:43:56 [INFO] exp_shallowmodel: f1_score:   0.333
12/10/2017 06:43:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:43:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.18      0.17      0.18        23
          C       0.20      0.11      0.14        27
          F       0.76      0.87      0.81       250
          R       0.30      0.15      0.20        52

avg / total       0.61      0.66      0.63       352

12/10/2017 06:43:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:43:56 [INFO] exp_shallowmodel: 
[[  4   1  15   3]
 [  4   3  18   2]
 [  9   9 218  14]
 [  5   2  37   8]]
12/10/2017 06:43:56 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 06:43:56 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 06:43:56 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:43:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:43:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:43:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:43:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:43:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:44:47 [INFO] exp_shallowmodel: train time: 50.131s
12/10/2017 06:44:47 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:44:47 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 06:44:47 [INFO] exp_shallowmodel: f1_score:   0.262
12/10/2017 06:44:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:44:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.09      0.09        23
          C       0.06      0.04      0.05        27
          F       0.74      0.82      0.78       250
          R       0.16      0.12      0.13        52

avg / total       0.56      0.61      0.58       352

12/10/2017 06:44:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:44:47 [INFO] exp_shallowmodel: 
[[  2   0  19   2]
 [  1   1  18   7]
 [ 13  10 205  22]
 [  7   5  34   6]]
12/10/2017 06:44:47 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 06:44:47 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 06:44:47 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:44:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:44:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:44:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:44:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:44:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:45:35 [INFO] exp_shallowmodel: train time: 48.278s
12/10/2017 06:45:35 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:45:35 [INFO] exp_shallowmodel: accuracy:   0.624
12/10/2017 06:45:35 [INFO] exp_shallowmodel: f1_score:   0.304
12/10/2017 06:45:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:45:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.06      0.04      0.05        25
          C       0.30      0.22      0.26        27
          F       0.73      0.85      0.79       251
          R       0.17      0.10      0.13        59

avg / total       0.56      0.62      0.59       362

12/10/2017 06:45:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:45:35 [INFO] exp_shallowmodel: 
[[  1   0  17   7]
 [  3   6  16   2]
 [  8  10 213  20]
 [  4   4  45   6]]
12/10/2017 06:45:41 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 06:45:41 [INFO] task_runner: context=last, feature=7-d2v
12/10/2017 06:45:41 [INFO] task_runner: retained feature numbers=[10.1]
12/10/2017 06:45:41 [INFO] task_runner: #(data)=5241
12/10/2017 06:45:41 [INFO] task_runner: #(feature)=900
12/10/2017 06:45:41 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 06:45:41 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 06:45:41 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:45:41 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:45:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:45:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:45:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:45:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:45:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:47:36 [INFO] exp_shallowmodel: train time: 115.081s
12/10/2017 06:47:36 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:47:36 [INFO] exp_shallowmodel: accuracy:   0.728
12/10/2017 06:47:36 [INFO] exp_shallowmodel: f1_score:   0.338
12/10/2017 06:47:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:47:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.17      0.22        59
          C       0.20      0.08      0.12        12
          F       0.80      0.91      0.85       396
          R       0.19      0.13      0.15        55

avg / total       0.67      0.73      0.69       522

12/10/2017 06:47:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:47:36 [INFO] exp_shallowmodel: 
[[ 10   3  36  10]
 [  0   1   8   3]
 [ 17   1 362  16]
 [  3   0  45   7]]
12/10/2017 06:47:36 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 06:47:36 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:47:36 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:47:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:47:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:47:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:47:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:47:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:49:28 [INFO] exp_shallowmodel: train time: 111.695s
12/10/2017 06:49:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:49:28 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 06:49:28 [INFO] exp_shallowmodel: f1_score:   0.353
12/10/2017 06:49:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:49:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.19      0.20        59
          C       0.33      0.08      0.13        12
          F       0.78      0.87      0.82       396
          R       0.33      0.20      0.25        55

avg / total       0.66      0.70      0.68       522

12/10/2017 06:49:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:49:28 [INFO] exp_shallowmodel: 
[[ 11   1  43   4]
 [  1   1   9   1]
 [ 35   1 343  17]
 [  2   0  42  11]]
12/10/2017 06:49:28 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 06:49:28 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:49:28 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:49:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:49:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:49:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:49:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:49:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:51:19 [INFO] exp_shallowmodel: train time: 111.035s
12/10/2017 06:51:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:51:19 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 06:51:19 [INFO] exp_shallowmodel: f1_score:   0.337
12/10/2017 06:51:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:51:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.14      0.16        59
          C       0.25      0.08      0.12        12
          F       0.79      0.89      0.84       396
          R       0.28      0.18      0.22        55

avg / total       0.66      0.71      0.68       522

12/10/2017 06:51:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:51:19 [INFO] exp_shallowmodel: 
[[  8   1  46   4]
 [  2   1   9   0]
 [ 20   2 352  22]
 [  9   0  36  10]]
12/10/2017 06:51:19 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 06:51:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:51:19 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:51:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:51:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:51:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:51:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:51:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:53:12 [INFO] exp_shallowmodel: train time: 113.022s
12/10/2017 06:53:12 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:53:12 [INFO] exp_shallowmodel: accuracy:   0.697
12/10/2017 06:53:12 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 06:53:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:53:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.25      0.25        59
          C       0.00      0.00      0.00        12
          F       0.82      0.85      0.84       396
          R       0.29      0.24      0.26        55

avg / total       0.68      0.70      0.69       522

12/10/2017 06:53:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:53:12 [INFO] exp_shallowmodel: 
[[ 15   1  33  10]
 [  3   0   8   1]
 [ 33   6 336  21]
 [ 10   1  31  13]]
12/10/2017 06:53:12 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 06:53:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:53:12 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:53:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:53:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:53:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:53:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:53:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:55:07 [INFO] exp_shallowmodel: train time: 114.780s
12/10/2017 06:55:07 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:55:07 [INFO] exp_shallowmodel: accuracy:   0.697
12/10/2017 06:55:07 [INFO] exp_shallowmodel: f1_score:   0.283
12/10/2017 06:55:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:55:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.07      0.09        59
          C       0.00      0.00      0.00        12
          F       0.79      0.88      0.83       396
          R       0.24      0.18      0.21        55

avg / total       0.64      0.70      0.66       522

12/10/2017 06:55:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:55:07 [INFO] exp_shallowmodel: 
[[  4   1  42  12]
 [  2   0   9   1]
 [ 21   6 350  19]
 [  3   0  42  10]]
12/10/2017 06:55:07 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 06:55:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:55:07 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:55:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:55:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:55:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:55:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:55:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:57:09 [INFO] exp_shallowmodel: train time: 121.522s
12/10/2017 06:57:09 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:57:09 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 06:57:09 [INFO] exp_shallowmodel: f1_score:   0.308
12/10/2017 06:57:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:57:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.19      0.24        59
          C       0.00      0.00      0.00        12
          F       0.78      0.91      0.84       396
          R       0.24      0.11      0.15        55

avg / total       0.66      0.72      0.68       522

12/10/2017 06:57:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:57:09 [INFO] exp_shallowmodel: 
[[ 11   0  44   4]
 [  2   0  10   0]
 [ 17   3 361  15]
 [  2   0  47   6]]
12/10/2017 06:57:09 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 06:57:09 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:57:09 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:57:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:57:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:57:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:57:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:57:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 06:59:16 [INFO] exp_shallowmodel: train time: 127.229s
12/10/2017 06:59:16 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 06:59:16 [INFO] exp_shallowmodel: accuracy:   0.718
12/10/2017 06:59:16 [INFO] exp_shallowmodel: f1_score:   0.299
12/10/2017 06:59:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 06:59:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.14      0.18        59
          C       0.00      0.00      0.00        12
          F       0.79      0.91      0.85       396
          R       0.27      0.13      0.17        55

avg / total       0.66      0.72      0.68       522

12/10/2017 06:59:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 06:59:16 [INFO] exp_shallowmodel: 
[[  8   4  42   5]
 [  0   0  12   0]
 [ 16   6 360  14]
 [  8   0  40   7]]
12/10/2017 06:59:16 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 06:59:16 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 06:59:16 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 06:59:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 06:59:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 06:59:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 06:59:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 06:59:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:01:25 [INFO] exp_shallowmodel: train time: 128.849s
12/10/2017 07:01:25 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:01:25 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 07:01:25 [INFO] exp_shallowmodel: f1_score:   0.320
12/10/2017 07:01:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:01:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.27      0.28        59
          C       0.00      0.00      0.00        12
          F       0.82      0.87      0.84       396
          R       0.19      0.13      0.15        55

avg / total       0.67      0.71      0.69       522

12/10/2017 07:01:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:01:25 [INFO] exp_shallowmodel: 
[[ 16   4  33   6]
 [  1   0  10   1]
 [ 24   4 346  22]
 [ 13   1  34   7]]
12/10/2017 07:01:25 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 07:01:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:01:25 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:01:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:01:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:01:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:01:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:01:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:03:24 [INFO] exp_shallowmodel: train time: 118.690s
12/10/2017 07:03:24 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:03:24 [INFO] exp_shallowmodel: accuracy:   0.720
12/10/2017 07:03:24 [INFO] exp_shallowmodel: f1_score:   0.339
12/10/2017 07:03:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:03:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.22      0.25        59
          C       0.17      0.08      0.11        12
          F       0.80      0.90      0.85       396
          R       0.23      0.11      0.15        55

avg / total       0.67      0.72      0.69       522

12/10/2017 07:03:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:03:24 [INFO] exp_shallowmodel: 
[[ 13   1  36   9]
 [  1   1  10   0]
 [ 25   4 356  11]
 [  7   0  42   6]]
12/10/2017 07:03:24 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 07:03:24 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 07:03:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:03:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:03:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:03:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:03:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:03:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:05:31 [INFO] exp_shallowmodel: train time: 127.679s
12/10/2017 07:05:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:05:31 [INFO] exp_shallowmodel: accuracy:   0.687
12/10/2017 07:05:31 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 07:05:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:05:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.19      0.22        64
          C       0.00      0.00      0.00        14
          F       0.77      0.88      0.82       402
          R       0.23      0.11      0.15        63

avg / total       0.63      0.69      0.65       543

12/10/2017 07:05:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:05:31 [INFO] exp_shallowmodel: 
[[ 12   0  48   4]
 [  3   0  11   0]
 [ 23   6 354  19]
 [  8   2  46   7]]
12/10/2017 07:05:32 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 07:05:32 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:05:32 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:05:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:05:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:05:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:05:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:05:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:07:26 [INFO] exp_shallowmodel: train time: 114.552s
12/10/2017 07:07:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:07:26 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 07:07:26 [INFO] exp_shallowmodel: f1_score:   0.308
12/10/2017 07:07:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:07:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.19      0.22        59
          C       0.00      0.00      0.00        12
          F       0.80      0.86      0.83       396
          R       0.20      0.16      0.18        55

avg / total       0.66      0.69      0.67       522

12/10/2017 07:07:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:07:26 [INFO] exp_shallowmodel: 
[[ 11   0  40   8]
 [  2   0   9   1]
 [ 21   6 342  27]
 [  6   2  38   9]]
12/10/2017 07:07:26 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 07:07:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:07:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:07:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:07:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:07:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:07:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:07:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:09:21 [INFO] exp_shallowmodel: train time: 114.771s
12/10/2017 07:09:21 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:09:21 [INFO] exp_shallowmodel: accuracy:   0.728
12/10/2017 07:09:21 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 07:09:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:09:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.14      0.17        59
          C       0.23      0.25      0.24        12
          F       0.81      0.91      0.86       396
          R       0.23      0.13      0.16        55

avg / total       0.67      0.73      0.69       522

12/10/2017 07:09:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:09:21 [INFO] exp_shallowmodel: 
[[  8   2  40   9]
 [  2   3   6   1]
 [ 15   6 362  13]
 [  8   2  38   7]]
12/10/2017 07:09:21 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 07:09:21 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:09:21 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:09:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:09:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:09:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:09:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:09:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:11:23 [INFO] exp_shallowmodel: train time: 121.698s
12/10/2017 07:11:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:11:23 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 07:11:23 [INFO] exp_shallowmodel: f1_score:   0.345
12/10/2017 07:11:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:11:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.20      0.23        59
          C       0.14      0.08      0.11        12
          F       0.80      0.88      0.84       396
          R       0.27      0.16      0.20        55

avg / total       0.67      0.71      0.69       522

12/10/2017 07:11:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:11:23 [INFO] exp_shallowmodel: 
[[ 12   1  40   6]
 [  1   1  10   0]
 [ 26   3 349  18]
 [  6   2  38   9]]
12/10/2017 07:11:23 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 07:11:23 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:11:23 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:11:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:11:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:11:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:11:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:11:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:13:20 [INFO] exp_shallowmodel: train time: 116.637s
12/10/2017 07:13:20 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:13:20 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 07:13:20 [INFO] exp_shallowmodel: f1_score:   0.341
12/10/2017 07:13:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:13:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.19      0.22        59
          C       0.00      0.00      0.00        12
          F       0.81      0.89      0.85       396
          R       0.36      0.25      0.30        55

avg / total       0.68      0.72      0.70       522

12/10/2017 07:13:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:13:20 [INFO] exp_shallowmodel: 
[[ 11   2  41   5]
 [  0   0  10   2]
 [ 23   3 352  18]
 [  6   1  34  14]]
12/10/2017 07:13:20 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 07:13:20 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:13:20 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:13:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:13:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:13:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:13:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:13:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:15:19 [INFO] exp_shallowmodel: train time: 119.530s
12/10/2017 07:15:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:15:19 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 07:15:19 [INFO] exp_shallowmodel: f1_score:   0.323
12/10/2017 07:15:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:15:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.17      0.19        59
          C       0.20      0.08      0.12        12
          F       0.80      0.89      0.84       396
          R       0.22      0.11      0.15        55

avg / total       0.66      0.71      0.68       522

12/10/2017 07:15:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:15:19 [INFO] exp_shallowmodel: 
[[ 10   1  40   8]
 [  2   1   9   0]
 [ 28   2 353  13]
 [  9   1  39   6]]
12/10/2017 07:15:19 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 07:15:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:15:19 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:15:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:15:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:15:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:15:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:15:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:17:25 [INFO] exp_shallowmodel: train time: 125.822s
12/10/2017 07:17:25 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:17:25 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 07:17:25 [INFO] exp_shallowmodel: f1_score:   0.347
12/10/2017 07:17:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:17:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.19      0.22        59
          C       0.17      0.08      0.11        12
          F       0.79      0.88      0.84       396
          R       0.27      0.18      0.22        55

avg / total       0.67      0.71      0.68       522

12/10/2017 07:17:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:17:25 [INFO] exp_shallowmodel: 
[[ 11   2  40   6]
 [  1   1  10   0]
 [ 23   3 349  21]
 [  5   0  40  10]]
12/10/2017 07:17:25 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 07:17:25 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:17:25 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:17:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:17:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:17:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:17:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:17:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:19:31 [INFO] exp_shallowmodel: train time: 126.084s
12/10/2017 07:19:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:19:31 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 07:19:31 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 07:19:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:19:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.19      0.22        59
          C       0.17      0.08      0.11        12
          F       0.80      0.90      0.84       396
          R       0.10      0.05      0.07        55

avg / total       0.65      0.71      0.68       522

12/10/2017 07:19:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:19:31 [INFO] exp_shallowmodel: 
[[ 11   2  35  11]
 [  1   1   9   1]
 [ 24   3 355  14]
 [  6   0  46   3]]
12/10/2017 07:19:31 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 07:19:31 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:19:31 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:19:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:19:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:19:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:19:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:19:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:21:29 [INFO] exp_shallowmodel: train time: 117.171s
12/10/2017 07:21:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:21:29 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 07:21:29 [INFO] exp_shallowmodel: f1_score:   0.348
12/10/2017 07:21:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:21:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.20      0.25        59
          C       0.14      0.08      0.11        12
          F       0.80      0.90      0.85       396
          R       0.28      0.15      0.19        55

avg / total       0.67      0.73      0.69       522

12/10/2017 07:21:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:21:29 [INFO] exp_shallowmodel: 
[[ 12   1  40   6]
 [  1   1   8   2]
 [ 21   4 358  13]
 [  4   1  42   8]]
12/10/2017 07:21:29 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 07:21:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:21:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:21:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:21:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:21:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:21:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:21:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:23:32 [INFO] exp_shallowmodel: train time: 123.088s
12/10/2017 07:23:32 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:23:32 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 07:23:32 [INFO] exp_shallowmodel: f1_score:   0.303
12/10/2017 07:23:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:23:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.15      0.21        59
          C       0.00      0.00      0.00        12
          F       0.79      0.90      0.84       396
          R       0.23      0.13      0.16        55

avg / total       0.66      0.71      0.68       522

12/10/2017 07:23:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:23:32 [INFO] exp_shallowmodel: 
[[  9   4  43   3]
 [  0   0  10   2]
 [ 15   6 356  19]
 [  3   2  43   7]]
12/10/2017 07:23:32 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 07:23:32 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 07:23:32 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:23:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:23:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:23:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:23:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:23:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:25:22 [INFO] exp_shallowmodel: train time: 110.117s
12/10/2017 07:25:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:25:22 [INFO] exp_shallowmodel: accuracy:   0.681
12/10/2017 07:25:22 [INFO] exp_shallowmodel: f1_score:   0.332
12/10/2017 07:25:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:25:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.15      0.09      0.11        64
          C       0.21      0.21      0.21        14
          F       0.76      0.88      0.81       402
          R       0.35      0.13      0.19        63

avg / total       0.63      0.68      0.64       543

12/10/2017 07:25:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:25:22 [INFO] exp_shallowmodel: 
[[  6   2  54   2]
 [  0   3  11   0]
 [ 28   8 353  13]
 [  7   1  47   8]]
12/10/2017 07:25:22 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 07:25:22 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:25:22 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:25:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:25:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:25:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:25:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:25:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:27:29 [INFO] exp_shallowmodel: train time: 126.371s
12/10/2017 07:27:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:27:29 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 07:27:29 [INFO] exp_shallowmodel: f1_score:   0.341
12/10/2017 07:27:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:27:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.15      0.20        59
          C       0.08      0.08      0.08        12
          F       0.80      0.89      0.84       396
          R       0.29      0.20      0.24        55

avg / total       0.67      0.72      0.69       522

12/10/2017 07:27:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:27:29 [INFO] exp_shallowmodel: 
[[  9   2  41   7]
 [  2   1   7   2]
 [ 19   6 353  18]
 [  1   3  40  11]]
12/10/2017 07:27:29 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 07:27:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:27:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:27:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:27:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:27:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:27:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:27:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:29:31 [INFO] exp_shallowmodel: train time: 121.961s
12/10/2017 07:29:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:29:31 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 07:29:31 [INFO] exp_shallowmodel: f1_score:   0.342
12/10/2017 07:29:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:29:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.20      0.23        59
          C       0.20      0.08      0.12        12
          F       0.80      0.88      0.84       396
          R       0.24      0.15      0.18        55

avg / total       0.66      0.71      0.68       522

12/10/2017 07:29:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:29:31 [INFO] exp_shallowmodel: 
[[ 12   0  40   7]
 [  1   1   6   4]
 [ 29   3 350  14]
 [  2   1  44   8]]
12/10/2017 07:29:31 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 07:29:31 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:29:31 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:29:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:29:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:29:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:29:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:29:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:31:26 [INFO] exp_shallowmodel: train time: 115.053s
12/10/2017 07:31:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:31:26 [INFO] exp_shallowmodel: accuracy:   0.734
12/10/2017 07:31:26 [INFO] exp_shallowmodel: f1_score:   0.397
12/10/2017 07:31:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:31:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.32      0.35        59
          C       0.22      0.17      0.19        12
          F       0.81      0.89      0.85       396
          R       0.30      0.15      0.20        55

avg / total       0.69      0.73      0.71       522

12/10/2017 07:31:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:31:26 [INFO] exp_shallowmodel: 
[[ 19   1  36   3]
 [  3   2   7   0]
 [ 20   6 354  16]
 [  7   0  40   8]]
12/10/2017 07:31:26 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 07:31:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:31:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:31:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:31:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:31:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:31:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:31:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:33:19 [INFO] exp_shallowmodel: train time: 112.735s
12/10/2017 07:33:19 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:33:19 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 07:33:19 [INFO] exp_shallowmodel: f1_score:   0.269
12/10/2017 07:33:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:33:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.16      0.08      0.11        59
          C       0.00      0.00      0.00        12
          F       0.78      0.91      0.84       396
          R       0.19      0.09      0.12        55

avg / total       0.63      0.71      0.67       522

12/10/2017 07:33:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:33:19 [INFO] exp_shallowmodel: 
[[  5   0  48   6]
 [  3   0   7   2]
 [ 19   3 361  13]
 [  5   1  44   5]]
12/10/2017 07:33:19 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 07:33:19 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:33:19 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:33:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:33:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:33:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:33:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:33:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:35:23 [INFO] exp_shallowmodel: train time: 124.324s
12/10/2017 07:35:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:35:23 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 07:35:23 [INFO] exp_shallowmodel: f1_score:   0.342
12/10/2017 07:35:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:35:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.17      0.22        59
          C       0.25      0.08      0.12        12
          F       0.80      0.91      0.85       396
          R       0.20      0.15      0.17        55

avg / total       0.67      0.72      0.69       522

12/10/2017 07:35:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:35:23 [INFO] exp_shallowmodel: 
[[ 10   2  39   8]
 [  0   1  10   1]
 [ 12   1 359  24]
 [  9   0  38   8]]
12/10/2017 07:35:23 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 07:35:23 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:35:23 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:35:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:35:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:35:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:35:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:35:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:37:23 [INFO] exp_shallowmodel: train time: 120.265s
12/10/2017 07:37:23 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:37:23 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 07:37:23 [INFO] exp_shallowmodel: f1_score:   0.364
12/10/2017 07:37:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:37:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.31      0.19      0.23        59
          C       0.25      0.08      0.12        12
          F       0.80      0.90      0.85       396
          R       0.30      0.22      0.25        55

avg / total       0.68      0.73      0.70       522

12/10/2017 07:37:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:37:23 [INFO] exp_shallowmodel: 
[[ 11   1  39   8]
 [  0   1  10   1]
 [ 20   2 355  19]
 [  4   0  39  12]]
12/10/2017 07:37:24 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 07:37:24 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:37:24 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:37:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:37:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:37:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:37:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:37:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:39:38 [INFO] exp_shallowmodel: train time: 134.355s
12/10/2017 07:39:38 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:39:38 [INFO] exp_shallowmodel: accuracy:   0.686
12/10/2017 07:39:38 [INFO] exp_shallowmodel: f1_score:   0.294
12/10/2017 07:39:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:39:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.20      0.22        59
          C       0.00      0.00      0.00        12
          F       0.79      0.86      0.83       396
          R       0.17      0.11      0.13        55

avg / total       0.65      0.69      0.66       522

12/10/2017 07:39:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:39:38 [INFO] exp_shallowmodel: 
[[ 12   2  38   7]
 [  3   0   9   0]
 [ 30   3 340  23]
 [  6   2  41   6]]
12/10/2017 07:39:38 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 07:39:38 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:39:38 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:39:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:39:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:39:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:39:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:39:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:41:37 [INFO] exp_shallowmodel: train time: 119.091s
12/10/2017 07:41:37 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:41:37 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 07:41:37 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 07:41:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:41:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.25      0.27        59
          C       0.00      0.00      0.00        12
          F       0.79      0.89      0.84       396
          R       0.27      0.11      0.16        55

avg / total       0.66      0.71      0.68       522

12/10/2017 07:41:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:41:37 [INFO] exp_shallowmodel: 
[[ 15   1  39   4]
 [  1   0  11   0]
 [ 29   4 351  12]
 [  7   0  42   6]]
12/10/2017 07:41:37 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 07:41:37 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:41:37 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:41:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:41:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:41:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:41:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:41:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:43:31 [INFO] exp_shallowmodel: train time: 113.690s
12/10/2017 07:43:31 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:43:31 [INFO] exp_shallowmodel: accuracy:   0.726
12/10/2017 07:43:31 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 07:43:31 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:43:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.22      0.28        59
          C       0.00      0.00      0.00        12
          F       0.79      0.91      0.85       396
          R       0.22      0.11      0.15        55

avg / total       0.67      0.73      0.69       522

12/10/2017 07:43:31 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:43:31 [INFO] exp_shallowmodel: 
[[ 13   0  41   5]
 [  0   0  11   1]
 [ 17   4 360  15]
 [  5   1  43   6]]
12/10/2017 07:43:31 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 07:43:31 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 07:43:31 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:43:31 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:43:31 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:43:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:43:31 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:43:31 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:45:32 [INFO] exp_shallowmodel: train time: 120.895s
12/10/2017 07:45:32 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:45:32 [INFO] exp_shallowmodel: accuracy:   0.696
12/10/2017 07:45:32 [INFO] exp_shallowmodel: f1_score:   0.294
12/10/2017 07:45:32 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:45:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.14      0.18        64
          C       0.00      0.00      0.00        14
          F       0.78      0.90      0.83       402
          R       0.22      0.13      0.16        63

avg / total       0.63      0.70      0.66       543

12/10/2017 07:45:32 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:45:32 [INFO] exp_shallowmodel: 
[[  9   3  45   7]
 [  2   0  12   0]
 [ 18   2 361  21]
 [  6   2  47   8]]
12/10/2017 07:45:32 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 07:45:32 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:45:32 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:45:32 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:45:32 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:45:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:45:32 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:45:32 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:47:42 [INFO] exp_shallowmodel: train time: 129.564s
12/10/2017 07:47:42 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:47:42 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 07:47:42 [INFO] exp_shallowmodel: f1_score:   0.293
12/10/2017 07:47:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:47:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.15      0.20        59
          C       0.00      0.00      0.00        12
          F       0.79      0.90      0.84       396
          R       0.16      0.11      0.13        55

avg / total       0.65      0.71      0.67       522

12/10/2017 07:47:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:47:42 [INFO] exp_shallowmodel: 
[[  9   1  37  12]
 [  0   0  12   0]
 [ 18   3 355  20]
 [  3   0  46   6]]
12/10/2017 07:47:42 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 07:47:42 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:47:42 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:47:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:47:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:47:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:47:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:47:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:49:34 [INFO] exp_shallowmodel: train time: 112.162s
12/10/2017 07:49:34 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:49:34 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 07:49:34 [INFO] exp_shallowmodel: f1_score:   0.334
12/10/2017 07:49:34 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:49:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.22      0.25        59
          C       0.00      0.00      0.00        12
          F       0.80      0.88      0.84       396
          R       0.31      0.20      0.24        55

avg / total       0.67      0.71      0.69       522

12/10/2017 07:49:34 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:49:34 [INFO] exp_shallowmodel: 
[[ 13   2  40   4]
 [  2   0   9   1]
 [ 24   5 348  19]
 [  5   1  38  11]]
12/10/2017 07:49:34 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 07:49:34 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:49:34 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:49:34 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:49:34 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:49:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:49:34 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:49:34 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:51:28 [INFO] exp_shallowmodel: train time: 113.901s
12/10/2017 07:51:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:51:28 [INFO] exp_shallowmodel: accuracy:   0.701
12/10/2017 07:51:28 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 07:51:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:51:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.14      0.17        59
          C       0.00      0.00      0.00        12
          F       0.79      0.89      0.84       396
          R       0.12      0.07      0.09        55

avg / total       0.64      0.70      0.66       522

12/10/2017 07:51:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:51:28 [INFO] exp_shallowmodel: 
[[  8   1  40  10]
 [  0   0  10   2]
 [ 21   3 354  18]
 [  5   0  46   4]]
12/10/2017 07:51:28 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 07:51:28 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:51:28 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:51:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:51:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:51:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:51:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:51:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:53:29 [INFO] exp_shallowmodel: train time: 120.950s
12/10/2017 07:53:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:53:29 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 07:53:29 [INFO] exp_shallowmodel: f1_score:   0.321
12/10/2017 07:53:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:53:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.20      0.26        59
          C       0.00      0.00      0.00        12
          F       0.80      0.88      0.84       396
          R       0.23      0.16      0.19        55

avg / total       0.67      0.71      0.68       522

12/10/2017 07:53:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:53:29 [INFO] exp_shallowmodel: 
[[ 12   1  39   7]
 [  1   0  11   0]
 [ 19   3 350  24]
 [  3   3  40   9]]
12/10/2017 07:53:29 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 07:53:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:53:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:53:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:53:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:53:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:53:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:53:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:55:39 [INFO] exp_shallowmodel: train time: 129.977s
12/10/2017 07:55:39 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:55:39 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 07:55:39 [INFO] exp_shallowmodel: f1_score:   0.304
12/10/2017 07:55:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:55:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.14      0.17        59
          C       0.00      0.00      0.00        12
          F       0.80      0.90      0.84       396
          R       0.26      0.16      0.20        55

avg / total       0.66      0.71      0.68       522

12/10/2017 07:55:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:55:39 [INFO] exp_shallowmodel: 
[[  8   1  44   6]
 [  1   0   9   2]
 [ 19   4 356  17]
 [  8   0  38   9]]
12/10/2017 07:55:39 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 07:55:39 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:55:39 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:55:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:55:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:55:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:55:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:55:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:57:29 [INFO] exp_shallowmodel: train time: 109.780s
12/10/2017 07:57:29 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:57:29 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 07:57:29 [INFO] exp_shallowmodel: f1_score:   0.319
12/10/2017 07:57:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:57:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.15      0.19        59
          C       0.14      0.08      0.11        12
          F       0.80      0.90      0.85       396
          R       0.19      0.11      0.14        55

avg / total       0.66      0.71      0.68       522

12/10/2017 07:57:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:57:29 [INFO] exp_shallowmodel: 
[[  9   3  40   7]
 [  0   1  11   0]
 [ 19   3 356  18]
 [ 10   0  39   6]]
12/10/2017 07:57:29 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 07:57:29 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:57:29 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:57:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:57:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:57:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:57:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:57:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 07:59:18 [INFO] exp_shallowmodel: train time: 108.936s
12/10/2017 07:59:18 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 07:59:18 [INFO] exp_shallowmodel: accuracy:   0.728
12/10/2017 07:59:18 [INFO] exp_shallowmodel: f1_score:   0.363
12/10/2017 07:59:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 07:59:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.15      0.19        59
          C       0.12      0.08      0.10        12
          F       0.81      0.90      0.85       396
          R       0.37      0.27      0.31        55

avg / total       0.69      0.73      0.70       522

12/10/2017 07:59:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 07:59:18 [INFO] exp_shallowmodel: 
[[  9   0  42   8]
 [  0   1   9   2]
 [ 21   4 355  16]
 [  7   3  30  15]]
12/10/2017 07:59:18 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 07:59:18 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 07:59:18 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 07:59:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 07:59:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 07:59:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 07:59:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 07:59:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:01:03 [INFO] exp_shallowmodel: train time: 105.030s
12/10/2017 08:01:03 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:01:03 [INFO] exp_shallowmodel: accuracy:   0.703
12/10/2017 08:01:03 [INFO] exp_shallowmodel: f1_score:   0.326
12/10/2017 08:01:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:01:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.27      0.30        59
          C       0.00      0.00      0.00        12
          F       0.79      0.87      0.83       396
          R       0.24      0.15      0.18        55

avg / total       0.66      0.70      0.68       522

12/10/2017 08:01:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:01:03 [INFO] exp_shallowmodel: 
[[ 16   0  39   4]
 [  2   0   9   1]
 [ 28   5 343  20]
 [  3   2  42   8]]
12/10/2017 08:01:03 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 08:01:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:01:03 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:01:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:01:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:01:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:01:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:01:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:02:54 [INFO] exp_shallowmodel: train time: 110.866s
12/10/2017 08:02:54 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:02:54 [INFO] exp_shallowmodel: accuracy:   0.718
12/10/2017 08:02:54 [INFO] exp_shallowmodel: f1_score:   0.360
12/10/2017 08:02:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:02:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.19      0.21        59
          C       0.17      0.08      0.11        12
          F       0.80      0.89      0.84       396
          R       0.38      0.22      0.28        55

avg / total       0.68      0.72      0.69       522

12/10/2017 08:02:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:02:54 [INFO] exp_shallowmodel: 
[[ 11   2  42   4]
 [  0   1  11   0]
 [ 26   3 351  16]
 [  7   0  36  12]]
12/10/2017 08:02:54 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 08:02:54 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 08:02:54 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:02:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:02:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:02:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:02:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:02:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:04:42 [INFO] exp_shallowmodel: train time: 107.417s
12/10/2017 08:04:42 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:04:42 [INFO] exp_shallowmodel: accuracy:   0.681
12/10/2017 08:04:42 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 08:04:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:04:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.13      0.08      0.10        64
          C       0.12      0.07      0.09        14
          F       0.77      0.88      0.82       402
          R       0.29      0.17      0.22        63

avg / total       0.62      0.68      0.65       543

12/10/2017 08:04:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:04:42 [INFO] exp_shallowmodel: 
[[  5   1  52   6]
 [  3   1   8   2]
 [ 24   6 353  19]
 [  7   0  45  11]]
12/10/2017 08:04:42 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 08:04:42 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:04:42 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:04:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:04:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:04:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:04:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:04:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:06:22 [INFO] exp_shallowmodel: train time: 100.592s
12/10/2017 08:06:22 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:06:22 [INFO] exp_shallowmodel: accuracy:   0.693
12/10/2017 08:06:22 [INFO] exp_shallowmodel: f1_score:   0.303
12/10/2017 08:06:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:06:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.21      0.14      0.16        59
          C       0.14      0.08      0.11        12
          F       0.79      0.88      0.83       396
          R       0.13      0.09      0.11        55

avg / total       0.64      0.69      0.66       522

12/10/2017 08:06:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:06:22 [INFO] exp_shallowmodel: 
[[  8   1  35  15]
 [  1   1  10   0]
 [ 25   5 348  18]
 [  4   0  46   5]]
12/10/2017 08:06:22 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 08:06:22 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:06:22 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:06:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:06:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:06:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:06:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:06:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:08:15 [INFO] exp_shallowmodel: train time: 112.567s
12/10/2017 08:08:15 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:08:15 [INFO] exp_shallowmodel: accuracy:   0.709
12/10/2017 08:08:15 [INFO] exp_shallowmodel: f1_score:   0.330
12/10/2017 08:08:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:08:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.29      0.28        59
          C       0.00      0.00      0.00        12
          F       0.82      0.87      0.85       396
          R       0.23      0.16      0.19        55

avg / total       0.68      0.71      0.69       522

12/10/2017 08:08:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:08:15 [INFO] exp_shallowmodel: 
[[ 17   3  31   8]
 [  2   0   9   1]
 [ 30   1 344  21]
 [ 13   0  33   9]]
12/10/2017 08:08:15 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 08:08:15 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:08:15 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:08:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:08:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:08:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:08:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:08:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:10:03 [INFO] exp_shallowmodel: train time: 107.403s
12/10/2017 08:10:03 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:10:03 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 08:10:03 [INFO] exp_shallowmodel: f1_score:   0.317
12/10/2017 08:10:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:10:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.22      0.26        59
          C       0.00      0.00      0.00        12
          F       0.78      0.89      0.84       396
          R       0.26      0.13      0.17        55

avg / total       0.66      0.72      0.68       522

12/10/2017 08:10:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:10:03 [INFO] exp_shallowmodel: 
[[ 13   1  44   1]
 [  2   0  10   0]
 [ 20   3 354  19]
 [  5   0  43   7]]
12/10/2017 08:10:03 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 08:10:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:10:03 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:10:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:10:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:10:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:10:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:10:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:11:44 [INFO] exp_shallowmodel: train time: 101.812s
12/10/2017 08:11:44 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:11:44 [INFO] exp_shallowmodel: accuracy:   0.711
12/10/2017 08:11:44 [INFO] exp_shallowmodel: f1_score:   0.336
12/10/2017 08:11:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:11:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.19      0.23        59
          C       0.14      0.08      0.11        12
          F       0.80      0.89      0.84       396
          R       0.20      0.15      0.17        55

avg / total       0.67      0.71      0.69       522

12/10/2017 08:11:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:11:44 [INFO] exp_shallowmodel: 
[[ 11   2  36  10]
 [  2   1   9   0]
 [ 21   2 351  22]
 [  4   2  41   8]]
12/10/2017 08:11:45 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 08:11:45 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:11:45 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:11:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:11:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:11:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:11:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:11:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:13:26 [INFO] exp_shallowmodel: train time: 101.187s
12/10/2017 08:13:26 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:13:26 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 08:13:26 [INFO] exp_shallowmodel: f1_score:   0.344
12/10/2017 08:13:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:13:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.15      0.19        59
          C       0.10      0.08      0.09        12
          F       0.81      0.91      0.86       396
          R       0.34      0.18      0.24        55

avg / total       0.68      0.73      0.70       522

12/10/2017 08:13:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:13:26 [INFO] exp_shallowmodel: 
[[  9   3  38   9]
 [  0   1  10   1]
 [ 22   4 361   9]
 [  5   2  38  10]]
12/10/2017 08:13:26 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 08:13:26 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:13:26 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:13:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:13:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:13:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:13:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:13:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:15:09 [INFO] exp_shallowmodel: train time: 103.524s
12/10/2017 08:15:09 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:15:09 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 08:15:09 [INFO] exp_shallowmodel: f1_score:   0.313
12/10/2017 08:15:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:15:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.15      0.20        59
          C       0.17      0.08      0.11        12
          F       0.79      0.91      0.85       396
          R       0.13      0.07      0.09        55

avg / total       0.65      0.72      0.68       522

12/10/2017 08:15:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:15:09 [INFO] exp_shallowmodel: 
[[  9   2  38  10]
 [  1   1   8   2]
 [ 18   3 360  15]
 [  3   0  48   4]]
12/10/2017 08:15:09 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 08:15:09 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:15:09 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:15:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:15:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:15:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:15:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:15:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:17:01 [INFO] exp_shallowmodel: train time: 112.015s
12/10/2017 08:17:01 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:17:01 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 08:17:01 [INFO] exp_shallowmodel: f1_score:   0.316
12/10/2017 08:17:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:17:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.32      0.20      0.25        59
          C       0.00      0.00      0.00        12
          F       0.79      0.90      0.84       396
          R       0.28      0.13      0.17        55

avg / total       0.66      0.72      0.69       522

12/10/2017 08:17:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:17:01 [INFO] exp_shallowmodel: 
[[ 12   1  40   6]
 [  2   0  10   0]
 [ 21   5 358  12]
 [  3   0  45   7]]
12/10/2017 08:17:02 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 08:17:02 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:17:02 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:17:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:17:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:17:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:17:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:17:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:18:48 [INFO] exp_shallowmodel: train time: 106.250s
12/10/2017 08:18:48 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:18:48 [INFO] exp_shallowmodel: accuracy:   0.695
12/10/2017 08:18:48 [INFO] exp_shallowmodel: f1_score:   0.302
12/10/2017 08:18:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:18:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.20      0.21        59
          C       0.00      0.00      0.00        12
          F       0.80      0.87      0.83       396
          R       0.23      0.13      0.16        55

avg / total       0.66      0.70      0.67       522

12/10/2017 08:18:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:18:48 [INFO] exp_shallowmodel: 
[[ 12   1  41   5]
 [  1   0  10   1]
 [ 29   6 344  17]
 [ 12   0  36   7]]
12/10/2017 08:18:48 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 08:18:48 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 08:18:48 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:18:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:18:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:18:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:18:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:18:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:20:28 [INFO] exp_shallowmodel: train time: 100.013s
12/10/2017 08:20:28 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:20:28 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 08:20:28 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 08:20:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:20:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.11      0.07      0.09        59
          C       0.08      0.08      0.08        12
          F       0.80      0.88      0.84       396
          R       0.28      0.18      0.22        55

avg / total       0.65      0.70      0.67       522

12/10/2017 08:20:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:20:28 [INFO] exp_shallowmodel: 
[[  4   2  47   6]
 [  1   1  10   0]
 [ 20   6 350  20]
 [ 10   3  32  10]]
12/10/2017 08:20:28 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 08:20:28 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 08:20:28 [INFO] exp_shallowmodel: #(feature) = 900
12/10/2017 08:20:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 08:20:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 08:20:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 08:20:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 08:20:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 08:22:12 [INFO] exp_shallowmodel: train time: 103.547s
12/10/2017 08:22:12 [INFO] exp_shallowmodel: test time:  0.001s
12/10/2017 08:22:12 [INFO] exp_shallowmodel: accuracy:   0.715
12/10/2017 08:22:12 [INFO] exp_shallowmodel: f1_score:   0.353
12/10/2017 08:22:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 08:22:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.20      0.25        64
          C       0.17      0.07      0.10        14
          F       0.79      0.90      0.84       402
          R       0.31      0.17      0.22        63

avg / total       0.66      0.71      0.68       543

12/10/2017 08:22:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 08:22:12 [INFO] exp_shallowmodel: 
[[ 13   1  45   5]
 [  3   1   9   1]
 [ 16   4 363  19]
 [  8   0  44  11]]
Done: 20171210-082212
