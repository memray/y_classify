/ihome/pbrusilosky/rum20/packages/anaconda3/bin/python -m dialogue.classify.task_runner -experiment_mode cross_validation -selected_feature_set_id 4 -add_similarity_feature -selected_context_id 1
No. of param settings = 1
[('experiment_mode', 'cross_validation'), ('deep_model', False), ('selected_context_id', 1), ('selected_feature_set_id', 4), ('similarity_feature', True), ('k_feature_to_keep', -1), ('k_component_for_pca', -1)]
Loading extracted features of dstc2
Loading extracted features of dstc3
Loading extracted features of family
Loading extracted features of ghome
02/04/2018 01:25:54 [INFO] configuration: experiment_mode  :   cross_validation
02/04/2018 01:25:54 [INFO] configuration: deep_model  :   False
02/04/2018 01:25:54 [INFO] configuration: selected_context_id  :   1
02/04/2018 01:25:54 [INFO] configuration: selected_feature_set_id  :   4
02/04/2018 01:25:54 [INFO] configuration: similarity_feature  :   True
02/04/2018 01:25:54 [INFO] configuration: k_feature_to_keep  :   -1
02/04/2018 01:25:54 [INFO] configuration: k_component_for_pca  :   -1
02/04/2018 01:25:54 [INFO] configuration: seed  :   154316847
02/04/2018 01:25:54 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
02/04/2018 01:25:54 [INFO] configuration: task_name  :   utterance_type
02/04/2018 01:25:54 [INFO] configuration: timemark  :   20180204-012554
02/04/2018 01:25:54 [INFO] configuration: context_set  :   current
02/04/2018 01:25:54 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
02/04/2018 01:25:54 [INFO] configuration: utterance_range  :   ['current_user_utterance', 'next_system_utterance']
02/04/2018 01:25:54 [INFO] configuration: feature_set  :   4-syntactic
02/04/2018 01:25:54 [INFO] configuration: feature_set_number  :   ['7']
02/04/2018 01:25:54 [INFO] configuration: experiment_name  :   20180204-012554.cross_validation.context=current.feature=4-syntactic.similarity=true
02/04/2018 01:25:54 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20180204-012554.cross_validation.context=current.feature=4-syntactic.similarity=true
02/04/2018 01:25:54 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20180204-012554.cross_validation.context=current.feature=4-syntactic.similarity=true/output.log
02/04/2018 01:25:54 [INFO] configuration: valid_type  :   {'A', 'F', 'R', 'C'}
02/04/2018 01:25:54 [INFO] configuration: data_name  :   
02/04/2018 01:25:54 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
02/04/2018 01:25:54 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
02/04/2018 01:25:54 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
02/04/2018 01:25:54 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
02/04/2018 01:25:54 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
02/04/2018 01:25:54 [INFO] configuration: do_cross_validation  :   True
02/04/2018 01:25:54 [INFO] configuration: #division  :   5
02/04/2018 01:25:54 [INFO] configuration: #cross_validation  :   10
02/04/2018 01:25:54 [INFO] configuration: cv_index_cache_path  :   
02/04/2018 01:25:54 [INFO] configuration: action_words  :   {'help', 'start', 'part', 'else', 'phone', 'expens', 'list', 'volume', 'centre', 'stop', 'play', 'number', 'food', 'snooz', 'delet', 'shuffl', 'moderate', 'next', 'tell', 'matter', 'telephon', 'weather', 'remove', 'telephone', 'moder', 'south', 'alarm', 'room', 'volum', 'temperature', 'temperatur', 'items', 'ani', 'turn', 'north', 'member', 'video', 'shuffle', 'cast', 'song', 'timer', 'price', 'item', 'clear', 'address', 'time', 'reminders', 'centr', 'discard', 'findcare', 'findcar', 'skip', 'remind', 'add', 'area', 'delete', 'reminds', 'cheap', 'music', 'expensive', 'light', 'els', 'show', 'reminder', 'any', 'snooze', 'remov', 'post', 'watch', 'share'}
02/04/2018 01:25:54 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
02/04/2018 01:25:54 [INFO] configuration: lda_topic_number  :   50
02/04/2018 01:25:54 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
02/04/2018 01:25:54 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
02/04/2018 01:25:54 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
02/04/2018 01:25:54 [INFO] configuration: w2v_path  :   /home/memray/Data/glove/GoogleNews-vectors-negative300.bin
02/04/2018 01:25:54 [INFO] configuration: w2v_vector_length  :   300
02/04/2018 01:25:54 [INFO] configuration: d2v_vector_length  :   300
02/04/2018 01:25:54 [INFO] configuration: d2v_window_size  :   5
02/04/2018 01:25:54 [INFO] configuration: d2v_min_count  :   2
02/04/2018 01:25:54 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
02/04/2018 01:25:54 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
02/04/2018 01:25:54 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
02/04/2018 01:25:54 [INFO] configuration: batch_size  :   128
02/04/2018 01:25:54 [INFO] configuration: max_epoch  :   50
02/04/2018 01:25:54 [INFO] configuration: early_stop_tolerance  :   2
02/04/2018 01:25:54 [INFO] configuration: concat_sents  :   False
02/04/2018 01:25:54 [INFO] configuration: cnn_setting  :   {'model': 'rand', 'early_stopping': True, 'word_dim': 300, 'filters': [3, 4, 5], 'filter_num': [100, 100, 100], 'class_size': 4, 'batch_size': 128, 'learning_rate': 0.001, 'norm_limit': 10, 'dropout_prob': 0.0, 'sentence_num': 2}
02/04/2018 01:25:54 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 2, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
02/04/2018 01:25:54 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
02/04/2018 01:25:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
02/04/2018 01:25:57 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:25:57 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:25:57 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:25:57 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:25:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:25:57 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:25:57 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:00 [INFO] exp_shallowmodel: train time: 3.780s
02/04/2018 01:26:00 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:26:00 [INFO] exp_shallowmodel: accuracy:   0.597
02/04/2018 01:26:00 [INFO] exp_shallowmodel: f1_score:   0.402
02/04/2018 01:26:00 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.74      0.61       164
          F       0.69      0.72      0.70       268
          R       0.48      0.22      0.30       125

avg / total       0.58      0.60      0.57       571

02/04/2018 01:26:00 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:00 [INFO] exp_shallowmodel: 
[[  0   8   3   3]
 [  0 121  33  10]
 [  0  59 193  16]
 [  0  46  52  27]]
02/04/2018 01:26:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
02/04/2018 01:26:00 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:00 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:00 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:00 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:00 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:00 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:03 [INFO] exp_shallowmodel: train time: 2.250s
02/04/2018 01:26:03 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:03 [INFO] exp_shallowmodel: accuracy:   0.599
02/04/2018 01:26:03 [INFO] exp_shallowmodel: f1_score:   0.446
02/04/2018 01:26:03 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.07      0.12        14
          C       0.55      0.76      0.64       164
          F       0.69      0.68      0.69       268
          R       0.44      0.28      0.34       125

avg / total       0.59      0.60      0.58       571

02/04/2018 01:26:03 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:03 [INFO] exp_shallowmodel: 
[[  1   4   5   4]
 [  0 124  23  17]
 [  2  61 182  23]
 [  0  37  53  35]]
02/04/2018 01:26:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
02/04/2018 01:26:03 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:03 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:03 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:03 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:03 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:03 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:07 [INFO] exp_shallowmodel: train time: 4.108s
02/04/2018 01:26:07 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:07 [INFO] exp_shallowmodel: accuracy:   0.587
02/04/2018 01:26:07 [INFO] exp_shallowmodel: f1_score:   0.397
02/04/2018 01:26:07 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.77      0.59       164
          F       0.74      0.68      0.71       268
          R       0.44      0.22      0.29       125

avg / total       0.58      0.59      0.57       571

02/04/2018 01:26:07 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:07 [INFO] exp_shallowmodel: 
[[  0   7   4   3]
 [  0 126  23  15]
 [  1  68 182  17]
 [  1  61  36  27]]
02/04/2018 01:26:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
02/04/2018 01:26:07 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:07 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:07 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:07 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:07 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:07 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:11 [INFO] exp_shallowmodel: train time: 4.492s
02/04/2018 01:26:11 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:11 [INFO] exp_shallowmodel: accuracy:   0.573
02/04/2018 01:26:11 [INFO] exp_shallowmodel: f1_score:   0.396
02/04/2018 01:26:11 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.71      0.58       164
          F       0.70      0.66      0.68       268
          R       0.43      0.26      0.33       125

avg / total       0.56      0.57      0.56       571

02/04/2018 01:26:11 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:11 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 117  29  18]
 [  0  68 177  23]
 [  0  53  39  33]]
02/04/2018 01:26:11 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
02/04/2018 01:26:11 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:11 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:11 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:11 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:11 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:11 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:15 [INFO] exp_shallowmodel: train time: 3.488s
02/04/2018 01:26:15 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:15 [INFO] exp_shallowmodel: accuracy:   0.576
02/04/2018 01:26:15 [INFO] exp_shallowmodel: f1_score:   0.399
02/04/2018 01:26:15 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.73      0.59       164
          F       0.70      0.66      0.68       268
          R       0.45      0.26      0.33       125

avg / total       0.57      0.58      0.56       571

02/04/2018 01:26:15 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:15 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  1 120  26  17]
 [  0  69 176  23]
 [  0  52  40  33]]
02/04/2018 01:26:15 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
02/04/2018 01:26:15 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:15 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:15 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:15 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:15 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:15 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:19 [INFO] exp_shallowmodel: train time: 3.753s
02/04/2018 01:26:19 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:19 [INFO] exp_shallowmodel: accuracy:   0.578
02/04/2018 01:26:19 [INFO] exp_shallowmodel: f1_score:   0.396
02/04/2018 01:26:19 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.75      0.60       164
          F       0.67      0.66      0.67       268
          R       0.49      0.23      0.32       125

avg / total       0.57      0.58      0.55       571

02/04/2018 01:26:19 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:19 [INFO] exp_shallowmodel: 
[[  0   8   3   3]
 [  0 123  33   8]
 [  1  70 178  19]
 [  0  46  50  29]]
02/04/2018 01:26:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
02/04/2018 01:26:19 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:19 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:19 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:19 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:19 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:19 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:22 [INFO] exp_shallowmodel: train time: 3.672s
02/04/2018 01:26:22 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:22 [INFO] exp_shallowmodel: accuracy:   0.622
02/04/2018 01:26:22 [INFO] exp_shallowmodel: f1_score:   0.425
02/04/2018 01:26:22 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.76      0.64       164
          F       0.69      0.74      0.72       268
          R       0.52      0.26      0.34       125

avg / total       0.60      0.62      0.60       571

02/04/2018 01:26:22 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:22 [INFO] exp_shallowmodel: 
[[  0   5   6   3]
 [  0 124  31   9]
 [  0  51 199  18]
 [  0  42  51  32]]
02/04/2018 01:26:22 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
02/04/2018 01:26:22 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:22 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:22 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:22 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:22 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:22 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:25 [INFO] exp_shallowmodel: train time: 2.852s
02/04/2018 01:26:25 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:25 [INFO] exp_shallowmodel: accuracy:   0.564
02/04/2018 01:26:25 [INFO] exp_shallowmodel: f1_score:   0.372
02/04/2018 01:26:25 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.68      0.56       164
          F       0.68      0.71      0.69       268
          R       0.36      0.18      0.24       125

avg / total       0.54      0.56      0.54       571

02/04/2018 01:26:25 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:25 [INFO] exp_shallowmodel: 
[[  0   9   4   1]
 [  0 111  35  18]
 [  0  59 189  20]
 [  0  54  49  22]]
02/04/2018 01:26:25 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
02/04/2018 01:26:25 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:25 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:25 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:25 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:25 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:25 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:29 [INFO] exp_shallowmodel: train time: 3.886s
02/04/2018 01:26:29 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:29 [INFO] exp_shallowmodel: accuracy:   0.583
02/04/2018 01:26:29 [INFO] exp_shallowmodel: f1_score:   0.401
02/04/2018 01:26:29 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.80      0.63       164
          F       0.70      0.64      0.67       268
          R       0.45      0.24      0.31       125

avg / total       0.57      0.58      0.56       571

02/04/2018 01:26:29 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:29 [INFO] exp_shallowmodel: 
[[  0   4   4   6]
 [  0 132  19  13]
 [  0  79 171  18]
 [  0  43  52  30]]
02/04/2018 01:26:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
02/04/2018 01:26:29 [INFO] exp_shallowmodel: #(data) = 4568
02/04/2018 01:26:29 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:29 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:29 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:29 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:29 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:33 [INFO] exp_shallowmodel: train time: 3.907s
02/04/2018 01:26:33 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:33 [INFO] exp_shallowmodel: accuracy:   0.556
02/04/2018 01:26:33 [INFO] exp_shallowmodel: f1_score:   0.371
02/04/2018 01:26:33 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.46      0.66      0.54       169
          F       0.65      0.70      0.68       271
          R       0.45      0.18      0.26       130

avg / total       0.54      0.56      0.53       586

02/04/2018 01:26:33 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:33 [INFO] exp_shallowmodel: 
[[  0   5   8   3]
 [  0 111  45  13]
 [  0  67 191  13]
 [  0  57  49  24]]
02/04/2018 01:26:33 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
02/04/2018 01:26:33 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:33 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:33 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:33 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:33 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:33 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:37 [INFO] exp_shallowmodel: train time: 3.950s
02/04/2018 01:26:37 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:37 [INFO] exp_shallowmodel: accuracy:   0.580
02/04/2018 01:26:37 [INFO] exp_shallowmodel: f1_score:   0.391
02/04/2018 01:26:37 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.69      0.58       164
          F       0.67      0.71      0.69       268
          R       0.44      0.22      0.29       125

avg / total       0.56      0.58      0.56       571

02/04/2018 01:26:37 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:37 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  1 113  34  16]
 [  0  63 191  14]
 [  0  47  51  27]]
02/04/2018 01:26:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
02/04/2018 01:26:37 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:37 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:37 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:37 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:37 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:37 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:40 [INFO] exp_shallowmodel: train time: 2.766s
02/04/2018 01:26:40 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:40 [INFO] exp_shallowmodel: accuracy:   0.571
02/04/2018 01:26:40 [INFO] exp_shallowmodel: f1_score:   0.391
02/04/2018 01:26:40 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.66      0.55       164
          F       0.68      0.70      0.69       268
          R       0.47      0.25      0.32       125

avg / total       0.56      0.57      0.55       571

02/04/2018 01:26:40 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:40 [INFO] exp_shallowmodel: 
[[  0   8   4   2]
 [  0 108  39  17]
 [  1  64 187  16]
 [  0  47  47  31]]
02/04/2018 01:26:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
02/04/2018 01:26:40 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:40 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:40 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:40 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:40 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:40 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:43 [INFO] exp_shallowmodel: train time: 3.273s
02/04/2018 01:26:43 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:43 [INFO] exp_shallowmodel: accuracy:   0.574
02/04/2018 01:26:43 [INFO] exp_shallowmodel: f1_score:   0.385
02/04/2018 01:26:43 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.76      0.59       164
          F       0.71      0.67      0.69       268
          R       0.43      0.19      0.27       125

avg / total       0.56      0.57      0.55       571

02/04/2018 01:26:43 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:43 [INFO] exp_shallowmodel: 
[[  0   8   3   3]
 [  0 125  27  12]
 [  0  72 179  17]
 [  0  58  43  24]]
02/04/2018 01:26:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
02/04/2018 01:26:43 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:43 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:43 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:43 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:43 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:43 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:46 [INFO] exp_shallowmodel: train time: 2.806s
02/04/2018 01:26:46 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:46 [INFO] exp_shallowmodel: accuracy:   0.602
02/04/2018 01:26:46 [INFO] exp_shallowmodel: f1_score:   0.423
02/04/2018 01:26:46 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.81      0.62       164
          F       0.72      0.65      0.68       268
          R       0.56      0.29      0.38       125

avg / total       0.61      0.60      0.58       571

02/04/2018 01:26:46 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:46 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 133  19  12]
 [  1  79 175  13]
 [  1  46  42  36]]
02/04/2018 01:26:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
02/04/2018 01:26:46 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:46 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:46 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:46 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:46 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:46 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:49 [INFO] exp_shallowmodel: train time: 3.262s
02/04/2018 01:26:49 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:49 [INFO] exp_shallowmodel: accuracy:   0.571
02/04/2018 01:26:49 [INFO] exp_shallowmodel: f1_score:   0.386
02/04/2018 01:26:49 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.68      0.57       164
          F       0.69      0.70      0.69       268
          R       0.38      0.22      0.28       125

avg / total       0.55      0.57      0.55       571

02/04/2018 01:26:49 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:49 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 111  32  21]
 [  0  59 187  22]
 [  0  51  46  28]]
02/04/2018 01:26:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
02/04/2018 01:26:49 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:49 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:49 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:49 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:49 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:49 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:54 [INFO] exp_shallowmodel: train time: 4.338s
02/04/2018 01:26:54 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:54 [INFO] exp_shallowmodel: accuracy:   0.578
02/04/2018 01:26:54 [INFO] exp_shallowmodel: f1_score:   0.394
02/04/2018 01:26:54 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.77      0.59       164
          F       0.71      0.66      0.68       268
          R       0.46      0.22      0.30       125

avg / total       0.57      0.58      0.56       571

02/04/2018 01:26:54 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:54 [INFO] exp_shallowmodel: 
[[  0   7   5   2]
 [  1 126  23  14]
 [  0  75 176  17]
 [  0  52  45  28]]
02/04/2018 01:26:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
02/04/2018 01:26:54 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:54 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:54 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:54 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:54 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:54 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:26:57 [INFO] exp_shallowmodel: train time: 3.620s
02/04/2018 01:26:57 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:26:57 [INFO] exp_shallowmodel: accuracy:   0.606
02/04/2018 01:26:57 [INFO] exp_shallowmodel: f1_score:   0.417
02/04/2018 01:26:57 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:26:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.77      0.63       164
          F       0.69      0.70      0.70       268
          R       0.49      0.26      0.34       125

avg / total       0.59      0.61      0.58       571

02/04/2018 01:26:57 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:26:57 [INFO] exp_shallowmodel: 
[[  0   4   5   5]
 [  0 126  30   8]
 [  0  60 188  20]
 [  0  45  48  32]]
02/04/2018 01:26:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
02/04/2018 01:26:58 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:26:58 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:26:58 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:26:58 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:26:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:26:58 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:26:58 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:00 [INFO] exp_shallowmodel: train time: 2.940s
02/04/2018 01:27:00 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:00 [INFO] exp_shallowmodel: accuracy:   0.573
02/04/2018 01:27:00 [INFO] exp_shallowmodel: f1_score:   0.379
02/04/2018 01:27:00 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.70      0.58       164
          F       0.66      0.71      0.68       268
          R       0.42      0.18      0.25       125

avg / total       0.54      0.57      0.54       571

02/04/2018 01:27:00 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:00 [INFO] exp_shallowmodel: 
[[  0   7   5   2]
 [  0 115  36  13]
 [  0  62 190  16]
 [  0  47  56  22]]
02/04/2018 01:27:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
02/04/2018 01:27:01 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:01 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:01 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:01 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:01 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:01 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:06 [INFO] exp_shallowmodel: train time: 5.948s
02/04/2018 01:27:06 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:27:06 [INFO] exp_shallowmodel: accuracy:   0.595
02/04/2018 01:27:06 [INFO] exp_shallowmodel: f1_score:   0.410
02/04/2018 01:27:06 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.74      0.60       164
          F       0.71      0.69      0.70       268
          R       0.46      0.26      0.34       125

avg / total       0.58      0.60      0.58       571

02/04/2018 01:27:06 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:06 [INFO] exp_shallowmodel: 
[[  0   4   6   4]
 [  0 122  31  11]
 [  0  59 185  24]
 [  0  55  37  33]]
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
02/04/2018 01:27:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
02/04/2018 01:27:07 [INFO] exp_shallowmodel: #(data) = 4568
02/04/2018 01:27:07 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:07 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:07 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:07 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:07 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:09 [INFO] exp_shallowmodel: train time: 2.950s
02/04/2018 01:27:09 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:09 [INFO] exp_shallowmodel: accuracy:   0.573
02/04/2018 01:27:09 [INFO] exp_shallowmodel: f1_score:   0.397
02/04/2018 01:27:09 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.51      0.74      0.60       169
          F       0.66      0.66      0.66       271
          R       0.46      0.25      0.33       130

avg / total       0.55      0.57      0.55       586

02/04/2018 01:27:09 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:09 [INFO] exp_shallowmodel: 
[[  0   4   8   4]
 [  0 125  34  10]
 [  0  68 178  25]
 [  0  48  49  33]]
02/04/2018 01:27:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
02/04/2018 01:27:10 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:10 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:10 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:10 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:10 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:10 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:13 [INFO] exp_shallowmodel: train time: 3.404s
02/04/2018 01:27:13 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:13 [INFO] exp_shallowmodel: accuracy:   0.613
02/04/2018 01:27:13 [INFO] exp_shallowmodel: f1_score:   0.425
02/04/2018 01:27:13 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.77      0.63       164
          F       0.72      0.71      0.71       268
          R       0.55      0.27      0.36       125

avg / total       0.61      0.61      0.59       571

02/04/2018 01:27:13 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:13 [INFO] exp_shallowmodel: 
[[  0   8   4   2]
 [  1 127  26  10]
 [  0  63 189  16]
 [  2  44  45  34]]
02/04/2018 01:27:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
02/04/2018 01:27:13 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:13 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:13 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:13 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:13 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:13 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:16 [INFO] exp_shallowmodel: train time: 3.250s
02/04/2018 01:27:16 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:16 [INFO] exp_shallowmodel: accuracy:   0.564
02/04/2018 01:27:16 [INFO] exp_shallowmodel: f1_score:   0.378
02/04/2018 01:27:16 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.70      0.57       164
          F       0.69      0.68      0.69       268
          R       0.38      0.20      0.26       125

avg / total       0.54      0.56      0.54       571

02/04/2018 01:27:16 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:16 [INFO] exp_shallowmodel: 
[[  0   6   7   1]
 [  0 114  36  14]
 [  0  59 183  26]
 [  0  60  40  25]]
02/04/2018 01:27:16 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
02/04/2018 01:27:16 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:16 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:16 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:16 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:16 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:16 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:19 [INFO] exp_shallowmodel: train time: 3.225s
02/04/2018 01:27:19 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:19 [INFO] exp_shallowmodel: accuracy:   0.581
02/04/2018 01:27:19 [INFO] exp_shallowmodel: f1_score:   0.385
02/04/2018 01:27:19 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.73      0.61       164
          F       0.65      0.71      0.68       268
          R       0.48      0.18      0.26       125

avg / total       0.56      0.58      0.55       571

02/04/2018 01:27:19 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:19 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 120  36   8]
 [  0  65 190  13]
 [  0  42  61  22]]
02/04/2018 01:27:20 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
02/04/2018 01:27:20 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:20 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:20 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:20 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:20 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:20 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:23 [INFO] exp_shallowmodel: train time: 3.233s
02/04/2018 01:27:23 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:27:23 [INFO] exp_shallowmodel: accuracy:   0.567
02/04/2018 01:27:23 [INFO] exp_shallowmodel: f1_score:   0.384
02/04/2018 01:27:23 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.66      0.56       164
          F       0.65      0.70      0.68       268
          R       0.51      0.22      0.30       125

avg / total       0.55      0.57      0.54       571

02/04/2018 01:27:23 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:23 [INFO] exp_shallowmodel: 
[[  0   5   5   4]
 [  1 109  43  11]
 [  1  68 188  11]
 [  0  45  53  27]]
02/04/2018 01:27:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
02/04/2018 01:27:23 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:23 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:23 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:23 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:23 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:23 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:27 [INFO] exp_shallowmodel: train time: 4.338s
02/04/2018 01:27:27 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:27 [INFO] exp_shallowmodel: accuracy:   0.606
02/04/2018 01:27:27 [INFO] exp_shallowmodel: f1_score:   0.421
02/04/2018 01:27:27 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.74      0.62       164
          F       0.69      0.71      0.70       268
          R       0.51      0.28      0.36       125

avg / total       0.59      0.61      0.59       571

02/04/2018 01:27:27 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:27 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  1 121  29  13]
 [  1  59 190  18]
 [  0  41  49  35]]
02/04/2018 01:27:27 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
02/04/2018 01:27:27 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:27 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:27 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:27 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:27 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:27 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:31 [INFO] exp_shallowmodel: train time: 3.645s
02/04/2018 01:27:31 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:31 [INFO] exp_shallowmodel: accuracy:   0.602
02/04/2018 01:27:31 [INFO] exp_shallowmodel: f1_score:   0.411
02/04/2018 01:27:31 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.82      0.64       164
          F       0.71      0.67      0.69       268
          R       0.48      0.23      0.31       125

avg / total       0.59      0.60      0.58       571

02/04/2018 01:27:31 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:31 [INFO] exp_shallowmodel: 
[[  0   7   4   3]
 [  0 135  21   8]
 [  0  68 180  20]
 [  0  46  50  29]]
02/04/2018 01:27:31 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
02/04/2018 01:27:31 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:31 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:31 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:31 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:31 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:31 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:34 [INFO] exp_shallowmodel: train time: 3.342s
02/04/2018 01:27:34 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:34 [INFO] exp_shallowmodel: accuracy:   0.587
02/04/2018 01:27:34 [INFO] exp_shallowmodel: f1_score:   0.401
02/04/2018 01:27:34 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.73      0.59       164
          F       0.71      0.69      0.70       268
          R       0.45      0.24      0.31       125

avg / total       0.57      0.59      0.57       571

02/04/2018 01:27:34 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:34 [INFO] exp_shallowmodel: 
[[  0   5   4   5]
 [  0 120  31  13]
 [  1  64 185  18]
 [  0  54  41  30]]
02/04/2018 01:27:34 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
02/04/2018 01:27:34 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:34 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:34 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:34 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:34 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:34 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:38 [INFO] exp_shallowmodel: train time: 3.712s
02/04/2018 01:27:38 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:38 [INFO] exp_shallowmodel: accuracy:   0.583
02/04/2018 01:27:38 [INFO] exp_shallowmodel: f1_score:   0.399
02/04/2018 01:27:38 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.67      0.56       164
          F       0.70      0.71      0.71       268
          R       0.45      0.26      0.33       125

avg / total       0.57      0.58      0.56       571

02/04/2018 01:27:38 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:38 [INFO] exp_shallowmodel: 
[[  0   7   5   2]
 [  0 110  35  19]
 [  0  59 191  18]
 [  0  51  42  32]]
02/04/2018 01:27:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
02/04/2018 01:27:38 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:38 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:38 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:38 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:38 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:38 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:43 [INFO] exp_shallowmodel: train time: 4.484s
02/04/2018 01:27:43 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:43 [INFO] exp_shallowmodel: accuracy:   0.599
02/04/2018 01:27:43 [INFO] exp_shallowmodel: f1_score:   0.399
02/04/2018 01:27:43 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.78      0.62       164
          F       0.73      0.71      0.72       268
          R       0.39      0.19      0.26       125

avg / total       0.57      0.60      0.57       571

02/04/2018 01:27:43 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:43 [INFO] exp_shallowmodel: 
[[  0   4   7   3]
 [  0 128  22  14]
 [  0  58 190  20]
 [  0  58  43  24]]
02/04/2018 01:27:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
02/04/2018 01:27:43 [INFO] exp_shallowmodel: #(data) = 4568
02/04/2018 01:27:43 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:43 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:43 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:43 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:43 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:47 [INFO] exp_shallowmodel: train time: 4.239s
02/04/2018 01:27:47 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:27:47 [INFO] exp_shallowmodel: accuracy:   0.560
02/04/2018 01:27:47 [INFO] exp_shallowmodel: f1_score:   0.377
02/04/2018 01:27:47 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.49      0.72      0.58       169
          F       0.65      0.67      0.66       271
          R       0.43      0.19      0.27       130

avg / total       0.54      0.56      0.53       586

02/04/2018 01:27:47 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:47 [INFO] exp_shallowmodel: 
[[  0   6   7   3]
 [  0 122  33  14]
 [  0  74 181  16]
 [  0  48  57  25]]
02/04/2018 01:27:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
02/04/2018 01:27:47 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:47 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:47 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:47 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:47 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:47 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:52 [INFO] exp_shallowmodel: train time: 4.751s
02/04/2018 01:27:52 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:52 [INFO] exp_shallowmodel: accuracy:   0.557
02/04/2018 01:27:52 [INFO] exp_shallowmodel: f1_score:   0.365
02/04/2018 01:27:52 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.46      0.72      0.56       164
          F       0.67      0.68      0.67       268
          R       0.40      0.15      0.22       125

avg / total       0.54      0.56      0.53       571

02/04/2018 01:27:52 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:52 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  0 118  34  12]
 [  0  73 181  14]
 [  1  57  48  19]]
02/04/2018 01:27:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
02/04/2018 01:27:52 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:52 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:52 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:52 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:52 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:52 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:55 [INFO] exp_shallowmodel: train time: 3.511s
02/04/2018 01:27:55 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:55 [INFO] exp_shallowmodel: accuracy:   0.599
02/04/2018 01:27:55 [INFO] exp_shallowmodel: f1_score:   0.407
02/04/2018 01:27:55 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.79      0.64       164
          F       0.68      0.69      0.68       268
          R       0.50      0.22      0.31       125

avg / total       0.58      0.60      0.57       571

02/04/2018 01:27:55 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:55 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 130  25   9]
 [  0  68 184  16]
 [  0  45  52  28]]
02/04/2018 01:27:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
02/04/2018 01:27:55 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:55 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:55 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:55 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:55 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:55 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:27:58 [INFO] exp_shallowmodel: train time: 2.626s
02/04/2018 01:27:58 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:27:58 [INFO] exp_shallowmodel: accuracy:   0.566
02/04/2018 01:27:58 [INFO] exp_shallowmodel: f1_score:   0.388
02/04/2018 01:27:58 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:27:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.47      0.70      0.56       164
          F       0.68      0.66      0.67       268
          R       0.45      0.24      0.31       125

avg / total       0.56      0.57      0.55       571

02/04/2018 01:27:58 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:27:58 [INFO] exp_shallowmodel: 
[[  0   6   4   4]
 [  0 115  34  15]
 [  0  73 178  17]
 [  0  51  44  30]]
02/04/2018 01:27:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
02/04/2018 01:27:58 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:27:58 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:27:58 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:27:58 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:27:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:27:58 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:27:58 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:01 [INFO] exp_shallowmodel: train time: 3.460s
02/04/2018 01:28:01 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
02/04/2018 01:28:01 [INFO] exp_shallowmodel: accuracy:   0.613
02/04/2018 01:28:01 [INFO] exp_shallowmodel: f1_score:   0.413
02/04/2018 01:28:01 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.76      0.61       164
          F       0.74      0.74      0.74       268
          R       0.47      0.22      0.30       125

avg / total       0.60      0.61      0.59       571

02/04/2018 01:28:01 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:01 [INFO] exp_shallowmodel: 
[[  0  11   3   0]
 [  0 125  23  16]
 [  0  56 197  15]
 [  0  52  45  28]]
02/04/2018 01:28:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
02/04/2018 01:28:01 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:01 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:01 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:01 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:01 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:01 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:06 [INFO] exp_shallowmodel: train time: 4.550s
02/04/2018 01:28:06 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:28:06 [INFO] exp_shallowmodel: accuracy:   0.609
02/04/2018 01:28:06 [INFO] exp_shallowmodel: f1_score:   0.403
02/04/2018 01:28:06 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.76      0.61       164
          F       0.72      0.75      0.73       268
          R       0.50      0.18      0.27       125

avg / total       0.59      0.61      0.58       571

02/04/2018 01:28:06 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:06 [INFO] exp_shallowmodel: 
[[  0   7   6   1]
 [  0 125  28  11]
 [  0  57 200  11]
 [  0  57  45  23]]
02/04/2018 01:28:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
02/04/2018 01:28:06 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:06 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:06 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:06 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:06 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:06 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:10 [INFO] exp_shallowmodel: train time: 3.940s
02/04/2018 01:28:10 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:10 [INFO] exp_shallowmodel: accuracy:   0.585
02/04/2018 01:28:10 [INFO] exp_shallowmodel: f1_score:   0.396
02/04/2018 01:28:10 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.76      0.60       164
          F       0.71      0.68      0.69       268
          R       0.42      0.22      0.29       125

avg / total       0.57      0.58      0.56       571

02/04/2018 01:28:10 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:10 [INFO] exp_shallowmodel: 
[[  0   6   5   3]
 [  0 124  30  10]
 [  0  61 183  24]
 [  0  57  41  27]]
02/04/2018 01:28:10 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
02/04/2018 01:28:10 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:10 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:10 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:10 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:10 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:10 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:13 [INFO] exp_shallowmodel: train time: 3.469s
02/04/2018 01:28:13 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:13 [INFO] exp_shallowmodel: accuracy:   0.564
02/04/2018 01:28:13 [INFO] exp_shallowmodel: f1_score:   0.382
02/04/2018 01:28:13 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.48      0.74      0.58       164
          F       0.68      0.65      0.66       268
          R       0.46      0.21      0.29       125

avg / total       0.55      0.56      0.54       571

02/04/2018 01:28:13 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:13 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  0 122  27  15]
 [  1  79 174  14]
 [  0  49  50  26]]
02/04/2018 01:28:13 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
02/04/2018 01:28:13 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:13 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:13 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:13 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:13 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:13 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:17 [INFO] exp_shallowmodel: train time: 3.210s
02/04/2018 01:28:17 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:17 [INFO] exp_shallowmodel: accuracy:   0.564
02/04/2018 01:28:17 [INFO] exp_shallowmodel: f1_score:   0.400
02/04/2018 01:28:17 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.44      0.76      0.56       164
          F       0.72      0.60      0.65       268
          R       0.55      0.30      0.39       125

avg / total       0.59      0.56      0.55       571

02/04/2018 01:28:17 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:17 [INFO] exp_shallowmodel: 
[[  0   7   5   2]
 [  0 124  23  17]
 [  0  96 161  11]
 [  0  53  35  37]]
02/04/2018 01:28:17 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
02/04/2018 01:28:17 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:17 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:17 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:17 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:17 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:17 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:19 [INFO] exp_shallowmodel: train time: 2.472s
02/04/2018 01:28:19 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:19 [INFO] exp_shallowmodel: accuracy:   0.583
02/04/2018 01:28:19 [INFO] exp_shallowmodel: f1_score:   0.402
02/04/2018 01:28:19 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.79      0.61       164
          F       0.73      0.64      0.68       268
          R       0.42      0.25      0.31       125

avg / total       0.58      0.58      0.56       571

02/04/2018 01:28:19 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:19 [INFO] exp_shallowmodel: 
[[  0   3   4   7]
 [  0 130  20  14]
 [  0  75 172  21]
 [  1  52  41  31]]
02/04/2018 01:28:19 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
02/04/2018 01:28:19 [INFO] exp_shallowmodel: #(data) = 4568
02/04/2018 01:28:19 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:19 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:19 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:19 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:19 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:23 [INFO] exp_shallowmodel: train time: 3.785s
02/04/2018 01:28:23 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:23 [INFO] exp_shallowmodel: accuracy:   0.565
02/04/2018 01:28:23 [INFO] exp_shallowmodel: f1_score:   0.388
02/04/2018 01:28:23 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.50      0.73      0.60       169
          F       0.67      0.65      0.66       271
          R       0.41      0.23      0.29       130

avg / total       0.54      0.56      0.54       586

02/04/2018 01:28:23 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:23 [INFO] exp_shallowmodel: 
[[  0   5   7   4]
 [  0 124  32  13]
 [  0  67 177  27]
 [  0  51  49  30]]
02/04/2018 01:28:23 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
02/04/2018 01:28:23 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:23 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:23 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:23 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:23 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:23 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:26 [INFO] exp_shallowmodel: train time: 3.032s
02/04/2018 01:28:26 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:26 [INFO] exp_shallowmodel: accuracy:   0.616
02/04/2018 01:28:26 [INFO] exp_shallowmodel: f1_score:   0.422
02/04/2018 01:28:26 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.84      0.66       164
          F       0.70      0.69      0.69       268
          R       0.55      0.24      0.33       125

avg / total       0.61      0.62      0.59       571

02/04/2018 01:28:26 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:26 [INFO] exp_shallowmodel: 
[[  0   8   5   1]
 [  0 138  14  12]
 [  0  72 184  12]
 [  1  35  59  30]]
02/04/2018 01:28:26 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
02/04/2018 01:28:26 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:26 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:26 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:26 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:26 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:26 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:29 [INFO] exp_shallowmodel: train time: 3.119s
02/04/2018 01:28:29 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:28:29 [INFO] exp_shallowmodel: accuracy:   0.562
02/04/2018 01:28:29 [INFO] exp_shallowmodel: f1_score:   0.382
02/04/2018 01:28:29 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.47      0.70      0.56       164
          F       0.66      0.67      0.67       268
          R       0.48      0.22      0.30       125

avg / total       0.55      0.56      0.54       571

02/04/2018 01:28:29 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:29 [INFO] exp_shallowmodel: 
[[  0   5   9   0]
 [  0 114  38  12]
 [  1  70 180  17]
 [  0  53  45  27]]
02/04/2018 01:28:29 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
02/04/2018 01:28:29 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:29 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:29 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:29 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:29 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:29 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:32 [INFO] exp_shallowmodel: train time: 2.657s
02/04/2018 01:28:32 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:32 [INFO] exp_shallowmodel: accuracy:   0.615
02/04/2018 01:28:32 [INFO] exp_shallowmodel: f1_score:   0.428
02/04/2018 01:28:32 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.76      0.61       164
          F       0.71      0.71      0.71       268
          R       0.59      0.29      0.39       125

avg / total       0.61      0.61      0.60       571

02/04/2018 01:28:32 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:32 [INFO] exp_shallowmodel: 
[[  0   3   7   4]
 [  0 124  32   8]
 [  0  64 191  13]
 [  1  50  38  36]]
02/04/2018 01:28:32 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
02/04/2018 01:28:32 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:32 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:32 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:32 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:32 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:32 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:35 [INFO] exp_shallowmodel: train time: 2.634s
02/04/2018 01:28:35 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:35 [INFO] exp_shallowmodel: accuracy:   0.553
02/04/2018 01:28:35 [INFO] exp_shallowmodel: f1_score:   0.377
02/04/2018 01:28:35 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.45      0.65      0.53       164
          F       0.68      0.68      0.68       268
          R       0.40      0.23      0.29       125

avg / total       0.54      0.55      0.54       571

02/04/2018 01:28:35 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:35 [INFO] exp_shallowmodel: 
[[  0   7   3   4]
 [  1 106  41  16]
 [  0  64 181  23]
 [  0  56  40  29]]
02/04/2018 01:28:35 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
02/04/2018 01:28:35 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:35 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:35 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:35 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:35 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:35 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:38 [INFO] exp_shallowmodel: train time: 3.495s
02/04/2018 01:28:38 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:38 [INFO] exp_shallowmodel: accuracy:   0.613
02/04/2018 01:28:38 [INFO] exp_shallowmodel: f1_score:   0.409
02/04/2018 01:28:38 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.79      0.64       164
          F       0.72      0.73      0.72       268
          R       0.45      0.20      0.28       125

avg / total       0.59      0.61      0.58       571

02/04/2018 01:28:38 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:38 [INFO] exp_shallowmodel: 
[[  0   7   6   1]
 [  0 130  19  15]
 [  0  58 195  15]
 [  0  49  51  25]]
02/04/2018 01:28:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
02/04/2018 01:28:38 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:38 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:38 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:38 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:38 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:38 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:43 [INFO] exp_shallowmodel: train time: 4.840s
02/04/2018 01:28:43 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:43 [INFO] exp_shallowmodel: accuracy:   0.588
02/04/2018 01:28:43 [INFO] exp_shallowmodel: f1_score:   0.409
02/04/2018 01:28:43 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.49      0.70      0.58       164
          F       0.71      0.69      0.70       268
          R       0.47      0.29      0.36       125

avg / total       0.58      0.59      0.57       571

02/04/2018 01:28:43 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:43 [INFO] exp_shallowmodel: 
[[  0   5   4   5]
 [  0 115  33  16]
 [  0  64 185  19]
 [  0  49  40  36]]
02/04/2018 01:28:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
02/04/2018 01:28:43 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:43 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:43 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:43 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:43 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:43 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:46 [INFO] exp_shallowmodel: train time: 3.227s
02/04/2018 01:28:46 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:46 [INFO] exp_shallowmodel: accuracy:   0.587
02/04/2018 01:28:46 [INFO] exp_shallowmodel: f1_score:   0.398
02/04/2018 01:28:46 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.50      0.74      0.60       164
          F       0.70      0.69      0.69       268
          R       0.46      0.22      0.30       125

avg / total       0.57      0.59      0.56       571

02/04/2018 01:28:46 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:46 [INFO] exp_shallowmodel: 
[[  0   6   6   2]
 [  0 122  25  17]
 [  0  69 185  14]
 [  0  47  50  28]]
02/04/2018 01:28:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
02/04/2018 01:28:46 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:46 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:46 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:46 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:46 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:46 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:49 [INFO] exp_shallowmodel: train time: 2.613s
02/04/2018 01:28:49 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:28:49 [INFO] exp_shallowmodel: accuracy:   0.557
02/04/2018 01:28:49 [INFO] exp_shallowmodel: f1_score:   0.377
02/04/2018 01:28:49 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.69      0.59       164
          F       0.64      0.67      0.66       268
          R       0.36      0.21      0.26       125

avg / total       0.53      0.56      0.53       571

02/04/2018 01:28:49 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:49 [INFO] exp_shallowmodel: 
[[  0   2   8   4]
 [  0 113  37  14]
 [  0  61 179  28]
 [  0  45  54  26]]
02/04/2018 01:28:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
02/04/2018 01:28:49 [INFO] exp_shallowmodel: #(data) = 4583
02/04/2018 01:28:49 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:49 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:49 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:49 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:49 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:53 [INFO] exp_shallowmodel: train time: 3.536s
02/04/2018 01:28:53 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:53 [INFO] exp_shallowmodel: accuracy:   0.587
02/04/2018 01:28:53 [INFO] exp_shallowmodel: f1_score:   0.399
02/04/2018 01:28:53 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.52      0.77      0.62       164
          F       0.70      0.68      0.69       268
          R       0.42      0.22      0.29       125

avg / total       0.57      0.59      0.56       571

02/04/2018 01:28:53 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:53 [INFO] exp_shallowmodel: 
[[  0   7   5   2]
 [  0 126  27  11]
 [  0  61 181  26]
 [  0  50  47  28]]
02/04/2018 01:28:53 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
02/04/2018 01:28:53 [INFO] exp_shallowmodel: #(data) = 4568
02/04/2018 01:28:53 [INFO] exp_shallowmodel: #(feature) = 306
02/04/2018 01:28:53 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:53 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:53 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:53 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:28:55 [INFO] exp_shallowmodel: train time: 2.732s
02/04/2018 01:28:55 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:28:55 [INFO] exp_shallowmodel: accuracy:   0.563
02/04/2018 01:28:55 [INFO] exp_shallowmodel: f1_score:   0.383
02/04/2018 01:28:55 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:28:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.49      0.76      0.60       169
          F       0.68      0.65      0.66       271
          R       0.39      0.21      0.27       130

avg / total       0.54      0.56      0.54       586

02/04/2018 01:28:55 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:28:55 [INFO] exp_shallowmodel: 
[[  0   7   6   3]
 [  0 128  25  16]
 [  0  73 175  23]
 [  1  52  50  27]]
02/04/2018 01:28:58 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
02/04/2018 01:28:58 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:28:58 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:28:58 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:28:58 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:28:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:28:58 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:28:58 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:01 [INFO] exp_shallowmodel: train time: 2.914s
02/04/2018 01:29:01 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:01 [INFO] exp_shallowmodel: accuracy:   0.554
02/04/2018 01:29:01 [INFO] exp_shallowmodel: f1_score:   0.379
02/04/2018 01:29:01 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.46      0.64      0.54       169
          F       0.67      0.71      0.69       281
          R       0.35      0.15      0.21       122

avg / total       0.53      0.55      0.53       592

02/04/2018 01:29:01 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:01 [INFO] exp_shallowmodel: 
[[  1   3  11   5]
 [  1 109  43  16]
 [  2  67 200  12]
 [  1  57  46  18]]
02/04/2018 01:29:01 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
02/04/2018 01:29:01 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:01 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:01 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:01 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:01 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:01 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:06 [INFO] exp_shallowmodel: train time: 5.139s
02/04/2018 01:29:06 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:06 [INFO] exp_shallowmodel: accuracy:   0.586
02/04/2018 01:29:06 [INFO] exp_shallowmodel: f1_score:   0.382
02/04/2018 01:29:06 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.72      0.58       169
          F       0.68      0.73      0.71       281
          R       0.58      0.16      0.25       122

avg / total       0.58      0.59      0.55       592

02/04/2018 01:29:06 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:06 [INFO] exp_shallowmodel: 
[[  0   4  14   2]
 [  0 122  39   8]
 [  0  71 206   4]
 [  2  57  44  19]]
02/04/2018 01:29:06 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
02/04/2018 01:29:06 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:06 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:06 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:06 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:06 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:06 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:10 [INFO] exp_shallowmodel: train time: 3.838s
02/04/2018 01:29:10 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:29:10 [INFO] exp_shallowmodel: accuracy:   0.569
02/04/2018 01:29:10 [INFO] exp_shallowmodel: f1_score:   0.394
02/04/2018 01:29:10 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.46      0.66      0.54       169
          F       0.66      0.73      0.69       281
          R       0.58      0.17      0.27       122

avg / total       0.57      0.57      0.54       592

02/04/2018 01:29:10 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:10 [INFO] exp_shallowmodel: 
[[  1   8  10   1]
 [  1 111  47  10]
 [  1  72 204   4]
 [  2  49  50  21]]
02/04/2018 01:29:10 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
02/04/2018 01:29:10 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:10 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:10 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:10 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:10 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:10 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:15 [INFO] exp_shallowmodel: train time: 4.734s
02/04/2018 01:29:15 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:15 [INFO] exp_shallowmodel: accuracy:   0.576
02/04/2018 01:29:15 [INFO] exp_shallowmodel: f1_score:   0.373
02/04/2018 01:29:15 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.74      0.59       169
          F       0.69      0.71      0.70       281
          R       0.38      0.14      0.20       122

avg / total       0.54      0.58      0.54       592

02/04/2018 01:29:15 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:15 [INFO] exp_shallowmodel: 
[[  0   8   8   4]
 [  0 125  33  11]
 [  0  69 199  13]
 [  2  54  49  17]]
02/04/2018 01:29:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
02/04/2018 01:29:15 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:15 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:15 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:15 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:15 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:15 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:20 [INFO] exp_shallowmodel: train time: 4.832s
02/04/2018 01:29:20 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:20 [INFO] exp_shallowmodel: accuracy:   0.561
02/04/2018 01:29:20 [INFO] exp_shallowmodel: f1_score:   0.363
02/04/2018 01:29:20 [INFO] exp_shallowmodel: classification report:
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
02/04/2018 01:29:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.78      0.58       169
          F       0.68      0.66      0.67       281
          R       0.47      0.13      0.21       122

avg / total       0.55      0.56      0.52       592

02/04/2018 01:29:20 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:20 [INFO] exp_shallowmodel: 
[[  0   7  11   2]
 [  0 131  29   9]
 [  0  89 185   7]
 [  0  59  47  16]]
02/04/2018 01:29:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
02/04/2018 01:29:20 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:20 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:20 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:20 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:20 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:20 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:25 [INFO] exp_shallowmodel: train time: 4.572s
02/04/2018 01:29:25 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:25 [INFO] exp_shallowmodel: accuracy:   0.564
02/04/2018 01:29:25 [INFO] exp_shallowmodel: f1_score:   0.394
02/04/2018 01:29:25 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.45      0.63      0.53       169
          F       0.67      0.73      0.70       281
          R       0.46      0.19      0.27       122

avg / total       0.55      0.56      0.54       592

02/04/2018 01:29:25 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:25 [INFO] exp_shallowmodel: 
[[  1   9   9   1]
 [  1 106  44  18]
 [  0  69 204   8]
 [  2  50  47  23]]
02/04/2018 01:29:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
02/04/2018 01:29:25 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:25 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:25 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:25 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:25 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:25 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:28 [INFO] exp_shallowmodel: train time: 3.589s
02/04/2018 01:29:28 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:28 [INFO] exp_shallowmodel: accuracy:   0.547
02/04/2018 01:29:28 [INFO] exp_shallowmodel: f1_score:   0.360
02/04/2018 01:29:28 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.66      0.55       169
          F       0.65      0.68      0.67       281
          R       0.36      0.16      0.22       122

avg / total       0.52      0.55      0.52       592

02/04/2018 01:29:28 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:28 [INFO] exp_shallowmodel: 
[[  0   7   8   5]
 [  0 112  43  14]
 [  1  71 192  17]
 [  0  51  51  20]]
02/04/2018 01:29:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
02/04/2018 01:29:28 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:28 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:28 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:28 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:28 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:28 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:33 [INFO] exp_shallowmodel: train time: 4.468s
02/04/2018 01:29:33 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:33 [INFO] exp_shallowmodel: accuracy:   0.561
02/04/2018 01:29:33 [INFO] exp_shallowmodel: f1_score:   0.389
02/04/2018 01:29:33 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.45      0.56      0.50       169
          F       0.63      0.77      0.69       281
          R       0.55      0.18      0.27       122

avg / total       0.57      0.56      0.53       592

02/04/2018 01:29:33 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:33 [INFO] exp_shallowmodel: 
[[  1   9   7   3]
 [  0  94  70   5]
 [  0  56 215  10]
 [  0  50  50  22]]
02/04/2018 01:29:33 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
02/04/2018 01:29:33 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:33 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:33 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:33 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:33 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:33 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:36 [INFO] exp_shallowmodel: train time: 3.683s
02/04/2018 01:29:36 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:36 [INFO] exp_shallowmodel: accuracy:   0.556
02/04/2018 01:29:36 [INFO] exp_shallowmodel: f1_score:   0.357
02/04/2018 01:29:36 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.67      0.55       169
          F       0.67      0.71      0.69       281
          R       0.35      0.13      0.19       122

avg / total       0.52      0.56      0.52       592

02/04/2018 01:29:36 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:36 [INFO] exp_shallowmodel: 
[[  0   5  12   3]
 [  2 114  40  13]
 [  0  68 199  14]
 [  0  59  47  16]]
02/04/2018 01:29:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
02/04/2018 01:29:37 [INFO] exp_shallowmodel: #(data) = 4736
02/04/2018 01:29:37 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:37 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:37 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:37 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:37 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:41 [INFO] exp_shallowmodel: train time: 4.749s
02/04/2018 01:29:41 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:29:41 [INFO] exp_shallowmodel: accuracy:   0.566
02/04/2018 01:29:41 [INFO] exp_shallowmodel: f1_score:   0.382
02/04/2018 01:29:41 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.44      0.69      0.54       172
          F       0.70      0.70      0.70       283
          R       0.53      0.20      0.29       123

avg / total       0.56      0.57      0.54       606

02/04/2018 01:29:41 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:41 [INFO] exp_shallowmodel: 
[[  0  11  10   7]
 [  0 119  46   7]
 [  0  76 199   8]
 [  1  66  31  25]]
02/04/2018 01:29:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
02/04/2018 01:29:41 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:41 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:41 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:41 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:41 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:41 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:45 [INFO] exp_shallowmodel: train time: 3.508s
02/04/2018 01:29:45 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:45 [INFO] exp_shallowmodel: accuracy:   0.590
02/04/2018 01:29:45 [INFO] exp_shallowmodel: f1_score:   0.407
02/04/2018 01:29:45 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.49      0.69      0.57       169
          F       0.69      0.75      0.72       281
          R       0.50      0.17      0.26       122

avg / total       0.58      0.59      0.56       592

02/04/2018 01:29:45 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:45 [INFO] exp_shallowmodel: 
[[  1   6  10   3]
 [  1 117  41  10]
 [  0  63 210   8]
 [  2  54  45  21]]
02/04/2018 01:29:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
02/04/2018 01:29:45 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:45 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:45 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:45 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:45 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:45 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:50 [INFO] exp_shallowmodel: train time: 4.819s
02/04/2018 01:29:50 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:50 [INFO] exp_shallowmodel: accuracy:   0.537
02/04/2018 01:29:50 [INFO] exp_shallowmodel: f1_score:   0.396
02/04/2018 01:29:50 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.10      0.17        20
          C       0.42      0.58      0.49       169
          F       0.64      0.70      0.67       281
          R       0.45      0.18      0.26       122

avg / total       0.54      0.54      0.51       592

02/04/2018 01:29:50 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:50 [INFO] exp_shallowmodel: 
[[  2   8   8   2]
 [  0  98  54  17]
 [  1  76 196   8]
 [  0  53  47  22]]
02/04/2018 01:29:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
02/04/2018 01:29:50 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:50 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:50 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:50 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:50 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:50 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:54 [INFO] exp_shallowmodel: train time: 4.583s
02/04/2018 01:29:54 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:54 [INFO] exp_shallowmodel: accuracy:   0.546
02/04/2018 01:29:54 [INFO] exp_shallowmodel: f1_score:   0.354
02/04/2018 01:29:54 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.44      0.69      0.53       169
          F       0.69      0.68      0.68       281
          R       0.37      0.14      0.20       122

avg / total       0.53      0.55      0.52       592

02/04/2018 01:29:54 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:54 [INFO] exp_shallowmodel: 
[[  0   8   6   6]
 [  1 116  39  13]
 [  0  81 190  10]
 [  2  61  42  17]]
02/04/2018 01:29:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
02/04/2018 01:29:54 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:54 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:54 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:54 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:54 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:54 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:29:59 [INFO] exp_shallowmodel: train time: 4.267s
02/04/2018 01:29:59 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:29:59 [INFO] exp_shallowmodel: accuracy:   0.568
02/04/2018 01:29:59 [INFO] exp_shallowmodel: f1_score:   0.406
02/04/2018 01:29:59 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:29:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.10      0.17        20
          C       0.44      0.69      0.54       169
          F       0.70      0.71      0.71       281
          R       0.44      0.14      0.21       122

avg / total       0.57      0.57      0.54       592

02/04/2018 01:29:59 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:29:59 [INFO] exp_shallowmodel: 
[[  2   7  10   1]
 [  1 117  41  10]
 [  1  69 200  11]
 [  0  70  35  17]]
02/04/2018 01:29:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
02/04/2018 01:29:59 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:29:59 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:29:59 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:29:59 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:29:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:29:59 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:29:59 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:02 [INFO] exp_shallowmodel: train time: 3.461s
02/04/2018 01:30:02 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:30:02 [INFO] exp_shallowmodel: accuracy:   0.581
02/04/2018 01:30:02 [INFO] exp_shallowmodel: f1_score:   0.385
02/04/2018 01:30:02 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.73      0.58       169
          F       0.69      0.71      0.70       281
          R       0.48      0.18      0.26       122

avg / total       0.56      0.58      0.55       592

02/04/2018 01:30:02 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:02 [INFO] exp_shallowmodel: 
[[  0   6  11   3]
 [  0 123  38   8]
 [  0  69 199  13]
 [  1  57  42  22]]
02/04/2018 01:30:02 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
02/04/2018 01:30:02 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:02 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:02 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:02 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:02 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:02 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:05 [INFO] exp_shallowmodel: train time: 2.801s
02/04/2018 01:30:05 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:05 [INFO] exp_shallowmodel: accuracy:   0.559
02/04/2018 01:30:05 [INFO] exp_shallowmodel: f1_score:   0.387
02/04/2018 01:30:05 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.47      0.74      0.58       169
          F       0.69      0.67      0.68       281
          R       0.33      0.15      0.20       122

avg / total       0.55      0.56      0.53       592

02/04/2018 01:30:05 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:05 [INFO] exp_shallowmodel: 
[[  1   6   9   4]
 [  0 125  31  13]
 [  1  73 187  20]
 [  0  60  44  18]]
02/04/2018 01:30:05 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
02/04/2018 01:30:05 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:05 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:05 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:05 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:05 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:05 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:09 [INFO] exp_shallowmodel: train time: 4.148s
02/04/2018 01:30:09 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:09 [INFO] exp_shallowmodel: accuracy:   0.571
02/04/2018 01:30:09 [INFO] exp_shallowmodel: f1_score:   0.384
02/04/2018 01:30:09 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.47      0.66      0.55       169
          F       0.66      0.72      0.69       281
          R       0.52      0.21      0.30       122

avg / total       0.56      0.57      0.54       592

02/04/2018 01:30:09 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:09 [INFO] exp_shallowmodel: 
[[  0   5  10   5]
 [  0 111  48  10]
 [  0  71 201   9]
 [  1  51  44  26]]
02/04/2018 01:30:09 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
02/04/2018 01:30:09 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:09 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:09 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:09 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:09 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:09 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:13 [INFO] exp_shallowmodel: train time: 3.300s
02/04/2018 01:30:13 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:13 [INFO] exp_shallowmodel: accuracy:   0.586
02/04/2018 01:30:13 [INFO] exp_shallowmodel: f1_score:   0.387
02/04/2018 01:30:13 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.49      0.69      0.57       169
          F       0.69      0.74      0.71       281
          R       0.43      0.19      0.26       122

avg / total       0.56      0.59      0.56       592

02/04/2018 01:30:13 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:13 [INFO] exp_shallowmodel: 
[[  0   4  10   6]
 [  0 116  40  13]
 [  0  62 208  11]
 [  0  55  44  23]]
02/04/2018 01:30:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
02/04/2018 01:30:13 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:13 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:13 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:13 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:13 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:13 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:17 [INFO] exp_shallowmodel: train time: 4.687s
02/04/2018 01:30:17 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:17 [INFO] exp_shallowmodel: accuracy:   0.549
02/04/2018 01:30:17 [INFO] exp_shallowmodel: f1_score:   0.372
02/04/2018 01:30:17 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.46      0.68      0.55       169
          F       0.65      0.69      0.67       281
          R       0.41      0.12      0.19       122

avg / total       0.53      0.55      0.52       592

02/04/2018 01:30:17 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:17 [INFO] exp_shallowmodel: 
[[  1   9   9   1]
 [  1 115  46   7]
 [  0  73 194  14]
 [  2  55  50  15]]
02/04/2018 01:30:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
02/04/2018 01:30:17 [INFO] exp_shallowmodel: #(data) = 4736
02/04/2018 01:30:17 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:17 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:17 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:17 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:17 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:22 [INFO] exp_shallowmodel: train time: 4.186s
02/04/2018 01:30:22 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:30:22 [INFO] exp_shallowmodel: accuracy:   0.561
02/04/2018 01:30:22 [INFO] exp_shallowmodel: f1_score:   0.369
02/04/2018 01:30:22 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.46      0.72      0.56       172
          F       0.67      0.70      0.68       283
          R       0.50      0.15      0.24       123

avg / total       0.54      0.56      0.53       606

02/04/2018 01:30:22 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:22 [INFO] exp_shallowmodel: 
[[  0  13  10   5]
 [  0 123  41   8]
 [  0  79 198   6]
 [  2  55  47  19]]
02/04/2018 01:30:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
02/04/2018 01:30:22 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:22 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:22 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:22 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:22 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:22 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:26 [INFO] exp_shallowmodel: train time: 4.280s
02/04/2018 01:30:26 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:26 [INFO] exp_shallowmodel: accuracy:   0.573
02/04/2018 01:30:26 [INFO] exp_shallowmodel: f1_score:   0.369
02/04/2018 01:30:26 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.70      0.57       169
          F       0.69      0.72      0.71       281
          R       0.35      0.14      0.20       122

avg / total       0.54      0.57      0.54       592

02/04/2018 01:30:26 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:26 [INFO] exp_shallowmodel: 
[[  0   2  13   5]
 [  0 119  35  15]
 [  0  67 203  11]
 [  2  61  42  17]]
02/04/2018 01:30:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
02/04/2018 01:30:26 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:26 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:26 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:26 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:26 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:26 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:30 [INFO] exp_shallowmodel: train time: 3.628s
02/04/2018 01:30:30 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:30 [INFO] exp_shallowmodel: accuracy:   0.566
02/04/2018 01:30:30 [INFO] exp_shallowmodel: f1_score:   0.380
02/04/2018 01:30:30 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.66      0.54       169
          F       0.66      0.70      0.68       281
          R       0.54      0.20      0.30       122

avg / total       0.56      0.57      0.54       592

02/04/2018 01:30:30 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:30 [INFO] exp_shallowmodel: 
[[  0   6  11   3]
 [  0 112  47  10]
 [  0  75 198   8]
 [  1  51  45  25]]
02/04/2018 01:30:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
02/04/2018 01:30:30 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:30 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:30 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:30 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:30 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:30 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:34 [INFO] exp_shallowmodel: train time: 4.191s
02/04/2018 01:30:34 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:34 [INFO] exp_shallowmodel: accuracy:   0.584
02/04/2018 01:30:34 [INFO] exp_shallowmodel: f1_score:   0.385
02/04/2018 01:30:34 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.72      0.57       169
          F       0.70      0.72      0.71       281
          R       0.53      0.17      0.26       122

avg / total       0.57      0.58      0.55       592

02/04/2018 01:30:34 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:34 [INFO] exp_shallowmodel: 
[[  0  10  10   0]
 [  2 122  34  11]
 [  0  70 203   8]
 [  2  54  45  21]]
02/04/2018 01:30:34 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
02/04/2018 01:30:34 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:34 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:34 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:34 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:34 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:34 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:37 [INFO] exp_shallowmodel: train time: 3.481s
02/04/2018 01:30:37 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:37 [INFO] exp_shallowmodel: accuracy:   0.556
02/04/2018 01:30:37 [INFO] exp_shallowmodel: f1_score:   0.387
02/04/2018 01:30:37 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.45      0.70      0.55       169
          F       0.66      0.68      0.67       281
          R       0.46      0.16      0.23       122

avg / total       0.57      0.56      0.53       592

02/04/2018 01:30:37 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:37 [INFO] exp_shallowmodel: 
[[  1   6  11   2]
 [  0 118  40  11]
 [  0  81 191   9]
 [  0  55  48  19]]
02/04/2018 01:30:38 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
02/04/2018 01:30:38 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:38 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:38 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:38 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:38 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:38 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:41 [INFO] exp_shallowmodel: train time: 3.356s
02/04/2018 01:30:41 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:41 [INFO] exp_shallowmodel: accuracy:   0.562
02/04/2018 01:30:41 [INFO] exp_shallowmodel: f1_score:   0.395
02/04/2018 01:30:41 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.47      0.66      0.55       169
          F       0.65      0.71      0.68       281
          R       0.47      0.18      0.26       122

avg / total       0.57      0.56      0.53       592

02/04/2018 01:30:41 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:41 [INFO] exp_shallowmodel: 
[[  1   5   9   5]
 [  0 111  49   9]
 [  0  71 199  11]
 [  0  49  51  22]]
02/04/2018 01:30:41 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
02/04/2018 01:30:41 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:41 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:41 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:41 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:41 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:41 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:45 [INFO] exp_shallowmodel: train time: 3.657s
02/04/2018 01:30:45 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:30:45 [INFO] exp_shallowmodel: accuracy:   0.529
02/04/2018 01:30:45 [INFO] exp_shallowmodel: f1_score:   0.359
02/04/2018 01:30:45 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        20
          C       0.44      0.62      0.51       169
          F       0.63      0.68      0.65       281
          R       0.34      0.12      0.18       122

avg / total       0.50      0.53      0.50       592

02/04/2018 01:30:45 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:45 [INFO] exp_shallowmodel: 
[[  1   6  11   2]
 [  0 105  52  12]
 [  1  73 192  15]
 [  1  55  51  15]]
02/04/2018 01:30:45 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
02/04/2018 01:30:45 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:45 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:45 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:45 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:45 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:45 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:49 [INFO] exp_shallowmodel: train time: 4.818s
02/04/2018 01:30:49 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:49 [INFO] exp_shallowmodel: accuracy:   0.539
02/04/2018 01:30:49 [INFO] exp_shallowmodel: f1_score:   0.357
02/04/2018 01:30:49 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.66      0.53       169
          F       0.66      0.67      0.66       281
          R       0.35      0.17      0.23       122

avg / total       0.51      0.54      0.51       592

02/04/2018 01:30:49 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:49 [INFO] exp_shallowmodel: 
[[  0  10   7   3]
 [  0 111  43  15]
 [  0  73 187  21]
 [  2  54  45  21]]
02/04/2018 01:30:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
02/04/2018 01:30:50 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:50 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:50 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:50 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:50 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:50 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:54 [INFO] exp_shallowmodel: train time: 4.577s
02/04/2018 01:30:54 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:54 [INFO] exp_shallowmodel: accuracy:   0.551
02/04/2018 01:30:54 [INFO] exp_shallowmodel: f1_score:   0.376
02/04/2018 01:30:54 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        20
          C       0.43      0.66      0.52       169
          F       0.68      0.70      0.69       281
          R       0.41      0.14      0.21       122

avg / total       0.54      0.55      0.52       592

02/04/2018 01:30:54 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:54 [INFO] exp_shallowmodel: 
[[  1   9   6   4]
 [  0 111  47  11]
 [  1  74 197   9]
 [  1  64  40  17]]
02/04/2018 01:30:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
02/04/2018 01:30:54 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:30:54 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:54 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:54 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:54 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:54 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:30:59 [INFO] exp_shallowmodel: train time: 4.911s
02/04/2018 01:30:59 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:30:59 [INFO] exp_shallowmodel: accuracy:   0.579
02/04/2018 01:30:59 [INFO] exp_shallowmodel: f1_score:   0.383
02/04/2018 01:30:59 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:30:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.75      0.59       169
          F       0.68      0.70      0.69       281
          R       0.50      0.17      0.26       122

avg / total       0.57      0.58      0.55       592

02/04/2018 01:30:59 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:30:59 [INFO] exp_shallowmodel: 
[[  0   5   9   6]
 [  1 126  35   7]
 [  0  77 196   8]
 [  2  52  47  21]]
02/04/2018 01:30:59 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
02/04/2018 01:30:59 [INFO] exp_shallowmodel: #(data) = 4736
02/04/2018 01:30:59 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:30:59 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:30:59 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:30:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:30:59 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:30:59 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:03 [INFO] exp_shallowmodel: train time: 3.910s
02/04/2018 01:31:03 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:31:03 [INFO] exp_shallowmodel: accuracy:   0.564
02/04/2018 01:31:03 [INFO] exp_shallowmodel: f1_score:   0.374
02/04/2018 01:31:03 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.45      0.70      0.55       172
          F       0.70      0.71      0.70       283
          R       0.45      0.17      0.25       123

avg / total       0.54      0.56      0.53       606

02/04/2018 01:31:03 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:03 [INFO] exp_shallowmodel: 
[[  0  14   9   5]
 [  2 121  39  10]
 [  0  72 200  11]
 [  0  63  39  21]]
02/04/2018 01:31:03 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
02/04/2018 01:31:03 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:03 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:03 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:03 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:03 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:03 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:08 [INFO] exp_shallowmodel: train time: 5.237s
02/04/2018 01:31:08 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:31:08 [INFO] exp_shallowmodel: accuracy:   0.603
02/04/2018 01:31:08 [INFO] exp_shallowmodel: f1_score:   0.401
02/04/2018 01:31:08 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.73      0.61       169
          F       0.69      0.74      0.71       281
          R       0.49      0.20      0.28       122

avg / total       0.57      0.60      0.57       592

02/04/2018 01:31:08 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:08 [INFO] exp_shallowmodel: 
[[  0   9   9   2]
 [  0 124  36   9]
 [  0  58 209  14]
 [  0  47  51  24]]
02/04/2018 01:31:08 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
02/04/2018 01:31:08 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:08 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:08 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:08 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:08 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:08 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:14 [INFO] exp_shallowmodel: train time: 5.241s
02/04/2018 01:31:14 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:31:14 [INFO] exp_shallowmodel: accuracy:   0.579
02/04/2018 01:31:14 [INFO] exp_shallowmodel: f1_score:   0.382
02/04/2018 01:31:14 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.66      0.54       169
          F       0.71      0.74      0.72       281
          R       0.48      0.19      0.27       122

avg / total       0.56      0.58      0.55       592

02/04/2018 01:31:14 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:14 [INFO] exp_shallowmodel: 
[[  0   8   9   3]
 [  1 112  43  13]
 [  0  64 208   9]
 [  0  64  35  23]]
02/04/2018 01:31:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
02/04/2018 01:31:14 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:14 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:14 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:14 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:14 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:14 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:18 [INFO] exp_shallowmodel: train time: 4.430s
02/04/2018 01:31:18 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:31:18 [INFO] exp_shallowmodel: accuracy:   0.556
02/04/2018 01:31:18 [INFO] exp_shallowmodel: f1_score:   0.383
02/04/2018 01:31:18 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.46      0.67      0.54       169
          F       0.65      0.70      0.68       281
          R       0.42      0.15      0.22       122

avg / total       0.54      0.56      0.52       592

02/04/2018 01:31:18 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:18 [INFO] exp_shallowmodel: 
[[  1   5   8   6]
 [  0 113  47   9]
 [  0  74 197  10]
 [  1  54  49  18]]
02/04/2018 01:31:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
02/04/2018 01:31:18 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:18 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:18 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:18 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:18 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:18 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:22 [INFO] exp_shallowmodel: train time: 4.100s
02/04/2018 01:31:22 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:31:22 [INFO] exp_shallowmodel: accuracy:   0.583
02/04/2018 01:31:22 [INFO] exp_shallowmodel: f1_score:   0.376
02/04/2018 01:31:22 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.73      0.60       169
          F       0.68      0.73      0.70       281
          R       0.39      0.14      0.20       122

avg / total       0.55      0.58      0.55       592

02/04/2018 01:31:22 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:22 [INFO] exp_shallowmodel: 
[[  0   7   7   6]
 [  0 123  37   9]
 [  0  64 205  12]
 [  3  49  53  17]]
02/04/2018 01:31:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
02/04/2018 01:31:22 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:22 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:22 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:22 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:22 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:22 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:26 [INFO] exp_shallowmodel: train time: 3.954s
02/04/2018 01:31:26 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:31:26 [INFO] exp_shallowmodel: accuracy:   0.571
02/04/2018 01:31:26 [INFO] exp_shallowmodel: f1_score:   0.380
02/04/2018 01:31:26 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.48      0.63      0.55       169
          F       0.64      0.74      0.69       281
          R       0.51      0.20      0.28       122

avg / total       0.55      0.57      0.54       592

02/04/2018 01:31:26 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:26 [INFO] exp_shallowmodel: 
[[  0  12   8   0]
 [  0 107  52  10]
 [  1  60 207  13]
 [  1  42  55  24]]
02/04/2018 01:31:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
02/04/2018 01:31:26 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:26 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:26 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:26 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:26 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:26 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:30 [INFO] exp_shallowmodel: train time: 3.254s
02/04/2018 01:31:30 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:31:30 [INFO] exp_shallowmodel: accuracy:   0.552
02/04/2018 01:31:30 [INFO] exp_shallowmodel: f1_score:   0.385
02/04/2018 01:31:30 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.47      0.66      0.55       169
          F       0.65      0.69      0.67       281
          R       0.38      0.17      0.24       122

avg / total       0.53      0.55      0.53       592

02/04/2018 01:31:30 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:30 [INFO] exp_shallowmodel: 
[[  1   3   8   8]
 [  0 112  44  13]
 [  3  71 193  14]
 [  0  51  50  21]]
02/04/2018 01:31:30 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
02/04/2018 01:31:30 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:30 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:30 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:30 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:30 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:30 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:33 [INFO] exp_shallowmodel: train time: 3.251s
02/04/2018 01:31:33 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:31:33 [INFO] exp_shallowmodel: accuracy:   0.552
02/04/2018 01:31:33 [INFO] exp_shallowmodel: f1_score:   0.360
02/04/2018 01:31:33 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.42      0.65      0.51       169
          F       0.69      0.70      0.70       281
          R       0.45      0.16      0.23       122

avg / total       0.54      0.55      0.52       592

02/04/2018 01:31:33 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:33 [INFO] exp_shallowmodel: 
[[  0  11   4   5]
 [  1 110  49   9]
 [  0  74 198   9]
 [  0  69  34  19]]
02/04/2018 01:31:33 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
02/04/2018 01:31:33 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:33 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:33 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:33 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:33 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:33 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:37 [INFO] exp_shallowmodel: train time: 4.168s
02/04/2018 01:31:37 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:31:37 [INFO] exp_shallowmodel: accuracy:   0.554
02/04/2018 01:31:37 [INFO] exp_shallowmodel: f1_score:   0.389
02/04/2018 01:31:37 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.05      0.08        20
          C       0.45      0.64      0.53       169
          F       0.66      0.69      0.68       281
          R       0.43      0.19      0.26       122

avg / total       0.54      0.55      0.53       592

02/04/2018 01:31:37 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:37 [INFO] exp_shallowmodel: 
[[  1   4  10   5]
 [  1 109  45  14]
 [  0  74 195  12]
 [  2  53  44  23]]
02/04/2018 01:31:37 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
02/04/2018 01:31:37 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:37 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:37 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:37 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:37 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:37 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:42 [INFO] exp_shallowmodel: train time: 4.299s
02/04/2018 01:31:42 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:31:42 [INFO] exp_shallowmodel: accuracy:   0.535
02/04/2018 01:31:42 [INFO] exp_shallowmodel: f1_score:   0.347
02/04/2018 01:31:42 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.43      0.65      0.52       169
          F       0.64      0.68      0.66       281
          R       0.48      0.13      0.21       122

avg / total       0.53      0.54      0.50       592

02/04/2018 01:31:42 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:42 [INFO] exp_shallowmodel: 
[[  0   9   9   2]
 [  3 110  48   8]
 [  3  80 191   7]
 [  1  54  51  16]]
02/04/2018 01:31:42 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
02/04/2018 01:31:42 [INFO] exp_shallowmodel: #(data) = 4736
02/04/2018 01:31:42 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:42 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:42 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:42 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:42 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:46 [INFO] exp_shallowmodel: train time: 4.788s
02/04/2018 01:31:46 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:31:46 [INFO] exp_shallowmodel: accuracy:   0.533
02/04/2018 01:31:46 [INFO] exp_shallowmodel: f1_score:   0.361
02/04/2018 01:31:46 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.06        28
          C       0.42      0.53      0.47       172
          F       0.61      0.75      0.67       283
          R       0.54      0.15      0.24       123

avg / total       0.53      0.53      0.50       606

02/04/2018 01:31:46 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:46 [INFO] exp_shallowmodel: 
[[  1   7  15   5]
 [  1  92  75   4]
 [  0  65 211   7]
 [  1  57  46  19]]
02/04/2018 01:31:46 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
02/04/2018 01:31:46 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:46 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:46 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:46 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:46 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:46 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:50 [INFO] exp_shallowmodel: train time: 3.725s
02/04/2018 01:31:50 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:31:50 [INFO] exp_shallowmodel: accuracy:   0.571
02/04/2018 01:31:50 [INFO] exp_shallowmodel: f1_score:   0.386
02/04/2018 01:31:50 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.46      0.69      0.55       169
          F       0.69      0.69      0.69       281
          R       0.46      0.22      0.30       122

avg / total       0.56      0.57      0.55       592

02/04/2018 01:31:50 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:50 [INFO] exp_shallowmodel: 
[[  0   4  10   6]
 [  1 116  40  12]
 [  0  72 195  14]
 [  1  58  36  27]]
02/04/2018 01:31:50 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
02/04/2018 01:31:50 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:50 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:50 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:50 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:50 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:50 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:54 [INFO] exp_shallowmodel: train time: 3.746s
02/04/2018 01:31:54 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:31:54 [INFO] exp_shallowmodel: accuracy:   0.564
02/04/2018 01:31:54 [INFO] exp_shallowmodel: f1_score:   0.387
02/04/2018 01:31:54 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.48      0.69      0.57       169
          F       0.67      0.71      0.69       281
          R       0.33      0.14      0.20       122

avg / total       0.56      0.56      0.53       592

02/04/2018 01:31:54 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:54 [INFO] exp_shallowmodel: 
[[  1   7   5   7]
 [  0 116  43  10]
 [  0  64 200  17]
 [  0  54  51  17]]
02/04/2018 01:31:54 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
02/04/2018 01:31:54 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:54 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:54 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:54 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:54 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:54 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:31:58 [INFO] exp_shallowmodel: train time: 4.416s
02/04/2018 01:31:58 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:31:58 [INFO] exp_shallowmodel: accuracy:   0.579
02/04/2018 01:31:58 [INFO] exp_shallowmodel: f1_score:   0.394
02/04/2018 01:31:58 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:31:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.05      0.08        20
          C       0.45      0.69      0.54       169
          F       0.70      0.74      0.72       281
          R       0.55      0.15      0.23       122

avg / total       0.58      0.58      0.55       592

02/04/2018 01:31:58 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:31:58 [INFO] exp_shallowmodel: 
[[  1  11   7   1]
 [  1 116  43   9]
 [  2  66 208   5]
 [  1  64  39  18]]
02/04/2018 01:31:58 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
02/04/2018 01:31:58 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:31:58 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:31:58 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:31:58 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:31:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:31:58 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:31:58 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:04 [INFO] exp_shallowmodel: train time: 5.049s
02/04/2018 01:32:04 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:32:04 [INFO] exp_shallowmodel: accuracy:   0.591
02/04/2018 01:32:04 [INFO] exp_shallowmodel: f1_score:   0.393
02/04/2018 01:32:04 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.50      0.75      0.60       169
          F       0.68      0.72      0.70       281
          R       0.56      0.18      0.27       122

avg / total       0.58      0.59      0.56       592

02/04/2018 01:32:04 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:04 [INFO] exp_shallowmodel: 
[[  0   4  13   3]
 [  2 127  35   5]
 [  1  70 201   9]
 [  1  54  45  22]]
02/04/2018 01:32:04 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
02/04/2018 01:32:04 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:32:04 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:32:04 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:04 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:04 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:04 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:07 [INFO] exp_shallowmodel: train time: 3.738s
02/04/2018 01:32:07 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:32:07 [INFO] exp_shallowmodel: accuracy:   0.529
02/04/2018 01:32:07 [INFO] exp_shallowmodel: f1_score:   0.351
02/04/2018 01:32:07 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.42      0.63      0.50       169
          F       0.65      0.69      0.67       281
          R       0.31      0.09      0.14       122

avg / total       0.51      0.53      0.49       592

02/04/2018 01:32:07 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:07 [INFO] exp_shallowmodel: 
[[  1   8  10   1]
 [  0 107  49  13]
 [  0  76 194  11]
 [  1  64  46  11]]
02/04/2018 01:32:07 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
02/04/2018 01:32:07 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:32:07 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:32:07 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:07 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:07 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:07 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:11 [INFO] exp_shallowmodel: train time: 3.322s
02/04/2018 01:32:11 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:32:11 [INFO] exp_shallowmodel: accuracy:   0.544
02/04/2018 01:32:11 [INFO] exp_shallowmodel: f1_score:   0.360
02/04/2018 01:32:11 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.45      0.64      0.53       169
          F       0.63      0.68      0.65       281
          R       0.51      0.17      0.26       122

avg / total       0.53      0.54      0.51       592

02/04/2018 01:32:11 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:11 [INFO] exp_shallowmodel: 
[[  0   6  13   1]
 [  1 109  51   8]
 [  0  78 192  11]
 [  1  50  50  21]]
02/04/2018 01:32:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
02/04/2018 01:32:11 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:32:11 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:32:11 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:11 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:11 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:11 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:15 [INFO] exp_shallowmodel: train time: 4.091s
02/04/2018 01:32:15 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:32:15 [INFO] exp_shallowmodel: accuracy:   0.573
02/04/2018 01:32:15 [INFO] exp_shallowmodel: f1_score:   0.409
02/04/2018 01:32:15 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.05      0.09        20
          C       0.45      0.70      0.55       169
          F       0.69      0.69      0.69       281
          R       0.53      0.21      0.30       122

avg / total       0.58      0.57      0.55       592

02/04/2018 01:32:15 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:15 [INFO] exp_shallowmodel: 
[[  1   6  10   3]
 [  0 118  39  12]
 [  1  78 194   8]
 [  0  59  37  26]]
02/04/2018 01:32:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
02/04/2018 01:32:15 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:32:15 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:32:15 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:15 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:15 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:15 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:19 [INFO] exp_shallowmodel: train time: 4.329s
02/04/2018 01:32:19 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:32:19 [INFO] exp_shallowmodel: accuracy:   0.557
02/04/2018 01:32:19 [INFO] exp_shallowmodel: f1_score:   0.375
02/04/2018 01:32:19 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.46      0.72      0.56       169
          F       0.67      0.69      0.68       281
          R       0.33      0.11      0.16       122

avg / total       0.55      0.56      0.52       592

02/04/2018 01:32:19 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:19 [INFO] exp_shallowmodel: 
[[  1   7   9   3]
 [  0 121  39   9]
 [  0  72 195  14]
 [  0  62  47  13]]
02/04/2018 01:32:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
02/04/2018 01:32:19 [INFO] exp_shallowmodel: #(data) = 4750
02/04/2018 01:32:19 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:32:19 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:19 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:19 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:19 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:23 [INFO] exp_shallowmodel: train time: 3.410s
02/04/2018 01:32:23 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:32:23 [INFO] exp_shallowmodel: accuracy:   0.551
02/04/2018 01:32:23 [INFO] exp_shallowmodel: f1_score:   0.366
02/04/2018 01:32:23 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.43      0.66      0.52       169
          F       0.68      0.68      0.68       281
          R       0.49      0.18      0.26       122

avg / total       0.54      0.55      0.53       592

02/04/2018 01:32:23 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:23 [INFO] exp_shallowmodel: 
[[  0  10   6   4]
 [  1 112  46  10]
 [  0  80 192   9]
 [  0  60  40  22]]
02/04/2018 01:32:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
02/04/2018 01:32:23 [INFO] exp_shallowmodel: #(data) = 4736
02/04/2018 01:32:23 [INFO] exp_shallowmodel: #(feature) = 395
02/04/2018 01:32:23 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:23 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:23 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:23 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:26 [INFO] exp_shallowmodel: train time: 3.578s
02/04/2018 01:32:26 [INFO] exp_shallowmodel: test time:  0.000s
02/04/2018 01:32:26 [INFO] exp_shallowmodel: accuracy:   0.574
02/04/2018 01:32:26 [INFO] exp_shallowmodel: f1_score:   0.397
02/04/2018 01:32:26 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.07        28
          C       0.46      0.74      0.57       172
          F       0.70      0.70      0.70       283
          R       0.48      0.17      0.25       123

avg / total       0.58      0.57      0.54       606

02/04/2018 01:32:26 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:26 [INFO] exp_shallowmodel: 
[[  1  12  10   5]
 [  1 127  36   8]
 [  0  74 199  10]
 [  0  61  41  21]]
02/04/2018 01:32:31 [INFO] exp_shallowmodel: ******************** family - Round 0 
02/04/2018 01:32:31 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:32:31 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:32:31 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:31 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:31 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:31 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:37 [INFO] exp_shallowmodel: train time: 6.308s
02/04/2018 01:32:37 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:32:37 [INFO] exp_shallowmodel: accuracy:   0.741
02/04/2018 01:32:37 [INFO] exp_shallowmodel: f1_score:   0.359
02/04/2018 01:32:37 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.09      0.15        23
          C       0.33      0.04      0.07        27
          F       0.76      0.98      0.85       250
          R       0.58      0.27      0.37        52

avg / total       0.68      0.74      0.68       352

02/04/2018 01:32:37 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:37 [INFO] exp_shallowmodel: 
[[  2   1  16   4]
 [  1   1  24   1]
 [  1   0 244   5]
 [  0   1  37  14]]
02/04/2018 01:32:37 [INFO] exp_shallowmodel: ******************** family - Round 1 
02/04/2018 01:32:37 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:32:37 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:32:37 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:37 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:37 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:37 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:43 [INFO] exp_shallowmodel: train time: 5.496s
02/04/2018 01:32:43 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:32:43 [INFO] exp_shallowmodel: accuracy:   0.730
02/04/2018 01:32:43 [INFO] exp_shallowmodel: f1_score:   0.324
02/04/2018 01:32:43 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.00      0.00      0.00        27
          F       0.75      0.97      0.85       250
          R       0.61      0.27      0.37        52

avg / total       0.64      0.73      0.66       352

02/04/2018 01:32:43 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:43 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  1   0  25   1]
 [  0   2 242   6]
 [  2   2  34  14]]
02/04/2018 01:32:43 [INFO] exp_shallowmodel: ******************** family - Round 2 
02/04/2018 01:32:43 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:32:43 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:32:43 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:43 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:43 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:43 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:46 [INFO] exp_shallowmodel: train time: 3.517s
02/04/2018 01:32:46 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:32:46 [INFO] exp_shallowmodel: accuracy:   0.713
02/04/2018 01:32:46 [INFO] exp_shallowmodel: f1_score:   0.314
02/04/2018 01:32:46 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.09      0.12        23
          C       0.00      0.00      0.00        27
          F       0.75      0.95      0.84       250
          R       0.48      0.21      0.29        52

avg / total       0.62      0.71      0.65       352

02/04/2018 01:32:46 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:46 [INFO] exp_shallowmodel: 
[[  2   0  19   2]
 [  1   0  23   3]
 [  3   2 238   7]
 [  3   0  38  11]]
02/04/2018 01:32:46 [INFO] exp_shallowmodel: ******************** family - Round 3 
02/04/2018 01:32:46 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:32:46 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:32:46 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:46 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:46 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:46 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:32:58 [INFO] exp_shallowmodel: train time: 11.990s
02/04/2018 01:32:58 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:32:58 [INFO] exp_shallowmodel: accuracy:   0.707
02/04/2018 01:32:58 [INFO] exp_shallowmodel: f1_score:   0.292
02/04/2018 01:32:58 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:32:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.50      0.04      0.07        27
          F       0.74      0.96      0.84       250
          R       0.32      0.13      0.19        52

avg / total       0.63      0.71      0.63       352

02/04/2018 01:32:58 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:32:58 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   1  22   4]
 [  1   0 240   9]
 [  3   1  41   7]]
02/04/2018 01:32:59 [INFO] exp_shallowmodel: ******************** family - Round 4 
02/04/2018 01:32:59 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:32:59 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:32:59 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:32:59 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:32:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:32:59 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:32:59 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:02 [INFO] exp_shallowmodel: train time: 3.478s
02/04/2018 01:33:02 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:02 [INFO] exp_shallowmodel: accuracy:   0.716
02/04/2018 01:33:02 [INFO] exp_shallowmodel: f1_score:   0.296
02/04/2018 01:33:02 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.25      0.04      0.06        27
          F       0.74      0.97      0.84       250
          R       0.44      0.13      0.21        52

avg / total       0.63      0.72      0.64       352

02/04/2018 01:33:02 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:02 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   1  22   4]
 [  2   3 243   2]
 [  1   0  44   7]]
02/04/2018 01:33:02 [INFO] exp_shallowmodel: ******************** family - Round 5 
02/04/2018 01:33:02 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:02 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:02 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:02 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:02 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:02 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:07 [INFO] exp_shallowmodel: train time: 5.236s
02/04/2018 01:33:07 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:07 [INFO] exp_shallowmodel: accuracy:   0.736
02/04/2018 01:33:07 [INFO] exp_shallowmodel: f1_score:   0.315
02/04/2018 01:33:07 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       1.00      0.04      0.07        27
          F       0.76      0.98      0.86       250
          R       0.50      0.25      0.33        52

avg / total       0.69      0.74      0.66       352

02/04/2018 01:33:07 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:07 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  1   1  19   6]
 [  1   0 245   4]
 [  0   0  39  13]]
02/04/2018 01:33:07 [INFO] exp_shallowmodel: ******************** family - Round 6 
02/04/2018 01:33:07 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:07 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:07 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:07 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:07 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:07 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:13 [INFO] exp_shallowmodel: train time: 5.787s
02/04/2018 01:33:13 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:13 [INFO] exp_shallowmodel: accuracy:   0.733
02/04/2018 01:33:13 [INFO] exp_shallowmodel: f1_score:   0.330
02/04/2018 01:33:13 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.20      0.04      0.06        27
          F       0.76      0.98      0.85       250
          R       0.60      0.23      0.33        52

avg / total       0.66      0.73      0.66       352

02/04/2018 01:33:13 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:13 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  1   1  20   5]
 [  2   3 244   1]
 [  1   1  38  12]]
02/04/2018 01:33:13 [INFO] exp_shallowmodel: ******************** family - Round 7 
02/04/2018 01:33:13 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:13 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:13 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:13 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:13 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:13 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:19 [INFO] exp_shallowmodel: train time: 5.888s
02/04/2018 01:33:19 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:19 [INFO] exp_shallowmodel: accuracy:   0.724
02/04/2018 01:33:19 [INFO] exp_shallowmodel: f1_score:   0.325
02/04/2018 01:33:19 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.13      0.21        23
          C       0.00      0.00      0.00        27
          F       0.75      0.97      0.85       250
          R       0.39      0.17      0.24        52

avg / total       0.63      0.72      0.65       352

02/04/2018 01:33:19 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:19 [INFO] exp_shallowmodel: 
[[  3   0  19   1]
 [  0   0  20   7]
 [  1   0 243   6]
 [  1   0  42   9]]
02/04/2018 01:33:19 [INFO] exp_shallowmodel: ******************** family - Round 8 
02/04/2018 01:33:19 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:19 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:19 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:19 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:19 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:19 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:24 [INFO] exp_shallowmodel: train time: 4.873s
02/04/2018 01:33:24 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:24 [INFO] exp_shallowmodel: accuracy:   0.719
02/04/2018 01:33:24 [INFO] exp_shallowmodel: f1_score:   0.292
02/04/2018 01:33:24 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.76      0.96      0.85       250
          R       0.45      0.25      0.32        52

avg / total       0.60      0.72      0.65       352

02/04/2018 01:33:24 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:24 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   0  23   4]
 [  1   0 240   9]
 [  2   3  34  13]]
02/04/2018 01:33:24 [INFO] exp_shallowmodel: ******************** family - Round 9 
02/04/2018 01:33:24 [INFO] exp_shallowmodel: #(data) = 2816
02/04/2018 01:33:24 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:24 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:24 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:24 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:24 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:29 [INFO] exp_shallowmodel: train time: 4.391s
02/04/2018 01:33:29 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:29 [INFO] exp_shallowmodel: accuracy:   0.696
02/04/2018 01:33:29 [INFO] exp_shallowmodel: f1_score:   0.270
02/04/2018 01:33:29 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        25
          C       0.00      0.00      0.00        27
          F       0.72      0.97      0.83       251
          R       0.41      0.12      0.18        59

avg / total       0.58      0.70      0.61       362

02/04/2018 01:33:29 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:29 [INFO] exp_shallowmodel: 
[[  1   0  22   2]
 [  0   0  24   3]
 [  2   0 244   5]
 [  1   1  50   7]]
02/04/2018 01:33:29 [INFO] exp_shallowmodel: ******************** family - Round 10 
02/04/2018 01:33:29 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:29 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:29 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:29 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:29 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:29 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:33 [INFO] exp_shallowmodel: train time: 4.157s
02/04/2018 01:33:33 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:33 [INFO] exp_shallowmodel: accuracy:   0.727
02/04/2018 01:33:33 [INFO] exp_shallowmodel: f1_score:   0.340
02/04/2018 01:33:33 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.33      0.04      0.07        27
          F       0.75      0.96      0.84       250
          R       0.54      0.29      0.37        52

avg / total       0.66      0.73      0.66       352

02/04/2018 01:33:33 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:33 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   1  21   5]
 [  2   1 239   8]
 [  0   1  36  15]]
02/04/2018 01:33:33 [INFO] exp_shallowmodel: ******************** family - Round 11 
02/04/2018 01:33:33 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:33 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:33 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:33 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:33 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:33 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:37 [INFO] exp_shallowmodel: train time: 3.535s
02/04/2018 01:33:37 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:37 [INFO] exp_shallowmodel: accuracy:   0.710
02/04/2018 01:33:37 [INFO] exp_shallowmodel: f1_score:   0.284
02/04/2018 01:33:37 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.73      0.96      0.83       250
          R       0.42      0.15      0.23        52

avg / total       0.60      0.71      0.63       352

02/04/2018 01:33:37 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:37 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  1   0  22   4]
 [  1   1 241   7]
 [  0   0  44   8]]
02/04/2018 01:33:37 [INFO] exp_shallowmodel: ******************** family - Round 12 
02/04/2018 01:33:37 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:37 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:37 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:37 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:37 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:37 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:41 [INFO] exp_shallowmodel: train time: 4.016s
02/04/2018 01:33:41 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:41 [INFO] exp_shallowmodel: accuracy:   0.724
02/04/2018 01:33:41 [INFO] exp_shallowmodel: f1_score:   0.307
02/04/2018 01:33:41 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.07      0.11        27
          F       0.75      0.98      0.85       250
          R       0.56      0.17      0.26        52

avg / total       0.64      0.72      0.65       352

02/04/2018 01:33:41 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:41 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  1   2  22   2]
 [  2   1 244   3]
 [  1   5  37   9]]
02/04/2018 01:33:41 [INFO] exp_shallowmodel: ******************** family - Round 13 
02/04/2018 01:33:41 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:41 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:41 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:41 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:41 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:41 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:50 [INFO] exp_shallowmodel: train time: 9.137s
02/04/2018 01:33:50 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:50 [INFO] exp_shallowmodel: accuracy:   0.716
02/04/2018 01:33:50 [INFO] exp_shallowmodel: f1_score:   0.319
02/04/2018 01:33:50 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.09      0.15        23
          C       0.14      0.04      0.06        27
          F       0.75      0.96      0.84       250
          R       0.38      0.15      0.22        52

avg / total       0.64      0.72      0.65       352

02/04/2018 01:33:50 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:50 [INFO] exp_shallowmodel: 
[[  2   1  17   3]
 [  0   1  22   4]
 [  0   3 241   6]
 [  1   2  41   8]]
02/04/2018 01:33:50 [INFO] exp_shallowmodel: ******************** family - Round 14 
02/04/2018 01:33:50 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:50 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:50 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:50 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:50 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:50 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:54 [INFO] exp_shallowmodel: train time: 3.557s
02/04/2018 01:33:54 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:54 [INFO] exp_shallowmodel: accuracy:   0.719
02/04/2018 01:33:54 [INFO] exp_shallowmodel: f1_score:   0.291
02/04/2018 01:33:54 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.20      0.04      0.06        27
          F       0.75      0.97      0.85       250
          R       0.47      0.17      0.25        52

avg / total       0.62      0.72      0.64       352

02/04/2018 01:33:54 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:54 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   1  21   5]
 [  2   1 243   4]
 [  3   3  37   9]]
02/04/2018 01:33:54 [INFO] exp_shallowmodel: ******************** family - Round 15 
02/04/2018 01:33:54 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:54 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:54 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:54 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:54 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:54 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:33:58 [INFO] exp_shallowmodel: train time: 3.996s
02/04/2018 01:33:58 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:33:58 [INFO] exp_shallowmodel: accuracy:   0.716
02/04/2018 01:33:58 [INFO] exp_shallowmodel: f1_score:   0.293
02/04/2018 01:33:58 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:33:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.04      0.07        23
          C       0.00      0.00      0.00        27
          F       0.75      0.97      0.85       250
          R       0.47      0.17      0.25        52

avg / total       0.62      0.72      0.64       352

02/04/2018 01:33:58 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:33:58 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   0  25   2]
 [  1   2 242   5]
 [  3   3  37   9]]
02/04/2018 01:33:58 [INFO] exp_shallowmodel: ******************** family - Round 16 
02/04/2018 01:33:58 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:33:58 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:33:58 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:33:58 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:33:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:33:58 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:33:58 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:34:04 [INFO] exp_shallowmodel: train time: 5.772s
02/04/2018 01:34:04 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:34:04 [INFO] exp_shallowmodel: accuracy:   0.722
02/04/2018 01:34:04 [INFO] exp_shallowmodel: f1_score:   0.318
02/04/2018 01:34:04 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:34:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       1.00      0.04      0.07        27
          F       0.75      0.95      0.84       250
          R       0.48      0.29      0.36        52

avg / total       0.68      0.72      0.66       352

02/04/2018 01:34:04 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:34:04 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   1  23   3]
 [  2   0 238  10]
 [  2   0  35  15]]
02/04/2018 01:34:04 [INFO] exp_shallowmodel: ******************** family - Round 17 
02/04/2018 01:34:04 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:34:04 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:34:04 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:34:04 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:34:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:34:04 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:34:04 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:34:14 [INFO] exp_shallowmodel: train time: 10.016s
02/04/2018 01:34:14 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:34:14 [INFO] exp_shallowmodel: accuracy:   0.724
02/04/2018 01:34:14 [INFO] exp_shallowmodel: f1_score:   0.309
02/04/2018 01:34:14 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:34:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.00      0.00      0.00        27
          F       0.74      0.97      0.84       250
          R       0.52      0.23      0.32        52

avg / total       0.62      0.72      0.65       352

02/04/2018 01:34:14 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:34:14 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  2   0  23   2]
 [  1   0 242   7]
 [  0   0  40  12]]
02/04/2018 01:34:14 [INFO] exp_shallowmodel: ******************** family - Round 18 
02/04/2018 01:34:14 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:34:14 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:34:14 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:34:14 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:34:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:34:14 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:34:14 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:34:18 [INFO] exp_shallowmodel: train time: 4.017s
02/04/2018 01:34:18 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:34:18 [INFO] exp_shallowmodel: accuracy:   0.722
02/04/2018 01:34:18 [INFO] exp_shallowmodel: f1_score:   0.283
02/04/2018 01:34:18 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:34:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.04      0.07        27
          F       0.75      0.98      0.85       250
          R       0.38      0.15      0.22        52

avg / total       0.61      0.72      0.64       352

02/04/2018 01:34:18 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:34:18 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  0   1  20   6]
 [  0   1 245   4]
 [  0   0  44   8]]
02/04/2018 01:34:18 [INFO] exp_shallowmodel: ******************** family - Round 19 
02/04/2018 01:34:18 [INFO] exp_shallowmodel: #(data) = 2816
02/04/2018 01:34:18 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:34:18 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:34:18 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:34:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:34:18 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:34:18 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:34:22 [INFO] exp_shallowmodel: train time: 4.152s
02/04/2018 01:34:22 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:34:22 [INFO] exp_shallowmodel: accuracy:   0.707
02/04/2018 01:34:22 [INFO] exp_shallowmodel: f1_score:   0.295
02/04/2018 01:34:22 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:34:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        25
          C       0.00      0.00      0.00        27
          F       0.73      0.97      0.84       251
          R       0.52      0.19      0.27        59

avg / total       0.61      0.71      0.63       362

02/04/2018 01:34:22 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:34:22 [INFO] exp_shallowmodel: 
[[  1   0  21   3]
 [  0   0  24   3]
 [  0   3 244   4]
 [  3   1  44  11]]
02/04/2018 01:34:22 [INFO] exp_shallowmodel: ******************** family - Round 20 
02/04/2018 01:34:22 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:34:22 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:34:22 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:34:22 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:34:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:34:22 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:34:22 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:34:27 [INFO] exp_shallowmodel: train time: 4.504s
02/04/2018 01:34:27 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:34:27 [INFO] exp_shallowmodel: accuracy:   0.730
02/04/2018 01:34:27 [INFO] exp_shallowmodel: f1_score:   0.337
02/04/2018 01:34:27 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:34:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.22      0.07      0.11        27
          F       0.76      0.96      0.85       250
          R       0.70      0.27      0.39        52

avg / total       0.66      0.73      0.67       352

02/04/2018 01:34:27 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:34:27 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  1   2  22   2]
 [  1   4 241   4]
 [  2   3  33  14]]
02/04/2018 01:34:27 [INFO] exp_shallowmodel: ******************** family - Round 21 
02/04/2018 01:34:27 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:34:27 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:34:27 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:34:27 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:34:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:34:27 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:34:27 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:34:36 [INFO] exp_shallowmodel: train time: 8.747s
02/04/2018 01:34:36 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:34:36 [INFO] exp_shallowmodel: accuracy:   0.722
02/04/2018 01:34:36 [INFO] exp_shallowmodel: f1_score:   0.296
02/04/2018 01:34:36 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:34:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.73      0.98      0.84       250
          R       0.56      0.17      0.26        52

avg / total       0.64      0.72      0.64       352

02/04/2018 01:34:36 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:34:36 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   0  24   3]
 [  0   2 244   4]
 [  1   0  42   9]]
02/04/2018 01:34:36 [INFO] exp_shallowmodel: ******************** family - Round 22 
02/04/2018 01:34:36 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:34:36 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:34:36 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:34:36 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:34:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:34:36 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:34:36 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:34:41 [INFO] exp_shallowmodel: train time: 5.473s
02/04/2018 01:34:41 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:34:41 [INFO] exp_shallowmodel: accuracy:   0.741
02/04/2018 01:34:41 [INFO] exp_shallowmodel: f1_score:   0.350
02/04/2018 01:34:41 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:34:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.25      0.04      0.06        27
          F       0.76      0.97      0.86       250
          R       0.57      0.31      0.40        52

avg / total       0.68      0.74      0.68       352

02/04/2018 01:34:41 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:34:41 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   1  22   4]
 [  0   1 243   6]
 [  1   1  34  16]]
02/04/2018 01:34:42 [INFO] exp_shallowmodel: ******************** family - Round 23 
02/04/2018 01:34:42 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:34:42 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:34:42 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:34:42 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:34:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:34:42 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:34:42 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:34:46 [INFO] exp_shallowmodel: train time: 4.943s
02/04/2018 01:34:46 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:34:46 [INFO] exp_shallowmodel: accuracy:   0.707
02/04/2018 01:34:46 [INFO] exp_shallowmodel: f1_score:   0.268
02/04/2018 01:34:46 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:34:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.74      0.96      0.83       250
          R       0.39      0.17      0.24        52

avg / total       0.58      0.71      0.63       352

02/04/2018 01:34:46 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:34:46 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   0  23   4]
 [  1   0 240   9]
 [  1   1  41   9]]
02/04/2018 01:34:47 [INFO] exp_shallowmodel: ******************** family - Round 24 
02/04/2018 01:34:47 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:34:47 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:34:47 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:34:47 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:34:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:34:47 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:34:47 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:34:50 [INFO] exp_shallowmodel: train time: 3.573s
02/04/2018 01:34:50 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:34:50 [INFO] exp_shallowmodel: accuracy:   0.716
02/04/2018 01:34:50 [INFO] exp_shallowmodel: f1_score:   0.326
02/04/2018 01:34:50 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:34:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.33      0.04      0.07        27
          F       0.76      0.94      0.84       250
          R       0.40      0.27      0.32        52

avg / total       0.64      0.72      0.66       352

02/04/2018 01:34:50 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:34:50 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   1  19   7]
 [  2   0 236  12]
 [  1   2  35  14]]
02/04/2018 01:34:50 [INFO] exp_shallowmodel: ******************** family - Round 25 
02/04/2018 01:34:50 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:34:50 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:34:50 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:34:50 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:34:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:34:50 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:34:50 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:34:54 [INFO] exp_shallowmodel: train time: 3.254s
02/04/2018 01:34:54 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:34:54 [INFO] exp_shallowmodel: accuracy:   0.727
02/04/2018 01:34:54 [INFO] exp_shallowmodel: f1_score:   0.317
02/04/2018 01:34:54 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:34:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.75      0.97      0.84       250
          R       0.57      0.25      0.35        52

avg / total       0.65      0.73      0.66       352

02/04/2018 01:34:54 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:34:54 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   0  24   3]
 [  0   2 242   6]
 [  1   1  37  13]]
02/04/2018 01:34:54 [INFO] exp_shallowmodel: ******************** family - Round 26 
02/04/2018 01:34:54 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:34:54 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:34:54 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:34:54 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:34:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:34:54 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:34:54 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:35:01 [INFO] exp_shallowmodel: train time: 7.161s
02/04/2018 01:35:01 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:35:01 [INFO] exp_shallowmodel: accuracy:   0.702
02/04/2018 01:35:01 [INFO] exp_shallowmodel: f1_score:   0.274
02/04/2018 01:35:01 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:35:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.75      0.95      0.83       250
          R       0.40      0.19      0.26        52

avg / total       0.59      0.70      0.63       352

02/04/2018 01:35:01 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:35:01 [INFO] exp_shallowmodel: 
[[  0   1  20   2]
 [  0   0  23   4]
 [  3   1 237   9]
 [  2   2  38  10]]
02/04/2018 01:35:01 [INFO] exp_shallowmodel: ******************** family - Round 27 
02/04/2018 01:35:01 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:35:01 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:35:01 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:35:01 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:35:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:35:01 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:35:01 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:35:05 [INFO] exp_shallowmodel: train time: 4.375s
02/04/2018 01:35:05 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:35:05 [INFO] exp_shallowmodel: accuracy:   0.713
02/04/2018 01:35:05 [INFO] exp_shallowmodel: f1_score:   0.260
02/04/2018 01:35:05 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:35:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.74      0.98      0.84       250
          R       0.39      0.13      0.20        52

avg / total       0.58      0.71      0.63       352

02/04/2018 01:35:05 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:35:05 [INFO] exp_shallowmodel: 
[[  0   1  19   3]
 [  0   0  23   4]
 [  2   0 244   4]
 [  0   0  45   7]]
02/04/2018 01:35:05 [INFO] exp_shallowmodel: ******************** family - Round 28 
02/04/2018 01:35:05 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:35:05 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:35:05 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:35:05 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:35:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:35:05 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:35:05 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:35:17 [INFO] exp_shallowmodel: train time: 11.711s
02/04/2018 01:35:17 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:35:17 [INFO] exp_shallowmodel: accuracy:   0.699
02/04/2018 01:35:17 [INFO] exp_shallowmodel: f1_score:   0.250
02/04/2018 01:35:17 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:35:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.74      0.96      0.84       250
          R       0.27      0.12      0.16        52

avg / total       0.57      0.70      0.62       352

02/04/2018 01:35:17 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:35:17 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  2   0  19   6]
 [  2   2 240   6]
 [  1   0  45   6]]
02/04/2018 01:35:17 [INFO] exp_shallowmodel: ******************** family - Round 29 
02/04/2018 01:35:17 [INFO] exp_shallowmodel: #(data) = 2816
02/04/2018 01:35:17 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:35:17 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:35:17 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:35:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:35:17 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:35:17 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:35:29 [INFO] exp_shallowmodel: train time: 11.398s
02/04/2018 01:35:29 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:35:29 [INFO] exp_shallowmodel: accuracy:   0.724
02/04/2018 01:35:29 [INFO] exp_shallowmodel: f1_score:   0.366
02/04/2018 01:35:29 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:35:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.16      0.26        25
          C       0.33      0.04      0.07        27
          F       0.74      0.98      0.84       251
          R       0.55      0.20      0.30        59

avg / total       0.67      0.72      0.65       362

02/04/2018 01:35:29 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:35:29 [INFO] exp_shallowmodel: 
[[  4   0  19   2]
 [  0   1  22   4]
 [  1   1 245   4]
 [  1   1  45  12]]
02/04/2018 01:35:29 [INFO] exp_shallowmodel: ******************** family - Round 30 
02/04/2018 01:35:29 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:35:29 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:35:29 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:35:29 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:35:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:35:29 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:35:29 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:35:33 [INFO] exp_shallowmodel: train time: 4.173s
02/04/2018 01:35:33 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:35:33 [INFO] exp_shallowmodel: accuracy:   0.705
02/04/2018 01:35:33 [INFO] exp_shallowmodel: f1_score:   0.285
02/04/2018 01:35:33 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:35:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.10      0.04      0.05        27
          F       0.75      0.95      0.84       250
          R       0.41      0.17      0.24        52

avg / total       0.60      0.70      0.64       352

02/04/2018 01:35:33 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:35:33 [INFO] exp_shallowmodel: 
[[  0   1  21   1]
 [  1   1  21   4]
 [  1   3 238   8]
 [  2   5  36   9]]
02/04/2018 01:35:33 [INFO] exp_shallowmodel: ******************** family - Round 31 
02/04/2018 01:35:33 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:35:33 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:35:33 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:35:33 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:35:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:35:33 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:35:33 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:35:38 [INFO] exp_shallowmodel: train time: 4.904s
02/04/2018 01:35:38 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:35:38 [INFO] exp_shallowmodel: accuracy:   0.736
02/04/2018 01:35:38 [INFO] exp_shallowmodel: f1_score:   0.312
02/04/2018 01:35:38 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:35:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.76      0.97      0.85       250
          R       0.55      0.31      0.40        52

avg / total       0.62      0.74      0.66       352

02/04/2018 01:35:38 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:35:38 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  0   0  22   5]
 [  1   2 243   4]
 [  0   0  36  16]]
02/04/2018 01:35:38 [INFO] exp_shallowmodel: ******************** family - Round 32 
02/04/2018 01:35:38 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:35:38 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:35:38 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:35:38 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:35:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:35:38 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:35:38 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:35:42 [INFO] exp_shallowmodel: train time: 4.025s
02/04/2018 01:35:42 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:35:42 [INFO] exp_shallowmodel: accuracy:   0.739
02/04/2018 01:35:42 [INFO] exp_shallowmodel: f1_score:   0.336
02/04/2018 01:35:42 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:35:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.76      0.97      0.85       250
          R       0.57      0.33      0.41        52

avg / total       0.65      0.74      0.67       352

02/04/2018 01:35:42 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:35:42 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   0  22   5]
 [  0   1 242   7]
 [  2   1  32  17]]
02/04/2018 01:35:42 [INFO] exp_shallowmodel: ******************** family - Round 33 
02/04/2018 01:35:42 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:35:42 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:35:42 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:35:42 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:35:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:35:42 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:35:42 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:35:47 [INFO] exp_shallowmodel: train time: 4.699s
02/04/2018 01:35:47 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:35:47 [INFO] exp_shallowmodel: accuracy:   0.696
02/04/2018 01:35:47 [INFO] exp_shallowmodel: f1_score:   0.242
02/04/2018 01:35:47 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:35:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.73      0.96      0.83       250
          R       0.26      0.10      0.14        52

avg / total       0.56      0.70      0.61       352

02/04/2018 01:35:47 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:35:47 [INFO] exp_shallowmodel: 
[[  0   0  19   4]
 [  0   0  25   2]
 [  1   1 240   8]
 [  1   0  46   5]]
02/04/2018 01:35:47 [INFO] exp_shallowmodel: ******************** family - Round 34 
02/04/2018 01:35:47 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:35:47 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:35:47 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:35:47 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:35:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:35:47 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:35:47 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:35:52 [INFO] exp_shallowmodel: train time: 4.649s
02/04/2018 01:35:52 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:35:52 [INFO] exp_shallowmodel: accuracy:   0.722
02/04/2018 01:35:52 [INFO] exp_shallowmodel: f1_score:   0.292
02/04/2018 01:35:52 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:35:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.04      0.07        27
          F       0.74      0.98      0.84       250
          R       0.50      0.17      0.26        52

avg / total       0.64      0.72      0.64       352

02/04/2018 01:35:52 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:35:52 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   1  23   3]
 [  1   1 244   4]
 [  0   0  43   9]]
02/04/2018 01:35:52 [INFO] exp_shallowmodel: ******************** family - Round 35 
02/04/2018 01:35:52 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:35:52 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:35:52 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:35:52 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:35:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:35:52 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:35:52 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:35:57 [INFO] exp_shallowmodel: train time: 5.383s
02/04/2018 01:35:57 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:35:57 [INFO] exp_shallowmodel: accuracy:   0.722
02/04/2018 01:35:57 [INFO] exp_shallowmodel: f1_score:   0.314
02/04/2018 01:35:57 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:35:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.13      0.21        23
          C       0.00      0.00      0.00        27
          F       0.74      0.98      0.84       250
          R       0.47      0.13      0.21        52

avg / total       0.63      0.72      0.64       352

02/04/2018 01:35:57 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:35:57 [INFO] exp_shallowmodel: 
[[  3   0  20   0]
 [  1   0  22   4]
 [  1   1 244   4]
 [  1   0  44   7]]
02/04/2018 01:35:57 [INFO] exp_shallowmodel: ******************** family - Round 36 
02/04/2018 01:35:57 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:35:57 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:35:57 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:35:57 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:35:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:35:57 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:35:57 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:36:03 [INFO] exp_shallowmodel: train time: 5.754s
02/04/2018 01:36:03 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:36:03 [INFO] exp_shallowmodel: accuracy:   0.713
02/04/2018 01:36:03 [INFO] exp_shallowmodel: f1_score:   0.290
02/04/2018 01:36:03 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:36:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.74      0.96      0.84       250
          R       0.41      0.17      0.24        52

avg / total       0.65      0.71      0.63       352

02/04/2018 01:36:03 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:36:03 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   0  23   4]
 [  0   0 241   9]
 [  0   2  41   9]]
02/04/2018 01:36:03 [INFO] exp_shallowmodel: ******************** family - Round 37 
02/04/2018 01:36:03 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:36:03 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:36:03 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:36:03 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:36:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:36:03 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:36:03 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:36:08 [INFO] exp_shallowmodel: train time: 4.365s
02/04/2018 01:36:08 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:36:08 [INFO] exp_shallowmodel: accuracy:   0.727
02/04/2018 01:36:08 [INFO] exp_shallowmodel: f1_score:   0.331
02/04/2018 01:36:08 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:36:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.09      0.16        23
          C       0.20      0.04      0.06        27
          F       0.75      0.98      0.85       250
          R       0.47      0.17      0.25        52

avg / total       0.68      0.73      0.65       352

02/04/2018 01:36:08 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:36:08 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   1  21   5]
 [  0   2 244   4]
 [  0   2  41   9]]
02/04/2018 01:36:08 [INFO] exp_shallowmodel: ******************** family - Round 38 
02/04/2018 01:36:08 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:36:08 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:36:08 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:36:08 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:36:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:36:08 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:36:08 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:36:18 [INFO] exp_shallowmodel: train time: 10.663s
02/04/2018 01:36:18 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:36:18 [INFO] exp_shallowmodel: accuracy:   0.707
02/04/2018 01:36:18 [INFO] exp_shallowmodel: f1_score:   0.292
02/04/2018 01:36:18 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:36:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.04      0.07        23
          C       0.00      0.00      0.00        27
          F       0.74      0.95      0.84       250
          R       0.42      0.19      0.26        52

avg / total       0.60      0.71      0.64       352

02/04/2018 01:36:18 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:36:18 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   0  25   2]
 [  2   1 238   9]
 [  3   0  39  10]]
02/04/2018 01:36:18 [INFO] exp_shallowmodel: ******************** family - Round 39 
02/04/2018 01:36:18 [INFO] exp_shallowmodel: #(data) = 2816
02/04/2018 01:36:18 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:36:18 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:36:18 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:36:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:36:18 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:36:18 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:36:24 [INFO] exp_shallowmodel: train time: 5.212s
02/04/2018 01:36:24 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:36:24 [INFO] exp_shallowmodel: accuracy:   0.707
02/04/2018 01:36:24 [INFO] exp_shallowmodel: f1_score:   0.289
02/04/2018 01:36:24 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:36:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        25
          C       0.00      0.00      0.00        27
          F       0.72      0.98      0.83       251
          R       0.53      0.17      0.26        59

avg / total       0.61      0.71      0.62       362

02/04/2018 01:36:24 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:36:24 [INFO] exp_shallowmodel: 
[[  1   1  21   2]
 [  1   0  23   3]
 [  2   0 245   4]
 [  0   0  49  10]]
02/04/2018 01:36:24 [INFO] exp_shallowmodel: ******************** family - Round 40 
02/04/2018 01:36:24 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:36:24 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:36:24 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:36:24 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:36:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:36:24 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:36:24 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:36:30 [INFO] exp_shallowmodel: train time: 5.849s
02/04/2018 01:36:30 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:36:30 [INFO] exp_shallowmodel: accuracy:   0.722
02/04/2018 01:36:30 [INFO] exp_shallowmodel: f1_score:   0.294
02/04/2018 01:36:30 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:36:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.75      0.96      0.85       250
          R       0.48      0.25      0.33        52

avg / total       0.61      0.72      0.65       352

02/04/2018 01:36:30 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:36:30 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  1   0  23   3]
 [  0   1 241   8]
 [  2   1  36  13]]
02/04/2018 01:36:30 [INFO] exp_shallowmodel: ******************** family - Round 41 
02/04/2018 01:36:30 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:36:30 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:36:30 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:36:30 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:36:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:36:30 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:36:30 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:36:34 [INFO] exp_shallowmodel: train time: 4.724s
02/04/2018 01:36:34 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:36:34 [INFO] exp_shallowmodel: accuracy:   0.713
02/04/2018 01:36:34 [INFO] exp_shallowmodel: f1_score:   0.266
02/04/2018 01:36:34 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:36:34 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.74      0.97      0.84       250
          R       0.42      0.15      0.23        52

avg / total       0.59      0.71      0.63       352

02/04/2018 01:36:34 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:36:34 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  1   0  23   3]
 [  2   0 243   5]
 [  0   0  44   8]]
02/04/2018 01:36:35 [INFO] exp_shallowmodel: ******************** family - Round 42 
02/04/2018 01:36:35 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:36:35 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:36:35 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:36:35 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:36:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:36:35 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:36:35 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:36:39 [INFO] exp_shallowmodel: train time: 4.502s
02/04/2018 01:36:39 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:36:39 [INFO] exp_shallowmodel: accuracy:   0.741
02/04/2018 01:36:39 [INFO] exp_shallowmodel: f1_score:   0.321
02/04/2018 01:36:39 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:36:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.77      0.99      0.87       250
          R       0.52      0.25      0.34        52

avg / total       0.65      0.74      0.67       352

02/04/2018 01:36:39 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:36:39 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   0  21   6]
 [  0   0 247   3]
 [  2   5  32  13]]
02/04/2018 01:36:39 [INFO] exp_shallowmodel: ******************** family - Round 43 
02/04/2018 01:36:39 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:36:39 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:36:39 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:36:39 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:36:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:36:39 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:36:39 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:36:52 [INFO] exp_shallowmodel: train time: 12.553s
02/04/2018 01:36:52 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:36:52 [INFO] exp_shallowmodel: accuracy:   0.722
02/04/2018 01:36:52 [INFO] exp_shallowmodel: f1_score:   0.312
02/04/2018 01:36:52 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:36:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.75      0.96      0.85       250
          R       0.46      0.25      0.33        52

avg / total       0.63      0.72      0.65       352

02/04/2018 01:36:52 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:36:52 [INFO] exp_shallowmodel: 
[[  1   1  18   3]
 [  0   0  22   5]
 [  2   1 240   7]
 [  0   1  38  13]]
02/04/2018 01:36:52 [INFO] exp_shallowmodel: ******************** family - Round 44 
02/04/2018 01:36:52 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:36:52 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:36:52 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:36:52 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:36:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:36:52 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:36:52 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:36:57 [INFO] exp_shallowmodel: train time: 5.255s
02/04/2018 01:36:57 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:36:57 [INFO] exp_shallowmodel: accuracy:   0.722
02/04/2018 01:36:57 [INFO] exp_shallowmodel: f1_score:   0.300
02/04/2018 01:36:57 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:36:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.04      0.07        23
          C       0.00      0.00      0.00        27
          F       0.75      0.97      0.85       250
          R       0.50      0.19      0.28        52

avg / total       0.62      0.72      0.65       352

02/04/2018 01:36:57 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:36:57 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   0  24   3]
 [  1   1 243   5]
 [  2   2  38  10]]
02/04/2018 01:36:57 [INFO] exp_shallowmodel: ******************** family - Round 45 
02/04/2018 01:36:57 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:36:57 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:36:57 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:36:57 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:36:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:36:57 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:36:57 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:37:06 [INFO] exp_shallowmodel: train time: 8.672s
02/04/2018 01:37:06 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:37:06 [INFO] exp_shallowmodel: accuracy:   0.733
02/04/2018 01:37:06 [INFO] exp_shallowmodel: f1_score:   0.345
02/04/2018 01:37:06 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:37:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.09      0.14        23
          C       0.67      0.07      0.13        27
          F       0.76      0.98      0.85       250
          R       0.47      0.17      0.25        52

avg / total       0.68      0.73      0.66       352

02/04/2018 01:37:06 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:37:06 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  1   2  17   7]
 [  2   1 245   2]
 [  1   0  42   9]]
02/04/2018 01:37:06 [INFO] exp_shallowmodel: ******************** family - Round 46 
02/04/2018 01:37:06 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:37:06 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:37:06 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:37:06 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:37:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:37:06 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:37:06 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:37:11 [INFO] exp_shallowmodel: train time: 4.886s
02/04/2018 01:37:11 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:37:11 [INFO] exp_shallowmodel: accuracy:   0.724
02/04/2018 01:37:11 [INFO] exp_shallowmodel: f1_score:   0.292
02/04/2018 01:37:11 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:37:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.75      0.97      0.85       250
          R       0.55      0.23      0.32        52

avg / total       0.61      0.72      0.65       352

02/04/2018 01:37:11 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:37:11 [INFO] exp_shallowmodel: 
[[  0   1  18   4]
 [  0   0  25   2]
 [  1   2 243   4]
 [  1   0  39  12]]
02/04/2018 01:37:11 [INFO] exp_shallowmodel: ******************** family - Round 47 
02/04/2018 01:37:11 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:37:11 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:37:11 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:37:11 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:37:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:37:11 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:37:11 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:37:19 [INFO] exp_shallowmodel: train time: 8.081s
02/04/2018 01:37:19 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:37:19 [INFO] exp_shallowmodel: accuracy:   0.730
02/04/2018 01:37:19 [INFO] exp_shallowmodel: f1_score:   0.345
02/04/2018 01:37:19 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:37:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.09      0.16        23
          C       0.25      0.04      0.06        27
          F       0.76      0.97      0.85       250
          R       0.46      0.23      0.31        52

avg / total       0.69      0.73      0.66       352

02/04/2018 01:37:19 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:37:19 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   1  19   7]
 [  0   2 242   6]
 [  0   1  39  12]]
02/04/2018 01:37:19 [INFO] exp_shallowmodel: ******************** family - Round 48 
02/04/2018 01:37:19 [INFO] exp_shallowmodel: #(data) = 2826
02/04/2018 01:37:19 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:37:19 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:37:19 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:37:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:37:19 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:37:19 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:37:23 [INFO] exp_shallowmodel: train time: 3.892s
02/04/2018 01:37:23 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:37:23 [INFO] exp_shallowmodel: accuracy:   0.713
02/04/2018 01:37:23 [INFO] exp_shallowmodel: f1_score:   0.338
02/04/2018 01:37:23 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:37:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.09      0.15        23
          C       0.33      0.07      0.12        27
          F       0.74      0.95      0.84       250
          R       0.39      0.17      0.24        52

avg / total       0.66      0.71      0.65       352

02/04/2018 01:37:23 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:37:23 [INFO] exp_shallowmodel: 
[[  2   0  19   2]
 [  0   2  21   4]
 [  1   3 238   8]
 [  0   1  42   9]]
02/04/2018 01:37:23 [INFO] exp_shallowmodel: ******************** family - Round 49 
02/04/2018 01:37:23 [INFO] exp_shallowmodel: #(data) = 2816
02/04/2018 01:37:23 [INFO] exp_shallowmodel: #(feature) = 1214
02/04/2018 01:37:23 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:37:23 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:37:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:37:23 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:37:23 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:37:26 [INFO] exp_shallowmodel: train time: 3.039s
02/04/2018 01:37:26 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:37:26 [INFO] exp_shallowmodel: accuracy:   0.710
02/04/2018 01:37:26 [INFO] exp_shallowmodel: f1_score:   0.289
02/04/2018 01:37:26 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:37:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.00      0.00      0.00        27
          F       0.73      0.97      0.83       251
          R       0.59      0.22      0.32        59

avg / total       0.60      0.71      0.63       362

02/04/2018 01:37:26 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:37:26 [INFO] exp_shallowmodel: 
[[  0   0  24   1]
 [  2   0  22   3]
 [  0   2 244   5]
 [  1   1  44  13]]
02/04/2018 01:37:31 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
02/04/2018 01:37:31 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:37:31 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:37:31 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:37:31 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:37:31 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:37:31 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:37:31 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:37:44 [INFO] exp_shallowmodel: train time: 12.590s
02/04/2018 01:37:44 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:37:44 [INFO] exp_shallowmodel: accuracy:   0.762
02/04/2018 01:37:44 [INFO] exp_shallowmodel: f1_score:   0.295
02/04/2018 01:37:44 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:37:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.54      0.12      0.19        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.29      0.07      0.12        55

avg / total       0.68      0.76      0.69       522

02/04/2018 01:37:44 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:37:44 [INFO] exp_shallowmodel: 
[[  7   0  49   3]
 [  0   0  12   0]
 [  2   0 387   7]
 [  4   0  47   4]]
02/04/2018 01:37:44 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
02/04/2018 01:37:44 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:37:44 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:37:44 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:37:44 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:37:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:37:44 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:37:44 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:37:55 [INFO] exp_shallowmodel: train time: 10.733s
02/04/2018 01:37:55 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:37:55 [INFO] exp_shallowmodel: accuracy:   0.753
02/04/2018 01:37:55 [INFO] exp_shallowmodel: f1_score:   0.287
02/04/2018 01:37:55 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:37:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.14      0.19        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.21      0.05      0.09        55

avg / total       0.66      0.75      0.69       522

02/04/2018 01:37:55 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:37:55 [INFO] exp_shallowmodel: 
[[  8   0  47   4]
 [  2   0   9   1]
 [  7   1 382   6]
 [  7   1  44   3]]
02/04/2018 01:37:55 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
02/04/2018 01:37:55 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:37:55 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:37:55 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:37:55 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:37:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:37:55 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:37:55 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:38:03 [INFO] exp_shallowmodel: train time: 8.326s
02/04/2018 01:38:03 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:38:03 [INFO] exp_shallowmodel: accuracy:   0.755
02/04/2018 01:38:03 [INFO] exp_shallowmodel: f1_score:   0.317
02/04/2018 01:38:03 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:38:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.07      0.12        59
          C       0.50      0.08      0.14        12
          F       0.77      0.97      0.86       396
          R       0.42      0.09      0.15        55

avg / total       0.69      0.75      0.68       522

02/04/2018 01:38:03 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:38:03 [INFO] exp_shallowmodel: 
[[  4   0  54   1]
 [  0   1  11   0]
 [  5   1 384   6]
 [  1   0  49   5]]
02/04/2018 01:38:04 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
02/04/2018 01:38:04 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:38:04 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:38:04 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:38:04 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:38:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:38:04 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:38:04 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:38:11 [INFO] exp_shallowmodel: train time: 7.854s
02/04/2018 01:38:11 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:38:11 [INFO] exp_shallowmodel: accuracy:   0.761
02/04/2018 01:38:11 [INFO] exp_shallowmodel: f1_score:   0.295
02/04/2018 01:38:11 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:38:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.26      0.08      0.13        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.50      0.11      0.18        55

avg / total       0.68      0.76      0.69       522

02/04/2018 01:38:11 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:38:11 [INFO] exp_shallowmodel: 
[[  5   0  51   3]
 [  0   0  12   0]
 [  6   1 386   3]
 [  8   0  41   6]]
02/04/2018 01:38:12 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
02/04/2018 01:38:12 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:38:12 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:38:12 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:38:12 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:38:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:38:12 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:38:12 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:38:24 [INFO] exp_shallowmodel: train time: 12.663s
02/04/2018 01:38:24 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:38:24 [INFO] exp_shallowmodel: accuracy:   0.753
02/04/2018 01:38:24 [INFO] exp_shallowmodel: f1_score:   0.300
02/04/2018 01:38:24 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:38:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.15      0.22        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.24      0.07      0.11        55

avg / total       0.67      0.75      0.69       522

02/04/2018 01:38:24 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:38:24 [INFO] exp_shallowmodel: 
[[  9   1  45   4]
 [  0   0  10   2]
 [  8   1 380   7]
 [  6   0  45   4]]
02/04/2018 01:38:25 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
02/04/2018 01:38:25 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:38:25 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:38:25 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:38:25 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:38:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:38:25 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:38:25 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:38:41 [INFO] exp_shallowmodel: train time: 16.759s
02/04/2018 01:38:41 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:38:41 [INFO] exp_shallowmodel: accuracy:   0.772
02/04/2018 01:38:41 [INFO] exp_shallowmodel: f1_score:   0.362
02/04/2018 01:38:41 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:38:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.14      0.21        59
          C       0.50      0.08      0.14        12
          F       0.80      0.97      0.88       396
          R       0.50      0.15      0.23        55

avg / total       0.72      0.77      0.71       522

02/04/2018 01:38:41 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:38:41 [INFO] exp_shallowmodel: 
[[  8   1  46   4]
 [  1   1  10   0]
 [  6   0 386   4]
 [  4   0  43   8]]
02/04/2018 01:38:42 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
02/04/2018 01:38:42 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:38:42 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:38:42 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:38:42 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:38:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:38:42 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:38:42 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:38:51 [INFO] exp_shallowmodel: train time: 9.751s
02/04/2018 01:38:51 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:38:51 [INFO] exp_shallowmodel: accuracy:   0.768
02/04/2018 01:38:51 [INFO] exp_shallowmodel: f1_score:   0.360
02/04/2018 01:38:51 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:38:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.58      0.19      0.28        59
          C       0.50      0.08      0.14        12
          F       0.79      0.97      0.87       396
          R       0.36      0.09      0.14        55

avg / total       0.71      0.77      0.71       522

02/04/2018 01:38:51 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:38:51 [INFO] exp_shallowmodel: 
[[ 11   0  44   4]
 [  0   1  11   0]
 [  7   0 384   5]
 [  1   1  48   5]]
02/04/2018 01:38:51 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
02/04/2018 01:38:51 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:38:51 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:38:51 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:38:51 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:38:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:38:51 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:38:51 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:39:06 [INFO] exp_shallowmodel: train time: 14.126s
02/04/2018 01:39:06 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:39:06 [INFO] exp_shallowmodel: accuracy:   0.768
02/04/2018 01:39:06 [INFO] exp_shallowmodel: f1_score:   0.321
02/04/2018 01:39:06 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:39:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.14      0.20        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.70      0.13      0.22        55

avg / total       0.71      0.77      0.71       522

02/04/2018 01:39:06 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:39:06 [INFO] exp_shallowmodel: 
[[  8   0  50   1]
 [  1   0  10   1]
 [  7   2 386   1]
 [  7   0  41   7]]
02/04/2018 01:39:06 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
02/04/2018 01:39:06 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:39:06 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:39:06 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:39:06 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:39:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:39:06 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:39:06 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:39:16 [INFO] exp_shallowmodel: train time: 10.399s
02/04/2018 01:39:16 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:39:16 [INFO] exp_shallowmodel: accuracy:   0.751
02/04/2018 01:39:16 [INFO] exp_shallowmodel: f1_score:   0.291
02/04/2018 01:39:16 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:39:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.05      0.08        59
          C       1.00      0.08      0.15        12
          F       0.78      0.97      0.86       396
          R       0.20      0.04      0.06        55

avg / total       0.66      0.75      0.67       522

02/04/2018 01:39:16 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:39:16 [INFO] exp_shallowmodel: 
[[  3   0  53   3]
 [  0   1  11   0]
 [  5   0 386   5]
 [  5   0  48   2]]
02/04/2018 01:39:16 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
02/04/2018 01:39:16 [INFO] exp_shallowmodel: #(data) = 4176
02/04/2018 01:39:16 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:39:16 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:39:16 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:39:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:39:16 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:39:16 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:39:31 [INFO] exp_shallowmodel: train time: 14.885s
02/04/2018 01:39:31 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:39:31 [INFO] exp_shallowmodel: accuracy:   0.751
02/04/2018 01:39:31 [INFO] exp_shallowmodel: f1_score:   0.315
02/04/2018 01:39:31 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:39:31 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.20      0.29        64
          C       0.00      0.00      0.00        14
          F       0.78      0.97      0.87       402
          R       0.27      0.06      0.10        63

avg / total       0.67      0.75      0.69       543

02/04/2018 01:39:31 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:39:31 [INFO] exp_shallowmodel: 
[[ 13   0  45   6]
 [  1   0  13   0]
 [  5   1 391   5]
 [  7   1  51   4]]
02/04/2018 01:39:32 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
02/04/2018 01:39:32 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:39:32 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:39:32 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:39:32 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:39:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:39:32 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:39:32 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:39:42 [INFO] exp_shallowmodel: train time: 10.237s
02/04/2018 01:39:42 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:39:42 [INFO] exp_shallowmodel: accuracy:   0.764
02/04/2018 01:39:42 [INFO] exp_shallowmodel: f1_score:   0.361
02/04/2018 01:39:42 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:39:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.55      0.19      0.28        59
          C       0.33      0.08      0.13        12
          F       0.79      0.96      0.87       396
          R       0.32      0.11      0.16        55

avg / total       0.71      0.76      0.71       522

02/04/2018 01:39:42 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:39:42 [INFO] exp_shallowmodel: 
[[ 11   0  44   4]
 [  0   1  11   0]
 [  5   1 381   9]
 [  4   1  44   6]]
02/04/2018 01:39:42 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
02/04/2018 01:39:42 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:39:42 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:39:42 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:39:42 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:39:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:39:42 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:39:42 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:39:53 [INFO] exp_shallowmodel: train time: 11.359s
02/04/2018 01:39:53 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:39:53 [INFO] exp_shallowmodel: accuracy:   0.764
02/04/2018 01:39:53 [INFO] exp_shallowmodel: f1_score:   0.328
02/04/2018 01:39:53 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:39:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.08      0.14        59
          C       0.33      0.08      0.13        12
          F       0.79      0.98      0.88       396
          R       0.38      0.11      0.17        55

avg / total       0.69      0.76      0.70       522

02/04/2018 01:39:53 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:39:53 [INFO] exp_shallowmodel: 
[[  5   1  48   5]
 [  1   1   9   1]
 [  5   0 387   4]
 [  4   1  44   6]]
02/04/2018 01:39:54 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
02/04/2018 01:39:54 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:39:54 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:39:54 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:39:54 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:39:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:39:54 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:39:54 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:40:04 [INFO] exp_shallowmodel: train time: 10.844s
02/04/2018 01:40:04 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:40:04 [INFO] exp_shallowmodel: accuracy:   0.757
02/04/2018 01:40:04 [INFO] exp_shallowmodel: f1_score:   0.300
02/04/2018 01:40:04 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:40:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.08      0.13        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.54      0.13      0.21        55

avg / total       0.68      0.76      0.69       522

02/04/2018 01:40:04 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:40:04 [INFO] exp_shallowmodel: 
[[  5   1  52   1]
 [  2   0  10   0]
 [  7   1 383   5]
 [  6   0  42   7]]
02/04/2018 01:40:05 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
02/04/2018 01:40:05 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:40:05 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:40:05 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:40:05 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:40:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:40:05 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:40:05 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:40:15 [INFO] exp_shallowmodel: train time: 10.431s
02/04/2018 01:40:15 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:40:15 [INFO] exp_shallowmodel: accuracy:   0.764
02/04/2018 01:40:15 [INFO] exp_shallowmodel: f1_score:   0.313
02/04/2018 01:40:15 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:40:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.14      0.21        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.38      0.11      0.17        55

avg / total       0.69      0.76      0.70       522

02/04/2018 01:40:15 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:40:15 [INFO] exp_shallowmodel: 
[[  8   1  47   3]
 [  1   0  10   1]
 [  4   1 385   6]
 [  3   0  46   6]]
02/04/2018 01:40:15 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
02/04/2018 01:40:15 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:40:15 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:40:15 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:40:15 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:40:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:40:15 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:40:15 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:40:25 [INFO] exp_shallowmodel: train time: 9.440s
02/04/2018 01:40:25 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:40:25 [INFO] exp_shallowmodel: accuracy:   0.774
02/04/2018 01:40:25 [INFO] exp_shallowmodel: f1_score:   0.327
02/04/2018 01:40:25 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:40:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.14      0.21        59
          C       0.00      0.00      0.00        12
          F       0.80      0.98      0.88       396
          R       0.40      0.15      0.21        55

avg / total       0.71      0.77      0.71       522

02/04/2018 01:40:25 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:40:25 [INFO] exp_shallowmodel: 
[[  8   0  44   7]
 [  2   0  10   0]
 [  2   1 388   5]
 [  4   0  43   8]]
02/04/2018 01:40:25 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
02/04/2018 01:40:25 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:40:25 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:40:25 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:40:25 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:40:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:40:25 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:40:25 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:40:38 [INFO] exp_shallowmodel: train time: 12.873s
02/04/2018 01:40:38 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:40:38 [INFO] exp_shallowmodel: accuracy:   0.751
02/04/2018 01:40:38 [INFO] exp_shallowmodel: f1_score:   0.298
02/04/2018 01:40:38 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:40:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.19      0.27        59
          C       0.00      0.00      0.00        12
          F       0.78      0.96      0.86       396
          R       0.17      0.04      0.06        55

avg / total       0.67      0.75      0.69       522

02/04/2018 01:40:38 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:40:38 [INFO] exp_shallowmodel: 
[[ 11   0  44   4]
 [  0   0  11   1]
 [ 11   1 379   5]
 [  0   1  52   2]]
02/04/2018 01:40:38 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
02/04/2018 01:40:38 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:40:38 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:40:38 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:40:38 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:40:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:40:38 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:40:38 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:40:49 [INFO] exp_shallowmodel: train time: 11.125s
02/04/2018 01:40:49 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:40:49 [INFO] exp_shallowmodel: accuracy:   0.755
02/04/2018 01:40:49 [INFO] exp_shallowmodel: f1_score:   0.289
02/04/2018 01:40:49 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:40:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.10      0.16        59
          C       0.00      0.00      0.00        12
          F       0.80      0.97      0.87       396
          R       0.22      0.09      0.13        55

avg / total       0.66      0.75      0.69       522

02/04/2018 01:40:49 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:40:49 [INFO] exp_shallowmodel: 
[[  6   0  42  11]
 [  1   0   9   2]
 [  8   0 383   5]
 [  3   0  47   5]]
02/04/2018 01:40:49 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
02/04/2018 01:40:49 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:40:49 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:40:49 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:40:49 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:40:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:40:49 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:40:49 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:40:59 [INFO] exp_shallowmodel: train time: 10.141s
02/04/2018 01:40:59 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:40:59 [INFO] exp_shallowmodel: accuracy:   0.768
02/04/2018 01:40:59 [INFO] exp_shallowmodel: f1_score:   0.307
02/04/2018 01:40:59 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:40:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.59      0.17      0.26        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.38      0.05      0.10        55

avg / total       0.70      0.77      0.70       522

02/04/2018 01:40:59 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:40:59 [INFO] exp_shallowmodel: 
[[ 10   1  48   0]
 [  1   0  11   0]
 [  3   0 388   5]
 [  3   0  49   3]]
02/04/2018 01:41:00 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
02/04/2018 01:41:00 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:41:00 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:41:00 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:41:00 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:41:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:41:00 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:41:00 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:41:10 [INFO] exp_shallowmodel: train time: 10.539s
02/04/2018 01:41:10 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:41:10 [INFO] exp_shallowmodel: accuracy:   0.749
02/04/2018 01:41:10 [INFO] exp_shallowmodel: f1_score:   0.259
02/04/2018 01:41:10 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:41:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.16      0.05      0.08        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.23      0.05      0.09        55

avg / total       0.64      0.75      0.68       522

02/04/2018 01:41:10 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:41:10 [INFO] exp_shallowmodel: 
[[  3   0  51   5]
 [  0   0  11   1]
 [  7   0 385   4]
 [  9   0  43   3]]
02/04/2018 01:41:10 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
02/04/2018 01:41:10 [INFO] exp_shallowmodel: #(data) = 4176
02/04/2018 01:41:10 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:41:10 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:41:10 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:41:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:41:10 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:41:10 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:41:22 [INFO] exp_shallowmodel: train time: 11.601s
02/04/2018 01:41:22 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:41:22 [INFO] exp_shallowmodel: accuracy:   0.746
02/04/2018 01:41:22 [INFO] exp_shallowmodel: f1_score:   0.287
02/04/2018 01:41:22 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:41:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.09      0.15        64
          C       0.00      0.00      0.00        14
          F       0.76      0.98      0.86       402
          R       0.56      0.08      0.14        63

avg / total       0.67      0.75      0.67       543

02/04/2018 01:41:22 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:41:22 [INFO] exp_shallowmodel: 
[[  6   0  56   2]
 [  1   0  13   0]
 [  5   1 394   2]
 [  4   0  54   5]]
02/04/2018 01:41:22 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
02/04/2018 01:41:22 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:41:22 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:41:22 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:41:22 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:41:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:41:22 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:41:22 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:41:37 [INFO] exp_shallowmodel: train time: 14.918s
02/04/2018 01:41:37 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:41:37 [INFO] exp_shallowmodel: accuracy:   0.745
02/04/2018 01:41:37 [INFO] exp_shallowmodel: f1_score:   0.308
02/04/2018 01:41:37 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:41:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.17      0.24        59
          C       0.00      0.00      0.00        12
          F       0.78      0.94      0.86       396
          R       0.29      0.09      0.14        55

avg / total       0.67      0.75      0.69       522

02/04/2018 01:41:37 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:41:37 [INFO] exp_shallowmodel: 
[[ 10   1  45   3]
 [  1   0  10   1]
 [ 13   1 374   8]
 [  2   0  48   5]]
02/04/2018 01:41:37 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
02/04/2018 01:41:37 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:41:37 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:41:37 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:41:37 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:41:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:41:37 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:41:37 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:41:51 [INFO] exp_shallowmodel: train time: 13.881s
02/04/2018 01:41:51 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:41:51 [INFO] exp_shallowmodel: accuracy:   0.761
02/04/2018 01:41:51 [INFO] exp_shallowmodel: f1_score:   0.297
02/04/2018 01:41:51 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:41:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.15      0.23        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.27      0.05      0.09        55

avg / total       0.68      0.76      0.70       522

02/04/2018 01:41:51 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:41:51 [INFO] exp_shallowmodel: 
[[  9   2  46   2]
 [  0   0  10   2]
 [  7   0 385   4]
 [  4   0  48   3]]
02/04/2018 01:41:52 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
02/04/2018 01:41:52 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:41:52 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:41:52 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:41:52 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:41:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:41:52 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:41:52 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:42:01 [INFO] exp_shallowmodel: train time: 9.928s
02/04/2018 01:42:01 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:42:01 [INFO] exp_shallowmodel: accuracy:   0.747
02/04/2018 01:42:01 [INFO] exp_shallowmodel: f1_score:   0.265
02/04/2018 01:42:01 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:42:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.07      0.10        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.86       396
          R       0.33      0.05      0.09        55

avg / total       0.65      0.75      0.67       522

02/04/2018 01:42:01 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:42:01 [INFO] exp_shallowmodel: 
[[  4   0  52   3]
 [  2   0  10   0]
 [  9   1 383   3]
 [  3   0  49   3]]
02/04/2018 01:42:02 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
02/04/2018 01:42:02 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:42:02 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:42:02 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:42:02 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:42:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:42:02 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:42:02 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:42:12 [INFO] exp_shallowmodel: train time: 10.021s
02/04/2018 01:42:12 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:42:12 [INFO] exp_shallowmodel: accuracy:   0.764
02/04/2018 01:42:12 [INFO] exp_shallowmodel: f1_score:   0.344
02/04/2018 01:42:12 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:42:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.37      0.12      0.18        59
          C       1.00      0.08      0.15        12
          F       0.79      0.97      0.87       396
          R       0.35      0.11      0.17        55

avg / total       0.70      0.76      0.70       522

02/04/2018 01:42:12 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:42:12 [INFO] exp_shallowmodel: 
[[  7   0  46   6]
 [  0   1  10   1]
 [  7   0 385   4]
 [  5   0  44   6]]
02/04/2018 01:42:12 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
02/04/2018 01:42:12 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:42:12 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:42:12 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:42:12 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:42:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:42:12 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:42:12 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:42:26 [INFO] exp_shallowmodel: train time: 14.155s
02/04/2018 01:42:26 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:42:26 [INFO] exp_shallowmodel: accuracy:   0.764
02/04/2018 01:42:26 [INFO] exp_shallowmodel: f1_score:   0.289
02/04/2018 01:42:26 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:42:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.79      0.98      0.88       396
          R       0.29      0.09      0.14        55

avg / total       0.68      0.76      0.70       522

02/04/2018 01:42:26 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:42:26 [INFO] exp_shallowmodel: 
[[  5   1  47   6]
 [  1   0  10   1]
 [  2   0 389   5]
 [  5   1  44   5]]
02/04/2018 01:42:26 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
02/04/2018 01:42:26 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:42:26 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:42:26 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:42:26 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:42:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:42:26 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:42:26 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:42:43 [INFO] exp_shallowmodel: train time: 16.744s
02/04/2018 01:42:43 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:42:43 [INFO] exp_shallowmodel: accuracy:   0.749
02/04/2018 01:42:43 [INFO] exp_shallowmodel: f1_score:   0.308
02/04/2018 01:42:43 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:42:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.10      0.15        59
          C       0.00      0.00      0.00        12
          F       0.79      0.95      0.86       396
          R       0.44      0.15      0.22        55

avg / total       0.68      0.75      0.69       522

02/04/2018 01:42:43 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:42:43 [INFO] exp_shallowmodel: 
[[  6   0  51   2]
 [  1   0  10   1]
 [  9   3 377   7]
 [  5   1  41   8]]
02/04/2018 01:42:43 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
02/04/2018 01:42:43 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:42:43 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:42:43 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:42:43 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:42:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:42:43 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:42:43 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:43:07 [INFO] exp_shallowmodel: train time: 23.798s
02/04/2018 01:43:07 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:43:07 [INFO] exp_shallowmodel: accuracy:   0.770
02/04/2018 01:43:07 [INFO] exp_shallowmodel: f1_score:   0.317
02/04/2018 01:43:07 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:43:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.15      0.24        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.50      0.09      0.15        55

avg / total       0.71      0.77      0.70       522

02/04/2018 01:43:07 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:43:07 [INFO] exp_shallowmodel: 
[[  9   0  48   2]
 [  0   0  12   0]
 [  4   1 388   3]
 [  2   0  48   5]]
02/04/2018 01:43:07 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
02/04/2018 01:43:07 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:43:07 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:43:07 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:43:07 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:43:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:43:07 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:43:07 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:43:17 [INFO] exp_shallowmodel: train time: 9.540s
02/04/2018 01:43:17 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:43:17 [INFO] exp_shallowmodel: accuracy:   0.762
02/04/2018 01:43:17 [INFO] exp_shallowmodel: f1_score:   0.323
02/04/2018 01:43:17 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:43:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.17      0.24        59
          C       0.00      0.00      0.00        12
          F       0.78      0.96      0.87       396
          R       0.75      0.11      0.19        55

avg / total       0.72      0.76      0.70       522

02/04/2018 01:43:17 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:43:17 [INFO] exp_shallowmodel: 
[[ 10   1  47   1]
 [  1   0  11   0]
 [ 12   1 382   1]
 [  2   0  47   6]]
02/04/2018 01:43:17 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
02/04/2018 01:43:17 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:43:17 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:43:17 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:43:17 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:43:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:43:17 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:43:17 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:43:27 [INFO] exp_shallowmodel: train time: 10.316s
02/04/2018 01:43:27 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:43:27 [INFO] exp_shallowmodel: accuracy:   0.762
02/04/2018 01:43:27 [INFO] exp_shallowmodel: f1_score:   0.319
02/04/2018 01:43:27 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:43:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.10      0.16        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.56      0.16      0.25        55

avg / total       0.69      0.76      0.70       522

02/04/2018 01:43:27 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:43:27 [INFO] exp_shallowmodel: 
[[  6   0  51   2]
 [  0   0  12   0]
 [  7   1 383   5]
 [  5   0  41   9]]
02/04/2018 01:43:28 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
02/04/2018 01:43:28 [INFO] exp_shallowmodel: #(data) = 4176
02/04/2018 01:43:28 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:43:28 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:43:28 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:43:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:43:28 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:43:28 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:43:38 [INFO] exp_shallowmodel: train time: 10.586s
02/04/2018 01:43:38 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:43:38 [INFO] exp_shallowmodel: accuracy:   0.735
02/04/2018 01:43:38 [INFO] exp_shallowmodel: f1_score:   0.298
02/04/2018 01:43:38 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:43:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.12      0.19        64
          C       0.00      0.00      0.00        14
          F       0.76      0.96      0.85       402
          R       0.38      0.10      0.15        63

avg / total       0.65      0.73      0.67       543

02/04/2018 01:43:38 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:43:38 [INFO] exp_shallowmodel: 
[[  8   1  52   3]
 [  1   0  13   0]
 [  9   1 385   7]
 [  3   0  54   6]]
02/04/2018 01:43:38 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
02/04/2018 01:43:38 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:43:38 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:43:38 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:43:38 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:43:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:43:38 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:43:38 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:43:50 [INFO] exp_shallowmodel: train time: 11.954s
02/04/2018 01:43:50 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:43:50 [INFO] exp_shallowmodel: accuracy:   0.761
02/04/2018 01:43:50 [INFO] exp_shallowmodel: f1_score:   0.294
02/04/2018 01:43:50 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:43:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.12      0.18        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.87       396
          R       0.44      0.07      0.12        55

avg / total       0.69      0.76      0.69       522

02/04/2018 01:43:50 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:43:50 [INFO] exp_shallowmodel: 
[[  7   1  49   2]
 [  1   0  11   0]
 [  6   1 386   3]
 [  4   1  46   4]]
02/04/2018 01:43:50 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
02/04/2018 01:43:50 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:43:50 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:43:50 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:43:50 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:43:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:43:50 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:43:50 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:44:07 [INFO] exp_shallowmodel: train time: 16.126s
02/04/2018 01:44:07 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:44:07 [INFO] exp_shallowmodel: accuracy:   0.751
02/04/2018 01:44:07 [INFO] exp_shallowmodel: f1_score:   0.270
02/04/2018 01:44:07 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:44:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.12      0.19        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.86       396
          R       0.09      0.02      0.03        55

avg / total       0.65      0.75      0.68       522

02/04/2018 01:44:07 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:44:07 [INFO] exp_shallowmodel: 
[[  7   0  48   4]
 [  1   0  11   0]
 [  6   0 384   6]
 [  2   0  52   1]]
02/04/2018 01:44:07 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
02/04/2018 01:44:07 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:44:07 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:44:07 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:44:07 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:44:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:44:07 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:44:07 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:44:21 [INFO] exp_shallowmodel: train time: 14.186s
02/04/2018 01:44:21 [INFO] exp_shallowmodel: test time:  0.002s
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
02/04/2018 01:44:21 [INFO] exp_shallowmodel: accuracy:   0.770
02/04/2018 01:44:21 [INFO] exp_shallowmodel: f1_score:   0.306
02/04/2018 01:44:21 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:44:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.78      0.98      0.87       396
          R       0.62      0.15      0.24        55

avg / total       0.70      0.77      0.70       522

02/04/2018 01:44:21 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:44:21 [INFO] exp_shallowmodel: 
[[  4   0  52   3]
 [  0   0  12   0]
 [  4   0 390   2]
 [  2   0  45   8]]
02/04/2018 01:44:21 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
02/04/2018 01:44:21 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:44:21 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:44:21 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:44:21 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:44:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:44:21 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:44:21 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:44:33 [INFO] exp_shallowmodel: train time: 11.352s
02/04/2018 01:44:33 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:44:33 [INFO] exp_shallowmodel: accuracy:   0.774
02/04/2018 01:44:33 [INFO] exp_shallowmodel: f1_score:   0.357
02/04/2018 01:44:33 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:44:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.15      0.23        59
          C       0.50      0.08      0.14        12
          F       0.80      0.98      0.88       396
          R       0.50      0.11      0.18        55

avg / total       0.72      0.77      0.71       522

02/04/2018 01:44:33 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:44:33 [INFO] exp_shallowmodel: 
[[  9   0  49   1]
 [  1   1   8   2]
 [  4   1 388   3]
 [  6   0  43   6]]
02/04/2018 01:44:33 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
02/04/2018 01:44:33 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:44:33 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:44:33 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:44:33 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:44:33 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:44:33 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:44:33 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:44:44 [INFO] exp_shallowmodel: train time: 11.455s
02/04/2018 01:44:44 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:44:44 [INFO] exp_shallowmodel: accuracy:   0.753
02/04/2018 01:44:44 [INFO] exp_shallowmodel: f1_score:   0.296
02/04/2018 01:44:44 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:44:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.28      0.12      0.17        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.45      0.09      0.15        55

avg / total       0.68      0.75      0.69       522

02/04/2018 01:44:44 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:44:44 [INFO] exp_shallowmodel: 
[[  7   2  49   1]
 [  1   0  10   1]
 [ 10   1 381   4]
 [  7   0  43   5]]
02/04/2018 01:44:44 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
02/04/2018 01:44:44 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:44:44 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:44:44 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:44:44 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:44:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:44:44 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:44:44 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:44:54 [INFO] exp_shallowmodel: train time: 9.119s
02/04/2018 01:44:54 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:44:54 [INFO] exp_shallowmodel: accuracy:   0.755
02/04/2018 01:44:54 [INFO] exp_shallowmodel: f1_score:   0.289
02/04/2018 01:44:54 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:44:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.14      0.20        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.23      0.05      0.09        55

avg / total       0.67      0.75      0.69       522

02/04/2018 01:44:54 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:44:54 [INFO] exp_shallowmodel: 
[[  8   3  43   5]
 [  1   0  11   0]
 [  7   1 383   5]
 [  6   0  46   3]]
02/04/2018 01:44:54 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
02/04/2018 01:44:54 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:44:54 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:44:54 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:44:54 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:44:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:44:54 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:44:54 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:45:07 [INFO] exp_shallowmodel: train time: 12.952s
02/04/2018 01:45:07 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:45:07 [INFO] exp_shallowmodel: accuracy:   0.766
02/04/2018 01:45:07 [INFO] exp_shallowmodel: f1_score:   0.314
02/04/2018 01:45:07 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:45:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.19      0.26        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.44      0.07      0.12        55

avg / total       0.70      0.77      0.70       522

02/04/2018 01:45:07 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:45:07 [INFO] exp_shallowmodel: 
[[ 11   0  45   3]
 [  0   0  12   0]
 [  9   0 385   2]
 [  6   1  44   4]]
02/04/2018 01:45:07 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
02/04/2018 01:45:07 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:45:07 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:45:07 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:45:07 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:45:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:45:07 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:45:07 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:45:20 [INFO] exp_shallowmodel: train time: 13.468s
02/04/2018 01:45:20 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:45:20 [INFO] exp_shallowmodel: accuracy:   0.759
02/04/2018 01:45:20 [INFO] exp_shallowmodel: f1_score:   0.325
02/04/2018 01:45:20 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:45:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.15      0.22        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.42      0.15      0.22        55

avg / total       0.69      0.76      0.70       522

02/04/2018 01:45:20 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:45:20 [INFO] exp_shallowmodel: 
[[  9   0  48   2]
 [  1   0  10   1]
 [  9   0 379   8]
 [  4   0  43   8]]
02/04/2018 01:45:21 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
02/04/2018 01:45:21 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:45:21 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:45:21 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:45:21 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:45:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:45:21 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:45:21 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:45:32 [INFO] exp_shallowmodel: train time: 11.408s
02/04/2018 01:45:32 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:45:32 [INFO] exp_shallowmodel: accuracy:   0.759
02/04/2018 01:45:32 [INFO] exp_shallowmodel: f1_score:   0.336
02/04/2018 01:45:32 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:45:32 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.39      0.12      0.18        59
          C       1.00      0.08      0.15        12
          F       0.79      0.97      0.87       396
          R       0.31      0.09      0.14        55

avg / total       0.70      0.76      0.70       522

02/04/2018 01:45:32 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:45:32 [INFO] exp_shallowmodel: 
[[  7   0  47   5]
 [  1   1  10   0]
 [  7   0 383   6]
 [  3   0  47   5]]
02/04/2018 01:45:32 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
02/04/2018 01:45:32 [INFO] exp_shallowmodel: #(data) = 4176
02/04/2018 01:45:32 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:45:32 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:45:32 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:45:32 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:45:32 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:45:32 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:45:43 [INFO] exp_shallowmodel: train time: 10.373s
02/04/2018 01:45:43 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:45:43 [INFO] exp_shallowmodel: accuracy:   0.733
02/04/2018 01:45:43 [INFO] exp_shallowmodel: f1_score:   0.281
02/04/2018 01:45:43 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:45:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.24      0.08      0.12        64
          C       0.00      0.00      0.00        14
          F       0.77      0.96      0.85       402
          R       0.38      0.10      0.15        63

avg / total       0.64      0.73      0.66       543

02/04/2018 01:45:43 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:45:43 [INFO] exp_shallowmodel: 
[[  5   0  54   5]
 [  2   0  11   1]
 [ 10   1 387   4]
 [  4   0  53   6]]
02/04/2018 01:45:43 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
02/04/2018 01:45:43 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:45:43 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:45:43 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:45:43 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:45:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:45:43 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:45:43 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:45:53 [INFO] exp_shallowmodel: train time: 10.236s
02/04/2018 01:45:53 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:45:53 [INFO] exp_shallowmodel: accuracy:   0.759
02/04/2018 01:45:53 [INFO] exp_shallowmodel: f1_score:   0.322
02/04/2018 01:45:53 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:45:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.14      0.21        59
          C       1.00      0.08      0.15        12
          F       0.78      0.97      0.86       396
          R       0.25      0.04      0.06        55

avg / total       0.69      0.76      0.69       522

02/04/2018 01:45:53 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:45:53 [INFO] exp_shallowmodel: 
[[  8   0  51   0]
 [  0   1  11   0]
 [  5   0 385   6]
 [  5   0  48   2]]
02/04/2018 01:45:53 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
02/04/2018 01:45:53 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:45:53 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:45:53 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:45:53 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:45:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:45:53 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:45:53 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:46:06 [INFO] exp_shallowmodel: train time: 12.749s
02/04/2018 01:46:06 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:46:06 [INFO] exp_shallowmodel: accuracy:   0.764
02/04/2018 01:46:06 [INFO] exp_shallowmodel: f1_score:   0.307
02/04/2018 01:46:06 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:46:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.14      0.21        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.38      0.09      0.15        55

avg / total       0.69      0.76      0.70       522

02/04/2018 01:46:06 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:46:06 [INFO] exp_shallowmodel: 
[[  8   1  48   2]
 [  0   0  10   2]
 [  6   0 386   4]
 [  5   2  43   5]]
02/04/2018 01:46:06 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
02/04/2018 01:46:06 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:46:06 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:46:06 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:46:06 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:46:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:46:06 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:46:06 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:46:17 [INFO] exp_shallowmodel: train time: 10.677s
02/04/2018 01:46:17 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:46:17 [INFO] exp_shallowmodel: accuracy:   0.759
02/04/2018 01:46:17 [INFO] exp_shallowmodel: f1_score:   0.303
02/04/2018 01:46:17 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:46:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.79      0.97      0.87       396
          R       0.35      0.15      0.21        55

avg / total       0.68      0.76      0.70       522

02/04/2018 01:46:17 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:46:17 [INFO] exp_shallowmodel: 
[[  5   0  47   7]
 [  1   0  10   1]
 [  6   0 383   7]
 [  2   0  45   8]]
02/04/2018 01:46:17 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
02/04/2018 01:46:17 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:46:17 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:46:17 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:46:17 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:46:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:46:17 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:46:17 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:46:33 [INFO] exp_shallowmodel: train time: 16.287s
02/04/2018 01:46:33 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:46:33 [INFO] exp_shallowmodel: accuracy:   0.755
02/04/2018 01:46:33 [INFO] exp_shallowmodel: f1_score:   0.301
02/04/2018 01:46:33 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:46:33 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.15      0.23        59
          C       0.00      0.00      0.00        12
          F       0.79      0.96      0.87       396
          R       0.24      0.07      0.11        55

avg / total       0.67      0.75      0.70       522

02/04/2018 01:46:33 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:46:33 [INFO] exp_shallowmodel: 
[[  9   0  46   4]
 [  2   0  10   0]
 [  4   2 381   9]
 [  6   1  44   4]]
02/04/2018 01:46:34 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
02/04/2018 01:46:34 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:46:34 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:46:34 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:46:34 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:46:34 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:46:34 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:46:34 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:46:48 [INFO] exp_shallowmodel: train time: 14.218s
02/04/2018 01:46:48 [INFO] exp_shallowmodel: test time:  0.002s
02/04/2018 01:46:48 [INFO] exp_shallowmodel: accuracy:   0.772
02/04/2018 01:46:48 [INFO] exp_shallowmodel: f1_score:   0.371
02/04/2018 01:46:48 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:46:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.19      0.27        59
          C       0.50      0.08      0.14        12
          F       0.80      0.97      0.88       396
          R       0.47      0.13      0.20        55

avg / total       0.72      0.77      0.72       522

02/04/2018 01:46:48 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:46:48 [INFO] exp_shallowmodel: 
[[ 11   1  44   3]
 [  0   1  11   0]
 [  7   0 384   5]
 [  6   0  42   7]]
02/04/2018 01:46:48 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
02/04/2018 01:46:48 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:46:48 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:46:48 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:46:48 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:46:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:46:48 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:46:48 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:47:02 [INFO] exp_shallowmodel: train time: 13.417s
02/04/2018 01:47:02 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:47:02 [INFO] exp_shallowmodel: accuracy:   0.766
02/04/2018 01:47:02 [INFO] exp_shallowmodel: f1_score:   0.311
02/04/2018 01:47:02 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:47:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.15      0.23        59
          C       0.00      0.00      0.00        12
          F       0.80      0.97      0.88       396
          R       0.31      0.09      0.14        55

avg / total       0.69      0.77      0.71       522

02/04/2018 01:47:02 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:47:02 [INFO] exp_shallowmodel: 
[[  9   0  45   5]
 [  0   0  10   2]
 [  6   0 386   4]
 [  6   1  43   5]]
02/04/2018 01:47:02 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
02/04/2018 01:47:02 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:47:02 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:47:02 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:47:02 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:47:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:47:02 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:47:02 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:47:13 [INFO] exp_shallowmodel: train time: 11.604s
02/04/2018 01:47:13 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:47:13 [INFO] exp_shallowmodel: accuracy:   0.759
02/04/2018 01:47:13 [INFO] exp_shallowmodel: f1_score:   0.323
02/04/2018 01:47:13 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:47:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.34      0.17      0.23        59
          C       0.00      0.00      0.00        12
          F       0.80      0.96      0.87       396
          R       0.44      0.13      0.20        55

avg / total       0.69      0.76      0.71       522

02/04/2018 01:47:13 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:47:13 [INFO] exp_shallowmodel: 
[[ 10   1  43   5]
 [  1   0  11   0]
 [ 13   0 379   4]
 [  5   0  43   7]]
02/04/2018 01:47:14 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
02/04/2018 01:47:14 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:47:14 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:47:14 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:47:14 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:47:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:47:14 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:47:14 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:47:30 [INFO] exp_shallowmodel: train time: 16.509s
02/04/2018 01:47:30 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:47:30 [INFO] exp_shallowmodel: accuracy:   0.759
02/04/2018 01:47:30 [INFO] exp_shallowmodel: f1_score:   0.287
02/04/2018 01:47:30 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:47:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.35      0.10      0.16        59
          C       0.00      0.00      0.00        12
          F       0.78      0.97      0.87       396
          R       0.40      0.07      0.12        55

avg / total       0.67      0.76      0.69       522

02/04/2018 01:47:30 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:47:30 [INFO] exp_shallowmodel: 
[[  6   0  52   1]
 [  1   0  11   0]
 [  5   0 386   5]
 [  5   0  46   4]]
02/04/2018 01:47:30 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
02/04/2018 01:47:30 [INFO] exp_shallowmodel: #(data) = 4197
02/04/2018 01:47:30 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:47:30 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:47:30 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:47:30 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:47:30 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:47:30 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:47:41 [INFO] exp_shallowmodel: train time: 10.617s
02/04/2018 01:47:41 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:47:41 [INFO] exp_shallowmodel: accuracy:   0.766
02/04/2018 01:47:41 [INFO] exp_shallowmodel: f1_score:   0.338
02/04/2018 01:47:41 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:47:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.12      0.19        59
          C       0.50      0.08      0.14        12
          F       0.78      0.98      0.87       396
          R       0.38      0.09      0.15        55

avg / total       0.70      0.77      0.70       522

02/04/2018 01:47:41 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:47:41 [INFO] exp_shallowmodel: 
[[  7   0  47   5]
 [  0   1  11   0]
 [  6   0 387   3]
 [  1   1  48   5]]
02/04/2018 01:47:41 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
02/04/2018 01:47:41 [INFO] exp_shallowmodel: #(data) = 4176
02/04/2018 01:47:41 [INFO] exp_shallowmodel: #(feature) = 1352
02/04/2018 01:47:41 [INFO] exp_shallowmodel: ================================================================================
02/04/2018 01:47:41 [INFO] exp_shallowmodel: LR.pen=l1.C=1.000000
02/04/2018 01:47:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
02/04/2018 01:47:41 [INFO] exp_shallowmodel: Training: 
02/04/2018 01:47:41 [INFO] exp_shallowmodel: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
02/04/2018 01:47:52 [INFO] exp_shallowmodel: train time: 10.638s
02/04/2018 01:47:52 [INFO] exp_shallowmodel: test time:  0.001s
02/04/2018 01:47:52 [INFO] exp_shallowmodel: accuracy:   0.768
02/04/2018 01:47:52 [INFO] exp_shallowmodel: f1_score:   0.347
02/04/2018 01:47:52 [INFO] exp_shallowmodel: classification report:
02/04/2018 01:47:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.57      0.19      0.28        64
          C       0.00      0.00      0.00        14
          F       0.78      0.99      0.87       402
          R       0.69      0.14      0.24        63

avg / total       0.72      0.77      0.70       543

02/04/2018 01:47:52 [INFO] exp_shallowmodel: confusion matrix:
02/04/2018 01:47:52 [INFO] exp_shallowmodel: 
[[ 12   0  50   2]
 [  1   0  12   1]
 [  5   0 396   1]
 [  3   0  51   9]]
Done: 20180204-014753
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/packages/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
