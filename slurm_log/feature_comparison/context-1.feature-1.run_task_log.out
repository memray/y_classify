/ihome/pbrusilosky/rum20/.conda/envs/py36/bin/python -m dialogue.classify.task_runner -selected_feature_set_id 1 -selected_context_id 1
No. of param settings = 1
[('deep_model', False), ('selected_context_id', 1), ('selected_feature_set_id', 1), ('similarity_feature', False)]
12/10/2017 02:14:33 [INFO] configuration: deep_model  :   False
12/10/2017 02:14:33 [INFO] configuration: selected_context_id  :   1
12/10/2017 02:14:33 [INFO] configuration: selected_feature_set_id  :   1
12/10/2017 02:14:33 [INFO] configuration: similarity_feature  :   False
12/10/2017 02:14:33 [INFO] configuration: seed  :   154316847
12/10/2017 02:14:33 [INFO] configuration: root_path  :   /ihome/pbrusilosky/rum20/y_classify
12/10/2017 02:14:33 [INFO] configuration: task_name  :   utterance_type
12/10/2017 02:14:33 [INFO] configuration: timemark  :   20171210-021433
12/10/2017 02:14:33 [INFO] configuration: context_set  :   current
12/10/2017 02:14:33 [INFO] configuration: utterance_names  :   ['last_user_utterance', 'last_system_utterance', 'current_user_utterance', 'next_system_utterance', 'next_user_utterance']
12/10/2017 02:14:33 [INFO] configuration: utterance_range  :   ['current_user_utterance']
12/10/2017 02:14:33 [INFO] configuration: experiment_mode  :   single_run_context_feature
12/10/2017 02:14:33 [INFO] configuration: feature_set  :   1-basic
12/10/2017 02:14:33 [INFO] configuration: feature_set_number  :   ['1', '2', '3']
12/10/2017 02:14:33 [INFO] configuration: experiment_name  :   20171210-021433.context=current.feature=1-basic.similarity=false
12/10/2017 02:14:33 [INFO] configuration: experiment_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021433.context=current.feature=1-basic.similarity=false
12/10/2017 02:14:33 [INFO] configuration: log_path  :   /ihome/pbrusilosky/rum20/y_classify/output/20171210-021433.context=current.feature=1-basic.similarity=false/output.log
12/10/2017 02:14:33 [INFO] configuration: valid_type  :   {'C', 'R', 'F', 'A'}
12/10/2017 02:14:33 [INFO] configuration: data_name  :   
12/10/2017 02:14:33 [INFO] configuration: data_names  :   ['dstc2', 'dstc3', 'family', 'ghome']
12/10/2017 02:14:33 [INFO] configuration: raw_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.raw_feature.pkl
12/10/2017 02:14:33 [INFO] configuration: extracted_feature_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.extracted_feature.pkl
12/10/2017 02:14:33 [INFO] configuration: pipeline_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/%s.pipeline.pkl
12/10/2017 02:14:33 [INFO] configuration: metrics  :   ['accuracy', 'precision', 'recall', 'f1_score', 'training_time', 'test_time']
12/10/2017 02:14:33 [INFO] configuration: do_cross_validation  :   True
12/10/2017 02:14:33 [INFO] configuration: #division  :   5
12/10/2017 02:14:33 [INFO] configuration: #cross_validation  :   10
12/10/2017 02:14:33 [INFO] configuration: cv_index_cache_path  :   
12/10/2017 02:14:33 [INFO] configuration: action_words  :   {'els', 'video', 'findcare', 'member', 'price', 'ani', 'part', 'moder', 'expens', 'share', 'temperatur', 'snooze', 'remind', 'volum', 'telephon', 'cheap', 'music', 'item', 'alarm', 'watch', 'phone', 'next', 'number', 'address', 'song', 'time', 'any', 'food', 'delet', 'discard', 'reminders', 'turn', 'matter', 'moderate', 'cast', 'findcar', 'post', 'help', 'weather', 'north', 'temperature', 'else', 'south', 'delete', 'volume', 'stop', 'list', 'shuffle', 'light', 'timer', 'show', 'remove', 'items', 'play', 'remov', 'expensive', 'reminds', 'add', 'clear', 'start', 'room', 'shuffl', 'centr', 'snooz', 'reminder', 'tell', 'telephone', 'skip', 'area', 'centre'}
12/10/2017 02:14:33 [INFO] configuration: corenlp_jars  :   ('/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/*', '/Users/memray/Project/stanford/stanford-corenlp-full-3.8.0/stanford-english-kbp-corenlp-2017-06-09-models.jar')
12/10/2017 02:14:33 [INFO] configuration: lda_topic_number  :   50
12/10/2017 02:14:33 [INFO] configuration: lda_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.topic=50.lda.pkl
12/10/2017 02:14:33 [INFO] configuration: gensim_corpus_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.corpus.pkl
12/10/2017 02:14:33 [INFO] configuration: gensim_dict_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.dict
12/10/2017 02:14:33 [INFO] configuration: w2v_path  :   /Users/memray/Data/glove/GoogleNews-vectors-negative300.bin
12/10/2017 02:14:33 [INFO] configuration: w2v_vector_length  :   300
12/10/2017 02:14:33 [INFO] configuration: d2v_vector_length  :   300
12/10/2017 02:14:33 [INFO] configuration: d2v_window_size  :   5
12/10/2017 02:14:33 [INFO] configuration: d2v_min_count  :   2
12/10/2017 02:14:33 [INFO] configuration: d2v_model_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.model
12/10/2017 02:14:33 [INFO] configuration: d2v_vector_path  :   /ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.doc2vec.dim=300.window=5.min_count=2.vector
12/10/2017 02:14:33 [INFO] configuration: num_word_keep  :   {'dstc2': 300, 'dstc3': 300, 'family': 1000, 'ghome': 1000}
12/10/2017 02:14:33 [INFO] configuration: batch_size  :   128
12/10/2017 02:14:33 [INFO] configuration: max_epoch  :   50
12/10/2017 02:14:33 [INFO] configuration: early_stop_tolerance  :   2
12/10/2017 02:14:33 [INFO] configuration: concat_sents  :   True
12/10/2017 02:14:33 [INFO] configuration: cnn_setting  :   {'MODEL': 'multichannel', 'EARLY_STOPPING': True, 'WORD_DIM': 300, 'FILTERS': [3, 4, 5], 'FILTER_NUM': [100, 100, 100], 'CLASS_SIZE': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'NORM_LIMIT': 10, 'DROPOUT_PROB': 0.5}
12/10/2017 02:14:33 [INFO] configuration: skipthought_setting  :   {'skipthought_model_path': '/Users/memray/Data/skip-thought', 'skipthought_data_path': '/ihome/pbrusilosky/rum20/y_classify/dataset/feature/gensim/%s.skip-thought.biskip.vector', 'fixed_emb': True, 'sentence_num': 1, 'hidden_size': 2400, 'class_size': 4, 'learning_rate': 0.0001, 'norm_limit': 3, 'dropout_prob': 0.5}
12/10/2017 02:14:33 [INFO] configuration: lstm_setting  :   {'model': 'non-static', 'hidden_size': 32, 'embedding_size': 300, 'num_layers': 1, 'bidirectional': False, 'learning_rate': 0.001, 'class_size': 4, 'norm_limit': 2, 'clip_grad_norm': 2, 'dropout_prob': 0.1}
12/10/2017 02:14:36 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:36 [INFO] task_runner: context=current, feature=1-basic
12/10/2017 02:14:36 [INFO] task_runner: retained feature numbers=[1, 2.1, 3, 2.2]
12/10/2017 02:14:36 [INFO] task_runner: #(data)=5725
12/10/2017 02:14:36 [INFO] task_runner: #(feature)=31
12/10/2017 02:14:36 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 0 
12/10/2017 02:14:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:36 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:36 [INFO] exp_shallowmodel: train time: 0.652s
12/10/2017 02:14:36 [INFO] exp_shallowmodel: test time:  0.006s
12/10/2017 02:14:36 [INFO] exp_shallowmodel: accuracy:   0.667
12/10/2017 02:14:36 [INFO] exp_shallowmodel: f1_score:   0.446
12/10/2017 02:14:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.62      0.78      0.69       164
          F       0.72      0.84      0.78       268
          R       0.52      0.22      0.31       125

avg / total       0.63      0.67      0.63       571

12/10/2017 02:14:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:36 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 128  24  12]
 [  0  31 225  12]
 [  0  44  53  28]]
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ******************** dstc2 - Round 1 
12/10/2017 02:14:36 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:36 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:37 [INFO] exp_shallowmodel: train time: 0.650s
12/10/2017 02:14:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:37 [INFO] exp_shallowmodel: accuracy:   0.646
12/10/2017 02:14:37 [INFO] exp_shallowmodel: f1_score:   0.431
12/10/2017 02:14:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.73      0.65       164
          F       0.70      0.83      0.76       268
          R       0.53      0.22      0.31       125

avg / total       0.61      0.65      0.61       571

12/10/2017 02:14:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:37 [INFO] exp_shallowmodel: 
[[  0   2  12   0]
 [  0 119  28  17]
 [  0  38 222   8]
 [  0  42  55  28]]
12/10/2017 02:14:37 [INFO] exp_shallowmodel: ******************** dstc2 - Round 2 
12/10/2017 02:14:37 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:37 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:38 [INFO] exp_shallowmodel: train time: 1.144s
12/10/2017 02:14:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:38 [INFO] exp_shallowmodel: accuracy:   0.643
12/10/2017 02:14:38 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 02:14:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.68      0.62       164
          F       0.72      0.85      0.78       268
          R       0.50      0.21      0.29       125

avg / total       0.61      0.64      0.61       571

12/10/2017 02:14:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:38 [INFO] exp_shallowmodel: 
[[  0   1  10   3]
 [  0 112  35  17]
 [  0  33 229   6]
 [  0  53  46  26]]
12/10/2017 02:14:38 [INFO] exp_shallowmodel: ******************** dstc2 - Round 3 
12/10/2017 02:14:38 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:38 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:39 [INFO] exp_shallowmodel: train time: 0.555s
12/10/2017 02:14:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:39 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 02:14:39 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 02:14:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.70      0.63       164
          F       0.70      0.83      0.76       268
          R       0.49      0.22      0.31       125

avg / total       0.60      0.64      0.61       571

12/10/2017 02:14:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:39 [INFO] exp_shallowmodel: 
[[  0   0  10   4]
 [  0 115  33  16]
 [  0  37 222   9]
 [  0  47  50  28]]
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 4 
12/10/2017 02:14:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:39 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:39 [INFO] exp_shallowmodel: train time: 0.636s
12/10/2017 02:14:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:39 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 02:14:39 [INFO] exp_shallowmodel: f1_score:   0.401
12/10/2017 02:14:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.69      0.61       164
          F       0.69      0.81      0.75       268
          R       0.40      0.18      0.24       125

avg / total       0.57      0.61      0.58       571

12/10/2017 02:14:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:39 [INFO] exp_shallowmodel: 
[[  0   1  10   3]
 [  0 113  34  17]
 [  0  39 216  13]
 [  0  52  51  22]]
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ******************** dstc2 - Round 5 
12/10/2017 02:14:39 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:39 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:40 [INFO] exp_shallowmodel: train time: 0.555s
12/10/2017 02:14:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:40 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 02:14:40 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 02:14:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.67      0.60       164
          F       0.69      0.82      0.75       268
          R       0.49      0.19      0.28       125

avg / total       0.59      0.62      0.59       571

12/10/2017 02:14:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:40 [INFO] exp_shallowmodel: 
[[  0   3  11   0]
 [  0 110  36  18]
 [  0  40 221   7]
 [  0  49  52  24]]
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 6 
12/10/2017 02:14:40 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:40 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:40 [INFO] exp_shallowmodel: train time: 0.666s
12/10/2017 02:14:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:40 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 02:14:40 [INFO] exp_shallowmodel: f1_score:   0.441
12/10/2017 02:14:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.63      0.77      0.69       164
          F       0.73      0.86      0.79       268
          R       0.49      0.20      0.28       125

avg / total       0.63      0.67      0.63       571

12/10/2017 02:14:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:40 [INFO] exp_shallowmodel: 
[[  0   1  10   3]
 [  0 127  24  13]
 [  0  28 230  10]
 [  0  47  53  25]]
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ******************** dstc2 - Round 7 
12/10/2017 02:14:40 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:40 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:41 [INFO] exp_shallowmodel: train time: 0.674s
12/10/2017 02:14:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:41 [INFO] exp_shallowmodel: accuracy:   0.629
12/10/2017 02:14:41 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 02:14:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.68      0.63       164
          F       0.69      0.85      0.76       268
          R       0.41      0.16      0.23       125

avg / total       0.58      0.63      0.59       571

12/10/2017 02:14:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:41 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 112  33  19]
 [  0  32 227   9]
 [  0  48  57  20]]
12/10/2017 02:14:41 [INFO] exp_shallowmodel: ******************** dstc2 - Round 8 
12/10/2017 02:14:41 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:41 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:42 [INFO] exp_shallowmodel: train time: 0.802s
12/10/2017 02:14:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:42 [INFO] exp_shallowmodel: accuracy:   0.632
12/10/2017 02:14:42 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 02:14:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.73      0.64       164
          F       0.69      0.82      0.75       268
          R       0.47      0.18      0.26       125

avg / total       0.59      0.63      0.59       571

12/10/2017 02:14:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:42 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 119  31  14]
 [  0  38 219  11]
 [  0  46  56  23]]
12/10/2017 02:14:42 [INFO] exp_shallowmodel: ******************** dstc2 - Round 9 
12/10/2017 02:14:42 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:14:42 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:43 [INFO] exp_shallowmodel: train time: 0.574s
12/10/2017 02:14:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:43 [INFO] exp_shallowmodel: accuracy:   0.618
12/10/2017 02:14:43 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 02:14:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.53      0.70      0.61       169
          F       0.70      0.82      0.75       271
          R       0.47      0.16      0.24       130

avg / total       0.58      0.62      0.58       586

12/10/2017 02:14:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:43 [INFO] exp_shallowmodel: 
[[  0   3  11   2]
 [  0 118  35  16]
 [  0  42 223   6]
 [  0  58  51  21]]
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 10 
12/10/2017 02:14:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:43 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:43 [INFO] exp_shallowmodel: train time: 0.591s
12/10/2017 02:14:43 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:14:43 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:14:43 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 02:14:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.74      0.65       164
          F       0.68      0.80      0.74       268
          R       0.41      0.16      0.23       125

avg / total       0.58      0.62      0.58       571

12/10/2017 02:14:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:43 [INFO] exp_shallowmodel: 
[[  0   0  12   2]
 [  0 121  30  13]
 [  0  39 215  14]
 [  0  48  57  20]]
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ******************** dstc2 - Round 11 
12/10/2017 02:14:43 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:43 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:44 [INFO] exp_shallowmodel: train time: 0.794s
12/10/2017 02:14:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:44 [INFO] exp_shallowmodel: accuracy:   0.620
12/10/2017 02:14:44 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 02:14:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.70      0.62       164
          F       0.68      0.81      0.74       268
          R       0.49      0.19      0.28       125

avg / total       0.59      0.62      0.58       571

12/10/2017 02:14:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:44 [INFO] exp_shallowmodel: 
[[  0   1  12   1]
 [  0 114  38  12]
 [  0  40 216  12]
 [  0  50  51  24]]
12/10/2017 02:14:44 [INFO] exp_shallowmodel: ******************** dstc2 - Round 12 
12/10/2017 02:14:44 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:44 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:45 [INFO] exp_shallowmodel: train time: 0.575s
12/10/2017 02:14:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:45 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 02:14:45 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 02:14:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.67      0.62       164
          F       0.67      0.81      0.73       268
          R       0.47      0.19      0.27       125

avg / total       0.58      0.62      0.58       571

12/10/2017 02:14:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:45 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 110  39  15]
 [  0  41 218   9]
 [  0  40  61  24]]
12/10/2017 02:14:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 13 
12/10/2017 02:14:45 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:45 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:45 [INFO] exp_shallowmodel: train time: 0.425s
12/10/2017 02:14:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:45 [INFO] exp_shallowmodel: accuracy:   0.658
12/10/2017 02:14:45 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 02:14:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.74      0.66       164
          F       0.72      0.85      0.78       268
          R       0.49      0.21      0.29       125

avg / total       0.62      0.66      0.62       571

12/10/2017 02:14:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:45 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 121  27  16]
 [  0  30 229   9]
 [  0  49  50  26]]
12/10/2017 02:14:45 [INFO] exp_shallowmodel: ******************** dstc2 - Round 14 
12/10/2017 02:14:45 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:45 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:46 [INFO] exp_shallowmodel: train time: 0.660s
12/10/2017 02:14:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:46 [INFO] exp_shallowmodel: accuracy:   0.658
12/10/2017 02:14:46 [INFO] exp_shallowmodel: f1_score:   0.449
12/10/2017 02:14:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.70      0.64       164
          F       0.72      0.84      0.78       268
          R       0.54      0.29      0.37       125

avg / total       0.63      0.66      0.63       571

12/10/2017 02:14:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:46 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 114  31  19]
 [  0  32 226  10]
 [  0  44  45  36]]
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 15 
12/10/2017 02:14:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:46 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:46 [INFO] exp_shallowmodel: train time: 0.519s
12/10/2017 02:14:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:46 [INFO] exp_shallowmodel: accuracy:   0.648
12/10/2017 02:14:46 [INFO] exp_shallowmodel: f1_score:   0.434
12/10/2017 02:14:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.70      0.62       164
          F       0.72      0.84      0.78       268
          R       0.56      0.24      0.34       125

avg / total       0.62      0.65      0.62       571

12/10/2017 02:14:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:46 [INFO] exp_shallowmodel: 
[[  0   2   9   3]
 [  0 115  36  13]
 [  0  35 225   8]
 [  0  54  41  30]]
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ******************** dstc2 - Round 16 
12/10/2017 02:14:46 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:46 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:47 [INFO] exp_shallowmodel: train time: 0.577s
12/10/2017 02:14:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:47 [INFO] exp_shallowmodel: accuracy:   0.655
12/10/2017 02:14:47 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 02:14:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.76      0.66       164
          F       0.73      0.85      0.79       268
          R       0.47      0.17      0.25       125

avg / total       0.61      0.65      0.61       571

12/10/2017 02:14:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:47 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 124  22  18]
 [  0  34 229   5]
 [  0  50  54  21]]
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 17 
12/10/2017 02:14:47 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:47 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:47 [INFO] exp_shallowmodel: train time: 0.744s
12/10/2017 02:14:47 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:47 [INFO] exp_shallowmodel: accuracy:   0.644
12/10/2017 02:14:47 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 02:14:47 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:47 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.74      0.66       164
          F       0.70      0.84      0.76       268
          R       0.48      0.18      0.26       125

avg / total       0.60      0.64      0.60       571

12/10/2017 02:14:47 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:47 [INFO] exp_shallowmodel: 
[[  0   1  11   2]
 [  0 122  30  12]
 [  0  34 224  10]
 [  0  46  57  22]]
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ******************** dstc2 - Round 18 
12/10/2017 02:14:47 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:47 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:47 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:47 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:47 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:47 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:48 [INFO] exp_shallowmodel: train time: 0.522s
12/10/2017 02:14:48 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:48 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:14:48 [INFO] exp_shallowmodel: f1_score:   0.392
12/10/2017 02:14:48 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:48 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.74      0.64       164
          F       0.69      0.82      0.75       268
          R       0.37      0.11      0.17       125

avg / total       0.57      0.62      0.58       571

12/10/2017 02:14:48 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:48 [INFO] exp_shallowmodel: 
[[  0   0  12   2]
 [  0 122  28  14]
 [  0  40 220   8]
 [  0  54  57  14]]
12/10/2017 02:14:48 [INFO] exp_shallowmodel: ******************** dstc2 - Round 19 
12/10/2017 02:14:48 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:14:48 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:48 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:48 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:48 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:48 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:48 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:49 [INFO] exp_shallowmodel: train time: 0.539s
12/10/2017 02:14:49 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:49 [INFO] exp_shallowmodel: accuracy:   0.642
12/10/2017 02:14:49 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 02:14:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.58      0.72      0.64       169
          F       0.70      0.83      0.76       271
          R       0.53      0.24      0.33       130

avg / total       0.61      0.64      0.61       586

12/10/2017 02:14:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:49 [INFO] exp_shallowmodel: 
[[  0   1  13   2]
 [  0 121  30  18]
 [  0  40 224   7]
 [  0  47  52  31]]
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 20 
12/10/2017 02:14:49 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:49 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:49 [INFO] exp_shallowmodel: train time: 0.637s
12/10/2017 02:14:49 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:14:49 [INFO] exp_shallowmodel: accuracy:   0.627
12/10/2017 02:14:49 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 02:14:49 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:49 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.71      0.62       164
          F       0.70      0.81      0.75       268
          R       0.48      0.19      0.27       125

avg / total       0.59      0.63      0.59       571

12/10/2017 02:14:49 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:49 [INFO] exp_shallowmodel: 
[[  0   2  12   0]
 [  0 117  33  14]
 [  0  39 217  12]
 [  0  53  48  24]]
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ******************** dstc2 - Round 21 
12/10/2017 02:14:49 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:49 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:49 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:49 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:49 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:49 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:50 [INFO] exp_shallowmodel: train time: 0.488s
12/10/2017 02:14:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:50 [INFO] exp_shallowmodel: accuracy:   0.648
12/10/2017 02:14:50 [INFO] exp_shallowmodel: f1_score:   0.438
12/10/2017 02:14:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.65      0.59       164
          F       0.72      0.85      0.78       268
          R       0.62      0.27      0.38       125

avg / total       0.63      0.65      0.62       571

12/10/2017 02:14:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:50 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 107  42  15]
 [  0  34 229   5]
 [  0  54  37  34]]
12/10/2017 02:14:50 [INFO] exp_shallowmodel: ******************** dstc2 - Round 22 
12/10/2017 02:14:50 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:50 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:50 [INFO] exp_shallowmodel: train time: 0.645s
12/10/2017 02:14:50 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:50 [INFO] exp_shallowmodel: accuracy:   0.629
12/10/2017 02:14:50 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 02:14:50 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:50 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.71      0.65       164
          F       0.69      0.84      0.75       268
          R       0.39      0.14      0.21       125

avg / total       0.58      0.63      0.59       571

12/10/2017 02:14:50 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:50 [INFO] exp_shallowmodel: 
[[  0   0  10   4]
 [  0 117  31  16]
 [  0  36 224   8]
 [  0  45  62  18]]
12/10/2017 02:14:50 [INFO] exp_shallowmodel: ******************** dstc2 - Round 23 
12/10/2017 02:14:50 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:50 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:50 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:50 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:50 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:50 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:50 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:51 [INFO] exp_shallowmodel: train time: 0.469s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: accuracy:   0.634
12/10/2017 02:14:51 [INFO] exp_shallowmodel: f1_score:   0.421
12/10/2017 02:14:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.73      0.65       164
          F       0.70      0.81      0.75       268
          R       0.45      0.21      0.28       125

avg / total       0.60      0.63      0.60       571

12/10/2017 02:14:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:51 [INFO] exp_shallowmodel: 
[[  0   0  12   2]
 [  0 119  28  17]
 [  0  38 217  13]
 [  0  46  53  26]]
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 24 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:51 [INFO] exp_shallowmodel: train time: 0.650s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:51 [INFO] exp_shallowmodel: accuracy:   0.616
12/10/2017 02:14:51 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 02:14:51 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:51 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.70      0.61       164
          F       0.71      0.81      0.76       268
          R       0.36      0.16      0.22       125

avg / total       0.57      0.62      0.58       571

12/10/2017 02:14:51 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:51 [INFO] exp_shallowmodel: 
[[  0   3   6   5]
 [  0 115  27  22]
 [  0  42 217   9]
 [  0  51  54  20]]
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ******************** dstc2 - Round 25 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:51 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:51 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:51 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:51 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:52 [INFO] exp_shallowmodel: train time: 0.546s
12/10/2017 02:14:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:52 [INFO] exp_shallowmodel: accuracy:   0.650
12/10/2017 02:14:52 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 02:14:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.71      0.65       164
          F       0.69      0.85      0.76       268
          R       0.56      0.22      0.32       125

avg / total       0.62      0.65      0.61       571

12/10/2017 02:14:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:52 [INFO] exp_shallowmodel: 
[[  0   4  10   0]
 [  0 116  33  15]
 [  0  34 227   7]
 [  0  40  57  28]]
12/10/2017 02:14:52 [INFO] exp_shallowmodel: ******************** dstc2 - Round 26 
12/10/2017 02:14:52 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:52 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:53 [INFO] exp_shallowmodel: train time: 0.848s
12/10/2017 02:14:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:53 [INFO] exp_shallowmodel: accuracy:   0.639
12/10/2017 02:14:53 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 02:14:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.68      0.63       164
          F       0.70      0.85      0.77       268
          R       0.46      0.20      0.28       125

avg / total       0.60      0.64      0.60       571

12/10/2017 02:14:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:53 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 112  34  18]
 [  0  31 228   9]
 [  0  48  52  25]]
12/10/2017 02:14:53 [INFO] exp_shallowmodel: ******************** dstc2 - Round 27 
12/10/2017 02:14:53 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:53 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:54 [INFO] exp_shallowmodel: train time: 0.720s
12/10/2017 02:14:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:54 [INFO] exp_shallowmodel: accuracy:   0.660
12/10/2017 02:14:54 [INFO] exp_shallowmodel: f1_score:   0.436
12/10/2017 02:14:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.75      0.67       164
          F       0.72      0.85      0.78       268
          R       0.53      0.21      0.30       125

avg / total       0.63      0.66      0.62       571

12/10/2017 02:14:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:54 [INFO] exp_shallowmodel: 
[[  0   1  13   0]
 [  0 123  26  15]
 [  0  32 228   8]
 [  0  48  51  26]]
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 28 
12/10/2017 02:14:54 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:54 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:54 [INFO] exp_shallowmodel: train time: 0.434s
12/10/2017 02:14:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:54 [INFO] exp_shallowmodel: accuracy:   0.644
12/10/2017 02:14:54 [INFO] exp_shallowmodel: f1_score:   0.425
12/10/2017 02:14:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.68      0.62       164
          F       0.72      0.85      0.78       268
          R       0.51      0.22      0.30       125

avg / total       0.61      0.64      0.61       571

12/10/2017 02:14:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:54 [INFO] exp_shallowmodel: 
[[  0   1   9   4]
 [  0 112  39  13]
 [  0  30 229   9]
 [  0  56  42  27]]
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ******************** dstc2 - Round 29 
12/10/2017 02:14:54 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:14:54 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:55 [INFO] exp_shallowmodel: train time: 0.542s
12/10/2017 02:14:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:55 [INFO] exp_shallowmodel: accuracy:   0.621
12/10/2017 02:14:55 [INFO] exp_shallowmodel: f1_score:   0.398
12/10/2017 02:14:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.59      0.74      0.66       169
          F       0.67      0.82      0.74       271
          R       0.41      0.13      0.20       130

avg / total       0.57      0.62      0.57       586

12/10/2017 02:14:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:55 [INFO] exp_shallowmodel: 
[[  0   1  13   2]
 [  0 125  31  13]
 [  0  40 222   9]
 [  0  46  67  17]]
12/10/2017 02:14:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 30 
12/10/2017 02:14:55 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:55 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:55 [INFO] exp_shallowmodel: train time: 0.520s
12/10/2017 02:14:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:55 [INFO] exp_shallowmodel: accuracy:   0.599
12/10/2017 02:14:55 [INFO] exp_shallowmodel: f1_score:   0.391
12/10/2017 02:14:55 [INFO] exp_shallowmodel: classification report:
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:14:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.54      0.63      0.58       164
          F       0.68      0.81      0.74       268
          R       0.37      0.18      0.25       125

avg / total       0.56      0.60      0.57       571

12/10/2017 02:14:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:55 [INFO] exp_shallowmodel: 
[[  0   1   8   5]
 [  0 103  38  23]
 [  0  41 216  11]
 [  0  47  55  23]]
12/10/2017 02:14:55 [INFO] exp_shallowmodel: ******************** dstc2 - Round 31 
12/10/2017 02:14:55 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:55 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:56 [INFO] exp_shallowmodel: train time: 0.823s
12/10/2017 02:14:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:56 [INFO] exp_shallowmodel: accuracy:   0.613
12/10/2017 02:14:56 [INFO] exp_shallowmodel: f1_score:   0.406
12/10/2017 02:14:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.68      0.62       164
          F       0.68      0.79      0.73       268
          R       0.44      0.20      0.27       125

avg / total       0.58      0.61      0.58       571

12/10/2017 02:14:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:56 [INFO] exp_shallowmodel: 
[[  0   0  12   2]
 [  0 112  29  23]
 [  0  48 213   7]
 [  0  40  60  25]]
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ******************** dstc2 - Round 32 
12/10/2017 02:14:56 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:56 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:57 [INFO] exp_shallowmodel: train time: 0.744s
12/10/2017 02:14:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:57 [INFO] exp_shallowmodel: accuracy:   0.627
12/10/2017 02:14:57 [INFO] exp_shallowmodel: f1_score:   0.407
12/10/2017 02:14:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.74      0.66       164
          F       0.68      0.81      0.74       268
          R       0.38      0.16      0.22       125

avg / total       0.58      0.63      0.59       571

12/10/2017 02:14:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:57 [INFO] exp_shallowmodel: 
[[  0   1  12   1]
 [  0 121  24  19]
 [  0  38 217  13]
 [  0  41  64  20]]
12/10/2017 02:14:57 [INFO] exp_shallowmodel: ******************** dstc2 - Round 33 
12/10/2017 02:14:57 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:57 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:58 [INFO] exp_shallowmodel: train time: 0.799s
12/10/2017 02:14:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:58 [INFO] exp_shallowmodel: accuracy:   0.655
12/10/2017 02:14:58 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 02:14:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.61      0.74      0.67       164
          F       0.72      0.87      0.78       268
          R       0.44      0.17      0.24       125

avg / total       0.61      0.65      0.61       571

12/10/2017 02:14:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:58 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 121  30  13]
 [  0  24 232  12]
 [  0  52  52  21]]
12/10/2017 02:14:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 34 
12/10/2017 02:14:58 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:58 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:58 [INFO] exp_shallowmodel: train time: 0.537s
12/10/2017 02:14:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:58 [INFO] exp_shallowmodel: accuracy:   0.653
12/10/2017 02:14:58 [INFO] exp_shallowmodel: f1_score:   0.418
12/10/2017 02:14:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.56      0.77      0.65       164
          F       0.73      0.85      0.78       268
          R       0.59      0.15      0.24       125

avg / total       0.63      0.65      0.61       571

12/10/2017 02:14:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:58 [INFO] exp_shallowmodel: 
[[  0   2  12   0]
 [  0 126  33   5]
 [  0  32 228   8]
 [  0  65  41  19]]
12/10/2017 02:14:58 [INFO] exp_shallowmodel: ******************** dstc2 - Round 35 
12/10/2017 02:14:58 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:58 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:14:59 [INFO] exp_shallowmodel: train time: 0.817s
12/10/2017 02:14:59 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:14:59 [INFO] exp_shallowmodel: accuracy:   0.669
12/10/2017 02:14:59 [INFO] exp_shallowmodel: f1_score:   0.444
12/10/2017 02:14:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:14:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.57      0.79      0.66       164
          F       0.76      0.84      0.80       268
          R       0.57      0.22      0.31       125

avg / total       0.65      0.67      0.63       571

12/10/2017 02:14:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:14:59 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  0 129  24  11]
 [  0  36 226   6]
 [  0  57  41  27]]
12/10/2017 02:14:59 [INFO] exp_shallowmodel: ******************** dstc2 - Round 36 
12/10/2017 02:14:59 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:14:59 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:14:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:14:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:14:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:14:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:14:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:00 [INFO] exp_shallowmodel: train time: 0.629s
12/10/2017 02:15:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:00 [INFO] exp_shallowmodel: accuracy:   0.643
12/10/2017 02:15:00 [INFO] exp_shallowmodel: f1_score:   0.430
12/10/2017 02:15:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.74      0.65       164
          F       0.67      0.82      0.74       268
          R       0.69      0.22      0.33       125

avg / total       0.64      0.64      0.61       571

12/10/2017 02:15:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:00 [INFO] exp_shallowmodel: 
[[  0   2  12   0]
 [  0 121  36   7]
 [  0  44 219   5]
 [  0  40  58  27]]
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 37 
12/10/2017 02:15:00 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:00 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:00 [INFO] exp_shallowmodel: train time: 0.670s
12/10/2017 02:15:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:00 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:15:00 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 02:15:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.66      0.60       164
          F       0.70      0.84      0.76       268
          R       0.46      0.18      0.26       125

avg / total       0.58      0.62      0.59       571

12/10/2017 02:15:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:00 [INFO] exp_shallowmodel: 
[[  0   1  12   1]
 [  0 108  34  22]
 [  0  39 225   4]
 [  0  50  52  23]]
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ******************** dstc2 - Round 38 
12/10/2017 02:15:00 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:00 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:01 [INFO] exp_shallowmodel: train time: 0.484s
12/10/2017 02:15:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:01 [INFO] exp_shallowmodel: accuracy:   0.636
12/10/2017 02:15:01 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 02:15:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.58      0.72      0.64       164
          F       0.70      0.82      0.76       268
          R       0.48      0.20      0.28       125

avg / total       0.60      0.64      0.60       571

12/10/2017 02:15:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:01 [INFO] exp_shallowmodel: 
[[  0   1  11   2]
 [  0 118  29  17]
 [  0  40 220   8]
 [  0  46  54  25]]
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 39 
12/10/2017 02:15:01 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:15:01 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:01 [INFO] exp_shallowmodel: train time: 0.491s
12/10/2017 02:15:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:01 [INFO] exp_shallowmodel: accuracy:   0.618
12/10/2017 02:15:01 [INFO] exp_shallowmodel: f1_score:   0.411
12/10/2017 02:15:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.56      0.69      0.62       169
          F       0.68      0.81      0.74       271
          R       0.45      0.21      0.28       130

avg / total       0.58      0.62      0.58       586

12/10/2017 02:15:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:01 [INFO] exp_shallowmodel: 
[[  0   3  11   2]
 [  0 116  35  18]
 [  0  39 219  13]
 [  0  48  55  27]]
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ******************** dstc2 - Round 40 
12/10/2017 02:15:01 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:01 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:02 [INFO] exp_shallowmodel: train time: 0.731s
12/10/2017 02:15:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:02 [INFO] exp_shallowmodel: accuracy:   0.650
12/10/2017 02:15:02 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 02:15:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.74      0.66       164
          F       0.70      0.83      0.76       268
          R       0.56      0.22      0.31       125

avg / total       0.62      0.65      0.61       571

12/10/2017 02:15:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:02 [INFO] exp_shallowmodel: 
[[  0   2  11   1]
 [  0 121  29  14]
 [  0  39 223   6]
 [  0  41  57  27]]
12/10/2017 02:15:02 [INFO] exp_shallowmodel: ******************** dstc2 - Round 41 
12/10/2017 02:15:02 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:02 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:03 [INFO] exp_shallowmodel: train time: 0.596s
12/10/2017 02:15:03 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:15:03 [INFO] exp_shallowmodel: accuracy:   0.630
12/10/2017 02:15:03 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:15:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.55      0.73      0.63       164
          F       0.71      0.82      0.76       268
          R       0.48      0.17      0.25       125

avg / total       0.59      0.63      0.59       571

12/10/2017 02:15:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:03 [INFO] exp_shallowmodel: 
[[  0   3   8   3]
 [  0 119  32  13]
 [  0  41 220   7]
 [  0  53  51  21]]
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 42 
12/10/2017 02:15:03 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:03 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:03 [INFO] exp_shallowmodel: train time: 0.650s
12/10/2017 02:15:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:03 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 02:15:03 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 02:15:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.51      0.66      0.58       164
          F       0.70      0.80      0.75       268
          R       0.45      0.18      0.25       125

avg / total       0.57      0.61      0.57       571

12/10/2017 02:15:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:03 [INFO] exp_shallowmodel: 
[[  0   3  10   1]
 [  0 109  37  18]
 [  1  44 215   8]
 [  0  56  47  22]]
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ******************** dstc2 - Round 43 
12/10/2017 02:15:03 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:03 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:04 [INFO] exp_shallowmodel: train time: 0.561s
12/10/2017 02:15:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:04 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 02:15:04 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:15:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.53      0.71      0.61       164
          F       0.70      0.80      0.75       268
          R       0.50      0.19      0.28       125

avg / total       0.59      0.62      0.59       571

12/10/2017 02:15:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:04 [INFO] exp_shallowmodel: 
[[  0   0  12   2]
 [  0 117  31  16]
 [  0  48 214   6]
 [  0  54  47  24]]
12/10/2017 02:15:04 [INFO] exp_shallowmodel: ******************** dstc2 - Round 44 
12/10/2017 02:15:04 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:04 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:05 [INFO] exp_shallowmodel: train time: 0.789s
12/10/2017 02:15:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:05 [INFO] exp_shallowmodel: accuracy:   0.650
12/10/2017 02:15:05 [INFO] exp_shallowmodel: f1_score:   0.423
12/10/2017 02:15:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.71      0.65       164
          F       0.70      0.86      0.77       268
          R       0.49      0.18      0.27       125

avg / total       0.61      0.65      0.61       571

12/10/2017 02:15:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:05 [INFO] exp_shallowmodel: 
[[  0   3   9   2]
 [  0 117  33  14]
 [  0  29 231   8]
 [  0  46  56  23]]
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 45 
12/10/2017 02:15:05 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:05 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:05 [INFO] exp_shallowmodel: train time: 0.632s
12/10/2017 02:15:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:05 [INFO] exp_shallowmodel: accuracy:   0.641
12/10/2017 02:15:05 [INFO] exp_shallowmodel: f1_score:   0.420
12/10/2017 02:15:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.68      0.63       164
          F       0.69      0.86      0.77       268
          R       0.50      0.20      0.29       125

avg / total       0.60      0.64      0.60       571

12/10/2017 02:15:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:05 [INFO] exp_shallowmodel: 
[[  0   1  11   2]
 [  0 111  40  13]
 [  0  28 230  10]
 [  0  48  52  25]]
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ******************** dstc2 - Round 46 
12/10/2017 02:15:05 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:05 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:06 [INFO] exp_shallowmodel: train time: 0.593s
12/10/2017 02:15:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:06 [INFO] exp_shallowmodel: accuracy:   0.643
12/10/2017 02:15:06 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 02:15:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.59      0.75      0.66       164
          F       0.72      0.83      0.77       268
          R       0.42      0.18      0.25       125

avg / total       0.60      0.64      0.60       571

12/10/2017 02:15:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:06 [INFO] exp_shallowmodel: 
[[  0   0  13   1]
 [  0 123  23  18]
 [  0  34 222  12]
 [  0  51  52  22]]
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 47 
12/10/2017 02:15:06 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:06 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:06 [INFO] exp_shallowmodel: train time: 0.664s
12/10/2017 02:15:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:06 [INFO] exp_shallowmodel: accuracy:   0.650
12/10/2017 02:15:06 [INFO] exp_shallowmodel: f1_score:   0.437
12/10/2017 02:15:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.73      0.66       164
          F       0.70      0.83      0.76       268
          R       0.56      0.24      0.34       125

avg / total       0.62      0.65      0.62       571

12/10/2017 02:15:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:06 [INFO] exp_shallowmodel: 
[[  0   2  10   2]
 [  0 119  33  12]
 [  0  36 222  10]
 [  0  41  54  30]]
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ******************** dstc2 - Round 48 
12/10/2017 02:15:06 [INFO] exp_shallowmodel: #(data) = 4583
12/10/2017 02:15:06 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:07 [INFO] exp_shallowmodel: train time: 0.461s
12/10/2017 02:15:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:07 [INFO] exp_shallowmodel: accuracy:   0.646
12/10/2017 02:15:07 [INFO] exp_shallowmodel: f1_score:   0.429
12/10/2017 02:15:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        14
          C       0.60      0.72      0.65       164
          F       0.70      0.84      0.76       268
          R       0.50      0.22      0.30       125

avg / total       0.61      0.65      0.61       571

12/10/2017 02:15:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:07 [INFO] exp_shallowmodel: 
[[  0   0  12   2]
 [  0 118  30  16]
 [  0  35 224   9]
 [  0  45  53  27]]
12/10/2017 02:15:07 [INFO] exp_shallowmodel: ******************** dstc2 - Round 49 
12/10/2017 02:15:07 [INFO] exp_shallowmodel: #(data) = 4568
12/10/2017 02:15:07 [INFO] exp_shallowmodel: #(feature) = 31
12/10/2017 02:15:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:07 [INFO] exp_shallowmodel: train time: 0.474s
12/10/2017 02:15:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:07 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:15:07 [INFO] exp_shallowmodel: f1_score:   0.413
12/10/2017 02:15:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        16
          C       0.57      0.72      0.63       169
          F       0.70      0.80      0.75       271
          R       0.43      0.20      0.27       130

avg / total       0.58      0.62      0.59       586

12/10/2017 02:15:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:07 [INFO] exp_shallowmodel: 
[[  0   2  12   2]
 [  0 121  29  19]
 [  0  40 218  13]
 [  0  51  53  26]]
12/10/2017 02:15:11 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:15:11 [INFO] task_runner: context=current, feature=1-basic
12/10/2017 02:15:11 [INFO] task_runner: retained feature numbers=[1, 2.1, 3, 2.2]
12/10/2017 02:15:11 [INFO] task_runner: #(data)=5934
12/10/2017 02:15:11 [INFO] task_runner: #(feature)=30
12/10/2017 02:15:11 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 0 
12/10/2017 02:15:11 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:11 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:11 [INFO] exp_shallowmodel: train time: 0.386s
12/10/2017 02:15:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:11 [INFO] exp_shallowmodel: accuracy:   0.632
12/10/2017 02:15:11 [INFO] exp_shallowmodel: f1_score:   0.439
12/10/2017 02:15:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.57      0.63      0.60       169
          F       0.68      0.85      0.76       281
          R       0.53      0.21      0.30       122

avg / total       0.63      0.63      0.60       592

12/10/2017 02:15:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:11 [INFO] exp_shallowmodel: 
[[  1   0  17   2]
 [  0 107  46  16]
 [  0  36 240   5]
 [  0  46  50  26]]
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ******************** dstc3 - Round 1 
12/10/2017 02:15:11 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:11 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:12 [INFO] exp_shallowmodel: train time: 0.450s
12/10/2017 02:15:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:12 [INFO] exp_shallowmodel: accuracy:   0.627
12/10/2017 02:15:12 [INFO] exp_shallowmodel: f1_score:   0.445
12/10/2017 02:15:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.55      0.64      0.59       169
          F       0.70      0.85      0.77       281
          R       0.42      0.16      0.24       122

avg / total       0.61      0.63      0.59       592

12/10/2017 02:15:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:12 [INFO] exp_shallowmodel: 
[[  2   4  13   1]
 [  0 109  43  17]
 [  0  31 240  10]
 [  0  54  48  20]]
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 2 
12/10/2017 02:15:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:12 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:12 [INFO] exp_shallowmodel: train time: 0.520s
12/10/2017 02:15:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:12 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 02:15:12 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 02:15:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.64      0.59       169
          F       0.68      0.84      0.75       281
          R       0.45      0.16      0.24       122

avg / total       0.57      0.61      0.57       592

12/10/2017 02:15:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:12 [INFO] exp_shallowmodel: 
[[  0   0  18   2]
 [  0 108  47  14]
 [  0  37 236   8]
 [  0  54  48  20]]
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ******************** dstc3 - Round 3 
12/10/2017 02:15:12 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:12 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:13 [INFO] exp_shallowmodel: train time: 0.217s
12/10/2017 02:15:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:13 [INFO] exp_shallowmodel: accuracy:   0.652
12/10/2017 02:15:13 [INFO] exp_shallowmodel: f1_score:   0.445
12/10/2017 02:15:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.60      0.73      0.66       169
          F       0.71      0.86      0.78       281
          R       0.45      0.17      0.25       122

avg / total       0.63      0.65      0.61       592

12/10/2017 02:15:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:13 [INFO] exp_shallowmodel: 
[[  1   3  15   1]
 [  0 123  29  17]
 [  0  32 241   8]
 [  0  46  55  21]]
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 4 
12/10/2017 02:15:13 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:13 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:13 [INFO] exp_shallowmodel: train time: 0.282s
12/10/2017 02:15:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:13 [INFO] exp_shallowmodel: accuracy:   0.605
12/10/2017 02:15:13 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 02:15:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.52      0.64      0.57       169
          F       0.68      0.83      0.75       281
          R       0.42      0.14      0.21       122

avg / total       0.56      0.60      0.56       592

12/10/2017 02:15:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:13 [INFO] exp_shallowmodel: 
[[  0   2  17   1]
 [  0 109  47  13]
 [  0  40 232   9]
 [  0  60  45  17]]
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 5 
12/10/2017 02:15:13 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:13 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:13 [INFO] exp_shallowmodel: train time: 0.442s
12/10/2017 02:15:13 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:15:13 [INFO] exp_shallowmodel: accuracy:   0.642
12/10/2017 02:15:13 [INFO] exp_shallowmodel: f1_score:   0.422
12/10/2017 02:15:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.56      0.70      0.62       169
          F       0.71      0.84      0.77       281
          R       0.53      0.20      0.30       122

avg / total       0.61      0.64      0.60       592

12/10/2017 02:15:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:13 [INFO] exp_shallowmodel: 
[[  0   3  15   2]
 [  0 119  36  14]
 [  0  39 236   6]
 [  0  51  46  25]]
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ******************** dstc3 - Round 6 
12/10/2017 02:15:13 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:13 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:14 [INFO] exp_shallowmodel: train time: 0.452s
12/10/2017 02:15:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:14 [INFO] exp_shallowmodel: accuracy:   0.633
12/10/2017 02:15:14 [INFO] exp_shallowmodel: f1_score:   0.425
12/10/2017 02:15:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.56      0.69      0.62       169
          F       0.71      0.85      0.78       281
          R       0.38      0.15      0.21       122

avg / total       0.61      0.63      0.59       592

12/10/2017 02:15:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:14 [INFO] exp_shallowmodel: 
[[  1   5  11   3]
 [  0 116  37  16]
 [  0  30 240  11]
 [  0  56  48  18]]
12/10/2017 02:15:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 7 
12/10/2017 02:15:14 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:14 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:14 [INFO] exp_shallowmodel: train time: 0.301s
12/10/2017 02:15:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:14 [INFO] exp_shallowmodel: accuracy:   0.596
12/10/2017 02:15:14 [INFO] exp_shallowmodel: f1_score:   0.382
12/10/2017 02:15:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.51      0.64      0.57       169
          F       0.68      0.80      0.74       281
          R       0.38      0.16      0.22       122

avg / total       0.55      0.60      0.56       592

12/10/2017 02:15:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:14 [INFO] exp_shallowmodel: 
[[  0   2  16   2]
 [  0 108  40  21]
 [  0  47 226   8]
 [  0  54  49  19]]
12/10/2017 02:15:14 [INFO] exp_shallowmodel: ******************** dstc3 - Round 8 
12/10/2017 02:15:14 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:14 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:14 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:14 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:14 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:14 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:14 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:14 [INFO] exp_shallowmodel: train time: 0.281s
12/10/2017 02:15:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:14 [INFO] exp_shallowmodel: accuracy:   0.603
12/10/2017 02:15:14 [INFO] exp_shallowmodel: f1_score:   0.453
12/10/2017 02:15:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.15      0.25        20
          C       0.53      0.56      0.54       169
          F       0.66      0.84      0.74       281
          R       0.45      0.20      0.28       122

avg / total       0.58      0.60      0.57       592

12/10/2017 02:15:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:14 [INFO] exp_shallowmodel: 
[[  3   0  15   2]
 [  0  94  59  16]
 [  1  33 235  12]
 [  0  51  46  25]]
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 9 
12/10/2017 02:15:15 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:15:15 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:15 [INFO] exp_shallowmodel: train time: 0.362s
12/10/2017 02:15:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:15 [INFO] exp_shallowmodel: accuracy:   0.627
12/10/2017 02:15:15 [INFO] exp_shallowmodel: f1_score:   0.414
12/10/2017 02:15:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.58      0.64      0.61       172
          F       0.68      0.86      0.76       283
          R       0.45      0.21      0.29       123

avg / total       0.57      0.63      0.59       606

12/10/2017 02:15:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:15 [INFO] exp_shallowmodel: 
[[  0   3  19   6]
 [  0 110  49  13]
 [  0  26 244  13]
 [  0  50  47  26]]
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 10 
12/10/2017 02:15:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:15 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:15 [INFO] exp_shallowmodel: train time: 0.307s
12/10/2017 02:15:15 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:15 [INFO] exp_shallowmodel: accuracy:   0.628
12/10/2017 02:15:15 [INFO] exp_shallowmodel: f1_score:   0.416
12/10/2017 02:15:15 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:15 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.55      0.65      0.60       169
          F       0.69      0.84      0.76       281
          R       0.52      0.22      0.31       122

avg / total       0.59      0.63      0.59       592

12/10/2017 02:15:15 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:15 [INFO] exp_shallowmodel: 
[[  0   3  15   2]
 [  0 110  42  17]
 [  0  40 235   6]
 [  0  46  49  27]]
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ******************** dstc3 - Round 11 
12/10/2017 02:15:15 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:15 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:15 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:15 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:15 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:15 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:16 [INFO] exp_shallowmodel: train time: 0.324s
12/10/2017 02:15:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:16 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 02:15:16 [INFO] exp_shallowmodel: f1_score:   0.393
12/10/2017 02:15:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.54      0.66      0.59       169
          F       0.69      0.83      0.76       281
          R       0.40      0.16      0.22       122

avg / total       0.57      0.61      0.57       592

12/10/2017 02:15:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:16 [INFO] exp_shallowmodel: 
[[  0   2  15   3]
 [  0 111  43  15]
 [  0  37 234  10]
 [  0  57  46  19]]
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 12 
12/10/2017 02:15:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:16 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:16 [INFO] exp_shallowmodel: train time: 0.267s
12/10/2017 02:15:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:16 [INFO] exp_shallowmodel: accuracy:   0.617
12/10/2017 02:15:16 [INFO] exp_shallowmodel: f1_score:   0.410
12/10/2017 02:15:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.53      0.65      0.59       169
          F       0.70      0.85      0.76       281
          R       0.37      0.13      0.19       122

avg / total       0.59      0.62      0.57       592

12/10/2017 02:15:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:16 [INFO] exp_shallowmodel: 
[[  1   2  15   2]
 [  0 110  40  19]
 [  0  37 238   6]
 [  0  57  49  16]]
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 13 
12/10/2017 02:15:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:16 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:16 [INFO] exp_shallowmodel: train time: 0.448s
12/10/2017 02:15:16 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:16 [INFO] exp_shallowmodel: accuracy:   0.625
12/10/2017 02:15:16 [INFO] exp_shallowmodel: f1_score:   0.458
12/10/2017 02:15:16 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:16 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.15      0.26        20
          C       0.54      0.63      0.58       169
          F       0.69      0.86      0.77       281
          R       0.42      0.15      0.22       122

avg / total       0.60      0.62      0.59       592

12/10/2017 02:15:16 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:16 [INFO] exp_shallowmodel: 
[[  3   1  14   2]
 [  0 107  47  15]
 [  0  31 242   8]
 [  0  58  46  18]]
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ******************** dstc3 - Round 14 
12/10/2017 02:15:16 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:16 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:16 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:16 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:16 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:16 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:17 [INFO] exp_shallowmodel: train time: 0.428s
12/10/2017 02:15:17 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:17 [INFO] exp_shallowmodel: accuracy:   0.659
12/10/2017 02:15:17 [INFO] exp_shallowmodel: f1_score:   0.453
12/10/2017 02:15:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.59      0.70      0.64       169
          F       0.71      0.88      0.79       281
          R       0.53      0.20      0.29       122

avg / total       0.65      0.66      0.62       592

12/10/2017 02:15:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:17 [INFO] exp_shallowmodel: 
[[  1   0  15   4]
 [  0 118  40  11]
 [  0  28 247   6]
 [  0  54  44  24]]
12/10/2017 02:15:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 15 
12/10/2017 02:15:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:17 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:17 [INFO] exp_shallowmodel: train time: 0.442s
12/10/2017 02:15:17 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:17 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 02:15:17 [INFO] exp_shallowmodel: f1_score:   0.400
12/10/2017 02:15:17 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:17 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.55      0.63      0.59       169
          F       0.68      0.83      0.75       281
          R       0.43      0.19      0.26       122

avg / total       0.57      0.61      0.58       592

12/10/2017 02:15:17 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:17 [INFO] exp_shallowmodel: 
[[  0   3  13   4]
 [  0 107  47  15]
 [  0  36 234  11]
 [  0  49  50  23]]
12/10/2017 02:15:17 [INFO] exp_shallowmodel: ******************** dstc3 - Round 16 
12/10/2017 02:15:17 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:17 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:17 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:17 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:17 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:17 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:17 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:18 [INFO] exp_shallowmodel: train time: 0.471s
12/10/2017 02:15:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:18 [INFO] exp_shallowmodel: accuracy:   0.598
12/10/2017 02:15:18 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:15:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.52      0.62      0.56       169
          F       0.69      0.81      0.74       281
          R       0.34      0.15      0.21       122

avg / total       0.58      0.60      0.56       592

12/10/2017 02:15:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:18 [INFO] exp_shallowmodel: 
[[  2   1  16   1]
 [  0 105  44  20]
 [  0  38 229  14]
 [  0  59  45  18]]
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 17 
12/10/2017 02:15:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:18 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:18 [INFO] exp_shallowmodel: train time: 0.324s
12/10/2017 02:15:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:18 [INFO] exp_shallowmodel: accuracy:   0.611
12/10/2017 02:15:18 [INFO] exp_shallowmodel: f1_score:   0.403
12/10/2017 02:15:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.56      0.68      0.61       169
          F       0.66      0.80      0.72       281
          R       0.50      0.19      0.27       122

avg / total       0.58      0.61      0.57       592

12/10/2017 02:15:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:18 [INFO] exp_shallowmodel: 
[[  0   1  18   1]
 [  0 115  40  14]
 [  1  48 224   8]
 [  0  41  58  23]]
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 18 
12/10/2017 02:15:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:18 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:18 [INFO] exp_shallowmodel: train time: 0.290s
12/10/2017 02:15:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:18 [INFO] exp_shallowmodel: accuracy:   0.617
12/10/2017 02:15:18 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 02:15:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.58      0.64      0.61       169
          F       0.66      0.83      0.73       281
          R       0.44      0.19      0.26       122

avg / total       0.60      0.62      0.58       592

12/10/2017 02:15:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:18 [INFO] exp_shallowmodel: 
[[  1   1  15   3]
 [  0 109  46  14]
 [  0  37 232  12]
 [  0  40  59  23]]
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 19 
12/10/2017 02:15:18 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:15:18 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:18 [INFO] exp_shallowmodel: train time: 0.229s
12/10/2017 02:15:18 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:18 [INFO] exp_shallowmodel: accuracy:   0.619
12/10/2017 02:15:18 [INFO] exp_shallowmodel: f1_score:   0.405
12/10/2017 02:15:18 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:18 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.56      0.65      0.60       172
          F       0.68      0.85      0.75       283
          R       0.46      0.19      0.27       123

avg / total       0.57      0.62      0.58       606

12/10/2017 02:15:18 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:18 [INFO] exp_shallowmodel: 
[[  0   6  21   1]
 [  0 112  48  12]
 [  0  29 240  14]
 [  1  54  45  23]]
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ******************** dstc3 - Round 20 
12/10/2017 02:15:18 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:18 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:18 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:18 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:18 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:18 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:19 [INFO] exp_shallowmodel: train time: 0.369s
12/10/2017 02:15:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:19 [INFO] exp_shallowmodel: accuracy:   0.632
12/10/2017 02:15:19 [INFO] exp_shallowmodel: f1_score:   0.448
12/10/2017 02:15:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.55      0.63      0.59       169
          F       0.70      0.87      0.78       281
          R       0.46      0.17      0.25       122

avg / total       0.62      0.63      0.59       592

12/10/2017 02:15:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:19 [INFO] exp_shallowmodel: 
[[  2   1  15   2]
 [  0 107  46  16]
 [  0  30 244   7]
 [  0  58  43  21]]
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 21 
12/10/2017 02:15:19 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:19 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:19 [INFO] exp_shallowmodel: train time: 0.418s
12/10/2017 02:15:19 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:19 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:15:19 [INFO] exp_shallowmodel: f1_score:   0.402
12/10/2017 02:15:19 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:19 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.55      0.63      0.59       169
          F       0.68      0.86      0.76       281
          R       0.47      0.18      0.26       122

avg / total       0.58      0.62      0.58       592

12/10/2017 02:15:19 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:19 [INFO] exp_shallowmodel: 
[[  0   3  15   2]
 [  0 106  45  18]
 [  0  35 241   5]
 [  0  47  53  22]]
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ******************** dstc3 - Round 22 
12/10/2017 02:15:19 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:19 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:19 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:19 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:19 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:19 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:20 [INFO] exp_shallowmodel: train time: 0.303s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: accuracy:   0.618
12/10/2017 02:15:20 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 02:15:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.57      0.66      0.61       169
          F       0.67      0.81      0.73       281
          R       0.49      0.20      0.29       122

avg / total       0.58      0.62      0.58       592

12/10/2017 02:15:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:20 [INFO] exp_shallowmodel: 
[[  0   1  16   3]
 [  0 112  45  12]
 [  0  41 229  11]
 [  0  44  53  25]]
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 23 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:20 [INFO] exp_shallowmodel: train time: 0.358s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: accuracy:   0.633
12/10/2017 02:15:20 [INFO] exp_shallowmodel: f1_score:   0.436
12/10/2017 02:15:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.55      0.70      0.61       169
          F       0.71      0.83      0.76       281
          R       0.50      0.19      0.27       122

avg / total       0.63      0.63      0.60       592

12/10/2017 02:15:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:20 [INFO] exp_shallowmodel: 
[[  1   1  15   3]
 [  0 118  42   9]
 [  0  37 233  11]
 [  0  60  39  23]]
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 24 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:20 [INFO] exp_shallowmodel: train time: 0.280s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:20 [INFO] exp_shallowmodel: accuracy:   0.625
12/10/2017 02:15:20 [INFO] exp_shallowmodel: f1_score:   0.445
12/10/2017 02:15:20 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:20 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.56      0.65      0.60       169
          F       0.69      0.85      0.76       281
          R       0.41      0.16      0.23       122

avg / total       0.61      0.62      0.59       592

12/10/2017 02:15:20 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:20 [INFO] exp_shallowmodel: 
[[  2   3  13   2]
 [  0 110  45  14]
 [  0  30 238  13]
 [  0  53  49  20]]
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ******************** dstc3 - Round 25 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:20 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:20 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:20 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:20 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:21 [INFO] exp_shallowmodel: train time: 0.332s
12/10/2017 02:15:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:21 [INFO] exp_shallowmodel: accuracy:   0.617
12/10/2017 02:15:21 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 02:15:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.63      0.57       169
          F       0.69      0.85      0.76       281
          R       0.43      0.16      0.24       122

avg / total       0.57      0.62      0.57       592

12/10/2017 02:15:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:21 [INFO] exp_shallowmodel: 
[[  0   2  16   2]
 [  0 106  47  16]
 [  0  34 239   8]
 [  0  58  44  20]]
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 26 
12/10/2017 02:15:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:21 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:21 [INFO] exp_shallowmodel: train time: 0.430s
12/10/2017 02:15:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:21 [INFO] exp_shallowmodel: accuracy:   0.640
12/10/2017 02:15:21 [INFO] exp_shallowmodel: f1_score:   0.442
12/10/2017 02:15:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.60      0.69      0.64       169
          F       0.68      0.85      0.75       281
          R       0.50      0.19      0.27       122

avg / total       0.63      0.64      0.60       592

12/10/2017 02:15:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:21 [INFO] exp_shallowmodel: 
[[  1   2  16   1]
 [  0 117  43   9]
 [  0  30 238  13]
 [  0  46  53  23]]
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 27 
12/10/2017 02:15:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:21 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:21 [INFO] exp_shallowmodel: train time: 0.461s
12/10/2017 02:15:21 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:21 [INFO] exp_shallowmodel: accuracy:   0.633
12/10/2017 02:15:21 [INFO] exp_shallowmodel: f1_score:   0.415
12/10/2017 02:15:21 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:21 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.56      0.69      0.62       169
          F       0.70      0.83      0.76       281
          R       0.49      0.20      0.28       122

avg / total       0.59      0.63      0.60       592

12/10/2017 02:15:21 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:21 [INFO] exp_shallowmodel: 
[[  0   3  15   2]
 [  0 117  36  16]
 [  0  40 234   7]
 [  0  50  48  24]]
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ******************** dstc3 - Round 28 
12/10/2017 02:15:21 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:21 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:21 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:21 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:21 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:21 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:22 [INFO] exp_shallowmodel: train time: 0.288s
12/10/2017 02:15:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:22 [INFO] exp_shallowmodel: accuracy:   0.622
12/10/2017 02:15:22 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 02:15:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.55      0.63      0.59       169
          F       0.69      0.85      0.76       281
          R       0.42      0.19      0.26       122

avg / total       0.61      0.62      0.59       592

12/10/2017 02:15:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:22 [INFO] exp_shallowmodel: 
[[  1   0  15   4]
 [  0 106  43  20]
 [  0  35 238   8]
 [  0  52  47  23]]
12/10/2017 02:15:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 29 
12/10/2017 02:15:22 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:15:22 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:22 [INFO] exp_shallowmodel: train time: 0.389s
12/10/2017 02:15:22 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:22 [INFO] exp_shallowmodel: accuracy:   0.606
12/10/2017 02:15:22 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:15:22 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:22 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.07        28
          C       0.55      0.63      0.59       172
          F       0.67      0.83      0.74       283
          R       0.40      0.17      0.24       123

avg / total       0.59      0.61      0.56       606

12/10/2017 02:15:22 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:22 [INFO] exp_shallowmodel: 
[[  1   5  20   2]
 [  0 109  46  17]
 [  0  34 236  13]
 [  0  51  51  21]]
12/10/2017 02:15:22 [INFO] exp_shallowmodel: ******************** dstc3 - Round 30 
12/10/2017 02:15:22 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:22 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:22 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:22 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:22 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:22 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:22 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:23 [INFO] exp_shallowmodel: train time: 0.389s
12/10/2017 02:15:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:23 [INFO] exp_shallowmodel: accuracy:   0.635
12/10/2017 02:15:23 [INFO] exp_shallowmodel: f1_score:   0.429
12/10/2017 02:15:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.60      0.70      0.64       169
          F       0.68      0.85      0.76       281
          R       0.42      0.15      0.22       122

avg / total       0.61      0.64      0.59       592

12/10/2017 02:15:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:23 [INFO] exp_shallowmodel: 
[[  1   0  16   3]
 [  0 118  40  11]
 [  0  31 239  11]
 [  0  48  56  18]]
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 31 
12/10/2017 02:15:23 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:23 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:23 [INFO] exp_shallowmodel: train time: 0.338s
12/10/2017 02:15:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:23 [INFO] exp_shallowmodel: accuracy:   0.635
12/10/2017 02:15:23 [INFO] exp_shallowmodel: f1_score:   0.426
12/10/2017 02:15:23 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.59      0.70      0.64       169
          F       0.70      0.85      0.77       281
          R       0.35      0.14      0.20       122

avg / total       0.61      0.64      0.59       592

12/10/2017 02:15:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:23 [INFO] exp_shallowmodel: 
[[  1   1  15   3]
 [  0 118  33  18]
 [  0  30 240  11]
 [  0  52  53  17]]
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 32 
12/10/2017 02:15:23 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:23 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:23 [INFO] exp_shallowmodel: train time: 0.460s
12/10/2017 02:15:23 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:23 [INFO] exp_shallowmodel: accuracy:   0.637
12/10/2017 02:15:23 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 02:15:23 [INFO] exp_shallowmodel: classification report:
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:15:23 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.55      0.68      0.61       169
          F       0.72      0.85      0.78       281
          R       0.48      0.18      0.26       122

avg / total       0.59      0.64      0.60       592

12/10/2017 02:15:23 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:23 [INFO] exp_shallowmodel: 
[[  0   5  12   3]
 [  0 115  39  15]
 [  0  35 240   6]
 [  0  56  44  22]]
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ******************** dstc3 - Round 33 
12/10/2017 02:15:23 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:23 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:23 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:23 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:23 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:23 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:24 [INFO] exp_shallowmodel: train time: 0.742s
12/10/2017 02:15:24 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:24 [INFO] exp_shallowmodel: accuracy:   0.627
12/10/2017 02:15:24 [INFO] exp_shallowmodel: f1_score:   0.412
12/10/2017 02:15:24 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:24 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.55      0.64      0.60       169
          F       0.70      0.84      0.77       281
          R       0.43      0.21      0.29       122

avg / total       0.58      0.63      0.59       592

12/10/2017 02:15:24 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:24 [INFO] exp_shallowmodel: 
[[  0   1  18   1]
 [  0 109  40  20]
 [  0  32 236  13]
 [  0  55  41  26]]
12/10/2017 02:15:24 [INFO] exp_shallowmodel: ******************** dstc3 - Round 34 
12/10/2017 02:15:24 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:24 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:24 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:24 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:24 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:24 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:24 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:25 [INFO] exp_shallowmodel: train time: 0.404s
12/10/2017 02:15:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:25 [INFO] exp_shallowmodel: accuracy:   0.627
12/10/2017 02:15:25 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 02:15:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.57      0.67      0.61       169
          F       0.68      0.83      0.75       281
          R       0.47      0.19      0.27       122

avg / total       0.62      0.63      0.59       592

12/10/2017 02:15:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:25 [INFO] exp_shallowmodel: 
[[  1   2  14   3]
 [  0 113  42  14]
 [  0  38 234   9]
 [  0  46  53  23]]
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 35 
12/10/2017 02:15:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:25 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:25 [INFO] exp_shallowmodel: train time: 0.347s
12/10/2017 02:15:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:25 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:15:25 [INFO] exp_shallowmodel: f1_score:   0.432
12/10/2017 02:15:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.55      0.64      0.59       169
          F       0.68      0.84      0.75       281
          R       0.52      0.20      0.29       122

avg / total       0.62      0.62      0.59       592

12/10/2017 02:15:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:25 [INFO] exp_shallowmodel: 
[[  1   1  16   2]
 [  0 108  48  13]
 [  0  38 235   8]
 [  0  51  46  25]]
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 36 
12/10/2017 02:15:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:25 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:25 [INFO] exp_shallowmodel: train time: 0.356s
12/10/2017 02:15:25 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:25 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:15:25 [INFO] exp_shallowmodel: f1_score:   0.396
12/10/2017 02:15:25 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:25 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.62      0.57       169
          F       0.69      0.87      0.77       281
          R       0.47      0.16      0.24       122

avg / total       0.58      0.62      0.58       592

12/10/2017 02:15:25 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:25 [INFO] exp_shallowmodel: 
[[  0   3  15   2]
 [  0 104  52  13]
 [  0  28 245   8]
 [  0  60  42  20]]
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ******************** dstc3 - Round 37 
12/10/2017 02:15:25 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:25 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:25 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:25 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:25 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:25 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:26 [INFO] exp_shallowmodel: train time: 0.392s
12/10/2017 02:15:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:26 [INFO] exp_shallowmodel: accuracy:   0.608
12/10/2017 02:15:26 [INFO] exp_shallowmodel: f1_score:   0.433
12/10/2017 02:15:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.54      0.63      0.58       169
          F       0.67      0.83      0.74       281
          R       0.45      0.16      0.23       122

avg / total       0.60      0.61      0.57       592

12/10/2017 02:15:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:26 [INFO] exp_shallowmodel: 
[[  2   1  16   1]
 [  0 107  48  14]
 [  0  41 232   8]
 [  0  51  52  19]]
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 38 
12/10/2017 02:15:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:26 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:26 [INFO] exp_shallowmodel: train time: 0.301s
12/10/2017 02:15:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:26 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:15:26 [INFO] exp_shallowmodel: f1_score:   0.439
12/10/2017 02:15:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.10      0.18        20
          C       0.55      0.64      0.59       169
          F       0.70      0.86      0.77       281
          R       0.35      0.15      0.21       122

avg / total       0.60      0.62      0.58       592

12/10/2017 02:15:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:26 [INFO] exp_shallowmodel: 
[[  2   2  15   1]
 [  0 108  37  24]
 [  0  32 241   8]
 [  0  54  50  18]]
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 39 
12/10/2017 02:15:26 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:15:26 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:26 [INFO] exp_shallowmodel: train time: 0.284s
12/10/2017 02:15:26 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:26 [INFO] exp_shallowmodel: accuracy:   0.592
12/10/2017 02:15:26 [INFO] exp_shallowmodel: f1_score:   0.384
12/10/2017 02:15:26 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:26 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        28
          C       0.50      0.62      0.55       172
          F       0.67      0.82      0.74       283
          R       0.48      0.17      0.25       123

avg / total       0.55      0.59      0.55       606

12/10/2017 02:15:26 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:26 [INFO] exp_shallowmodel: 
[[  0   5  19   4]
 [  0 106  56  10]
 [  0  42 232   9]
 [  0  61  41  21]]
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ******************** dstc3 - Round 40 
12/10/2017 02:15:26 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:26 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:26 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:26 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:26 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:26 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:27 [INFO] exp_shallowmodel: train time: 0.473s
12/10/2017 02:15:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:27 [INFO] exp_shallowmodel: accuracy:   0.618
12/10/2017 02:15:27 [INFO] exp_shallowmodel: f1_score:   0.394
12/10/2017 02:15:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.53      0.64      0.58       169
          F       0.69      0.85      0.76       281
          R       0.42      0.16      0.23       122

avg / total       0.57      0.62      0.58       592

12/10/2017 02:15:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:27 [INFO] exp_shallowmodel: 
[[  0   3  15   2]
 [  0 109  47  13]
 [  0  32 238  11]
 [  0  60  43  19]]
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 41 
12/10/2017 02:15:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:27 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:27 [INFO] exp_shallowmodel: train time: 0.350s
12/10/2017 02:15:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:27 [INFO] exp_shallowmodel: accuracy:   0.615
12/10/2017 02:15:27 [INFO] exp_shallowmodel: f1_score:   0.424
12/10/2017 02:15:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.52      0.62      0.57       169
          F       0.68      0.83      0.75       281
          R       0.51      0.20      0.28       122

avg / total       0.61      0.61      0.58       592

12/10/2017 02:15:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:27 [INFO] exp_shallowmodel: 
[[  1   2  13   4]
 [  0 105  51  13]
 [  0  41 234   6]
 [  0  53  45  24]]
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 42 
12/10/2017 02:15:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:27 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:27 [INFO] exp_shallowmodel: train time: 0.349s
12/10/2017 02:15:27 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:27 [INFO] exp_shallowmodel: accuracy:   0.630
12/10/2017 02:15:27 [INFO] exp_shallowmodel: f1_score:   0.404
12/10/2017 02:15:27 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:27 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.57      0.67      0.61       169
          F       0.69      0.85      0.77       281
          R       0.43      0.16      0.24       122

avg / total       0.58      0.63      0.59       592

12/10/2017 02:15:27 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:27 [INFO] exp_shallowmodel: 
[[  0   2  17   1]
 [  0 113  41  15]
 [  0  30 240  11]
 [  0  54  48  20]]
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ******************** dstc3 - Round 43 
12/10/2017 02:15:27 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:27 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:27 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:27 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:27 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:27 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:28 [INFO] exp_shallowmodel: train time: 0.373s
12/10/2017 02:15:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:28 [INFO] exp_shallowmodel: accuracy:   0.652
12/10/2017 02:15:28 [INFO] exp_shallowmodel: f1_score:   0.446
12/10/2017 02:15:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.59      0.72      0.65       169
          F       0.71      0.86      0.78       281
          R       0.50      0.18      0.27       122

avg / total       0.64      0.65      0.61       592

12/10/2017 02:15:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:28 [INFO] exp_shallowmodel: 
[[  1   1  18   0]
 [  0 121  33  15]
 [  0  32 242   7]
 [  0  52  48  22]]
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 44 
12/10/2017 02:15:28 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:28 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:28 [INFO] exp_shallowmodel: train time: 0.246s
12/10/2017 02:15:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:28 [INFO] exp_shallowmodel: accuracy:   0.595
12/10/2017 02:15:28 [INFO] exp_shallowmodel: f1_score:   0.408
12/10/2017 02:15:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.52      0.57      0.54       169
          F       0.67      0.83      0.74       281
          R       0.38      0.19      0.25       122

avg / total       0.58      0.59      0.56       592

12/10/2017 02:15:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:28 [INFO] exp_shallowmodel: 
[[  1   2  15   2]
 [  0  96  52  21]
 [  0  35 232  14]
 [  0  52  47  23]]
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 45 
12/10/2017 02:15:28 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:28 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:28 [INFO] exp_shallowmodel: train time: 0.289s
12/10/2017 02:15:28 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:28 [INFO] exp_shallowmodel: accuracy:   0.627
12/10/2017 02:15:28 [INFO] exp_shallowmodel: f1_score:   0.409
12/10/2017 02:15:28 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:28 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.56      0.65      0.60       169
          F       0.69      0.84      0.76       281
          R       0.47      0.20      0.28       122

avg / total       0.58      0.63      0.59       592

12/10/2017 02:15:28 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:28 [INFO] exp_shallowmodel: 
[[  0   3  15   2]
 [  0 110  43  16]
 [  0  35 237   9]
 [  0  49  49  24]]
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ******************** dstc3 - Round 46 
12/10/2017 02:15:28 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:28 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:28 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:28 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:28 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:28 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:29 [INFO] exp_shallowmodel: train time: 0.293s
12/10/2017 02:15:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:29 [INFO] exp_shallowmodel: accuracy:   0.610
12/10/2017 02:15:29 [INFO] exp_shallowmodel: f1_score:   0.417
12/10/2017 02:15:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.05      0.10        20
          C       0.55      0.62      0.58       169
          F       0.66      0.83      0.74       281
          R       0.46      0.17      0.25       122

avg / total       0.60      0.61      0.57       592

12/10/2017 02:15:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:29 [INFO] exp_shallowmodel: 
[[  1   1  16   2]
 [  0 105  49  15]
 [  0  39 234   8]
 [  0  45  56  21]]
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 47 
12/10/2017 02:15:29 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:29 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:29 [INFO] exp_shallowmodel: train time: 0.304s
12/10/2017 02:15:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:29 [INFO] exp_shallowmodel: accuracy:   0.610
12/10/2017 02:15:29 [INFO] exp_shallowmodel: f1_score:   0.456
12/10/2017 02:15:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.15      0.26        20
          C       0.55      0.69      0.61       169
          F       0.68      0.79      0.73       281
          R       0.37      0.16      0.22       122

avg / total       0.59      0.61      0.58       592

12/10/2017 02:15:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:29 [INFO] exp_shallowmodel: 
[[  3   1  13   3]
 [  0 116  38  15]
 [  0  43 223  15]
 [  0  51  52  19]]
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 48 
12/10/2017 02:15:29 [INFO] exp_shallowmodel: #(data) = 4750
12/10/2017 02:15:29 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:29 [INFO] exp_shallowmodel: train time: 0.384s
12/10/2017 02:15:29 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:29 [INFO] exp_shallowmodel: accuracy:   0.623
12/10/2017 02:15:29 [INFO] exp_shallowmodel: f1_score:   0.419
12/10/2017 02:15:29 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:29 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        20
          C       0.56      0.65      0.60       169
          F       0.68      0.81      0.74       281
          R       0.55      0.25      0.34       122

avg / total       0.59      0.62      0.59       592

12/10/2017 02:15:29 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:29 [INFO] exp_shallowmodel: 
[[  0   3  16   1]
 [  0 110  49  10]
 [  0  38 229  14]
 [  0  47  45  30]]
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ******************** dstc3 - Round 49 
12/10/2017 02:15:29 [INFO] exp_shallowmodel: #(data) = 4736
12/10/2017 02:15:29 [INFO] exp_shallowmodel: #(feature) = 30
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:29 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:29 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:29 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:29 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:30 [INFO] exp_shallowmodel: train time: 0.489s
12/10/2017 02:15:30 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:30 [INFO] exp_shallowmodel: accuracy:   0.647
12/10/2017 02:15:30 [INFO] exp_shallowmodel: f1_score:   0.429
12/10/2017 02:15:30 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:30 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.07        28
          C       0.60      0.70      0.65       172
          F       0.70      0.89      0.79       283
          R       0.42      0.15      0.22       123

avg / total       0.63      0.65      0.60       606

12/10/2017 02:15:30 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:30 [INFO] exp_shallowmodel: 
[[  1   4  18   5]
 [  0 121  35  16]
 [  0  27 252   4]
 [  0  51  54  18]]
12/10/2017 02:15:35 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:15:35 [INFO] task_runner: context=current, feature=1-basic
12/10/2017 02:15:35 [INFO] task_runner: retained feature numbers=[1, 2.1, 3, 2.2]
12/10/2017 02:15:35 [INFO] task_runner: #(data)=3530
12/10/2017 02:15:35 [INFO] task_runner: #(feature)=33
12/10/2017 02:15:35 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ******************** family - Round 0 
12/10/2017 02:15:35 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:35 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:35 [INFO] exp_shallowmodel: train time: 0.216s
12/10/2017 02:15:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:35 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:15:35 [INFO] exp_shallowmodel: f1_score:   0.244
12/10/2017 02:15:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.72      1.00      0.84       250
          R       0.80      0.08      0.14        52

avg / total       0.63      0.72      0.62       352

12/10/2017 02:15:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:35 [INFO] exp_shallowmodel: 
[[  0   1  22   0]
 [  0   0  27   0]
 [  0   0 249   1]
 [  0   1  47   4]]
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ******************** family - Round 1 
12/10/2017 02:15:35 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:35 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:35 [INFO] exp_shallowmodel: train time: 0.240s
12/10/2017 02:15:35 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:35 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:15:35 [INFO] exp_shallowmodel: f1_score:   0.268
12/10/2017 02:15:35 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:35 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.73      0.98      0.84       250
          R       0.36      0.10      0.15        52

avg / total       0.61      0.72      0.62       352

12/10/2017 02:15:35 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:35 [INFO] exp_shallowmodel: 
[[  1   0  19   3]
 [  0   0  23   4]
 [  1   1 246   2]
 [  0   0  47   5]]
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ******************** family - Round 2 
12/10/2017 02:15:35 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:35 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:35 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:35 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:35 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:35 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:36 [INFO] exp_shallowmodel: train time: 0.235s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:36 [INFO] exp_shallowmodel: f1_score:   0.256
12/10/2017 02:15:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.72      0.98      0.83       250
          R       0.55      0.12      0.19        52

avg / total       0.60      0.71      0.62       352

12/10/2017 02:15:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:36 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   0  25   2]
 [  1   1 245   3]
 [  0   1  45   6]]
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ******************** family - Round 3 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:36 [INFO] exp_shallowmodel: train time: 0.205s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:36 [INFO] exp_shallowmodel: f1_score:   0.265
12/10/2017 02:15:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.04      0.07        27
          F       0.72      0.98      0.83       250
          R       0.45      0.10      0.16        52

avg / total       0.62      0.71      0.62       352

12/10/2017 02:15:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:36 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   1  25   1]
 [  0   1 245   4]
 [  0   0  47   5]]
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ******************** family - Round 4 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:36 [INFO] exp_shallowmodel: train time: 0.206s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:15:36 [INFO] exp_shallowmodel: f1_score:   0.267
12/10/2017 02:15:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.33      0.04      0.07        27
          F       0.72      0.97      0.83       250
          R       0.23      0.06      0.09        52

avg / total       0.64      0.70      0.61       352

12/10/2017 02:15:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:36 [INFO] exp_shallowmodel: 
[[  1   1  19   2]
 [  0   1  25   1]
 [  0   1 242   7]
 [  0   0  49   3]]
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ******************** family - Round 5 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:36 [INFO] exp_shallowmodel: train time: 0.215s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:36 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:15:36 [INFO] exp_shallowmodel: f1_score:   0.287
12/10/2017 02:15:36 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:36 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.07      0.12        27
          F       0.74      0.98      0.84       250
          R       0.46      0.12      0.18        52

avg / total       0.62      0.72      0.63       352

12/10/2017 02:15:36 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:36 [INFO] exp_shallowmodel: 
[[  0   0  20   3]
 [  0   2  23   2]
 [  0   3 245   2]
 [  1   1  44   6]]
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ******************** family - Round 6 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:36 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:36 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:36 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:36 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:37 [INFO] exp_shallowmodel: train time: 0.231s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:15:37 [INFO] exp_shallowmodel: f1_score:   0.278
12/10/2017 02:15:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.67      0.07      0.13        27
          F       0.73      1.00      0.84       250
          R       0.50      0.08      0.13        52

avg / total       0.65      0.72      0.63       352

12/10/2017 02:15:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:37 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   2  21   4]
 [  0   1 249   0]
 [  1   0  47   4]]
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ******************** family - Round 7 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:37 [INFO] exp_shallowmodel: train time: 0.227s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:15:37 [INFO] exp_shallowmodel: f1_score:   0.280
12/10/2017 02:15:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.33      0.04      0.07        27
          F       0.73      0.99      0.84       250
          R       0.57      0.08      0.14        52

avg / total       0.66      0.72      0.63       352

12/10/2017 02:15:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:37 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   1  26   0]
 [  0   1 247   2]
 [  1   1  46   4]]
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ******************** family - Round 8 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:37 [INFO] exp_shallowmodel: train time: 0.200s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:15:37 [INFO] exp_shallowmodel: f1_score:   0.311
12/10/2017 02:15:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       1.00      0.19      0.31        27
          F       0.73      0.98      0.83       250
          R       0.30      0.06      0.10        52

avg / total       0.64      0.72      0.63       352

12/10/2017 02:15:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:37 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   5  21   1]
 [  0   0 245   5]
 [  0   0  49   3]]
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ******************** family - Round 9 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:37 [INFO] exp_shallowmodel: train time: 0.220s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:15:37 [INFO] exp_shallowmodel: accuracy:   0.704
12/10/2017 02:15:37 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 02:15:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.50      0.07      0.13        27
          F       0.71      0.99      0.83       251
          R       0.62      0.08      0.15        59

avg / total       0.63      0.70      0.61       362

12/10/2017 02:15:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:37 [INFO] exp_shallowmodel: 
[[  0   0  23   2]
 [  0   2  25   0]
 [  0   2 248   1]
 [  0   0  54   5]]
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ******************** family - Round 10 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:37 [INFO] exp_shallowmodel: train time: 0.216s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:37 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:15:37 [INFO] exp_shallowmodel: f1_score:   0.234
12/10/2017 02:15:37 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:37 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.72      0.99      0.84       250
          R       0.38      0.06      0.10        52

avg / total       0.57      0.71      0.61       352

12/10/2017 02:15:37 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:37 [INFO] exp_shallowmodel: 
[[  0   1  22   0]
 [  0   0  24   3]
 [  0   1 247   2]
 [  0   1  48   3]]
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ******************** family - Round 11 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:37 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:37 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:37 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:37 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:38 [INFO] exp_shallowmodel: train time: 0.210s
12/10/2017 02:15:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:38 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:15:38 [INFO] exp_shallowmodel: f1_score:   0.263
12/10/2017 02:15:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.67      0.07      0.13        27
          F       0.72      0.97      0.83       250
          R       0.23      0.06      0.09        52

avg / total       0.60      0.70      0.61       352

12/10/2017 02:15:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:38 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   2  24   1]
 [  0   1 242   7]
 [  0   0  49   3]]
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ******************** family - Round 12 
12/10/2017 02:15:38 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:38 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:38 [INFO] exp_shallowmodel: train time: 0.229s
12/10/2017 02:15:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:38 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:38 [INFO] exp_shallowmodel: f1_score:   0.289
12/10/2017 02:15:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.09      0.16        23
          C       0.25      0.04      0.06        27
          F       0.72      0.98      0.83       250
          R       0.38      0.06      0.10        52

avg / total       0.65      0.71      0.62       352

12/10/2017 02:15:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:38 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   1  25   1]
 [  0   2 245   3]
 [  0   1  48   3]]
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ******************** family - Round 13 
12/10/2017 02:15:38 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:38 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:38 [INFO] exp_shallowmodel: train time: 0.202s
12/10/2017 02:15:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:38 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:15:38 [INFO] exp_shallowmodel: f1_score:   0.243
12/10/2017 02:15:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.04      0.07        27
          F       0.72      0.99      0.83       250
          R       0.33      0.04      0.07        52

avg / total       0.59      0.71      0.61       352

12/10/2017 02:15:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:38 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   1  25   1]
 [  0   1 247   2]
 [  1   1  48   2]]
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ******************** family - Round 14 
12/10/2017 02:15:38 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:38 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:38 [INFO] exp_shallowmodel: train time: 0.210s
12/10/2017 02:15:38 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:38 [INFO] exp_shallowmodel: accuracy:   0.727
12/10/2017 02:15:38 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 02:15:38 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:38 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.75      0.11      0.19        27
          F       0.73      0.99      0.84       250
          R       0.60      0.12      0.19        52

avg / total       0.67      0.73      0.64       352

12/10/2017 02:15:38 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:38 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   3  23   1]
 [  1   1 247   1]
 [  0   0  46   6]]
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ******************** family - Round 15 
12/10/2017 02:15:38 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:38 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:38 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:38 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:38 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:38 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:39 [INFO] exp_shallowmodel: train time: 0.216s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:15:39 [INFO] exp_shallowmodel: f1_score:   0.270
12/10/2017 02:15:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       1.00      0.04      0.07        27
          F       0.73      1.00      0.84       250
          R       0.62      0.10      0.17        52

avg / total       0.69      0.72      0.63       352

12/10/2017 02:15:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:39 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   1  25   1]
 [  0   0 249   1]
 [  1   0  46   5]]
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ******************** family - Round 16 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:39 [INFO] exp_shallowmodel: train time: 0.218s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:15:39 [INFO] exp_shallowmodel: f1_score:   0.273
12/10/2017 02:15:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.07      0.13        27
          F       0.72      0.98      0.83       250
          R       0.44      0.08      0.13        52

avg / total       0.62      0.71      0.62       352

12/10/2017 02:15:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:39 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   2  25   0]
 [  0   1 244   5]
 [  1   1  46   4]]
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ******************** family - Round 17 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:39 [INFO] exp_shallowmodel: train time: 0.240s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:15:39 [INFO] exp_shallowmodel: f1_score:   0.296
12/10/2017 02:15:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.67      0.07      0.13        27
          F       0.73      0.99      0.84       250
          R       0.36      0.08      0.13        52

avg / total       0.69      0.72      0.63       352

12/10/2017 02:15:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:39 [INFO] exp_shallowmodel: 
[[  1   0  20   2]
 [  0   2  23   2]
 [  0   0 247   3]
 [  0   1  47   4]]
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ******************** family - Round 18 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:39 [INFO] exp_shallowmodel: train time: 0.211s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:39 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:15:39 [INFO] exp_shallowmodel: f1_score:   0.240
12/10/2017 02:15:39 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:39 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.04      0.07        27
          F       0.72      0.97      0.83       250
          R       0.18      0.04      0.06        52

avg / total       0.58      0.70      0.60       352

12/10/2017 02:15:39 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:39 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   1  24   2]
 [  1   1 243   5]
 [  1   0  49   2]]
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ******************** family - Round 19 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:15:39 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:39 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:39 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:39 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:40 [INFO] exp_shallowmodel: train time: 0.242s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:15:40 [INFO] exp_shallowmodel: f1_score:   0.287
12/10/2017 02:15:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        25
          C       0.25      0.04      0.06        27
          F       0.71      0.99      0.83       251
          R       0.75      0.10      0.18        59

avg / total       0.70      0.71      0.61       362

12/10/2017 02:15:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:40 [INFO] exp_shallowmodel: 
[[  1   0  24   0]
 [  0   1  24   2]
 [  0   3 248   0]
 [  0   0  53   6]]
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ******************** family - Round 20 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:40 [INFO] exp_shallowmodel: train time: 0.206s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:15:40 [INFO] exp_shallowmodel: f1_score:   0.281
12/10/2017 02:15:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.07      0.13        27
          F       0.72      0.98      0.83       250
          R       0.56      0.10      0.16        52

avg / total       0.63      0.72      0.62       352

12/10/2017 02:15:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:40 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   2  25   0]
 [  0   2 245   3]
 [  0   0  47   5]]
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ******************** family - Round 21 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:40 [INFO] exp_shallowmodel: train time: 0.212s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: accuracy:   0.724
12/10/2017 02:15:40 [INFO] exp_shallowmodel: f1_score:   0.291
12/10/2017 02:15:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.67      0.07      0.13        27
          F       0.73      0.99      0.84       250
          R       0.55      0.12      0.19        52

avg / total       0.65      0.72      0.64       352

12/10/2017 02:15:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:40 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   2  23   2]
 [  0   0 247   3]
 [  0   1  45   6]]
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ******************** family - Round 22 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:40 [INFO] exp_shallowmodel: train time: 0.195s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:15:40 [INFO] exp_shallowmodel: f1_score:   0.278
12/10/2017 02:15:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       0.33      0.04      0.07        27
          F       0.73      0.98      0.84       250
          R       0.44      0.08      0.13        52

avg / total       0.63      0.72      0.62       352

12/10/2017 02:15:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:40 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   1  23   3]
 [  0   2 246   2]
 [  2   0  46   4]]
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ******************** family - Round 23 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:40 [INFO] exp_shallowmodel: train time: 0.196s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:40 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:15:40 [INFO] exp_shallowmodel: f1_score:   0.282
12/10/2017 02:15:40 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:40 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.75      0.11      0.19        27
          F       0.73      0.98      0.84       250
          R       0.33      0.06      0.10        52

avg / total       0.62      0.72      0.62       352

12/10/2017 02:15:40 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:40 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   3  23   1]
 [  0   0 246   4]
 [  0   1  48   3]]
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ******************** family - Round 24 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:40 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:40 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:40 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:40 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:41 [INFO] exp_shallowmodel: train time: 0.207s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:15:41 [INFO] exp_shallowmodel: f1_score:   0.272
12/10/2017 02:15:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.07      0.13        27
          F       0.72      0.98      0.83       250
          R       0.36      0.08      0.13        52

avg / total       0.61      0.71      0.62       352

12/10/2017 02:15:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:41 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   2  24   1]
 [  0   2 244   4]
 [  0   0  48   4]]
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ******************** family - Round 25 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:41 [INFO] exp_shallowmodel: train time: 0.219s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: accuracy:   0.719
12/10/2017 02:15:41 [INFO] exp_shallowmodel: f1_score:   0.282
12/10/2017 02:15:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.60      0.11      0.19        27
          F       0.72      0.99      0.83       250
          R       0.60      0.06      0.11        52

avg / total       0.65      0.72      0.62       352

12/10/2017 02:15:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:41 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   3  24   0]
 [  0   1 247   2]
 [  0   1  48   3]]
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ******************** family - Round 26 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:41 [INFO] exp_shallowmodel: train time: 0.230s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:41 [INFO] exp_shallowmodel: f1_score:   0.277
12/10/2017 02:15:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.04      0.07        27
          F       0.73      0.97      0.83       250
          R       0.44      0.13      0.21        52

avg / total       0.61      0.71      0.63       352

12/10/2017 02:15:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:41 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   1  23   3]
 [  0   2 243   5]
 [  0   0  45   7]]
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ******************** family - Round 27 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:41 [INFO] exp_shallowmodel: train time: 0.223s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:15:41 [INFO] exp_shallowmodel: f1_score:   0.326
12/10/2017 02:15:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.09      0.16        23
          C       1.00      0.11      0.20        27
          F       0.73      1.00      0.84       250
          R       0.43      0.06      0.10        52

avg / total       0.73      0.73      0.64       352

12/10/2017 02:15:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:41 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   3  22   2]
 [  0   0 249   1]
 [  0   0  49   3]]
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ******************** family - Round 28 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:41 [INFO] exp_shallowmodel: train time: 0.221s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:41 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:15:41 [INFO] exp_shallowmodel: f1_score:   0.252
12/10/2017 02:15:41 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:41 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       1.00      0.04      0.07        27
          F       0.72      0.99      0.84       250
          R       0.43      0.06      0.10        52

avg / total       0.65      0.72      0.61       352

12/10/2017 02:15:41 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:41 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   1  25   1]
 [  0   0 248   2]
 [  1   0  48   3]]
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ******************** family - Round 29 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:15:41 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:41 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:41 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:41 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:42 [INFO] exp_shallowmodel: train time: 0.212s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:15:42 [INFO] exp_shallowmodel: f1_score:   0.239
12/10/2017 02:15:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.07        25
          C       0.00      0.00      0.00        27
          F       0.71      0.98      0.82       251
          R       0.29      0.03      0.06        59

avg / total       0.57      0.69      0.58       362

12/10/2017 02:15:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:42 [INFO] exp_shallowmodel: 
[[  1   2  20   2]
 [  0   0  26   1]
 [  1   2 246   2]
 [  0   1  56   2]]
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ******************** family - Round 30 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:42 [INFO] exp_shallowmodel: train time: 0.223s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:15:42 [INFO] exp_shallowmodel: f1_score:   0.314
12/10/2017 02:15:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.04      0.08        23
          C       0.50      0.07      0.13        27
          F       0.73      0.99      0.84       250
          R       1.00      0.12      0.21        52

avg / total       0.74      0.73      0.64       352

12/10/2017 02:15:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:42 [INFO] exp_shallowmodel: 
[[  1   1  21   0]
 [  0   2  25   0]
 [  1   1 248   0]
 [  0   0  46   6]]
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ******************** family - Round 31 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:42 [INFO] exp_shallowmodel: train time: 0.214s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:15:42 [INFO] exp_shallowmodel: f1_score:   0.282
12/10/2017 02:15:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       1.00      0.04      0.07        27
          F       0.72      0.98      0.83       250
          R       0.64      0.13      0.22        52

avg / total       0.68      0.72      0.63       352

12/10/2017 02:15:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:42 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   1  26   0]
 [  0   0 246   4]
 [  0   0  45   7]]
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ******************** family - Round 32 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:42 [INFO] exp_shallowmodel: train time: 0.221s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:42 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:15:42 [INFO] exp_shallowmodel: f1_score:   0.300
12/10/2017 02:15:42 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:42 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.67      0.07      0.13        27
          F       0.73      1.00      0.85       250
          R       0.57      0.08      0.14        52

avg / total       0.72      0.73      0.64       352

12/10/2017 02:15:42 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:42 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   2  22   3]
 [  0   0 250   0]
 [  0   1  47   4]]
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ******************** family - Round 33 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:42 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:42 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:42 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:42 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:43 [INFO] exp_shallowmodel: train time: 0.219s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:43 [INFO] exp_shallowmodel: f1_score:   0.275
12/10/2017 02:15:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.00      0.00      0.00        27
          F       0.72      0.98      0.83       250
          R       0.50      0.12      0.19        52

avg / total       0.65      0.71      0.62       352

12/10/2017 02:15:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:43 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   0  27   0]
 [  0   1 244   5]
 [  0   0  46   6]]
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ******************** family - Round 34 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:43 [INFO] exp_shallowmodel: train time: 0.234s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:15:43 [INFO] exp_shallowmodel: accuracy:   0.705
12/10/2017 02:15:43 [INFO] exp_shallowmodel: f1_score:   0.240
12/10/2017 02:15:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.17      0.04      0.06        27
          F       0.73      0.98      0.84       250
          R       0.18      0.04      0.06        52

avg / total       0.56      0.70      0.61       352

12/10/2017 02:15:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:43 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   1  21   5]
 [  0   3 245   2]
 [  0   2  48   2]]
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ******************** family - Round 35 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:43 [INFO] exp_shallowmodel: train time: 0.219s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:15:43 [INFO] exp_shallowmodel: f1_score:   0.298
12/10/2017 02:15:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.09      0.16        23
          C       0.33      0.04      0.07        27
          F       0.72      0.98      0.83       250
          R       0.44      0.08      0.13        52

avg / total       0.67      0.72      0.63       352

12/10/2017 02:15:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:43 [INFO] exp_shallowmodel: 
[[  2   0  20   1]
 [  0   1  25   1]
 [  0   2 245   3]
 [  0   0  48   4]]
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ******************** family - Round 36 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:43 [INFO] exp_shallowmodel: train time: 0.201s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:43 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:15:43 [INFO] exp_shallowmodel: f1_score:   0.247
12/10/2017 02:15:43 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:43 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.29      0.07      0.12        27
          F       0.72      0.98      0.83       250
          R       0.50      0.02      0.04        52

avg / total       0.61      0.71      0.61       352

12/10/2017 02:15:43 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:43 [INFO] exp_shallowmodel: 
[[  0   1  22   0]
 [  0   2  25   0]
 [  0   3 246   1]
 [  2   1  48   1]]
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ******************** family - Round 37 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:43 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:43 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:43 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:43 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:44 [INFO] exp_shallowmodel: train time: 0.226s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:15:44 [INFO] exp_shallowmodel: f1_score:   0.250
12/10/2017 02:15:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.04      0.06        27
          F       0.72      0.98      0.83       250
          R       0.60      0.06      0.11        52

avg / total       0.62      0.71      0.61       352

12/10/2017 02:15:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:44 [INFO] exp_shallowmodel: 
[[  0   1  22   0]
 [  0   1  26   0]
 [  0   2 246   2]
 [  0   0  49   3]]
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ******************** family - Round 38 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:44 [INFO] exp_shallowmodel: train time: 0.217s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: accuracy:   0.710
12/10/2017 02:15:44 [INFO] exp_shallowmodel: f1_score:   0.250
12/10/2017 02:15:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.25      0.04      0.06        27
          F       0.72      0.98      0.83       250
          R       0.60      0.06      0.11        52

avg / total       0.62      0.71      0.61       352

12/10/2017 02:15:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:44 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   1  26   0]
 [  0   2 246   2]
 [  0   1  48   3]]
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ******************** family - Round 39 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:44 [INFO] exp_shallowmodel: train time: 0.207s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: accuracy:   0.699
12/10/2017 02:15:44 [INFO] exp_shallowmodel: f1_score:   0.259
12/10/2017 02:15:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.25      0.04      0.06        27
          F       0.71      0.98      0.82       251
          R       0.56      0.08      0.15        59

avg / total       0.60      0.70      0.60       362

12/10/2017 02:15:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:44 [INFO] exp_shallowmodel: 
[[  0   0  25   0]
 [  0   1  24   2]
 [  0   2 247   2]
 [  0   1  53   5]]
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ******************** family - Round 40 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:44 [INFO] exp_shallowmodel: train time: 0.230s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: accuracy:   0.716
12/10/2017 02:15:44 [INFO] exp_shallowmodel: f1_score:   0.301
12/10/2017 02:15:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.40      0.07      0.12        27
          F       0.73      0.98      0.83       250
          R       0.50      0.10      0.16        52

avg / total       0.69      0.72      0.63       352

12/10/2017 02:15:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:44 [INFO] exp_shallowmodel: 
[[  1   0  22   0]
 [  0   2  23   2]
 [  0   3 244   3]
 [  0   0  47   5]]
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ******************** family - Round 41 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:44 [INFO] exp_shallowmodel: train time: 0.257s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:44 [INFO] exp_shallowmodel: accuracy:   0.702
12/10/2017 02:15:44 [INFO] exp_shallowmodel: f1_score:   0.269
12/10/2017 02:15:44 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:44 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.33      0.07      0.12        27
          F       0.72      0.96      0.82       250
          R       0.44      0.08      0.13        52

avg / total       0.60      0.70      0.61       352

12/10/2017 02:15:44 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:44 [INFO] exp_shallowmodel: 
[[  0   0  22   1]
 [  0   2  25   0]
 [  1   4 241   4]
 [  1   0  47   4]]
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ******************** family - Round 42 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:44 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:44 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:44 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:44 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:45 [INFO] exp_shallowmodel: train time: 0.233s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: accuracy:   0.713
12/10/2017 02:15:45 [INFO] exp_shallowmodel: f1_score:   0.259
12/10/2017 02:15:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.50      0.04      0.07        27
          F       0.73      0.98      0.84       250
          R       0.44      0.08      0.13        52

avg / total       0.62      0.71      0.62       352

12/10/2017 02:15:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:45 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  2   1  24   0]
 [  0   1 246   3]
 [  0   0  48   4]]
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ******************** family - Round 43 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:45 [INFO] exp_shallowmodel: train time: 0.208s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:15:45 [INFO] exp_shallowmodel: f1_score:   0.288
12/10/2017 02:15:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       0.25      0.04      0.06        27
          F       0.73      0.99      0.84       250
          R       0.62      0.10      0.17        52

avg / total       0.69      0.72      0.63       352

12/10/2017 02:15:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:45 [INFO] exp_shallowmodel: 
[[  1   1  21   0]
 [  0   1  25   1]
 [  0   1 247   2]
 [  0   1  46   5]]
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ******************** family - Round 44 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:45 [INFO] exp_shallowmodel: train time: 0.196s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:15:45 [INFO] exp_shallowmodel: f1_score:   0.239
12/10/2017 02:15:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.72      0.98      0.83       250
          R       0.36      0.08      0.13        52

avg / total       0.57      0.71      0.61       352

12/10/2017 02:15:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:45 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   0  26   1]
 [  0   1 245   4]
 [  0   0  48   4]]
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ******************** family - Round 45 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:45 [INFO] exp_shallowmodel: train time: 0.206s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:45 [INFO] exp_shallowmodel: accuracy:   0.730
12/10/2017 02:15:45 [INFO] exp_shallowmodel: f1_score:   0.307
12/10/2017 02:15:45 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:45 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.04      0.08        23
          C       1.00      0.07      0.14        27
          F       0.73      1.00      0.84       250
          R       0.56      0.10      0.16        52

avg / total       0.74      0.73      0.64       352

12/10/2017 02:15:45 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:45 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   2  23   2]
 [  0   0 249   1]
 [  0   0  47   5]]
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ******************** family - Round 46 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:45 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:45 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:45 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:45 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:46 [INFO] exp_shallowmodel: train time: 0.262s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: accuracy:   0.722
12/10/2017 02:15:46 [INFO] exp_shallowmodel: f1_score:   0.251
12/10/2017 02:15:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.73      1.00      0.84       250
          R       0.50      0.10      0.16        52

avg / total       0.59      0.72      0.62       352

12/10/2017 02:15:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:46 [INFO] exp_shallowmodel: 
[[  0   0  21   2]
 [  0   0  25   2]
 [  0   0 249   1]
 [  1   1  45   5]]
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ******************** family - Round 47 
12/10/2017 02:15:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:46 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:46 [INFO] exp_shallowmodel: train time: 0.193s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: accuracy:   0.707
12/10/2017 02:15:46 [INFO] exp_shallowmodel: f1_score:   0.241
12/10/2017 02:15:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        23
          C       0.00      0.00      0.00        27
          F       0.72      0.98      0.83       250
          R       0.50      0.08      0.13        52

avg / total       0.58      0.71      0.61       352

12/10/2017 02:15:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:46 [INFO] exp_shallowmodel: 
[[  0   0  23   0]
 [  0   0  26   1]
 [  0   2 245   3]
 [  0   1  47   4]]
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ******************** family - Round 48 
12/10/2017 02:15:46 [INFO] exp_shallowmodel: #(data) = 2826
12/10/2017 02:15:46 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:46 [INFO] exp_shallowmodel: train time: 0.205s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: accuracy:   0.733
12/10/2017 02:15:46 [INFO] exp_shallowmodel: f1_score:   0.315
12/10/2017 02:15:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.04      0.08        23
          C       1.00      0.07      0.14        27
          F       0.73      1.00      0.85       250
          R       0.75      0.12      0.20        52

avg / total       0.73      0.73      0.65       352

12/10/2017 02:15:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:46 [INFO] exp_shallowmodel: 
[[  1   0  21   1]
 [  0   2  25   0]
 [  0   0 249   1]
 [  2   0  44   6]]
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ******************** family - Round 49 
12/10/2017 02:15:46 [INFO] exp_shallowmodel: #(data) = 2816
12/10/2017 02:15:46 [INFO] exp_shallowmodel: #(feature) = 33
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:46 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:46 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:46 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:46 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:46 [INFO] exp_shallowmodel: train time: 0.205s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:46 [INFO] exp_shallowmodel: accuracy:   0.688
12/10/2017 02:15:46 [INFO] exp_shallowmodel: f1_score:   0.222
12/10/2017 02:15:46 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:46 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        25
          C       0.50      0.04      0.07        27
          F       0.70      0.99      0.82       251
          R       0.00      0.00      0.00        59

avg / total       0.52      0.69      0.57       362

12/10/2017 02:15:46 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:46 [INFO] exp_shallowmodel: 
[[  0   0  24   1]
 [  0   1  23   3]
 [  0   1 248   2]
 [  0   0  59   0]]
12/10/2017 02:15:52 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:15:52 [INFO] task_runner: context=current, feature=1-basic
12/10/2017 02:15:52 [INFO] task_runner: retained feature numbers=[1, 2.1, 3, 2.2]
12/10/2017 02:15:52 [INFO] task_runner: #(data)=5241
12/10/2017 02:15:52 [INFO] task_runner: #(feature)=47
12/10/2017 02:15:52 [INFO] task_runner: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ******************** ghome - Round 0 
12/10/2017 02:15:52 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:52 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:52 [INFO] exp_shallowmodel: train time: 0.405s
12/10/2017 02:15:52 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:52 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:15:52 [INFO] exp_shallowmodel: f1_score:   0.261
12/10/2017 02:15:52 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:52 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.29      0.04      0.06        55

avg / total       0.66      0.76      0.67       522

12/10/2017 02:15:52 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:52 [INFO] exp_shallowmodel: 
[[  4   0  55   0]
 [  1   0  11   0]
 [  2   0 389   5]
 [  3   0  50   2]]
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ******************** ghome - Round 1 
12/10/2017 02:15:52 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:52 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:52 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:52 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:52 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:52 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:53 [INFO] exp_shallowmodel: train time: 0.499s
12/10/2017 02:15:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:53 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:15:53 [INFO] exp_shallowmodel: f1_score:   0.224
12/10/2017 02:15:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        59
          C       0.00      0.00      0.00        12
          F       0.76      0.99      0.86       396
          R       0.25      0.02      0.03        55

avg / total       0.61      0.75      0.66       522

12/10/2017 02:15:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:53 [INFO] exp_shallowmodel: 
[[  0   0  58   1]
 [  1   0  11   0]
 [  2   1 391   2]
 [  2   0  52   1]]
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ******************** ghome - Round 2 
12/10/2017 02:15:53 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:53 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:53 [INFO] exp_shallowmodel: train time: 0.328s
12/10/2017 02:15:53 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:53 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:15:53 [INFO] exp_shallowmodel: f1_score:   0.240
12/10/2017 02:15:53 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:53 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.86       396
          R       0.50      0.02      0.04        55

avg / total       0.66      0.76      0.67       522

12/10/2017 02:15:53 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:53 [INFO] exp_shallowmodel: 
[[  2   0  56   1]
 [  1   0  11   0]
 [  4   0 392   0]
 [  2   0  52   1]]
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ******************** ghome - Round 3 
12/10/2017 02:15:53 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:53 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:53 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:53 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:53 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:53 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:54 [INFO] exp_shallowmodel: train time: 0.382s
12/10/2017 02:15:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:54 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:15:54 [INFO] exp_shallowmodel: f1_score:   0.261
12/10/2017 02:15:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.38      0.05      0.10        55

avg / total       0.66      0.75      0.67       522

12/10/2017 02:15:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:54 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  0   0  10   2]
 [  6   0 388   2]
 [  2   0  50   3]]
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ******************** ghome - Round 4 
12/10/2017 02:15:54 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:54 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:54 [INFO] exp_shallowmodel: train time: 0.420s
12/10/2017 02:15:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:54 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:15:54 [INFO] exp_shallowmodel: f1_score:   0.253
12/10/2017 02:15:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.20      0.04      0.06        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:15:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:54 [INFO] exp_shallowmodel: 
[[  3   1  53   2]
 [  1   0  11   0]
 [  3   0 387   6]
 [  3   0  50   2]]
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ******************** ghome - Round 5 
12/10/2017 02:15:54 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:54 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:54 [INFO] exp_shallowmodel: train time: 0.351s
12/10/2017 02:15:54 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:54 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:15:54 [INFO] exp_shallowmodel: f1_score:   0.257
12/10/2017 02:15:54 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:54 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       1.00      0.07      0.13        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.25      0.02      0.03        55

avg / total       0.72      0.76      0.68       522

12/10/2017 02:15:54 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:54 [INFO] exp_shallowmodel: 
[[  4   1  52   2]
 [  0   0  12   0]
 [  0   1 394   1]
 [  0   0  54   1]]
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ******************** ghome - Round 6 
12/10/2017 02:15:54 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:54 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:54 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:54 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:54 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:54 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:55 [INFO] exp_shallowmodel: train time: 0.424s
12/10/2017 02:15:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:55 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:15:55 [INFO] exp_shallowmodel: f1_score:   0.306
12/10/2017 02:15:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.08      0.14        59
          C       0.50      0.08      0.14        12
          F       0.77      0.99      0.87       396
          R       0.67      0.04      0.07        55

avg / total       0.72      0.77      0.69       522

12/10/2017 02:15:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:55 [INFO] exp_shallowmodel: 
[[  5   1  53   0]
 [  1   1  10   0]
 [  3   0 392   1]
 [  2   0  51   2]]
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ******************** ghome - Round 7 
12/10/2017 02:15:55 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:55 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:55 [INFO] exp_shallowmodel: train time: 0.323s
12/10/2017 02:15:55 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:55 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:15:55 [INFO] exp_shallowmodel: f1_score:   0.246
12/10/2017 02:15:55 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:55 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.27      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.50      0.02      0.04        55

avg / total       0.67      0.75      0.67       522

12/10/2017 02:15:55 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:55 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  0   0  12   0]
 [  6   1 389   0]
 [  2   1  51   1]]
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ******************** ghome - Round 8 
12/10/2017 02:15:55 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:55 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:55 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:55 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:55 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:55 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:56 [INFO] exp_shallowmodel: train time: 0.453s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:15:56 [INFO] exp_shallowmodel: f1_score:   0.278
12/10/2017 02:15:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.03      0.06        59
          C       1.00      0.08      0.15        12
          F       0.77      0.99      0.87       396
          R       0.25      0.02      0.03        55

avg / total       0.66      0.76      0.67       522

12/10/2017 02:15:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:56 [INFO] exp_shallowmodel: 
[[  2   0  55   2]
 [  0   1  11   0]
 [  3   0 392   1]
 [  3   0  51   1]]
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ******************** ghome - Round 9 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:56 [INFO] exp_shallowmodel: train time: 0.450s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 02:15:56 [INFO] exp_shallowmodel: f1_score:   0.241
12/10/2017 02:15:56 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.06      0.11        64
          C       0.00      0.00      0.00        14
          F       0.75      0.99      0.85       402
          R       0.00      0.00      0.00        63

avg / total       0.62      0.74      0.65       543

12/10/2017 02:15:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:56 [INFO] exp_shallowmodel: 
[[  4   0  58   2]
 [  2   0  12   0]
 [  0   1 397   4]
 [  2   0  61   0]]
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ******************** ghome - Round 10 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:56 [INFO] exp_shallowmodel: train time: 0.436s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:56 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:15:56 [INFO] exp_shallowmodel: f1_score:   0.266
12/10/2017 02:15:56 [INFO] exp_shallowmodel: classification report:
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:15:56 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.29      0.04      0.06        55

avg / total       0.66      0.75      0.68       522

12/10/2017 02:15:56 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:56 [INFO] exp_shallowmodel: 
[[  5   0  53   1]
 [  1   0  11   0]
 [  5   0 387   4]
 [  3   0  50   2]]
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ******************** ghome - Round 11 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:56 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:56 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:56 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:56 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:57 [INFO] exp_shallowmodel: train time: 0.491s
12/10/2017 02:15:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:57 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:15:57 [INFO] exp_shallowmodel: f1_score:   0.290
12/10/2017 02:15:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.07      0.12        59
          C       0.50      0.08      0.14        12
          F       0.77      0.99      0.87       396
          R       1.00      0.02      0.04        55

avg / total       0.75      0.76      0.68       522

12/10/2017 02:15:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:57 [INFO] exp_shallowmodel: 
[[  4   1  54   0]
 [  0   1  11   0]
 [  4   0 392   0]
 [  1   0  53   1]]
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ******************** ghome - Round 12 
12/10/2017 02:15:57 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:57 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:57 [INFO] exp_shallowmodel: train time: 0.377s
12/10/2017 02:15:57 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:57 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:15:57 [INFO] exp_shallowmodel: f1_score:   0.231
12/10/2017 02:15:57 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:57 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.09      0.02      0.03        55

avg / total       0.62      0.75      0.66       522

12/10/2017 02:15:57 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:57 [INFO] exp_shallowmodel: 
[[  1   0  55   3]
 [  2   0   9   1]
 [  1   0 389   6]
 [  1   0  53   1]]
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ******************** ghome - Round 13 
12/10/2017 02:15:57 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:57 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:57 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:57 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:57 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:57 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:58 [INFO] exp_shallowmodel: train time: 0.398s
12/10/2017 02:15:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:58 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:15:58 [INFO] exp_shallowmodel: f1_score:   0.279
12/10/2017 02:15:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.80      0.07      0.13        55

avg / total       0.72      0.76      0.68       522

12/10/2017 02:15:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:58 [INFO] exp_shallowmodel: 
[[  4   0  54   1]
 [  0   0  12   0]
 [  5   0 391   0]
 [  0   0  51   4]]
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ******************** ghome - Round 14 
12/10/2017 02:15:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:58 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:58 [INFO] exp_shallowmodel: train time: 0.388s
12/10/2017 02:15:58 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:58 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:15:58 [INFO] exp_shallowmodel: f1_score:   0.253
12/10/2017 02:15:58 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:58 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.00      0.00      0.00        55

avg / total       0.64      0.76      0.67       522

12/10/2017 02:15:58 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:58 [INFO] exp_shallowmodel: 
[[  5   0  53   1]
 [  1   0  11   0]
 [  2   1 392   1]
 [  2   0  53   0]]
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ******************** ghome - Round 15 
12/10/2017 02:15:58 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:58 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:58 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:58 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:58 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:58 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:59 [INFO] exp_shallowmodel: train time: 0.372s
12/10/2017 02:15:59 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:59 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:15:59 [INFO] exp_shallowmodel: f1_score:   0.240
12/10/2017 02:15:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.50      0.02      0.04        55

avg / total       0.67      0.76      0.67       522

12/10/2017 02:15:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:59 [INFO] exp_shallowmodel: 
[[  2   0  57   0]
 [  0   0  12   0]
 [  2   0 393   1]
 [  3   1  50   1]]
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ******************** ghome - Round 16 
12/10/2017 02:15:59 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:59 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:15:59 [INFO] exp_shallowmodel: train time: 0.487s
12/10/2017 02:15:59 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:15:59 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:15:59 [INFO] exp_shallowmodel: f1_score:   0.269
12/10/2017 02:15:59 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:15:59 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.60      0.10      0.17        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.14      0.02      0.03        55

avg / total       0.67      0.76      0.68       522

12/10/2017 02:15:59 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:15:59 [INFO] exp_shallowmodel: 
[[  6   1  49   3]
 [  1   0  10   1]
 [  2   0 392   2]
 [  1   0  53   1]]
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ******************** ghome - Round 17 
12/10/2017 02:15:59 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:15:59 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:15:59 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:15:59 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:15:59 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:15:59 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:00 [INFO] exp_shallowmodel: train time: 0.516s
12/10/2017 02:16:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:00 [INFO] exp_shallowmodel: accuracy:   0.766
12/10/2017 02:16:00 [INFO] exp_shallowmodel: f1_score:   0.321
12/10/2017 02:16:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.08      0.14        59
          C       0.50      0.08      0.14        12
          F       0.78      0.98      0.87       396
          R       0.57      0.07      0.13        55

avg / total       0.71      0.77      0.69       522

12/10/2017 02:16:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:00 [INFO] exp_shallowmodel: 
[[  5   0  54   0]
 [  1   1   9   1]
 [  3   1 390   2]
 [  2   0  49   4]]
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ******************** ghome - Round 18 
12/10/2017 02:16:00 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:00 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:00 [INFO] exp_shallowmodel: train time: 0.372s
12/10/2017 02:16:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:00 [INFO] exp_shallowmodel: accuracy:   0.747
12/10/2017 02:16:00 [INFO] exp_shallowmodel: f1_score:   0.244
12/10/2017 02:16:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.23      0.05      0.08        59
          C       0.00      0.00      0.00        12
          F       0.77      0.97      0.86       396
          R       0.20      0.02      0.03        55

avg / total       0.63      0.75      0.66       522

12/10/2017 02:16:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:00 [INFO] exp_shallowmodel: 
[[  3   1  54   1]
 [  1   0  11   0]
 [  7   0 386   3]
 [  2   0  52   1]]
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ******************** ghome - Round 19 
12/10/2017 02:16:00 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:16:00 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:00 [INFO] exp_shallowmodel: train time: 0.386s
12/10/2017 02:16:00 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:00 [INFO] exp_shallowmodel: accuracy:   0.750
12/10/2017 02:16:00 [INFO] exp_shallowmodel: f1_score:   0.297
12/10/2017 02:16:00 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:00 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.50      0.06      0.11        64
          C       1.00      0.07      0.13        14
          F       0.76      0.99      0.86       402
          R       0.43      0.05      0.09        63

avg / total       0.69      0.75      0.66       543

12/10/2017 02:16:00 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:00 [INFO] exp_shallowmodel: 
[[  4   0  57   3]
 [  0   1  13   0]
 [  2   0 399   1]
 [  2   0  58   3]]
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ******************** ghome - Round 20 
12/10/2017 02:16:00 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:00 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:00 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:00 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:00 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:00 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:01 [INFO] exp_shallowmodel: train time: 0.359s
12/10/2017 02:16:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:01 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:16:01 [INFO] exp_shallowmodel: f1_score:   0.253
12/10/2017 02:16:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.44      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.20      0.02      0.03        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:16:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:01 [INFO] exp_shallowmodel: 
[[  4   0  54   1]
 [  0   0  12   0]
 [  3   1 389   3]
 [  2   1  51   1]]
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ******************** ghome - Round 21 
12/10/2017 02:16:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:01 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:01 [INFO] exp_shallowmodel: train time: 0.458s
12/10/2017 02:16:01 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:01 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:16:01 [INFO] exp_shallowmodel: f1_score:   0.237
12/10/2017 02:16:01 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:01 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.00      0.00      0.00        55

avg / total       0.62      0.75      0.66       522

12/10/2017 02:16:01 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:01 [INFO] exp_shallowmodel: 
[[  3   1  54   1]
 [  0   0  12   0]
 [  4   0 388   4]
 [  2   0  53   0]]
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ******************** ghome - Round 22 
12/10/2017 02:16:01 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:01 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:01 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:01 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:01 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:01 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:02 [INFO] exp_shallowmodel: train time: 0.399s
12/10/2017 02:16:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:02 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:16:02 [INFO] exp_shallowmodel: f1_score:   0.256
12/10/2017 02:16:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.43      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.50      0.04      0.07        55

avg / total       0.68      0.76      0.67       522

12/10/2017 02:16:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:02 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  1   0  11   0]
 [  2   0 393   1]
 [  1   0  52   2]]
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ******************** ghome - Round 23 
12/10/2017 02:16:02 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:02 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:02 [INFO] exp_shallowmodel: train time: 0.418s
12/10/2017 02:16:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:02 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:16:02 [INFO] exp_shallowmodel: f1_score:   0.260
12/10/2017 02:16:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.29      0.07      0.11        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.33      0.04      0.07        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:16:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:02 [INFO] exp_shallowmodel: 
[[  4   0  53   2]
 [  1   0  11   0]
 [  6   1 387   2]
 [  3   0  50   2]]
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ******************** ghome - Round 24 
12/10/2017 02:16:02 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:02 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:02 [INFO] exp_shallowmodel: train time: 0.467s
12/10/2017 02:16:02 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:02 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:16:02 [INFO] exp_shallowmodel: f1_score:   0.231
12/10/2017 02:16:02 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:02 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.86       396
          R       0.00      0.00      0.00        55

avg / total       0.61      0.75      0.66       522

12/10/2017 02:16:02 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:02 [INFO] exp_shallowmodel: 
[[  2   0  56   1]
 [  1   0  11   0]
 [  4   0 392   0]
 [  2   0  53   0]]
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ******************** ghome - Round 25 
12/10/2017 02:16:02 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:02 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:02 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:02 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:02 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:02 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:03 [INFO] exp_shallowmodel: train time: 0.524s
12/10/2017 02:16:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:03 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:16:03 [INFO] exp_shallowmodel: f1_score:   0.257
12/10/2017 02:16:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.17      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.86       396
          R       0.67      0.07      0.13        55

avg / total       0.67      0.76      0.67       522

12/10/2017 02:16:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:03 [INFO] exp_shallowmodel: 
[[  1   1  57   0]
 [  1   0  11   0]
 [  3   0 391   2]
 [  1   0  50   4]]
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ******************** ghome - Round 26 
12/10/2017 02:16:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:03 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:03 [INFO] exp_shallowmodel: train time: 0.464s
12/10/2017 02:16:03 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:03 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:16:03 [INFO] exp_shallowmodel: f1_score:   0.254
12/10/2017 02:16:03 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:03 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.07      0.12        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.25      0.02      0.03        55

avg / total       0.66      0.76      0.67       522

12/10/2017 02:16:03 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:03 [INFO] exp_shallowmodel: 
[[  4   0  53   2]
 [  0   0  12   0]
 [  3   0 392   1]
 [  3   0  51   1]]
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ******************** ghome - Round 27 
12/10/2017 02:16:03 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:03 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:03 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:03 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:03 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:03 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:04 [INFO] exp_shallowmodel: train time: 0.424s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:16:04 [INFO] exp_shallowmodel: f1_score:   0.240
12/10/2017 02:16:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.86       396
          R       0.33      0.02      0.03        55

avg / total       0.65      0.76      0.67       522

12/10/2017 02:16:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:04 [INFO] exp_shallowmodel: 
[[  2   1  55   1]
 [  0   0  12   0]
 [  3   0 392   1]
 [  1   0  53   1]]
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ******************** ghome - Round 28 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:04 [INFO] exp_shallowmodel: train time: 0.455s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:04 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:16:04 [INFO] exp_shallowmodel: f1_score:   0.267
12/10/2017 02:16:04 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:04 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.45      0.08      0.14        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.25      0.04      0.06        55

avg / total       0.66      0.76      0.68       522

12/10/2017 02:16:04 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:04 [INFO] exp_shallowmodel: 
[[  5   0  53   1]
 [  1   0  10   1]
 [  4   0 388   4]
 [  1   0  52   2]]
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ******************** ghome - Round 29 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:16:04 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:04 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:04 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:04 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:05 [INFO] exp_shallowmodel: train time: 0.430s
12/10/2017 02:16:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:05 [INFO] exp_shallowmodel: accuracy:   0.750
12/10/2017 02:16:05 [INFO] exp_shallowmodel: f1_score:   0.276
12/10/2017 02:16:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.42      0.08      0.13        64
          C       0.00      0.00      0.00        14
          F       0.76      0.99      0.86       402
          R       0.57      0.06      0.11        63

avg / total       0.68      0.75      0.67       543

12/10/2017 02:16:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:05 [INFO] exp_shallowmodel: 
[[  5   0  57   2]
 [  2   0  12   0]
 [  3   0 398   1]
 [  2   0  57   4]]
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ******************** ghome - Round 30 
12/10/2017 02:16:05 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:05 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:05 [INFO] exp_shallowmodel: train time: 0.447s
12/10/2017 02:16:05 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:05 [INFO] exp_shallowmodel: accuracy:   0.768
12/10/2017 02:16:05 [INFO] exp_shallowmodel: f1_score:   0.286
12/10/2017 02:16:05 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:05 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.67      0.10      0.18        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.43      0.05      0.10        55

avg / total       0.71      0.77      0.69       522

12/10/2017 02:16:05 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:05 [INFO] exp_shallowmodel: 
[[  6   0  52   1]
 [  1   0  11   0]
 [  1   0 392   3]
 [  1   0  51   3]]
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ******************** ghome - Round 31 
12/10/2017 02:16:05 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:05 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:05 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:05 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:05 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:05 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:06 [INFO] exp_shallowmodel: train time: 0.414s
12/10/2017 02:16:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:06 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:16:06 [INFO] exp_shallowmodel: f1_score:   0.238
12/10/2017 02:16:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.76      0.98      0.86       396
          R       0.33      0.02      0.03        55

avg / total       0.64      0.75      0.66       522

12/10/2017 02:16:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:06 [INFO] exp_shallowmodel: 
[[  2   0  56   1]
 [  0   0  12   0]
 [  6   0 389   1]
 [  1   0  53   1]]
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ******************** ghome - Round 32 
12/10/2017 02:16:06 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:06 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:06 [INFO] exp_shallowmodel: train time: 0.446s
12/10/2017 02:16:06 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:06 [INFO] exp_shallowmodel: accuracy:   0.761
12/10/2017 02:16:06 [INFO] exp_shallowmodel: f1_score:   0.267
12/10/2017 02:16:06 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:06 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.46      0.10      0.17        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.87       396
          R       0.25      0.02      0.03        55

avg / total       0.66      0.76      0.68       522

12/10/2017 02:16:06 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:06 [INFO] exp_shallowmodel: 
[[  6   0  52   1]
 [  1   0  11   0]
 [  4   0 390   2]
 [  2   0  52   1]]
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ******************** ghome - Round 33 
12/10/2017 02:16:06 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:06 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:06 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:06 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:06 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:06 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:07 [INFO] exp_shallowmodel: train time: 0.469s
12/10/2017 02:16:07 [INFO] exp_shallowmodel: test time:  0.000s
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
12/10/2017 02:16:07 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:16:07 [INFO] exp_shallowmodel: f1_score:   0.248
12/10/2017 02:16:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.25      0.04      0.06        55

avg / total       0.64      0.76      0.67       522

12/10/2017 02:16:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:07 [INFO] exp_shallowmodel: 
[[  2   0  54   3]
 [  0   0  10   2]
 [  3   0 392   1]
 [  3   0  50   2]]
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ******************** ghome - Round 34 
12/10/2017 02:16:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:07 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:07 [INFO] exp_shallowmodel: train time: 0.515s
12/10/2017 02:16:07 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:07 [INFO] exp_shallowmodel: accuracy:   0.736
12/10/2017 02:16:07 [INFO] exp_shallowmodel: f1_score:   0.242
12/10/2017 02:16:07 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:07 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.09      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.76      0.96      0.85       396
          R       0.27      0.05      0.09        55

avg / total       0.62      0.74      0.66       522

12/10/2017 02:16:07 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:07 [INFO] exp_shallowmodel: 
[[  1   0  57   1]
 [  0   0  12   0]
 [  8   1 380   7]
 [  2   0  50   3]]
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ******************** ghome - Round 35 
12/10/2017 02:16:07 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:07 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:07 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:07 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:07 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:07 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:08 [INFO] exp_shallowmodel: train time: 0.461s
12/10/2017 02:16:08 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:08 [INFO] exp_shallowmodel: accuracy:   0.762
12/10/2017 02:16:08 [INFO] exp_shallowmodel: f1_score:   0.278
12/10/2017 02:16:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.20      0.02      0.03        59
          C       0.50      0.08      0.14        12
          F       0.77      0.99      0.87       396
          R       0.40      0.04      0.07        55

avg / total       0.66      0.76      0.67       522

12/10/2017 02:16:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:08 [INFO] exp_shallowmodel: 
[[  1   0  56   2]
 [  2   1   9   0]
 [  0   1 394   1]
 [  2   0  51   2]]
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ******************** ghome - Round 36 
12/10/2017 02:16:08 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:08 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:08 [INFO] exp_shallowmodel: train time: 0.444s
12/10/2017 02:16:08 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:08 [INFO] exp_shallowmodel: accuracy:   0.774
12/10/2017 02:16:08 [INFO] exp_shallowmodel: f1_score:   0.294
12/10/2017 02:16:08 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:08 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.64      0.12      0.20        59
          C       0.00      0.00      0.00        12
          F       0.78      0.99      0.87       396
          R       0.75      0.05      0.10        55

avg / total       0.74      0.77      0.70       522

12/10/2017 02:16:08 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:08 [INFO] exp_shallowmodel: 
[[  7   0  51   1]
 [  0   0  12   0]
 [  2   0 394   0]
 [  2   0  50   3]]
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ******************** ghome - Round 37 
12/10/2017 02:16:08 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:08 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:08 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:08 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:08 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:08 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:09 [INFO] exp_shallowmodel: train time: 0.627s
12/10/2017 02:16:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:09 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:16:09 [INFO] exp_shallowmodel: f1_score:   0.267
12/10/2017 02:16:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.25      0.03      0.06        59
          C       0.50      0.08      0.14        12
          F       0.77      0.99      0.86       396
          R       0.00      0.00      0.00        55

avg / total       0.62      0.75      0.67       522

12/10/2017 02:16:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:09 [INFO] exp_shallowmodel: 
[[  2   1  55   1]
 [  0   1  11   0]
 [  3   0 391   2]
 [  3   0  52   0]]
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ******************** ghome - Round 38 
12/10/2017 02:16:09 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:09 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:09 [INFO] exp_shallowmodel: train time: 0.360s
12/10/2017 02:16:09 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:09 [INFO] exp_shallowmodel: accuracy:   0.757
12/10/2017 02:16:09 [INFO] exp_shallowmodel: f1_score:   0.254
12/10/2017 02:16:09 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:09 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.30      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.33      0.04      0.07        55

avg / total       0.65      0.76      0.67       522

12/10/2017 02:16:09 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:09 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  1   0  10   1]
 [  4   0 390   2]
 [  2   0  51   2]]
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ******************** ghome - Round 39 
12/10/2017 02:16:09 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:16:09 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:09 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:09 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:09 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:09 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:10 [INFO] exp_shallowmodel: train time: 0.431s
12/10/2017 02:16:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:10 [INFO] exp_shallowmodel: accuracy:   0.738
12/10/2017 02:16:10 [INFO] exp_shallowmodel: f1_score:   0.281
12/10/2017 02:16:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.33      0.03      0.06        64
          C       1.00      0.07      0.13        14
          F       0.75      0.98      0.85       402
          R       0.30      0.05      0.08        63

avg / total       0.66      0.74      0.65       543

12/10/2017 02:16:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:10 [INFO] exp_shallowmodel: 
[[  2   0  58   4]
 [  0   1  13   0]
 [  4   0 395   3]
 [  0   0  60   3]]
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ******************** ghome - Round 40 
12/10/2017 02:16:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:10 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:10 [INFO] exp_shallowmodel: train time: 0.374s
12/10/2017 02:16:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:10 [INFO] exp_shallowmodel: accuracy:   0.751
12/10/2017 02:16:10 [INFO] exp_shallowmodel: f1_score:   0.280
12/10/2017 02:16:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.07      0.11        59
          C       0.50      0.08      0.14        12
          F       0.77      0.98      0.86       396
          R       0.00      0.00      0.00        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:16:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:10 [INFO] exp_shallowmodel: 
[[  4   1  51   3]
 [  0   1  10   1]
 [  5   0 387   4]
 [  2   0  53   0]]
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ******************** ghome - Round 41 
12/10/2017 02:16:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:10 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:10 [INFO] exp_shallowmodel: train time: 0.493s
12/10/2017 02:16:10 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:10 [INFO] exp_shallowmodel: accuracy:   0.753
12/10/2017 02:16:10 [INFO] exp_shallowmodel: f1_score:   0.260
12/10/2017 02:16:10 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:10 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.07      0.11        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.22      0.04      0.06        55

avg / total       0.65      0.75      0.67       522

12/10/2017 02:16:10 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:10 [INFO] exp_shallowmodel: 
[[  4   0  54   1]
 [  0   0  11   1]
 [  4   0 387   5]
 [  3   0  50   2]]
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ******************** ghome - Round 42 
12/10/2017 02:16:10 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:10 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:10 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:10 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:10 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:10 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:11 [INFO] exp_shallowmodel: train time: 0.331s
12/10/2017 02:16:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:11 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:16:11 [INFO] exp_shallowmodel: f1_score:   0.262
12/10/2017 02:16:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.10      0.02      0.03        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.86       396
          R       0.50      0.09      0.15        55

avg / total       0.65      0.75      0.68       522

12/10/2017 02:16:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:11 [INFO] exp_shallowmodel: 
[[  1   0  57   1]
 [  3   0   9   0]
 [  4   0 388   4]
 [  2   0  48   5]]
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ******************** ghome - Round 43 
12/10/2017 02:16:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:11 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:11 [INFO] exp_shallowmodel: train time: 0.409s
12/10/2017 02:16:11 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:11 [INFO] exp_shallowmodel: accuracy:   0.759
12/10/2017 02:16:11 [INFO] exp_shallowmodel: f1_score:   0.247
12/10/2017 02:16:11 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:11 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.38      0.05      0.09        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.87       396
          R       0.25      0.02      0.03        55

avg / total       0.65      0.76      0.67       522

12/10/2017 02:16:11 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:11 [INFO] exp_shallowmodel: 
[[  3   0  55   1]
 [  2   0  10   0]
 [  2   0 392   2]
 [  1   0  53   1]]
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ******************** ghome - Round 44 
12/10/2017 02:16:11 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:11 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:11 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:11 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:11 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:11 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:12 [INFO] exp_shallowmodel: train time: 0.381s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:16:12 [INFO] exp_shallowmodel: f1_score:   0.280
12/10/2017 02:16:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.36      0.07      0.11        59
          C       0.50      0.08      0.14        12
          F       0.77      0.98      0.86       396
          R       0.00      0.00      0.00        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:16:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:12 [INFO] exp_shallowmodel: 
[[  4   1  52   2]
 [  0   1  11   0]
 [  5   0 389   2]
 [  2   0  53   0]]
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ******************** ghome - Round 45 
12/10/2017 02:16:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:12 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:12 [INFO] exp_shallowmodel: train time: 0.382s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: accuracy:   0.755
12/10/2017 02:16:12 [INFO] exp_shallowmodel: f1_score:   0.239
12/10/2017 02:16:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.22      0.03      0.06        59
          C       0.00      0.00      0.00        12
          F       0.77      0.99      0.86       396
          R       0.33      0.02      0.03        55

avg / total       0.64      0.75      0.67       522

12/10/2017 02:16:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:12 [INFO] exp_shallowmodel: 
[[  2   0  55   2]
 [  1   0  11   0]
 [  4   1 391   0]
 [  2   0  52   1]]
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ******************** ghome - Round 46 
12/10/2017 02:16:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:12 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:12 [INFO] exp_shallowmodel: train time: 0.502s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:12 [INFO] exp_shallowmodel: accuracy:   0.764
12/10/2017 02:16:12 [INFO] exp_shallowmodel: f1_score:   0.281
12/10/2017 02:16:12 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:12 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.62      0.14      0.22        59
          C       0.00      0.00      0.00        12
          F       0.77      0.98      0.87       396
          R       0.33      0.02      0.03        55

avg / total       0.69      0.76      0.69       522

12/10/2017 02:16:12 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:12 [INFO] exp_shallowmodel: 
[[  8   0  51   0]
 [  0   0  12   0]
 [  4   0 390   2]
 [  1   2  51   1]]
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ******************** ghome - Round 47 
12/10/2017 02:16:12 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:12 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:12 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:12 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:12 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:12 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:13 [INFO] exp_shallowmodel: train time: 0.494s
12/10/2017 02:16:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:13 [INFO] exp_shallowmodel: accuracy:   0.749
12/10/2017 02:16:13 [INFO] exp_shallowmodel: f1_score:   0.231
12/10/2017 02:16:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.00      0.00      0.00        59
          C       0.00      0.00      0.00        12
          F       0.76      0.98      0.86       396
          R       0.29      0.04      0.06        55

avg / total       0.61      0.75      0.66       522

12/10/2017 02:16:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:13 [INFO] exp_shallowmodel: 
[[  0   0  57   2]
 [  0   0  12   0]
 [  4   0 389   3]
 [  1   0  52   2]]
12/10/2017 02:16:13 [INFO] exp_shallowmodel: ******************** ghome - Round 48 
12/10/2017 02:16:13 [INFO] exp_shallowmodel: #(data) = 4197
12/10/2017 02:16:13 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:13 [INFO] exp_shallowmodel: train time: 0.418s
12/10/2017 02:16:13 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:13 [INFO] exp_shallowmodel: accuracy:   0.776
12/10/2017 02:16:13 [INFO] exp_shallowmodel: f1_score:   0.335
12/10/2017 02:16:13 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:13 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.75      0.10      0.18        59
          C       1.00      0.08      0.15        12
          F       0.77      0.99      0.87       396
          R       1.00      0.07      0.14        55

avg / total       0.80      0.78      0.70       522

12/10/2017 02:16:13 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:13 [INFO] exp_shallowmodel: 
[[  6   0  53   0]
 [  0   1  11   0]
 [  2   0 394   0]
 [  0   0  51   4]]
12/10/2017 02:16:13 [INFO] exp_shallowmodel: ******************** ghome - Round 49 
12/10/2017 02:16:13 [INFO] exp_shallowmodel: #(data) = 4176
12/10/2017 02:16:13 [INFO] exp_shallowmodel: #(feature) = 47
12/10/2017 02:16:13 [INFO] exp_shallowmodel: ================================================================================
12/10/2017 02:16:13 [INFO] exp_shallowmodel: LR.pen=l1.C=2.000000
12/10/2017 02:16:13 [INFO] exp_shallowmodel: ________________________________________________________________________________
12/10/2017 02:16:13 [INFO] exp_shallowmodel: Training: 
12/10/2017 02:16:13 [INFO] exp_shallowmodel: LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
12/10/2017 02:16:14 [INFO] exp_shallowmodel: train time: 0.438s
12/10/2017 02:16:14 [INFO] exp_shallowmodel: test time:  0.000s
12/10/2017 02:16:14 [INFO] exp_shallowmodel: accuracy:   0.742
12/10/2017 02:16:14 [INFO] exp_shallowmodel: f1_score:   0.249
12/10/2017 02:16:14 [INFO] exp_shallowmodel: classification report:
12/10/2017 02:16:14 [INFO] exp_shallowmodel:              precision    recall  f1-score   support

          A       0.40      0.03      0.06        64
          C       0.00      0.00      0.00        14
          F       0.75      0.99      0.85       402
          R       0.43      0.05      0.09        63

avg / total       0.65      0.74      0.65       543

12/10/2017 02:16:14 [INFO] exp_shallowmodel: confusion matrix:
12/10/2017 02:16:14 [INFO] exp_shallowmodel: 
[[  2   0  61   1]
 [  2   0  12   0]
 [  0   1 398   3]
 [  1   0  59   3]]
Done: 20171210-021615
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/ihome/pbrusilosky/rum20/.conda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
